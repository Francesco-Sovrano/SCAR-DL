[
	{"string": "This is common in software design when the UI is assigned to computer programmers or engineers without specialized experience or training in UI design (Paap and Cooke, 1997).", "probabilities": [0.24911902844905853, 0.750880777835846, 2.108850196691492e-07], "prediction": "method"},
	{"string": "The most related items intersect first, and the least related last (Cooke, 1999).", "probabilities": [1.0, 2.368715446010583e-09, 3.931901559894868e-08], "prediction": "background"},
	{"string": "In this study, participants performed a hierarchical sort of the 44 declutter menu items, and the resulting data matrix was submitted to a complete hierarchical cluster analysis (HCA) (Romesburg, 2004).", "probabilities": [1.8514580006012693e-05, 0.9999815225601196, 9.948712964558126e-09], "prediction": "method"},
	{"string": "Card sorting software, xSort (Arroz, 2008) was used to collect data.", "probabilities": [1.554895447952731e-07, 0.9999998807907104, 7.496668175122068e-09], "prediction": "method"},
	{"string": "The concept of using PA to analyze SD evaluation data was previously proposed by Yamamoto et al. (2005).", "probabilities": [0.00033510944922454655, 0.9996647834777832, 6.274361652458538e-08], "prediction": "method"},
	{"string": "The PA approach for selecting a subset of variables was introduced by Krzanowski (1987), and combined with PCA to process sensory profiling data.", "probabilities": [2.5371705305587966e-06, 0.9999974966049194, 1.4976259121723956e-10], "prediction": "method"},
	{"string": "In chemometrics, PA has also been used to select informative variables and determine the correlation among spectroscopic measurement data sets (Andrade et al., 2004).", "probabilities": [4.114450803172076e-06, 0.9999958276748657, 1.8396083267813168e-10], "prediction": "method"},
	{"string": "For factor analyzing SD data, both the concepts and the scales must be as diverse and numerous as possible (Bynner and Coxhead, 1979).", "probabilities": [0.9999932050704956, 6.497408321592957e-06, 1.993513478737441e-07], "prediction": "background"},
	{"string": "The loss of information caused by the deletion of some variables can be measured by the residual sum of squared differences (RSSDs), d, between the two data matrices W and Z. The RSSD can be calculated as follows (Krzanowski, 1987", "probabilities": [0.0019511065911501646, 0.9980477094650269, 1.1614367849688279e-06], "prediction": "method"},
	{"string": "For a typical KE process, Nagamachi (1993) suggested the following procedures: (1) select the object; (2) collect adjectives; (3) understand the structural meanings of the adjectives; (4) prepare slides or samples of the materials; (5) evaluate emotions; (6) do statistical analysis; and (7) build an expert system.", "probabilities": [0.00032257576822303236, 0.9996774196624756, 1.8331784978897758e-09], "prediction": "method"},
	{"string": "In this study, 22 pairwise adjectives (Table 1), adopted from the research of Hsu et al. (2000), were used as the initial set of affective dimensions.", "probabilities": [1.553051873770528e-07, 0.9999998807907104, 4.680918319621696e-09], "prediction": "method"},
	{"string": "According to the principle provided by Bynner and Coxhead (1979), the selected product samples and adjectives must be as diverse as possible.", "probabilities": [0.9998267292976379, 0.0001228837063536048, 5.037109076511115e-05], "prediction": "background"},
	{"string": "This strategy is similar to the technique that combines FA and CA, which was adopted in the study by Choi and Jun (2007).", "probabilities": [6.966044452383358e-08, 0.006783946417272091, 0.9932159781455994], "prediction": "result"},
	{"string": "In the study by Hsiao and Chen (2006), FA was used to examine the affective dimensions applied to different product types and sizes.", "probabilities": [9.61802652454935e-06, 0.9999903440475464, 3.6242550294218745e-08], "prediction": "method"},
	{"string": "There is the potential that the teams could spend as much time creating good metadata as they do creating the dataset itself (Goodchild, 2007).", "probabilities": [0.9999998807907104, 1.0221028645673869e-07, 2.509437990738661e-08], "prediction": "background"},
	{"string": "This viewpoint contrasts with a requirement for high-quality metadata (Sboui et al., 2009).", "probabilities": [0.9999990463256836, 1.6940777669560703e-08, 9.310948030361033e-07], "prediction": "background"},
	{"string": "Unlike for SECOA, such metadata is usually created by a dedicated team of professionals (Mathes, 2004 in Kalantari et al., 2010).", "probabilities": [0.9999853372573853, 1.402837733621709e-05, 6.076256795495283e-07], "prediction": "background"},
	{"string": "A configurable system was therefore developed to support this approach (for further details of the general configuration approach, see Ellul et al., 2009).", "probabilities": [0.14863601326942444, 0.8513627052307129, 1.1715862910932628e-06], "prediction": "method"},
	{"string": "They are therefore useful in providing guidance for the development of the metadata system, and the selected fields listed below represent a balance between the conflicting usability requirements of CSC   i.e. minimise their metadata creation effort in order to ensure good quality metadata (Sboui et al., 2009) and WPL   who ideally require full information about the datasets they are receiving.a.Title   a short title (around 5 words) that describes the datasetb.Abstract   a short description of the content of the dataset, and any additional information about the dataset.", "probabilities": [0.9993784427642822, 0.0006212377920746803, 2.1860124377326429e-07], "prediction": "background"},
	{"string": "Although ideally existing metadata management tools (FGDC, 2010) would be utilised for the SECOA project, to minimise development effort, this option has been discounted for the present moment.", "probabilities": [0.08485788106918335, 0.9151400327682495, 2.0904992652504006e-06], "prediction": "method"},
	{"string": "Thus both internal quality issues (producer-driven) and external quality issues    fitness for purpose  (Devillers et al., 2005) are addressed.", "probabilities": [1.0, 8.916773097666919e-09, 2.736545745563035e-08], "prediction": "background"},
	{"string": "Tracking the metadata viewed and datasets downloaded provides an entry point into a ratings system, and addresses, in the context of a multi-location project, a requirement to study the users as they make use of the metadata (Poore and Wolf, 2010).", "probabilities": [0.9944236874580383, 0.005574922077357769, 1.3787374655294116e-06], "prediction": "background"},
	{"string": "In terms of metadata usability, it is important to also take into account the complexity of such standards-based metadata (Poore and Wolf, 2010)   there are a total of 30 elements in Table 1, although not all of these are mandatory.", "probabilities": [0.999996542930603, 3.4466972920199623e-06, 2.092527928709842e-08], "prediction": "background"},
	{"string": "It has been set up to examine the effects of human mobility on urban settlement growth and in fragile environments   in particular the potential impact of sea level rise (SECOA, 2011a).", "probabilities": [0.999997615814209, 2.435388978483388e-06, 1.3707864843226503e-09], "prediction": "background"},
	{"string": "In general,  the purpose of [ ] metadata is to facilitate the interpretation of data  (Sboui et al., 2009).", "probabilities": [0.9999998807907104, 1.0579360498752521e-08, 6.176824030035277e-08], "prediction": "background"},
	{"string": "A detailed description of the INSPIRE can be found at INSPIRE (2011a).", "probabilities": [0.9999939203262329, 4.665759547606285e-07, 5.640029939968372e-06], "prediction": "background"},
	{"string": "INSPIRE metadata is based on a widely used international metadata standard from the International Standards Organisation   namely ISO 19115 (INSPIRE, 2011b).", "probabilities": [6.6038469412887935e-06, 0.9999934434890747, 2.5887127996782056e-09], "prediction": "method"},
	{"string": "Metadata themes within this standard include temporal accuracy, thematic accuracy (is something that is marked as a building on the map actually a building on the ground), logical consistency (the degree to which the contents of the dataset follow the specification rules), completeness (are there gaps or missing data), positional accuracy, and lineage (how the dataset was acquired or compiled) (Goodchild, 2007).", "probabilities": [0.999980092048645, 1.9317822079756297e-05, 6.153210847514856e-07], "prediction": "background"},
	{"string": "Table 1 extracts a number key elements from the INSIPRE metadata standard (Walker, 2009).", "probabilities": [0.9999886751174927, 1.1044932762160897e-05, 2.0788041865671403e-07], "prediction": "background"},
	{"string": "A dashboard approach, where results are presented as a series of graphs, progress bars, speed dials and so forth (Devillers et al. 2002; in Devillers et al., 2005), could be utilised to report results of this analysis, building on the existing graphs used to report metadata capture tasks undertaken by each team.", "probabilities": [0.029143869876861572, 0.9678146243095398, 0.0030414569191634655], "prediction": "method"},
	{"string": "Metadata can be evaluated using multiple approaches   firstly, by polling the users as to what they find useful and what is not useful at all, and secondly and more formally, by using criteria such as those listed in Sboui et al. (2009)   which include examining how usable the language in the metadata is, how complete the metadata is and how much faith users have in the provided metadata.", "probabilities": [0.1458258181810379, 0.8541740775108337, 1.1726419302249269e-07], "prediction": "method"},
	{"string": "Additionally, with the growth of Volunteered Geographic Information (Goodchild, 2007b)   where non-specialist users contribute spatial data   metadata creation is no longer the purview of the few expert data producers.", "probabilities": [1.0, 1.765657486885175e-08, 3.5526852570910705e-08], "prediction": "background"},
	{"string": " Many view its generation as monotonous and time-consuming  (Batcheller, 2008) and labour intensive; metadata often takes low priority in relation to other activities and is seen as a  necessary evil  (ibid.).", "probabilities": [0.9999967813491821, 3.1524273254035506e-06, 1.465608789885664e-07], "prediction": "background"},
	{"string": "Poore and Wolf (2010) additionally note that issues relating to semantics and ontologies are not handled by current standards   this being of particular importance to SECOA given the multi-national research team, with many members having English (the official language of the project) as a second or third language.", "probabilities": [0.9999992847442627, 6.468442279583542e-07, 8.322290057094506e-08], "prediction": "background"},
	{"string": "Such descriptions should be aimed at non-expert users (an issue also raised by Timkpf et al. 1996; Frank, 1998 and Harvey, 1998 in Devillers et al., 2005).", "probabilities": [0.9999998807907104, 6.269632990552054e-08, 5.261696145453243e-08], "prediction": "background"},
	{"string": "This could include information providing a simple description of data quality or details of the impact that the dataset could have on the outcome of any analysis they wish to perform (Goodchild, 2007).", "probabilities": [0.9999966621398926, 3.337119323987281e-06, 3.20406208231816e-08], "prediction": "background"},
	{"string": "In short, the definition provided by Kim in 1999 that  metadata allows a producer to fully describe a dataset so that users can understand the assumptions and limitations and evaluate the dataset''s applicability for their intended use  (Kim, 1999) is now deemed to be not necessarily correct.", "probabilities": [0.9999998807907104, 8.525960737415517e-08, 9.465206396441772e-09], "prediction": "background"},
	{"string": "Even with this additional information, Poore and Wolf (2010) note that metadata can never be entirely complete as there are intangible, organisational aspects in the production process that cannot be captured.", "probabilities": [0.9999997615814209, 2.900124229654466e-07, 1.9680165053159726e-08], "prediction": "background"},
	{"string": "Devillers et al. (2005) mention that the reputation of the data producer is important.", "probabilities": [0.9999268054962158, 8.798372732599091e-07, 7.232141797430813e-05], "prediction": "background"},
	{"string": "The element  trust  has been further highlighted as important in the context of usability of geographic information produced by social networks (Bishr and Kuhn, 2007).", "probabilities": [0.999998927116394, 1.0747129408628098e-06, 8.697025322135232e-09], "prediction": "background"},
	{"string": "Brown et al. (2011) develop further the case for focussing on geographic information usability independent of interfaces.", "probabilities": [0.9999990463256836, 3.2261536375699507e-07, 5.444791781883396e-07], "prediction": "background"},
	{"string": "As described by Corbin and Strauss (2008) the aims of qualitative research can vary from description to conceptual ordering, through to theorising.", "probabilities": [0.9999122619628906, 8.691944822203368e-05, 8.259984838332457e-07], "prediction": "background"},
	{"string": "The term  information  is used in this paper to denote a dataset which has meaning added (as for example defined by Devlin, 1999).", "probabilities": [0.0015270378207787871, 0.9984729886054993, 7.770938559303886e-09], "prediction": "method"},
	{"string": "Some examples with more of an emphasis on information usability as distinct from applications and interfaces, though not necessarily applying UCD approaches, are cited by Hunter et al. (2003) such as the long term usability of NASA observational data and the usability of U.S.", "probabilities": [0.9592544436454773, 0.04066407307982445, 8.158028504112735e-05], "prediction": "background"},
	{"string": "In relation to work from NASA on planning earth science data capture, Maiden (2009) points out that the heterogeneous characteristics of spatio-temporal data, including different format types and structures, different states of processing (raw, derived, interpreted etc), data volumes, can lead to usability problems.", "probabilities": [0.9996685981750488, 0.00018239264318253845, 0.0001489145215600729], "prediction": "background"},
	{"string": "For example, Haklay (2010) examined the usability of Code-Point  Open, a dataset providing point locations for GB postcodes which is provided as part of OS OpenData .", "probabilities": [0.9997710585594177, 0.00021852545614819974, 1.0340348126192112e-05], "prediction": "background"},
	{"string": "Looking at the categories identified in this paper, the issues raised by interview participants mainly concern efficiency and effectiveness in the task, with less discussion of elements of satisfaction listed by Hunter et al. (2007) such as certification, legal defensibility, trust.", "probabilities": [0.7098231315612793, 0.2901400327682495, 3.6848145100520924e-05], "prediction": "background"},
	{"string": "Hunter et al. (2007) further organise elements of spatial data usability under the three components of usability as defined by the ISO 9241-11 standard (for Visual Display Terminal ergonomics) and widely used in discussions of usability, namely: efficiency, effectiveness and satisfaction.", "probabilities": [0.136569544672966, 0.8634303212165833, 1.343951936405574e-07], "prediction": "method"},
	{"string": "More recent work based on the source data and taking a grounded theory approach (Brown et al., 2010) is referred to in the conclusions of this paper.", "probabilities": [0.0074404156766831875, 0.9925575256347656, 1.977521606022492e-06], "prediction": "method"},
	{"string": "In the context of evaluating virtual environments, Neale and Nichols (2001) apply Theme Based Content Analysis (TBCA), which involves a stage of theme definition and classification following data collection and collation.", "probabilities": [0.0016207804437726736, 0.9983792304992676, 1.955924666674491e-08], "prediction": "method"},
	{"string": "By way of comparison with human factors investigations in new technology application areas, Neale and Nichols (2001) observe that exploratory formative studies frequently use collection of user centred qualitative data to guide design.", "probabilities": [0.9817634224891663, 4.055816589243477e-06, 0.01823248527944088], "prediction": "background"},
	{"string": "A generic outline for user needs interviews (as for example described by Kuniavsky, 2003) formed the basis of the interview structure, beginning with introductory information about the purpose for the research and general context of use questions followed by more specific focus on the  product idea  (in this case the use of information about geographic/real-world things in the task context), followed by stepping back to wider perspectives on the use context and finally summarising to conclude the interview.", "probabilities": [0.44841548800468445, 0.5515844821929932, 1.2183843267621342e-08], "prediction": "method"},
	{"string": "Hunter et al. (2003) also observe that a dataset''s perceived authoritativeness, validity and reliability can enhance perception of usability in the sense of the user having confidence in the data.", "probabilities": [0.9998698234558105, 0.00010718496923800558, 2.302498251083307e-05], "prediction": "background"},
	{"string": "To an extent the categories identified from interview records align with some of the elements of spatial data usability put forward in discussion by Hunter et al. (2003).", "probabilities": [0.9805701375007629, 0.015508082695305347, 0.0039218030869960785], "prediction": "background"},
	{"string": "Usability with respect to data quality may be considered in terms of the data quality elements identified in the ISO standard for  GeospatialInformation   Quality principles  (ISO, 2002).", "probabilities": [0.9984726309776306, 0.0015098672593012452, 1.7492971892352216e-05], "prediction": "background"},
	{"string": "This section builds on previous work towards identifying elements that contribute to geographic information usability (Harding and Pickering, 2007).", "probabilities": [0.9999971389770508, 2.7962685180682456e-06, 1.2806833638023818e-07], "prediction": "background"},
	{"string": "According to surveys, the average employee spends between one and two hours each day using the internet for social networking or online browsing (wiseGEEK, 2013).", "probabilities": [0.9996556043624878, 0.0003443768073339015, 1.92683358157808e-09], "prediction": "background"},
	{"string": "Researchers such as Enid Mumford (1987) were among the first to show that even when the underlying technology was adequate, a failure to address the social needs of the organisation could result in an unsatisfactory outcome.", "probabilities": [0.9999967813491821, 2.558770802352228e-06, 6.986095968386508e-07], "prediction": "background"},
	{"string": "Workflow software is designed to give structure and order to the unfolding of work activities, routing documents through the organisation and allowing users to gain an overview of the work process they are part of (Benyon, 2010a).", "probabilities": [0.5021844506263733, 0.4978155195713043, 2.1103184977278033e-08], "prediction": "background"},
	{"string": "Providing feedback on work performance has long been known to have a positive benefit on worker productivity (Matsui and Okada, 1983).", "probabilities": [0.999981164932251, 1.8677215848583728e-05, 8.874260970515024e-08], "prediction": "background"},
	{"string": "While such developments can achieve great benefits it also creates problems of available storage space, ensuring data security, and protecting privacy as the information multiplies and is shared ever more widely around the world (Economist, 2010).", "probabilities": [0.9999996423721313, 3.7699743415942066e-07, 1.6938493274665234e-08], "prediction": "background"},
	{"string": "Such temporal constraints are given using conjunctions of order constraints of the form x1OPx2, where OP is an arithmetic comparison operator, such as <,  , etc. Hurtado and Vaisman [39] call the resulting pairs (G, )c-temporal graphs.", "probabilities": [8.654576959088445e-06, 0.9999912977218628, 5.329360064365574e-09], "prediction": "method"},
	{"string": "Thus, we have the expected increase in data complexity given that the data complexity of evaluating any SPARQL graph pattern over RDF graphs can be done in LOGSPACE [75].", "probabilities": [0.6101497411727905, 0.38763365149497986, 0.0022167200222611427], "prediction": "background"},
	{"string": "Since q is fixed, the graph pattern P is also fixed, therefore the space becomes logarithmic in the size of the database D.Step 3 above can also be computed in LOGSPACE using the evaluation procedure EVAL presented by P rez et al. [75].", "probabilities": [5.335510167014945e-08, 0.9999996423721313, 3.738920781870547e-07], "prediction": "method"},
	{"string": "Therefore, when used in RDFi, this language allows us to extend RDF with the ability to represent  marked nulls  as in classical relational databases [41].", "probabilities": [0.9947807192802429, 0.005219119600951672, 1.5364285843588732e-07], "prediction": "background"},
	{"string": "Thus, they are reminiscent of conditional tuples in the conditional table model of Grahne [30].", "probabilities": [0.9817641377449036, 0.00024713482707738876, 0.017988678067922592], "prediction": "background"},
	{"string": "Thus, she might wish to find all values that certainly satisfy some qualification (this is the well-known notion of certain answers in incomplete databases [30]).", "probabilities": [0.9999992847442627, 1.3254741304535855e-07, 5.905810098738584e-07], "prediction": "background"},
	{"string": "PelletSpatial [83] is a hybrid spatial reasoner that provides RCC-8 and OWL 2 reasoning and querying capabilities.", "probabilities": [0.9999990463256836, 8.521600420863251e-07, 1.0746592238319863e-07], "prediction": "background"},
	{"string": "Cal  et al. [16] proposed the extension Datalog  as a unified framework for query answering and reasoning with incomplete data.", "probabilities": [0.9999980926513672, 1.964000091447815e-07, 1.6451053852506448e-06], "prediction": "background"},
	{"string": "RemarkThe concepts of Q-equivalence (Definition 8.4), representation systems (Definition 8.5), and coinitiality (Definition 8.6) were originally defined by Imieli ski and Lipski [41] for incomplete relational databases.", "probabilities": [0.003430891316384077, 0.9965671300888062, 1.8932071270683082e-06], "prediction": "method"},
	{"string": "In the same context, Grahne [30] refers to representation systems as weak query systems and to coinitiality as +-equivalence.", "probabilities": [0.9999936819076538, 2.5165223860312835e-07, 6.12020812695846e-06], "prediction": "background"},
	{"string": "The stRDF model extends RDF with the ability to represent geometries over Qk that change over time following the paradigm of constraint databases [44].", "probabilities": [0.05896430090069771, 0.941030740737915, 4.980948233423987e-06], "prediction": "method"},
	{"string": "The above set of triples is a graph in the model stRDF of Koubarakis and Kyzirakos [49].", "probabilities": [0.00014957593521103263, 0.9276458621025085, 0.07220445573329926], "prediction": "method"},
	{"string": "If we examine the database of Example 2.1, we can see that the answer should be conditional[41].", "probabilities": [0.9955586194992065, 0.004132384434342384, 0.00030890991911292076], "prediction": "background"},
	{"string": "The exact ranges are given in [48] and depend on the maximum absolute value of the constants appearing in formula  . Each value in these ranges takes up only polynomial amount of space with respect to the database size and the maximum absolute value of the constants of  , thus the guessing step can be done in polynomial time.", "probabilities": [0.9999384880065918, 6.142683560028672e-05, 1.0441598874422198e-07], "prediction": "background"},
	{"string": "Using Lemma 7.3 and Theorem 8.5 of Koubarakis [48], and Theorem 9.9 of our work, we can restrict the values over which the e-literals range only to a finite number of integers.", "probabilities": [0.9943959712982178, 0.005601051729172468, 3.0025519208720652e-06], "prediction": "background"},
	{"string": "The notions of domain and restriction of an e-mapping as well as the notion of compatibility of two e-mappings are defined as for mappings in the obvious way [75] (we also use the same notation for them).", "probabilities": [0.0010647723684087396, 0.998933732509613, 1.5412450693474966e-06], "prediction": "method"},
	{"string": "Consequently, M  should accept  .We stress here that Li et al. [52] represent polygonal constants in V-representation, i.e., they use points instead of half-spaces like we have done in this work.", "probabilities": [0.9998891353607178, 4.089858339284547e-05, 6.995257717790082e-05], "prediction": "background"},
	{"string": "As we have already noted in the introduction, the kinds of incomplete information we study here for RDF have not been studied in [10]; only the issue of OWA has been explored there.", "probabilities": [0.989544689655304, 0.00957530364394188, 0.0008800087962299585], "prediction": "background"},
	{"string": "Then, theory Th(MdePCL) is a sub-theory of Th(R,+,<), the theory of real numbers with addition and order [77].", "probabilities": [0.9999301433563232, 4.039246414322406e-05, 2.949246481875889e-05], "prediction": "background"},
	{"string": "Further, we assume the existence of a datatype map M[37] and distinguish a set of datatypes A from M for which e-literals are allowed.", "probabilities": [0.00875503197312355, 0.9912376999855042, 7.182254194049165e-06], "prediction": "method"},
	{"string": "In incomplete relational databases [41], Rep is a semantic function: it maps a table (a syntactic construct) to a set of relational instances (i.e., a set of possible worlds, a semantic construct).", "probabilities": [0.9999998807907104, 1.3801455089890169e-08, 6.921383999269892e-08], "prediction": "background"},
	{"string": "Proofa) and b) The results are trivial extensions of relevant results by Arenas and P rez [10].c) Consider a query q=(E,P) QAUFC and let G,H be two RDF graphs such that G H.", "probabilities": [0.00029833230655640364, 2.7407455490902066e-05, 0.9996743202209473], "prediction": "result"},
	{"string": "Definition 6.18P rez et al. [74]A SELECT query is a pair (W,P) where W is a set of variables from the set V and P is a graph pattern.", "probabilities": [0.9999939203262329, 1.5384839002763329e-07, 5.984561539662536e-06], "prediction": "background"},
	{"string": "The operation of left-outer join is defined as in the standard case [75]:  1 2=( 1 2) ( 1 2).", "probabilities": [0.9999896287918091, 1.011614494927926e-05, 2.967767329664639e-07], "prediction": "background"},
	{"string": "Regarding this last item, there is already a related line of research on querying incomplete graph data [13].", "probabilities": [0.9997825026512146, 0.00017050963651854545, 4.697236727224663e-05], "prediction": "background"},
	{"string": "Our results are summarized in Table 1 and show that the data complexity of the certainty problem for RDFi and this class of queries increases from LOGSPACE1 (the upper bound for queries from this class over RDF graphs [75]) to coNP-complete for all of the considered constraint languages.", "probabilities": [0.19003446400165558, 0.001777807716280222, 0.80818772315979], "prediction": "result"},
	{"string": "The problem of knowledge translation was addressed in [13] with the goal of formalizing the task of reusing/sharing existing encoded knowledge in the process of the development of new intelligent systems.", "probabilities": [1.875756061053835e-05, 0.9999812841415405, 5.770905975310825e-11], "prediction": "method"},
	{"string": "In particular, the problem of data exchange with incomplete source data was studied in [25], where an incomplete specification is understood as an object with (possibly infinitely) many interpretations.", "probabilities": [0.9993556141853333, 0.0006429462227970362, 1.4457764336839318e-06], "prediction": "background"},
	{"string": "In the seminal article [16], the data exchange problem was defined as the problem of transforming data structured under a source schema into data structured under a target schema, given a mapping specifying how to translate data from the source to the target schema.", "probabilities": [0.9999798536300659, 2.004203815886285e-05, 1.3032985179961543e-07], "prediction": "background"},
	{"string": "On the other hand, a target instance can be incomplete and a source instance can have many different solutions, as incomplete information can be introduced by the mapping layer (see also [22]).", "probabilities": [0.9999995231628418, 2.264223581960323e-07, 2.067580595621621e-07], "prediction": "background"},
	{"string": "It is well known that homomorphisms preserve answers to UCQs [57], in particular, if uni(K2) is  -homomorphically embeddable into uni(K1), then K1  -entails K2.", "probabilities": [0.999997615814209, 1.3442422641674057e-07, 2.2523363440996036e-06], "prediction": "background"},
	{"string": "To do so, we make use of infinite reachability games on graphs [62].", "probabilities": [7.050293061183766e-05, 0.9999295473098755, 8.533913131714144e-09], "prediction": "method"},
	{"string": "The general knowledge exchange framework proposed in [25] considers the case where the source is a KB as opposed to a relational database.", "probabilities": [0.9999980926513672, 5.295497658153181e-07, 1.3800813576381188e-06], "prediction": "background"},
	{"string": "Hence, the reduction provides a lower bound for data complexity [64].", "probabilities": [0.9999990463256836, 2.433008283730942e-08, 9.634952675696695e-07], "prediction": "background"},
	{"string": "Our knowledge base implements such a mechanism [28]: when the robot detects that a new human has appeared, it initialises a new independent knowledge model (an ontology) for this human agent.", "probabilities": [0.9999756813049316, 2.425618004053831e-05, 1.344378119938483e-07], "prediction": "background"},
	{"string": "In the field of cognitive architectures, the Soar architecture [51] is one of those that try to reproduce a human-like memory organisation.", "probabilities": [0.9999819993972778, 1.614550819795113e-05, 1.8762162881102995e-06], "prediction": "background"},
	{"string": "We have studied a prototypical example of semantic disambiguation in [17] with the children''s  spygame : two players are facing each other with a set of random objects in-between, one player mentally choose one object, and the other player has to guess the object by asking closed questions like Is your object small or large?", "probabilities": [0.9984862208366394, 0.001498397090472281, 1.53071123349946e-05], "prediction": "background"},
	{"string": "As put by Woolridge [27], BDI architectures are primarily focused on practical reasoning, i.e. the process of deciding, step by step, which action to perform to reach a goal.", "probabilities": [0.9973884224891663, 0.002611348871141672, 2.683315472040704e-07], "prediction": "background"},
	{"string": "Besides, the robot is able to compute an estimate of the effort needed by an agent to reach an object [73].", "probabilities": [0.995518684387207, 0.004481243900954723, 4.0926444455635647e-08], "prediction": "background"},
	{"string": "We focus on a specific class of interactions: human robot collaborative task achievement [1] supported by multi-modal and situated communication.", "probabilities": [0.9956921935081482, 0.00430784747004509, 2.05528003505151e-08], "prediction": "background"},
	{"string": "This translates into several decisional, planning, representation skills that need to be available to the robot [10].", "probabilities": [1.0, 3.669894965696585e-08, 2.329560100378103e-09], "prediction": "background"},
	{"string": "Due to expressiveness issues, we do not represent the planning domain (i.e., the set of tasks with their pre- and post-conditions) in the knowledge base directly (see appendix B of [81] for the full rationale).", "probabilities": [0.9999719858169556, 2.7912545192521065e-05, 7.188805284386035e-08], "prediction": "background"},
	{"string": "They also provide routines to compute spatial placements for robot and objects that obey constraints related to the interaction, like optimal mutual reachability or optimal visibility [97].", "probabilities": [0.8216885924339294, 0.17831134796142578, 5.642684897111394e-08], "prediction": "background"},
	{"string": "Spark embeds an amodal (as defined by Mavridis and Roy in [55]: the different perceptual modalities are abstracted away into a blended spatial model) geometric model of the environment that serves both as basis for the fusion of the perception modalities and as bridge with the symbolic layer.", "probabilities": [0.9999885559082031, 1.13475471152924e-05, 9.188060090536965e-08], "prediction": "background"},
	{"string": "When the adult requests the child to hand over  the ball , the child is able to correctly identify which ball the adult is referring to (i.e. the one visible from the adult point of view), without asking [63].", "probabilities": [0.9999994039535522, 6.456319852077286e-07, 3.938849957307866e-08], "prediction": "background"},
	{"string": "It is worth emphasising that while memory is commonly associated with the process of forgetting facts after a variable amount of time, it actually covers more mechanisms that are relevant to robotics, like priming (concept pre-activation triggered by a specific context [53]) or reinforcement learning.", "probabilities": [0.9999972581863403, 2.5406977783859475e-06, 2.415243613995699e-07], "prediction": "background"},
	{"string": "This has since been thoroughly studied in robotics and artificial intelligence (Pfeifer and Bongard [104] is one of the reference).", "probabilities": [0.9997650980949402, 0.00019186874851584435, 4.302121669752523e-05], "prediction": "background"},
	{"string": "This is more effective than maintaining a consistent one, either because the (cognitive) cost of switching is lower than remaining with the same perspective, or if the cost is about the same, because the spatial situation may be more easily described from one perspective rather than another [65].", "probabilities": [0.9999998807907104, 1.0395500282811554e-07, 1.7651252903760906e-08], "prediction": "background"},
	{"string": "In [13], the controller is complemented with a framework that allows the robot to estimate the mental state of the human partner, not only related to the environment but also related to the state of goals, plans and actions.", "probabilities": [0.9962543249130249, 0.003745628520846367, 5.7106515072291586e-08], "prediction": "background"},
	{"string": "It has been designed from two requirements: being practical (i.e. covering our experimental needs) and conforming as much as possible to existing standards (specifically, the OpenCyc upper ontology [38]).", "probabilities": [0.008362089283764362, 0.9916141033172607, 2.3814309315639548e-05], "prediction": "method"},
	{"string": "It exposes a json-based RPC API to query the knowledge base [29].", "probabilities": [0.9986163377761841, 0.0013819490559399128, 1.654861534916563e-06], "prediction": "background"},
	{"string": "Alternatives have been proposed (like KnowRob[33]) that interleave RDF with more expressive logic languages like Prolog with however other limitations, like closed-world reasoning.", "probabilities": [0.9860171675682068, 0.013982429169118404, 4.4412973920771037e-07], "prediction": "background"},
	{"string": "Contrary to similar projects like KnowRob [33] that relies on the concept of computables to lazily evaluate/acquire symbolic facts when needed, we have an explicit approach where we greedily compute and assert symbolic statements (like spatial relations between objects, see Section 3.2).", "probabilities": [0.0006517277215607464, 0.004245223943144083, 0.9951030015945435], "prediction": "result"},
	{"string": "A full account of the Dialogs features and the corresponding algorithms is available in [74].", "probabilities": [0.9999949932098389, 3.0562714528059587e-06, 1.8628046518642805e-06], "prediction": "background"},
	{"string": "Shary supports as well such a mechanism [88].", "probabilities": [0.9999984502792358, 8.788737773102184e-07, 6.928542575224128e-07], "prediction": "background"},
	{"string": "The acknowledgment of the importance of these concepts has impacted research in several domains [53].", "probabilities": [1.0, 2.5867667119428006e-08, 4.637235662130479e-08], "prediction": "background"},
	{"string": "One example of the quantification of reputation by Sabater and Sierra [71] relies on equations used to calculate individual reputations based on a database of individual impressions.", "probabilities": [0.0002947839384432882, 0.9997051358222961, 7.561945736256348e-09], "prediction": "method"},
	{"string": "From the theoretical background survey, two dimensions stand out as being intimately related to social power dynamics: motivations and personality [66].", "probabilities": [0.9999998807907104, 2.031724299911275e-08, 8.163070930322647e-08], "prediction": "background"},
	{"string": "Note that although these effects are not our focus, non-immediate effects may occur in the group-level dynamics (e.g., re-evaluation of group membership) and in the norm-level dynamics (e.g., re-evaluation of norm saliency) [36].", "probabilities": [0.9999992847442627, 1.3815116162163577e-08, 6.633979410253232e-07], "prediction": "background"},
	{"string": "Over the past century, much research has been performed, comprising diverse attempts and perspectives, toward an understanding of social power [34].", "probabilities": [0.999984860420227, 1.5139988136070315e-05, 8.311917376602196e-09], "prediction": "background"},
	{"string": "In another widely referenced work, Dhal [20] introduced a different perspective on social power, modeling it based on empirical data concerning its effects.", "probabilities": [0.999991774559021, 7.183835350588197e-06, 1.0631615623424295e-06], "prediction": "background"},
	{"string": "With the exception of rare cases, such as WordNet [6], for which knowledge has been manually encoded, the building of big repositories of knowledge requiring human intervention, and the extended development times this entails, has now become, unfortunately, no longer feasible.", "probabilities": [0.4753902852535248, 0.5246096253395081, 2.63501700459301e-08], "prediction": "method"},
	{"string": "This work is an extension of the conference paper  Two Is Bigger (and Better) Than One: The Wikipedia Bitaxonomy Project  [34].", "probabilities": [0.8859357237815857, 0.0002440887037664652, 0.11382020264863968], "prediction": "background"},
	{"string": "In linear elastic simulations, simplicial meshes (triangle and tetrahedral) can exhibit locking phenomenon [1] with low order basis functions; therefore, non-simplicial meshes (quads and hex) are preferred.", "probabilities": [0.9999978542327881, 1.358447661914397e-06, 8.683367127559904e-07], "prediction": "background"},
	{"string": "If there is an inverted face, apply locally injective mapping of Sch ller etc. [25] to obtain a fold-free mesh.7.If all the faces have positive Jacobian, improve mesh quality using Mesquite software, replace physical patch with the template mesh and update the mesh data structures.", "probabilities": [4.718035143014276e-06, 0.999995231628418, 1.5722874391332908e-10], "prediction": "method"},
	{"string": "Representations are organized collections of associated data elements collected together for specific uses [10].", "probabilities": [0.9999243021011353, 7.563964754808694e-05, 5.679246939394034e-08], "prediction": "background"},
	{"string": "According to the SASIG Guidelines for the Global Automotive Industry,  good product data quality means providing the right data to the right people at the right time [1] .", "probabilities": [0.9998811483383179, 0.00011725622607627884, 1.5036941931612091e-06], "prediction": "background"},
	{"string": "In this context, CAD model quality is a key concept, as the quality of a manufactured product depends on the quality of its design processes, which then depend on the quality of their data [2].", "probabilities": [0.998246431350708, 0.0017534620128571987, 1.0442894904372224e-07], "prediction": "background"},
	{"string": "Although in academic circles, Modeling Quality Testing is considered solved by a number of scholars, it has been reported that the implementation and practical application of these solutions in industrial settings is far from trivial [4].", "probabilities": [0.9642643332481384, 0.03573484718799591, 7.795633791829459e-07], "prediction": "background"},
	{"string": "Product data refers to all data involved in the design and manufacturing of a product [7].", "probabilities": [0.9999386072158813, 6.0987655160715804e-05, 3.7564552712865407e-07], "prediction": "background"},
	{"string": "The strategy to support legacy is durability, which requires compatibility (consistency along time) between CAD data of different versions of the same system [84].", "probabilities": [0.34125715494155884, 0.6585611701011658, 0.00018166867084801197], "prediction": "method"},
	{"string": "In other words, there is a need to convert the trimmed surfaces of B-reps into a form that removes the gaps between adjacent faces and allows a homogeneous representation of shape [32].", "probabilities": [0.999138355255127, 0.0008616680279374123, 2.000569132576402e-08], "prediction": "background"},
	{"string": "Computer generated data produces tessellated meshes, while scanned data produces digitized meshes [35].", "probabilities": [0.6885039806365967, 0.3114856779575348, 1.0327986274205614e-05], "prediction": "background"},
	{"string": "Closed B-Rep and meshed models provide a complete representation of a solid shape, but do not save the details on how the shape was created [37].", "probabilities": [0.8913055062294006, 0.10869279503822327, 1.6656874777254416e-06], "prediction": "background"},
	{"string": "We can classify these limitations through the quality dimensions of consistency and conciseness [115].", "probabilities": [0.24970440566539764, 0.7502943873405457, 1.1278417559879017e-06], "prediction": "method"},
	{"string": "Poorly perceived models require more time to alter [132].", "probabilities": [0.9999972581863403, 1.2870970067524468e-07, 2.6723284918261925e-06], "prediction": "background"},
	{"string": "While structural heterogeneity is the main cause of morphologic errors (and requires the mapping of features that are equivalent but defined with different data structures), the ultimate goal is the  semantic interoperability  of procedural representations, where the term semantic can be broadly defined as the meaning associated with a terminology in a particular context [94].", "probabilities": [0.9999998807907104, 8.251232941347553e-08, 2.0933563771308172e-09], "prediction": "background"},
	{"string": "Researchers Tessier and Wang identified two types of data interoperability incompatibilities in procedural CAD systems: Structural heterogeneity (caused by the use of different data structures; such as a CAD system that defines a fillet by the removed edge and the radius, while other requires the tangent edges instead of the original edge), and semantic heterogeneity (caused by naming and terminology differences, such as a CAD system using the term fillet for a feature that other systems recognize as round) [78].", "probabilities": [0.9523643255233765, 0.04763542860746384, 1.9161389275268448e-07], "prediction": "background"},
	{"string": "Mapping between data structures may be direct, or use a neutral exchange format [9].", "probabilities": [0.9999934434890747, 5.553751634579385e-06, 9.72233578977466e-07], "prediction": "background"},
	{"string": "Most of the solutions in this field are practical, but commercially protected (although some became publicly available [80]).", "probabilities": [0.9999926090240479, 4.2822402974707074e-06, 3.0998992315289797e-06], "prediction": "background"},
	{"string": "Direct translation is advantageous when systems share the same kernel (the geometric engine that stores and organizes the basic geometric shapes and model topologies), as these CAD systems can directly share modeling data recorded in the kernel s native format [46].", "probabilities": [0.9545878767967224, 0.04540146514773369, 1.074850752047496e-05], "prediction": "background"},
	{"string": "Nevertheless, kernel-level data exchange is limited by the different  flavors  developed by manufacturers, which are often protected for commercial reasons [81].", "probabilities": [0.9999998807907104, 1.5636661032658594e-07, 5.4109705160954036e-08], "prediction": "background"},
	{"string": "Healing and repairing involves processing a model with undesirable artifacts and creating a new version that is free from these errors [24].", "probabilities": [0.02631976455450058, 0.9736802577972412, 4.263828179418283e-10], "prediction": "method"},
	{"string": "Currently, expert user guidance is required (setting tolerances to define  likelihoods ), not all types of features can be detected (free-form surfaces and general sweeps are excluded), and some are prone to errors (due to the noise and incompleteness of measured data, and the numerical nature of the subsequent algorithmic phases) [105].", "probabilities": [0.9999986886978149, 1.3112316992192063e-06, 7.694822001802493e-10], "prediction": "background"},
	{"string": "These failures are similar to the unrealistic shapes described in Fig. 2 and fall in the range of the completeness dimension by Company et al. [115], which measures how well the model replicates the actual shape and size of the part.", "probabilities": [0.9581910371780396, 0.00040494059794582427, 0.041404083371162415], "prediction": "background"},
	{"string": "Interoperability encompasses the exchange of CAD models between different CAD systems and to downstream applications [48].", "probabilities": [0.012251919135451317, 0.9877477884292603, 3.003587210059777e-07], "prediction": "method"},
	{"string": "A common example of the latter type is converting a thin-walled solid into a shell by extracting its mid-surface and meshing it [109].", "probabilities": [0.9908242225646973, 0.009175583720207214, 1.9452829747024225e-07], "prediction": "background"},
	{"string": "Then, they find the translation and rotation of the sub-curve that yield the best least-squares fit to the appropriate portion of the larger curve, and construct new patches that fill the remaining holes (typical patches are triangles obtained by the 3D minimum-area triangulation technique) [74].", "probabilities": [0.15379804372787476, 0.8461939096450806, 8.05255513114389e-06], "prediction": "method"},
	{"string": "Authors van der Meiden et al. presented a method to compute the critical values when a single parameter of a model is modified, (i.e. the parameter values for which the topology of the model changes) [136].", "probabilities": [0.004131382331252098, 0.9958673715591431, 1.2980000292373006e-06], "prediction": "method"},
	{"string": "Abnormally small or uncommon volumes or holes include sliver-faces, micro-slots, etc. A sliver face is a face with a high aspect ratio, whereas a spike is a region with a high aspect ratio inside a face [66].", "probabilities": [0.9999982118606567, 1.5410507785418304e-06, 2.190653844991175e-07], "prediction": "background"},
	{"string": "They subdivided topological errors as: (1) Accuracy errors that consist of excessive geometric gaps between topologically connected elements (like one vertex that falls outside a tolerance volume which surrounds the intersection between the edges that should share it), and(2) Structure errors that occur when any topological element of a model, including vertices, edges, faces, and shells, is undefined or incorrectly linked [9].", "probabilities": [0.9999035596847534, 9.628613770473748e-05, 6.85381422727005e-08], "prediction": "background"},
	{"string": "They are the data sources for procedures that compute useful properties of objects [11].", "probabilities": [0.9998345375061035, 0.00016520034114364535, 1.9016064811694378e-07], "prediction": "background"},
	{"string": "This means a clear distinction between the data models (applications and logical layer) and the file format for data exchange (physical layer defined as in part 21) [15].", "probabilities": [0.9999984502792358, 1.305296848386206e-07, 1.4587916439268156e-06], "prediction": "background"},
	{"string": "Kim et al. [21] developed the prototype of an ISO 15926-based data repository called a fa ade for storing the equipment data of a nuclear power plant and servicing the data for interested organizations.", "probabilities": [0.9976115226745605, 0.002383066574111581, 5.466946731758071e-06], "prediction": "background"},
	{"string": "ISO 15926 Part 11 [41] defines a methodology for simplified industrial usage of reference data.", "probabilities": [0.9495972394943237, 0.05034039542078972, 6.235449109226465e-05], "prediction": "background"},
	{"string": "XMpLant [42] by Nextspace that provides a neutral plant data model and plant data exchange toolkits uses ISO 15926 RDL.", "probabilities": [0.9999339580535889, 5.257364682620391e-05, 1.3464982657751534e-05], "prediction": "background"},
	{"string": "POSC Caesar and Fiatech, an industry consortium based in the USA, developed a plant data exchange platform called iRINGTools [43] through the IDS/ADI program, a joint research program by both organizations.", "probabilities": [0.9007628560066223, 0.09923429787158966, 2.9344294034672203e-06], "prediction": "background"},
	{"string": "Lee et al. [22] proposed a data model for the effective operation and maintenance of manufacturing facilities by adopting the concept of the ISO 15926 Part 2 data model.", "probabilities": [0.009428717195987701, 0.9905360341072083, 3.5185919841751456e-05], "prediction": "method"},
	{"string": "POSC Caesar, an industry consortium based in Norway, developed a reference data service (RDS) [23] that delivers reference data to clients via Web services.", "probabilities": [0.9991737008094788, 0.0008261925540864468, 1.1543517786094526e-07], "prediction": "background"},
	{"string": "However, Jeon et al. [24] reported that iRINGTools cannot exchange the shape information contained in two-dimensional (2D) piping and instrumentation diagram (P&ID), with the exception of logical configuration and equipment specification data.", "probabilities": [0.999962568283081, 2.0323996068327688e-05, 1.7150792700704187e-05], "prediction": "background"},
	{"string": "Recently, attempts have been made to manage Semantic Web technology, including the Web Ontology Language (OWL) [9], in industrial data standards.", "probabilities": [0.992276132106781, 0.00772393774241209, 5.472851327681383e-08], "prediction": "background"},
	{"string": "ISO 15926 specifies that ISO 15926-based plant lifecycle data should be expressed in OWL and the Resource Description Framework (RDF) [10].", "probabilities": [0.9926038384437561, 0.007289351429790258, 0.0001068786732503213], "prediction": "background"},
	{"string": "Constraints provide the declared properties of geometric elements that must be invariant or constant [55].", "probabilities": [0.9999983310699463, 1.5663000567656127e-06, 1.2686346906320978e-07], "prediction": "background"},
	{"string": "The details of two templates DefinitionOfShapeOfIndividual and EnumerationOfClass defined in the course of this study are available at 15926.org Web site [25].", "probabilities": [0.9993684887886047, 0.0006281748064793646, 3.284561898908578e-06], "prediction": "background"},
	{"string": "Luukkainen and Karhela proposed an ontology-based method to combine 3D plant modeling, process simulation, and visualization [51].", "probabilities": [4.6601544454460964e-05, 0.9999533891677856, 8.230250925223004e-10], "prediction": "method"},
	{"string": "Kalogerakis et al. developed an application that supports the coupling of graphical contents with domain knowledge [52].", "probabilities": [0.9999972581863403, 1.1682857348205289e-06, 1.6022544286897755e-06], "prediction": "background"},
	{"string": "Andersen and Vasilakis proposed an ontology for 3D CAD models based on ISO 10303-42 [11].", "probabilities": [0.389798641204834, 0.610178530216217, 2.2812970200902782e-05], "prediction": "method"},
	{"string": "Posada et al. modeled ontologies for plant CAD models by adapting the entities and relationships presented in ISO 10303-227, and presented a semantic compression system for the design review of the large data sets of plant CAD models [53].", "probabilities": [9.228366252500564e-05, 0.9999077320098877, 1.7320305190082763e-08], "prediction": "method"},
	{"string": "Especially, it is very important to share the right information with the right stakeholder at the right time [3].", "probabilities": [0.9999998807907104, 1.4538811932141016e-08, 1.5468938840967894e-07], "prediction": "background"},
	{"string": "The integration lowers the cost of ownership and provides better accessibility to end-users and partners, which enhances the competitiveness of organizations [4].", "probabilities": [1.0, 3.3557267187234174e-08, 5.273140146755395e-08], "prediction": "background"},
	{"string": "Ensuring that consistent, unambiguous, and up-to-date data are available for engineering systems is basically required for data sharing [5].", "probabilities": [0.9999998807907104, 9.138317835777343e-08, 4.2813343981151775e-09], "prediction": "background"},
	{"string": "Design data including 3D data should also be controlled along the whole plant data lifecycle [6].", "probabilities": [0.9989784955978394, 0.0010181536199524999, 3.2865973480511457e-06], "prediction": "background"},
	{"string": "Industrial data standards, including ISO 15926, have been developed mainly with the use of the EXPRESS language [8].", "probabilities": [1.8491672335585463e-06, 0.9999980926513672, 1.2344693045562849e-09], "prediction": "method"},
	{"string": "Wang et al. explored an ontology and Semantic Web rule language (SWRL)-based 3D model retrieval system [14].", "probabilities": [0.9912683963775635, 0.008581322617828846, 0.0001503402745584026], "prediction": "background"},
	{"string": "Attene et al. proposed a method for decomposing a 3D shape into interesting features and attaching formal semantics to these features, as well as the entire shape [13].", "probabilities": [1.4549183333656401e-06, 0.9999985694885254, 1.826042511643422e-10], "prediction": "method"},
	{"string": "Dartigues et al. developed ontologies for design, process planning and common features to integrate CAD and computer-aided process planning (CAPP) data [16].", "probabilities": [0.9487160444259644, 0.05127726122736931, 6.6500442699179985e-06], "prediction": "background"},
	{"string": "Guti rrez et al. developed an ontology of virtual humans to incorporate semantics into human shapes [15].", "probabilities": [0.9999960660934448, 2.498484718671534e-06, 1.4095720644036192e-06], "prediction": "background"},
	{"string": "The Semantic Web [46] is an extension of the Web through standards by the World Wide Web Consortium (W3C).", "probabilities": [0.6427420973777771, 0.357248455286026, 9.487517672823742e-06], "prediction": "background"},
	{"string": "In addition to these two studies, a discussion forum on ISO 15926-based geometry is currently available at the 15926.org website [25].", "probabilities": [0.999948263168335, 1.2884210143226937e-08, 5.172816963749938e-05], "prediction": "background"},
	{"string": "On the other hand, the Semantic Web provides a common framework that allows data to be shared and reused across application, enterprise, and community boundaries [47].", "probabilities": [0.9911949634552002, 0.008805056102573872, 7.556190340096691e-09], "prediction": "background"},
	{"string": "In previous studies, the ontologies for 3D shapes were typically developed by referring to existing standards, including ISO 10303, and ISO/IEC 19775 [50].", "probabilities": [0.979957640171051, 0.020034076645970345, 8.2390833995305e-06], "prediction": "background"},
	{"string": "Peachavanish et al. presented a query-based method using ontology for integrating CAD and geospatial information system (GIS) data [5].", "probabilities": [7.07146483591714e-08, 0.9999998807907104, 7.301985682772738e-10], "prediction": "method"},
	{"string": "ISO 15926 Part 2 [35] provides a generic and conceptual data model.", "probabilities": [0.9999969005584717, 2.4311383128861053e-08, 3.0870942282490432e-06], "prediction": "background"},
	{"string": "ISO 15926-based plant 3D CAD model in OWL is first converted to an intermediate file in extensible markup language (XML) [60] using a converting tool called ISO 15926-based plant 3D CAD model converter.", "probabilities": [4.453075348465063e-07, 0.9999995231628418, 3.5589433622362776e-08], "prediction": "method"},
	{"string": "Engineers can define their products using terms familiar to them while enjoying the benefits of ontology, including generalization, classification, and consistency checking [12].", "probabilities": [0.9993915557861328, 0.0006084269261918962, 5.554149140607478e-09], "prediction": "background"},
	{"string": "Ontology-based models are useful for sharing the domain knowledge, improving interoperability among applications, making domain assumptions, enabling re-use of the domain knowledge [11].", "probabilities": [0.9993959665298462, 0.0006040000007487833, 9.368812392551717e-09], "prediction": "background"},
	{"string": "This type of modeling is called specification-driven modeling [30].", "probabilities": [0.005742099601775408, 0.9942571520805359, 7.704939548602852e-07], "prediction": "method"},
	{"string": "They provide indications of what dimensions are permissible to change [54].", "probabilities": [0.9999980926513672, 1.6381737566462107e-07, 1.8458249542163685e-06], "prediction": "background"},
	{"string": "In order to perform simulations on a given object using isogeometric analysis, a parameterization by NURBS volumes needs to be generated [1].", "probabilities": [1.619591039059287e-08, 1.0, 4.264295513922711e-12], "prediction": "method"},
	{"string": "This has substantially enlarged the class of feasible input data for the isogeometric segmentation pipeline [6].", "probabilities": [1.0, 2.2613145134187107e-08, 2.3505700497139514e-08], "prediction": "background"},
	{"string": "A more sophisticated trust measure is a PageRank-style random walk trust measure, in which a random walker surfs the social network much like the random surfer in the popular PageRank approach for Web ranking [32].", "probabilities": [0.9999790191650391, 1.9974608221673407e-05, 9.251265282728127e-07], "prediction": "background"},
	{"string": "A more detailed study of this dataset can be found in [12].", "probabilities": [0.9999803304672241, 3.4378467717033345e-06, 1.619572503841482e-05], "prediction": "background"},
	{"string": "The literature on usability identifies two main groups of usability evaluation techniques [7]:   Test Methods, which are normally applied to running applications (or at least with early-prototypes of these applications), and require real users.", "probabilities": [0.9999891519546509, 1.0856191693164874e-05, 7.746661090379803e-09], "prediction": "background"},
	{"string": "Usability can be defined as  the ease of use and acceptability of a system for a particular class of users carrying out specific tasks in a specific environment  [7].", "probabilities": [0.9999909400939941, 9.031041372509208e-06, 2.8315982891768954e-10], "prediction": "background"},
	{"string": "They had to answer questions related to  the eight golden rules  [16], shown in Table 2 .", "probabilities": [0.9999964237213135, 2.720198381211958e-06, 8.118421988001501e-07], "prediction": "background"},
	{"string": "This is due to the fact that, on the one hand, there is an increasing difficulty in the design of attractive and easily reusable web applications where a wide set of client-side technologies (e.g. HTML, Javascript, CSS, DHTML, Flash, or AJAX) and server-side technologies (e.g. ASP, JSP, JSF, .NET) need to be used, converting web designers in skilled programmers as pointed by Rochen et al. [15].", "probabilities": [0.9991443157196045, 0.0008556927205063403, 5.399101721259569e-10], "prediction": "background"},
	{"string": "  Semantic Pipes [9] focus on application developers who want to handle semantic data, as in Fortunata.", "probabilities": [0.9999997615814209, 1.5384767948489753e-07, 1.6579467398969427e-07], "prediction": "background"},
	{"string": "VPOET [14] allows client-side web designers to create interactive templates for a given ontology component, not just to show semantic data (output templates) but to request data from the user (input templates).", "probabilities": [0.9973648190498352, 0.0026352107524871826, 1.030367702270496e-08], "prediction": "background"},
	{"string": "This is exemplified by Wordnet [20] that is something like  the explicitation of the ontology inherent to the English language .", "probabilities": [0.996073842048645, 0.003877013921737671, 4.9217189371120185e-05], "prediction": "background"},
	{"string": "There are indeed other obstacles to information exchange and human collective intelligence in cyberspace than diverse data formats: diverse ontologies reflecting different contexts and area of practice, diverse classification systems, diverse folksonomies emerging from social tagging in various social media [24] and, last but not least, multiple natural languages.", "probabilities": [0.9999969005584717, 2.954416459033382e-06, 7.674866964180183e-08], "prediction": "background"},
	{"string": "The more our society depends on the creative management of knowledge the more this capacity becomes of fundamental importance [3].", "probabilities": [0.9999998807907104, 1.181582902631817e-07, 2.6710790024253583e-08], "prediction": "background"},
	{"string": "The participation in several social networks with hundred of contacts and the access to data and metadata through global sharing systems like Twitter (hashtags), Delicious, Twine, YouTube or Flickr, make the issue of categorization in personal and collective cloud management urgent [66].", "probabilities": [0.9999969005584717, 3.039879629795905e-06, 1.5982003276349133e-08], "prediction": "background"},
	{"string": "These incentives can be extrinsic or intrinsic and should be carefully selected in order to avoid negative effects such as the crowding-out effect, i.e., employees participating only in expectance of the reward [58].", "probabilities": [0.9999971389770508, 2.712289187911665e-06, 8.58081747878714e-08], "prediction": "background"},
	{"string": "Corporate knowledge, as a fluid mix of ideas, experience, intuition and lessons learned, does not exist only in information repositories but mainly resides in the minds of individuals [22].", "probabilities": [0.9996752738952637, 0.00032403841032646596, 6.71706573029951e-07], "prediction": "background"},
	{"string": "Secondly, they can generalize, meaning that they can correctly predict the output of unseen data, even if their training set contains noisy information [72].", "probabilities": [1.0, 3.314310248470065e-08, 5.3252431797545796e-08], "prediction": "background"},
	{"string": "Secondly, FFNNs depend on the size and quality of the data used for their training [32].", "probabilities": [0.9999128580093384, 8.714036084711552e-05, 2.034129664707507e-08], "prediction": "background"},
	{"string": "Note that, we take a look at the movie recommendation by making use of MovieLens data [1] in this study.", "probabilities": [1.0852887498913333e-05, 0.9999890327453613, 7.218771713723982e-08], "prediction": "method"},
	{"string": "To deal with this critical issue, in this paper, we extend our previous work [34] to predict the user s preferences by considering content-based CF and rough-set theory simultaneously.", "probabilities": [0.12019195407629013, 0.8797919154167175, 1.618322858121246e-05], "prediction": "method"},
	{"string": "The experimental data are based on the collection of MovieLens [1], which are provided by GroupLens Research at the University of Minnesota.", "probabilities": [7.201109752941193e-08, 0.9999998807907104, 8.880682855760824e-10], "prediction": "method"},
	{"string": "Lin et al. [21] found the overlaps of several users  tastes to match the active user s taste by utilizing the discovered user associations and article associations.", "probabilities": [0.7983342409133911, 0.201629638671875, 3.607217877288349e-05], "prediction": "background"},
	{"string": "Xu and Araki [39] proposed a learning algorithm that attempted to build a personalized recommender system based on SVM (Support Vector Machine).", "probabilities": [0.9983587861061096, 0.0016398552106693387, 1.3618317780128564e-06], "prediction": "background"},
	{"string": "Based on the fusion of user-based and item-based CF, Wang et al. [38] took advantage of a probabilistic framework to exploit available data in the user item matrix.", "probabilities": [1.0149292393180076e-05, 0.9999898672103882, 1.6058555374343086e-08], "prediction": "method"},
	{"string": "Di Marzo Serugendo [66] phrases the design of such systems as follows: The challenges to take up in this field relate to the design, and the development of applications which  work by themselves : how to define a global goal; how to design the components and their local functionality knowing that the global goal is not a local sum of functionality; which will be the interactions between components, and how to check that the desired result will emerge during the execution.", "probabilities": [0.9989522695541382, 0.001047621015459299, 9.387620281131603e-08], "prediction": "background"},
	{"string": "In recent work [68], di Marzo Serugendo works out the idea of a design framework, called METASELF, that follows a service-oriented architecture, combines design-time and run-time features and that can adaptively coordinate between system metadata about the functionality and performance characteristics (self-descriptions of components, coordination space environment, and self-* properties) and execution policies (guiding, coordination, bounding and sensing/acting).", "probabilities": [0.9999492168426514, 5.048465754953213e-05, 1.977488324200749e-07], "prediction": "background"},
	{"string": "In the editorial peer review process of many journals, an editor typically makes a three-way decision about a manuscript, namely, acceptance, rejection, or further revision, based on comments from reviewers; the final decision of the third category is subject to comments from reviewers in another round of review [29].", "probabilities": [0.9998912811279297, 0.00010865273361559957, 4.3239044345000366e-08], "prediction": "background"},
	{"string": "For example, based on the three regions of the rough set theory,  le zak et al. [21] consider a three-way decision when choosing data packs for query optimization; they classify data packs into the relevant, irrelevant, and suspect data packs.", "probabilities": [0.2499956339597702, 0.7500017881393433, 2.607460146464291e-06], "prediction": "method"},
	{"string": "Based on preliminary results in [39], we examine the formulations and interpretations of three-way decision rules as follows: in Section 2, we briefly review a few key studies that lead to three-way decision rules, which provides the motivations and justifications of the current study.", "probabilities": [0.015685411170125008, 0.0019805736374109983, 0.9823340177536011], "prediction": "result"},
	{"string": "From a new semantic interpretation of the positive, boundary and negative regions, we introduce and study the notion of three-way decisions, consisting of positive, boundary and negative rules [39].", "probabilities": [0.9980365633964539, 0.001963198184967041, 2.527407616526034e-07], "prediction": "background"},
	{"string": "A game-theoretic risk analysis of the required parameters in the decision-theoretic rough set models is given by Herhert and Yao [6].", "probabilities": [0.9985175728797913, 0.0014766169479116797, 5.8227979025105014e-06], "prediction": "background"},
	{"string": "With insufficient information as provided by a set of attributes A, the rough set theory promotes a methodology for three-way decision making [39].", "probabilities": [0.007925555109977722, 0.9920743703842163, 6.026605881004343e-09], "prediction": "method"},
	{"string": "In his book and earlier works, Pawlak [15] focused mainly on the positive region and certain rules, as they characterize the objects on which we can make consistent and correct decisions.", "probabilities": [0.9999548196792603, 1.4790702152822632e-05, 3.043010292458348e-05], "prediction": "background"},
	{"string": "One may associate probabilistic measures, such as accuracy, confidence, and coverage, to rules [25].", "probabilities": [0.9999997615814209, 2.64931315996364e-07, 2.1507675640464186e-08], "prediction": "background"},
	{"string": "However, as a concept induced from fuzzy sets, shadowed sets [32] have a close relationship with rough sets as well.", "probabilities": [0.9999973773956299, 1.569155756442342e-06, 1.1050091188735678e-06], "prediction": "background"},
	{"string": "Some recent research has linked grey sets with rough sets and proposed grey rough sets [40] for interval data.", "probabilities": [0.9997925162315369, 0.00014889704470988363, 5.859740122104995e-05], "prediction": "background"},
	{"string": "Various uncertainties in real world applications can bring difficulties in determining the crisp membership functions of type-1 fuzzy sets [25].", "probabilities": [0.9999957084655762, 3.6130486478214152e-06, 6.863973567305948e-07], "prediction": "background"},
	{"string": "Even though the pre-filtering phase has been detailed in [9], in this section we summarize the main aspects of this process with the goal of clarifying how the user s Ontology of Interest is selected (Section 4.1) and how it is processed by SA techniques in the recommendation phase of the strategy (Sections 4.2, 4.3, 4.4).", "probabilities": [2.78479376447649e-07, 0.9999997615814209, 1.5140356746101702e-09], "prediction": "method"},
	{"string": "Specifically, the structure of classes and properties in the TV ontology has been automatically extracted from the TV-Anytime metadata specification [38], which standardizes XML files describing multiple attributes of audiovisual contents (e.g. genres, credits involved in the programs, and target audience), as shown in Fig. 2.", "probabilities": [9.628847719156397e-10, 1.0, 2.4456174932407926e-13], "prediction": "method"},
	{"string": "In spite of its accuracy, this technique is limited due to the similarity metrics employed, which are based on rigid syntactic approaches that can only detect similarity between items that share all or some of their attributes [1].", "probabilities": [0.36635977029800415, 0.6336402297019958, 2.883078664694949e-08], "prediction": "method"},
	{"string": "We depict in Fig. 2 a brief excerpt from an ontology for the TV domain, defined from the TV-Anytime specification (a collection of metadata providing detailed descriptions about generic audiovisual contents [38]).", "probabilities": [0.5466660857200623, 0.4533318877220154, 1.9918634279747494e-06], "prediction": "background"},
	{"string": "However, rather than starting from scratch, we created our data base as a subset of a collection that already exhibited many desirable characteristics, including the very important ones of not being privately owned and of being freely available: the Benchatlon database [22].", "probabilities": [0.0006944144843146205, 0.9993053674697876, 2.9223812703094154e-07], "prediction": "method"},
	{"string": "Compared to other widely used datasets (e.g. Corel 3 and imageCLEF [32]) it is, in our opinion, a challenging dataset for the image retrieval task.", "probabilities": [0.003828068496659398, 0.00041397465975023806, 0.9957579970359802], "prediction": "result"},
	{"string": "Previous studies suggest that when our perceptual system does similarity matching, it does not do so completely independently of classification (see, for instance, the experiment of Maruyama et al. concerning the interpretation of face images [30]).", "probabilities": [0.8919935822486877, 0.048120152205228806, 0.059886299073696136], "prediction": "background"},
	{"string": "To do so we applied the Antipole clustering method [3] to select the visual words from a set of more than 15 millions descriptors extracted from the images in the dataset described in the next section.", "probabilities": [7.232960008707323e-09, 1.0, 4.524054308258085e-12], "prediction": "method"},
	{"string": "The SIFT descriptors extracted from an image are then quantized into  visual words , which are defined by clustering a large number of descriptors extracted from a set of training images [34].", "probabilities": [0.9660336375236511, 0.03396634757518768, 9.882125340254788e-09], "prediction": "background"},
	{"string": "One of the first attempts to integrate and compare semantic keywords and low-level features into a single CBIR framework is the SIMPLIcity system [55].", "probabilities": [0.9989413619041443, 0.0010243180440738797, 3.425526665523648e-05], "prediction": "background"},
	{"string": "We would like to highlight that the first bid to set a formal definition of interpretability dates to 1953, some years before the birth of fuzzy logic which was introduced by Zadeh [36] in 1965.", "probabilities": [0.9989784955978394, 0.0010200322140008211, 1.5228184793159016e-06], "prediction": "background"},
	{"string": "We build this model by feeding it past and present extrinsic data, and we use it as a predictive tool by feeding it past and present data and querying it on future data [1].", "probabilities": [3.614418275788012e-08, 1.0, 2.525909169326379e-12], "prediction": "method"},
	{"string": "  Fortran has had much more success and a much deeper impact than Algol, a language from the same generation (late 50s/early 60s), which is much more structured, much more orthogonal, and much better designed [2].", "probabilities": [0.9999948740005493, 4.14568876294652e-06, 8.967109010882268e-07], "prediction": "background"},
	{"string": "A common application of middleware is to allow programs written for access to a particular database to access other databases [3].", "probabilities": [0.9997504353523254, 0.0002495920634828508, 3.2120326398654697e-09], "prediction": "background"},
	{"string": "In Gaines [8], Gaines proposes a model for technology evolution called the BRETAM model (Breakthrough, Replicator, Empiricis, Theory, Automation, Maturity), and uses it to forecast the evolution of information technologies.", "probabilities": [0.9855713844299316, 0.014428279362618923, 2.976991879677371e-07], "prediction": "background"},
	{"string": "This matching problem is a specialization of subgraph isomorphism [25].", "probabilities": [0.9997735619544983, 8.724196231923997e-05, 0.00013922878133598715], "prediction": "background"},
	{"string": "The general subgraph isomorphism [15] only concerns the structure of two graphs (i.e., the adjacency relationship of vertices).", "probabilities": [0.9999994039535522, 5.73301548456584e-08, 6.544677830788714e-07], "prediction": "background"},
	{"string": "From our earlier work [19], we know that the filtering on a single machine depends on the number of matches.", "probabilities": [0.999997615814209, 4.196759277874662e-07, 1.8735063349595293e-06], "prediction": "background"},
	{"string": "To better understand the operation of a pub/sub cluster system, we first give an overview of the data model, which is the graph-based subscription and publication representation language introduced in [19].", "probabilities": [0.24453212320804596, 0.7554606199264526, 7.2852194534789305e-06], "prediction": "method"},
	{"string": "Our earlier work [19] shows that the filtering on a single machine depends on the number of matches.", "probabilities": [0.9990636706352234, 0.0005981698050163686, 0.0003380887792445719], "prediction": "background"},
	{"string": "Complexity analysis: As we analyzed in [19], the matching time to process a publication on a single node is linear in the number of matched subscriptions: O( ratio match   number_ of_ subscriptions).", "probabilities": [0.285879909992218, 0.7139724493026733, 0.00014766224194318056], "prediction": "method"},
	{"string": "To enable indexing algorithms and a faster filtering algorithm, we modified the two-level hash table structure as introduced in [19].", "probabilities": [2.5694525618291664e-08, 1.0, 3.1129687716457966e-10], "prediction": "method"},
	{"string": "The difference is that G-ToPSS in [19] checks the constraint for each subscription sequentially.", "probabilities": [0.9999637603759766, 1.671778704803728e-06, 3.451783049968071e-05], "prediction": "background"},
	{"string": "Among these, XTrie [6] is extensible supporting patterns including constraint predicates.", "probabilities": [0.9950839877128601, 0.004906384740024805, 9.625548045733012e-06], "prediction": "background"},
	{"string": "Gupta and Suciu [12] show how to process XML stream over XPath queries including predicates.", "probabilities": [0.9999370574951172, 5.717685053241439e-05, 5.732745648856508e-06], "prediction": "background"},
	{"string": "For filtering graph-based metadata, we proposed a model in [19].", "probabilities": [7.257893486212197e-08, 0.9999998807907104, 3.143944660166653e-09], "prediction": "method"},
	{"string": "From our earlier work [19], we know that the filtering on a single machine depends on the number of matches.", "probabilities": [0.999997615814209, 4.339453596458043e-07, 1.932489340106258e-06], "prediction": "background"},
	{"string": "Racer [13] is a pub/sub system using description logics as inference engine.", "probabilities": [0.20728877186775208, 0.7926963567733765, 1.4789311535423622e-05], "prediction": "method"},
	{"string": "We proposed a model for graph-based data filtering in [19].", "probabilities": [3.087201184825972e-05, 0.9999691247940063, 1.1956059253748208e-08], "prediction": "method"},
	{"string": "Similar multicast tree construction problem is also studied by Ying Zhu in [29] where she focused on elastic data.", "probabilities": [0.9878243207931519, 0.004477438051253557, 0.007698254194110632], "prediction": "background"},
	{"string": "SemCast [18] presents a semantic multicast approach that split the incoming data streams based on the overlapping of their contents.", "probabilities": [0.999998927116394, 1.0576303566267597e-06, 4.951951027010182e-08], "prediction": "background"},
	{"string": "These systems also suffer the scalability problem with a throughput of 250 queries per second as reported by RDFPeers [4].", "probabilities": [0.04733658581972122, 0.9524531364440918, 0.0002102700382238254], "prediction": "method"},
	{"string": "That is to say, a three-layer MLP neural network can approximate any arbitrary nonlinear continuous multidimensional function to any desired accuracy, provided that the model has enough neuronal units [24].", "probabilities": [0.9999740123748779, 2.4755761842243373e-05, 1.2269346143511939e-06], "prediction": "background"},
	{"string": "The basic learning algorithm used is backpropagation [22] which uses gradient descend to minimize a cost function, generally defined as the mean square error (MSE) between the desired output (targets) and the actual network output.", "probabilities": [0.0007644635625183582, 0.9992355108261108, 8.132547080208496e-09], "prediction": "method"},
	{"string": "In [25] an ANN model learns and adjusts those weights in order to avoid some of the disadvantages of both rule-based and learning-based ontology matching approaches, which ignore the information that instance data may provide.", "probabilities": [0.9841704368591309, 0.015829455107450485, 6.64172716824396e-08], "prediction": "background"},
	{"string": "For instance, recent ANN-based tools proposed in the literature use information regarding ontology schemas and instances to produce rules for ontology integration in heterogeneous databases [17].", "probabilities": [0.017169497907161713, 0.9828305244445801, 4.4442764135510515e-08], "prediction": "method"},
	{"string": "The recent work [28] proposes an adaptive approach for finding semantic correspondences between similar elements of different ontologies.", "probabilities": [0.9997863173484802, 0.00020342566131148487, 1.0259164810122456e-05], "prediction": "background"},
	{"string": "For instance, considering a set of positive and negative examples of alignments, the examples would be divided into a training set (typically 80% of data) and a validation or test set (typically 20% of data), which would be used for evaluating the performance of the learning algorithm [17].", "probabilities": [0.02645036205649376, 0.9729763269424438, 0.0005732846329919994], "prediction": "method"},
	{"string": "Ontologies provide a number of useful features for intelligent systems, as well as for knowledge representation in general, and for the knowledge engineering process [19].", "probabilities": [0.9996521472930908, 0.00034777834662236273, 7.018879699671743e-08], "prediction": "background"},
	{"string": "The data sets made for OAEI 6 (Ontology Alignment Evaluation Initiative) campaign can be considered correct (as far as construction is concerned) but they are neither realistic nor very hard [17].", "probabilities": [0.9974282383918762, 0.002558262785896659, 1.3440569091471843e-05], "prediction": "background"},
	{"string": "The k-fold cross validation method was used for training [22].", "probabilities": [3.633038403449973e-08, 1.0, 1.7819255793138922e-10], "prediction": "method"},
	{"string": "An important framework for creating such capabilities can be provided by the next generation of the Web architecture: the Semantic Web[30].", "probabilities": [0.9984143972396851, 0.0015854969387874007, 1.6754472653701669e-07], "prediction": "background"},
	{"string": "It will bring meaning to Web page contents, in which software agents roaming from page to page can execute automated tasks by using metadata or semantic annotations, ontologies and logic [1].", "probabilities": [0.6102650165557861, 0.3897349238395691, 2.0574432824105315e-08], "prediction": "background"},
	{"string": "Ontologies have become a de facto standard for the semantic description of data, resources and services in large distributed systems such as the Web [2].", "probabilities": [0.9999996423721313, 3.538329167440679e-07, 8.242823090753859e-10], "prediction": "background"},
	{"string": "In this context, the simplest document will consist of concrete facts, classes, properties definitions and metadata [23].", "probabilities": [0.9999969005584717, 2.736908072620281e-06, 3.39991402142914e-07], "prediction": "background"},
	{"string": "Therefore, it can be stated that, if labels are the same, the instances associated with them are likely to be the same or semantically related [16].", "probabilities": [0.9999983310699463, 5.010011516759505e-09, 1.6172655250557e-06], "prediction": "background"},
	{"string": "In [33], an architecture for discovering knowledge sources on the Semantic Web was proposed, which is composed of mobile agents, the knowledge source discovery (KSD) agent and web nodes (see Fig. 1).", "probabilities": [0.9999927282333374, 7.327452294703107e-06, 2.5103775058710198e-08], "prediction": "background"},
	{"string": "WordNet is a lexical database for the English language [18].", "probabilities": [0.9999995231628418, 1.2926822989811626e-07, 3.1676142953074304e-07], "prediction": "background"},
	{"string": "Training is an optimization process where internal parameters of the neural model (the weights) are adjusted to fit the training data [22].", "probabilities": [0.0023007462732493877, 0.9976988434791565, 3.057991477817268e-07], "prediction": "method"},
	{"string": "Besides ontologies, software agents will play a fundamental role in building the Semantic Web of the future [23].", "probabilities": [0.6327444911003113, 0.3672546148300171, 9.040043664754194e-07], "prediction": "background"},
	{"string": "There are different algorithms for implementing the matching process which can be generally classified along two dimensions [12].", "probabilities": [0.3938751816749573, 0.6061235666275024, 1.2615842024388257e-06], "prediction": "method"},
	{"string": "The Resource Description Framework (RDF) [16] is a popular data model for information on the Web.", "probabilities": [0.9998356103897095, 0.00016338849673047662, 9.705137244964135e-07], "prediction": "background"},
	{"string": "The standard query language for RDF data is SPARQL [20].", "probabilities": [0.5271235704421997, 0.4724879562854767, 0.00038851439603604376], "prediction": "background"},
	{"string": "The current version 1.1 of SPARQL extends SPARQL 1.0 [19] with important features such as aggregation and regular expressions.", "probabilities": [0.18155913054943085, 0.8184381723403931, 2.693325996006024e-06], "prediction": "method"},
	{"string": "Remark 7The pattern expressing MINUS, used in the proof of Proposition 4, is not well-designed [14].", "probabilities": [7.403210474876687e-05, 0.999925971031189, 2.3499151513561856e-09], "prediction": "method"},
	{"string": "For data complexity we have A fixed, so each state of AD can be described using logarithmic space and the number of states is polynomial in the size of the input, so the running time is NL.The lower bounds follow from the complexity of query evaluation of register automata [11].", "probabilities": [0.0012175256852060556, 0.9987824559211731, 6.712774780481823e-09], "prediction": "method"},
	{"string": "In this section we show how to use the model of variable automata introduced in [6] to query graph databases.", "probabilities": [3.6303663364378735e-05, 0.999963641166687, 1.4412564197652245e-10], "prediction": "method"},
	{"string": "Indeed, it appears that models that use memory, such as register automata and their expression equivalent [11], make the query evaluation PSpace-hard, while XPath-based approaches bring the complexity down to PTime, but lose the ability to store values into separate memory locations.", "probabilities": [0.9997095465660095, 0.0002904711291193962, 3.59924712256543e-08], "prediction": "background"},
	{"string": "Data words are commonly studied in XML literature [5], where they are used to describe paths in XML trees.", "probabilities": [0.0015959368320181966, 0.9984037280082703, 3.982924283718603e-07], "prediction": "method"},
	{"string": "It was shown in [7] that the language L={(ad1)(ad1)(ad2)(ad2) (adk)(adk)|k 1}, is not expressible by VFAs.", "probabilities": [0.9999359846115112, 9.071242857316975e-06, 5.493747448781505e-05], "prediction": "background"},
	{"string": "Originally they were defined on words over infinite alphabets [6], but it is straightforward to extend them to the setting of data words.", "probabilities": [0.9999997615814209, 1.6100480593195243e-07, 1.1731626869959655e-07], "prediction": "background"},
	{"string": "What all of these languages (with the sole exception of nested regular expressions [3]) have in common is that they rely on exploring the graph topology using paths.", "probabilities": [0.9999688863754272, 3.0577175493817776e-05, 5.251379775472742e-07], "prediction": "background"},
	{"string": "Note that besides the operators in Definition 2.1 the original proposal of GXPath includes data value comparisons [19].", "probabilities": [0.9995477795600891, 6.977753946557641e-05, 0.00038235323154367507], "prediction": "background"}
]