citfunc	sectitle	refentry	art	sectype	sectype2	refid	sec	ctx	pointerlist	nbcontexts	nbsections	itrp	anchorsent	partext	potential_cf	annotator	dataset
cites	Introduction	D.L. Hoffman, T.P. Novak, M. Peralta, Building consumer trust online , Communications of the ACM , vol. 42 (1999), pp.80-85	http://dx.doi.org/10.1016/j.aci.2009.04.001	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2009-04-001/br/b0145>	<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2009-04-001/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2009-04-001/ctx/ctx0003>				http://www.scar.disi.unibo.it/r/10-1016-j-aci-2009-04-001/itrp/0008	'In summary, the open nature of the Internet as a transaction infrastructure and its global nature create uncertainty around on-line transactions, and this poses trust, credibility and risk as crucial elements of e-transaction (Hoffman et al., 1999[[ refid=''b0145'' ]]).'				100_classified_citeAsReview
cites	Literature review	Boutell, M., Shen, X., Luo, J., Brown, C., 2003. Multi-label semantic scene classification. Technical report 813, Department of Computer Science, University of Rochester, Rochester, NY 14627 & Electronic Imaging Products R & D, Eastern Kodak Company.	http://dx.doi.org/10.1016/j.aci.2014.07.002			<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2014-07-002/br/b0010>	<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2014-07-002/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2014-07-002/ctx/ctx0009>				http://www.scar.disi.unibo.it/r/10-1016-j-aci-2014-07-002/itrp/0013	'Finally, a common data transformation method used in image classification that derives a single label binary classifier for every class in the class set is called Binary Relevance (BR) (Boutell et al., 2003[[ refid=''b0010'' ]]).'				100_classified_citeAsReview
cites_as_review	Introduction	Tsoumakas, G., Katakis, I., 2007. Multi-label classification: an overview. In: David Taniar (Ed.), International Journal of Data Warehousing and Mining, Idea Group Publishing, 3(3), pp. 1–13.	http://dx.doi.org/10.1016/j.aci.2014.07.002	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2014-07-002/br/b0095>	<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2014-07-002/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2014-07-002/ctx/ctx0001>				http://www.scar.disi.unibo.it/r/10-1016-j-aci-2014-07-002/itrp/0014	'Generally and according to (Tsoumakas and Katakis, 2007[[ refid=''b0095'' ]]), there are two types of classification problems, these are termed as single label and multi-label.'				100_classified_citeAsReview
cites	The proposed sport result prediction intelligent framework	J. Hucaljuk, A. Rakipović, Predicting	http://dx.doi.org/10.1016/j.aci.2017.09.005	results		<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/br/b0100>	<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/ctx/ctx0034>				http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/itrp/0034	'Hucaljuk and Rakipovic [15][[ refid=''b0100'' ]] included an expert-selected feature set in addition to their initial feature set.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	The proposed sport result prediction intelligent framework	I. Qabajeh, F. Thabtah, F. Chiclana, A dynamic rule-induction method for classification in data mining , J. Manage. Anal. , vol. 2 (2015), pp.233-253	http://dx.doi.org/10.1016/j.aci.2017.09.005	results		<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/br/b9035>	<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/ctx/ctx0037>				http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/itrp/0035	'The first step in the modelling process is to select which candidate models will be used in the experimentation [34][[ refid=''b9035'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	The proposed sport result prediction intelligent framework	J. Hucaljuk, A. Rakipović, Predicting	http://dx.doi.org/10.1016/j.aci.2017.09.005	results		<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/br/b0100>	<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/ctx/ctx0032>				http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/itrp/0040	'Hucaljuk and Rakipovic [15][[ refid=''b0100'' ]] used a separate expert-selected feature set against their own feature set, to investigate the value of expert opinion for feature selection.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	The proposed sport result prediction intelligent framework	C. Cao, Sports data mining technology used in basketball outcome prediction. Master’s Thesis, Dublin Institute of Technology, Ireland, 2012.	http://dx.doi.org/10.1016/j.aci.2017.09.005	results		<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/br/b0030>	<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/ctx/ctx0038>				http://www.scar.disi.unibo.it/r/10-1016-j-aci-2017-09-005/itrp/0041	'For example, Cao [5][[ refid=''b0030'' ]] used seasons up from 2005/2006 to 2009/2010 were used as the training data, and the 2010/2011 season was used as the test data, to evaluate models that predict basketball match results.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Related work	S. Park, A. Savvides, M.B. Srivastava, SensorSim: a simulation framework for sensor networks, in: Proceedings of the Third International Workshop on Modeling Analysis and Simulation of Wireless and Mobile Systems (MSWiM 2000), Boston, MA, USA, August, 2000.	http://dx.doi.org/10.1016/j.adhoc.2010.09.003	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2010-09-003/br/b0060>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2010-09-003/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2010-09-003/ctx/ctx0012>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2010-09-003/itrp/0045	'SensorSim [12][[ refid=''b0060'' ]] is an extension to ns-2.'				100_classified_extends
uses_method_in	Introduction	D. Gavidia, S. Voulgaris, M. van Steen, A Gossip-based distributed news service for wireless mesh networks, in: Proc. Third Int’l Conf. Wireless On-demand Network Systems and Services (WONS), January 2006.	http://dx.doi.org/10.1016/j.adhoc.2012.01.006	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-01-006/br/b0055>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-01-006/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-01-006/ctx/ctx0007>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-01-006/itrp/0029	'This deployment model was borrowed from the proposal presented in [11][[ refid=''b0055'' ]].'				100_classified_extends
uses_method_in	Research challenges	S. Barbarossa, G. Scutari, A. Swami, Distributed detection and estimation in decentralized sensor networks: and overview, in: Proceedings of EURASIP EUSIPCO, Florence, 2006.	http://dx.doi.org/10.1016/j.adhoc.2012.02.016			<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-02-016/br/b0295>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-02-016/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-02-016/ctx/ctx0041>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-02-016/itrp/0122	'Average field measurement is performed by the distributed self-clocking scheme described in [59][[ refid=''b0295'' ]].'				100_classified_citeAsReview
cites_as_review	Research challenges	D. Fudenberg, J. Tirole, Game Theory , None, MIT Press (1991)	http://dx.doi.org/10.1016/j.adhoc.2012.02.016			<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-02-016/br/b0475>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-02-016/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-02-016/ctx/ctx0068>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-02-016/itrp/0143	'A technical description of the issues arising in that context are beyond the scope of this survey: for a standard reference see [95][[ refid=''b0475'' ]].'				100_classified_citeAsReview
cites_as_review	Vision and concept	S. Dobson, S.G. Denazis, A. Fernández, D. Gaı¨ti, E. Gelenbe, F. Massacci, P. Nixon, F. Saffre, N. Schmidt, F. Zambonelli, A survey of autonomic communications , TAAS , vol. 1 (2006), pp.223-259	http://dx.doi.org/10.1016/j.adhoc.2012.02.016			<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-02-016/br/b0065>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-02-016/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-02-016/ctx/ctx0015>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-02-016/itrp/0174	'This includes ability to perform device and service discovery without requiring an external trigger, to build overlays and to adaptively tune protocols’ behavior to adapt to the current context [13][[ refid=''b0065'' ]].•Semantic interoperability and data management.'				100_classified_citeAsReview
cites	Related work	O.B. Akan, I.F. Akyildiz, Event-to-sink reliable transport in wireless sensor networks , IEEE/ACM Transactions on Networking , vol. 13 (2005), pp.1003-1016	http://dx.doi.org/10.1016/j.adhoc.2012.10.003	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-10-003/br/b0155>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-10-003/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-10-003/ctx/ctx0023>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-10-003/itrp/0002	'Event-to-Sink Reliable Transport (ESRT) decreases congestion near the data sink by regulating the frequency of sensors reporting [31][[ refid=''b0155'' ]].'				100_classified_citeAsReview
cites_as_review	Related work	G. Anastasi, M. Conti, M.D. Francesco, A. Passarella, Energy conservation in wireless sensor networks: a survey , Ad Hoc Networks , vol. 7 (2009), pp.537-568	http://dx.doi.org/10.1016/j.adhoc.2012.10.003	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-10-003/br/b0045>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-10-003/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-10-003/ctx/ctx0004>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2012-10-003/itrp/0028	'Hardware-level techniques are based on controlling the system power consumption by developing special design techniques for implementing low power circuits [9][[ refid=''b0045'' ]].'				100_classified_citeAsReview
cites_as_review	Introduction	A. Jøsang, R. Ismail, C. Boyd, A survey of trust and reputation systems for online service provision , Decis. Support Syst. , vol. 43 (2007), pp.618-644	http://dx.doi.org/10.1016/j.adhoc.2013.04.013	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-04-013/br/b0005>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-04-013/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-04-013/ctx/ctx0001>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-04-013/itrp/0017	'As a result, the topic of trust in computer networks is receiving significant attention in both the academic community and the e-commerce industry [1][[ refid=''b0005'' ]].'				100_classified_citeAsReview
extends	Zero-knowledge proofs	O. Baudron, P.-A. Fouque, D. Pointcheval, J. Stern, G. Poupard, Practical multi-candidate election system , Proceedings of the 20th Annual ACM Symposium on Principles of Distributed Computing, PODC ’01, ACM (2001)	http://dx.doi.org/10.1016/j.adhoc.2013.04.013			<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-04-013/br/b0115>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-04-013/sec/appendix-a>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-04-013/ctx/ctx0039>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-04-013/itrp/0034	'The proofs can be considered as an extension of the interactive protocols that were presented in [23][[ refid=''b0115'' ]].'				100_classified_extends
extends	Introduction	J.H. Cho, A. Swami, I.R. Chen, Modeling and analysis of trust management protocols: altruism versus selfishness in MANETs, in: M. Nishigaki, A. Jøsang, Y. Murayama, S. Marsh (Eds.), 4th IFIP Int’l Conf. on Trust Management, Morioka, Japan, 14–18 June 2010; Trust Management IV, IFIP Advances in Information and Communication Technology, Springer, 2010, vol. 321, pp. 141–15.	http://dx.doi.org/10.1016/j.adhoc.2013.05.004	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-05-004/br/b0160>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-05-004/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-05-004/ctx/ctx0040>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-05-004/itrp/0028	'This paper significantly extends our preliminary work published in [32][[ refid=''b0160'' ]].'				100_classified_extends
cites_as_review	Introduction	J.H. Cho, A. Swami, I.R. Chen, A survey of trust management in mobile ad hoc networks , IEEE Communications Surveys and Tutorials , vol. 13 (2011), pp.562-583	http://dx.doi.org/10.1016/j.adhoc.2013.05.004	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-05-004/br/b0180>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-05-004/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-05-004/ctx/ctx0035>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-05-004/itrp/0062	'Recently trust has been applied to security applications such as secure routing or intrusion detection in MANETs [36][[ refid=''b0180'' ]].'				100_classified_citeAsReview
uses_method_in	Performance evaluation	R. Forre, The strict avalanche criterion: spectral properties of Booleans functions and an extended definition , Advances in cryptology, Crypto’88, Lecture Notes in Computer Science , vol. 403 (1990), pp.450-468	http://dx.doi.org/10.1016/j.adhoc.2013.07.006	results		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-07-006/br/b0155>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-07-006/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-07-006/ctx/ctx0026>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2013-07-006/itrp/0006	'If a bit error occurs in the encrypted message block during transmission in the wireless channel, this error will expand to all bits of the decrypted message with a probability of 50%; this is a result of the Strict Avalanche Criterion (SAC) of the encryption algorithms [31][[ refid=''b0155'' ]].'				100_classified_extends
cites_as_review	Preliminaries	S. Ozdemir, Y. Xiao, Secure data aggregation in wireless sensor networks: a comprehensive overview , Comput. Netw. , vol. 53 (2009), pp.2022-2037	http://dx.doi.org/10.1016/j.adhoc.2014.03.009			<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-03-009/br/b0145>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-03-009/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-03-009/ctx/ctx0008>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-03-009/itrp/0016	'Their functionalities are sometimes gathering and processing data from each sensor node before forwarding non-redundant information, sending commands to the sensor network, facilitating authentication schemes, etc. [29][[ refid=''b0145'' ]].'				100_classified_citeAsReview
cites	Related work	M. Reed, P. Syverson, D. Goldschlag, Anonymous connections and onion routing , IEEE J. Sel. Areas Commun. , vol. 16 (1998), pp.482-494	http://dx.doi.org/10.1016/j.adhoc.2014.10.018	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-10-018/br/b0140>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-10-018/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-10-018/ctx/ctx0024>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-10-018/itrp/0010	'The idea of having a cascade of mix servers was expanded in [28][[ refid=''b0140'' ]] which proposed onion routing mechanisms that became the de facto privacy preserving protocols.'				100_classified_extends
cites_as_review	Related work	L. Xu, W. He, S. Li, Internet of things in industries: a survey , IEEE Trans. Ind. Inform. (2014)	http://dx.doi.org/10.1016/j.adhoc.2014.12.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/br/b0110>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/ctx/ctx0022>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/itrp/0066	'Recently, Xu et al. [22][[ refid=''b0110'' ]] has reviewed advances of IoT for industries.'				100_classified_citeAsReview
cites_as_review	Related work	C. Perera, A. Zaslavsky, P. Christen, D. Georgakopoulos, Context aware computing for the internet of things: a survey , IEEE Commun. Surv. Tutorials , vol. 16 (2014), pp.414-454	http://dx.doi.org/10.1016/j.adhoc.2014.12.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/br/b0115>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/ctx/ctx0023>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/itrp/0067	'A comprehensive survey and analysis of context aware systems for the IoT is presented in [23][[ refid=''b0115'' ]].'				100_classified_citeAsReview
cites_as_review	Related work	D. Singh, G. Tripathi, A.J. Jara, A survey of Internet-of-Things: Future vision, architecture, challenges and services, in: 2014 IEEE World Forum on Internet of Things (WF-IoT), Seoul, Korea, 2014, pp. 287–292.	http://dx.doi.org/10.1016/j.adhoc.2014.12.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/br/b0100>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/ctx/ctx0020>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/itrp/0068	'More recently, an insight on IoT vision, architecture, and services has been presented in [20][[ refid=''b0100'' ]].'				100_classified_citeAsReview
cites_as_review	Related work	D. Zeng, S. Guo, Z. Cheng, The web of things: a survey , J. Commun. , vol. 6 (2011), pp.424-438	http://dx.doi.org/10.1016/j.adhoc.2014.12.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/br/b0130>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/ctx/ctx0026>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/itrp/0070	'To the best of our knowledge, the work in [26][[ refid=''b0130'' ]] is the only comprehensive WoT survey.'				100_classified_citeAsReview
cites_as_review	Related work	T.-Y. Chung, I. Mashal, O. Alsaryrah, V. Huy, W.-H. Kuo, D.P. Agrawal, Social web of things: a survey , 19th IEEE International Conference on Parallel and Distributed Systems, IEEE (2013)	http://dx.doi.org/10.1016/j.adhoc.2014.12.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/br/b0135>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/ctx/ctx0027>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/itrp/0071	'Other than our previous work in [27][[ refid=''b0135'' ]], no other researcher has conducted any survey on SWoT.'				100_classified_citeAsReview
cites_as_review	Related work	C.-W. Tsai, C.-F. Lai, M.-C. Chiang, L.T. Yang, Data mining for internet of things: a survey , IEEE Commun. Surv. Tutorials , vol. 16 (2014), pp.77-97	http://dx.doi.org/10.1016/j.adhoc.2014.12.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/br/b0120>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/ctx/ctx0024>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/itrp/0072	'Tsai et al. [24][[ refid=''b0120'' ]] analyze and discuss several studies on applying data mining techniques for the IoT from different perspective.'				100_classified_citeAsReview
cites_as_review	Related work	T.L. Koreshoff, T. Robertson, T.W. Leong, Internet of things: a review of literature and products , Proceedings of the 25th Australian Computer–Human Interaction Conference. Augmentation, Application, Innovation, Collaboration, ACM (2013)	http://dx.doi.org/10.1016/j.adhoc.2014.12.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/br/b0125>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/ctx/ctx0025>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/itrp/0073	'Koreshoff et al. [25][[ refid=''b0125'' ]] examine and review 93 commercial products of the IoT and provide insights and full details of the types of sensors to be used in these applications by categorizing them and show how people can easily interact with them.'				100_classified_citeAsReview
cites_as_review	Related work	D. Miorandi, S. Sicari, F. De Pellegrini, I. Chlamtac, Internet of things: vision, applications and research challenges , Ad Hoc Netw. , vol. 10 (2012), pp.1497-1516	http://dx.doi.org/10.1016/j.adhoc.2014.12.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/br/b0095>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/ctx/ctx0019>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/itrp/0150	'Another good survey is [19][[ refid=''b0095'' ]] where IoT key issues, research challenges, and research directions have been identified.'				100_classified_citeAsReview
cites_as_review	Related work	L. Atzori, A. Iera, G. Morabito, The internet of things: a survey , Comput. Netw. , vol. 54 (2010), pp.2787-2805	http://dx.doi.org/10.1016/j.adhoc.2014.12.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/br/b0090>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/ctx/ctx0018>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/itrp/0151	'Atzori et al. [18][[ refid=''b0090'' ]] provide a comprehensive survey the IoT from three different angles: Internet, things, and semantics.'				100_classified_citeAsReview
cites_as_review	Related work	K. Al Nuaimi, M. Al Nuaimi, N. Mohamed, I. Jawhar, K. Shuaib, Web-based wireless sensor networks: a survey of architectures and applications , Proceedings of the 6th International Conference on Ubiquitous Information Management and Communication, ACM (2012)	http://dx.doi.org/10.1016/j.adhoc.2014.12.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/br/b0065>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/ctx/ctx0013>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/itrp/0152	'A survey on Web-based wireless sensor architecture and Web applications is presented in [13][[ refid=''b0065'' ]], including design challenges for sensor Web.'				100_classified_citeAsReview
cites_as_review	Related work	J. Yick, B. Mukherjee, D. Ghosal, Wireless sensor network survey , Comput. Netw. , vol. 52 (2008), pp.2292-2330	http://dx.doi.org/10.1016/j.adhoc.2014.12.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/br/b0060>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/ctx/ctx0012>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/itrp/0153	'Similarly, a comprehensive survey can be found in [12][[ refid=''b0060'' ]] where the authors summarize and compare different designs, platform, algorithms, communication protocols, and services.'				100_classified_citeAsReview
cites_as_review	Related work	I.F. Akyildiz, W. Su, Y. Sankarasubramaniam, E. Cayirci, Wireless sensor networks: a survey , Comput. Netw. , vol. 38 (2002), pp.393-422	http://dx.doi.org/10.1016/j.adhoc.2014.12.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/br/b0055>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/ctx/ctx0011>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/itrp/0154	'In the WSN field, a comprehensive survey of WSN design issues, protocols, physical constraints, routing, and applications has been introduced in [11][[ refid=''b0055'' ]].'				100_classified_citeAsReview
cites_as_review	Related work	F. Oppermann, C. Boano, K. Römer, A decade of wireless sensing applications: survey and taxonomy , The Art of Wireless Sensor Networks, Springer (2014)	http://dx.doi.org/10.1016/j.adhoc.2014.12.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/br/b0085>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/ctx/ctx0017>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/itrp/0156	'Different sensor network applications survey has been conducted, with most recent work presented in [17][[ refid=''b0085'' ]] where the authors cover a large number of applications from different domains.'				100_classified_citeAsReview
cites_as_review	Related work	M. Chen, J. Wan, S. Gonzalez, X. Liao, V.C.M. Leung, A survey of recent developments in home M2M networks , IEEE Commun. Surv. Tutorials , vol. 16 (2014), pp.98-114	http://dx.doi.org/10.1016/j.adhoc.2014.12.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/br/b0080>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/ctx/ctx0016>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/itrp/0157	'More recently, Chen et al. [16][[ refid=''b0080'' ]] survey and summarize advancements in home communication technologies specifically for Machine-to-Machine (M2M) exchange, and discuss state-of-the-art research on recent developments in communication protocols.'				100_classified_citeAsReview
cites_as_review	Related work	J.J. Rodrigues, P.A. Neves, A survey on IP-based wireless sensor network solutions , Int. J. Commun Syst , vol. 23 (2010), pp.963-981	http://dx.doi.org/10.1016/j.adhoc.2014.12.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/br/b0070>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/ctx/ctx0014>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2014-12-006/itrp/0159	'Analogously, the research activities reported in [14][[ refid=''b0070'' ]] provide an overview of architectures for IP-based sensor networks.'				100_classified_citeAsReview
cites_as_review	Multimedia sensing in IoMT	Ian F. Akyildiz, Ismail H. Kasimoglu, Wireless sensor and actor networks: research challenges , Ad Hoc Netw. , vol. 2 (2004), pp.351-367	http://dx.doi.org/10.1016/j.adhoc.2015.04.006			<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-04-006/br/b0170>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-04-006/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-04-006/ctx/ctx0020>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-04-006/itrp/0061	'These sensor devices are supposed to report the acquired data to the actors, which are intelligent and resource rich devices possessing high energy, processing and communicating capabilities [34][[ refid=''b0170'' ]].'				100_classified_citeAsReview
extends	Introduction	I.R. Chen, J. Guo, Dynamic hierarchical trust management of mobile groups and its application to misbehaving node detection, in: 28th IEEE International Conference on Advanced Information Networking and Applications, Victoria, Canada, 2014.	http://dx.doi.org/10.1016/j.adhoc.2015.05.004	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-05-004/br/b0205>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-05-004/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-05-004/ctx/ctx0007>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-05-004/itrp/0039	'This paper substantially extends from [41][[ refid=''b0205'' ]] by adding simulation validation using ns-3 (Section 5) as well as new materials, including a theoretical analysis of the protocol’s convergence, accuracy and resiliency properties (Section 4), a sensitivity analysis of the effect of trust formation on application performance (Section 6), and a discussion on applicability (Section 7).'				100_classified_extends
cites_as_review	Background and related work	S. Panichpapiboon, W. Pattara-Atikom, A review of information dissemination protocols for vehicular ad hoc networks , IEEE Commun. Surv. Tutor. , vol. 14 (2012), pp.784-798	http://dx.doi.org/10.1016/j.adhoc.2015.08.021	related work	background	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-08-021/br/bib0011>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-08-021/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-08-021/ctx/ctx0011>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-08-021/itrp/0052	'The basic approach that is commonly used for broadcast mitigation is to decrease the number of redundant data packets so that the delivery overhead is reduced, by selecting only a subset of vehicles to rebroadcast [11][[ refid=''bib0011'' ]].'				100_classified_citeAsReview
cites_as_review	Background and related work	A. Boukerche, Handbocites as review of Algorithms for Wireless Networking and Mobile Computing , None, CRC Press (2005)	http://dx.doi.org/10.1016/j.adhoc.2015.08.021	related work	background	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-08-021/br/bib0010>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-08-021/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-08-021/ctx/ctx0010>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-08-021/itrp/0053	'For a basic overview on mobile networks, we refer to [10][[ refid=''bib0010'' ]].'				100_classified_citeAsReview
cites_as_review	Introduction	B. Tavli, K. Bicakci, R. Zilan, J.M. Barcelo-Ordinas, A survey of visual sensor network platforms , Multimedia Tools Appl. , vol. 60 (2012), pp.689-726	http://dx.doi.org/10.1016/j.adhoc.2015.08.026	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-08-026/br/bib0007>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-08-026/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-08-026/ctx/ctx0006>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2015-08-026/itrp/0035	'Besides, bandwidth requirements for carrying visual data are also much higher [7][[ refid=''bib0007'' ]].'				100_classified_citeAsReview
cites_as_review	Formation of ICMANET	G. Tyson, N. Sastry, R. Cuevas, I. Rimac, A. Mauthe, A survey of mobility in information-centric networks , Commun. ACM , vol. 56 (2013), pp.90-98	http://dx.doi.org/10.1016/j.adhoc.2016.04.005			<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-04-005/br/bib0046>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-04-005/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-04-005/ctx/ctx0031>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-04-005/itrp/0084	'Thus, it allows the applications to publish and consume content directly through its name without being aware of the network-layer address [46][[ refid=''bib0046'' ]].'				100_classified_citeAsReview
cites_as_review	Formation of ICMANET	G. Tyson, N. Sastry, R. Cuevas, I. Rimac, A. Mauthe, A survey of mobility in information-centric networks , Commun. ACM , vol. 56 (2013), pp.90-98	http://dx.doi.org/10.1016/j.adhoc.2016.04.005			<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-04-005/br/bib0046>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-04-005/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-04-005/ctx/ctx0033>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-04-005/itrp/0086	'Normally, content retrieval in HCN depends strongly on location concept in the content identifier(e.g., URL) [46][[ refid=''bib0046'' ]].'				100_classified_citeAsReview
cites_as_review	Introduction	G. Kumar, K. Kumar, M. Sachdeva, The use of artificial intelligence based techniques for intrusion detection: a review , Artif. Intell. Rev. , vol. 34 (2010), pp.369-387	http://dx.doi.org/10.1016/j.adhoc.2016.06.013	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-06-013/br/bib0006>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-06-013/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-06-013/ctx/ctx0006>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-06-013/itrp/0010	'For example, in [6][[ refid=''bib0006'' ]], comparison among various InetIntel techniques for intrusion detection systems showed HIT''s superiority in achieving higher detection accuracy.'				100_classified_citeAsReview
cites	Overview of NetMem	S. Paul, An optimized distributed association rule mining algorithm in parallel and distributed data mining with xml data for improved response time , Int. J. Comput. Sci. Inform. Technol. , vol. 2 (2010), pp.88-101	http://dx.doi.org/10.1016/j.adhoc.2016.06.013			<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-06-013/br/bib0020>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-06-013/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-06-013/ctx/ctx0040>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-06-013/itrp/0066	'Those reports might reveal the occurrence of abnormal services or attacks;(b)Pattern learning which executes algorithms and statistical analysis models for StM data attributes and features discovery (e.g., ARL [20][[ refid=''bib0020'' ]]).'				100_classified_citeAsReview
cites_as_review	Introduction	J.M.T. Portocarrero, F.C. Delicato, P.F. Pires, N. Gámez, L. Fuentes, D. Ludovino, P. Ferreira, Autonomic wireless sensor networks: a systematic literature review , J. Sensors. , vol. 2014 (2014), pp.None	http://dx.doi.org/10.1016/j.adhoc.2016.11.004	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/br/bib0008>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/ctx/ctx0008>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/itrp/0014	'We argued in [8][[ refid=''bib0008'' ]] that middleware systems developed until today are valuable tools for assisting developers to build distributed applications, and for dealing with heterogeneity and distribution issues.'				100_classified_citeAsReview
cites_as_review	Introduction	C.M. De Farias, W. Li, F.C. Delicato, L. Pirmez, A.Y. Zomaya, P.F. Pires, J.N. De Souza, A systematic review of shared sensor networks , ACM Comput. Surv. , vol. 48 (2016), pp.1-50	http://dx.doi.org/10.1016/j.adhoc.2016.11.004	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/br/bib0005>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/ctx/ctx0005>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/itrp/0027	'However, when we consider more complex applications, with dynamic requirements, or when multiple applications share the WSN infrastructure [5][[ refid=''bib0005'' ]], the need for a more advanced, dynamically reconfigurable architecture, is evident.'				100_classified_citeAsReview
cites_as_review	Introduction	M.-M. Wang, J.-N. Cao, J. Li, S.K. Dasi, Middleware for wireless sensor networks: a survey , J. Comput. Sci. Technol. , vol. 23 (2008), pp.305-326	http://dx.doi.org/10.1016/j.adhoc.2016.11.004	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/br/bib0006>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/ctx/ctx0006>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/itrp/0028	'The above-mentioned characteristics require the use of specific middleware systems to WSNs [6][[ refid=''bib0006'' ]].'				100_classified_citeAsReview
uses_method_in	RAMSES evaluation	J.M.T. Portocarrero, F.C. Delicato, P.F. Pires, E.Y. Nakagawa, F. Oquendo, Self-adaptive middleware for wireless sensor networks: a reference architecture , Proceedings of the 2015 European Conference on Software Architecture Workshops - ECSAW ’15, ACM Press (2015)	http://dx.doi.org/10.1016/j.adhoc.2016.11.004	results		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/br/bib0015>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/ctx/ctx0059>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/itrp/0038	'We followed the recommendations as prescribed by FERA to conduct the evaluation of the two versions of RAMSES (the one published in [15][[ refid=''bib0015'' ]] - without considering RAModel - and the evolved version described in this paper).'				100_classified_extends
cites_as_review	The technical details of RAMSES	Z. Yang, Z. Li, Z. Jin, Y. Ghen, A systematic literature review of requirements modeling and analysis for self-adaptive systems , REFSQ, Springer (2014)	http://dx.doi.org/10.1016/j.adhoc.2016.11.004			<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/br/bib0027>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/ctx/ctx0039>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/itrp/0063	'For instance, Yang et al. [27][[ refid=''bib0027'' ]] adds adaptability as a relevant quality characteristic of self-adaptive systems.'				100_classified_citeAsReview
cites_as_review	Introduction	F.D. Macías-Escrivá, R. Haber, R. del Toro, V. Hernandez, Self-adaptive systems: a survey of current approaches, research challenges and applications , Expert Syst. Appl. , vol. 40 (2013), pp.7267-7279	http://dx.doi.org/10.1016/j.adhoc.2016.11.004	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/br/bib0011>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/ctx/ctx0011>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/itrp/0076	'These elements are known as MAPE-K model (Monitor, Analyze, Plan, Execute and Knowledge Base) [11][[ refid=''bib0011'' ]].'				100_classified_citeAsReview
cites_as_review	Introduction	J.M.T. Portocarrero, F.C. Delicato, P.F. Pires, N. Gámez, L. Fuentes, D. Ludovino, P. Ferreira, Autonomic wireless sensor networks: a systematic literature review , J. Sensors. , vol. 2014 (2014), pp.None	http://dx.doi.org/10.1016/j.adhoc.2016.11.004	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/br/bib0008>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/ctx/ctx0015>				http://www.scar.disi.unibo.it/r/10-1016-j-adhoc-2016-11-004/itrp/0080	'The RA was conceived based on some noticeable self-adaptive middleware systems for WSNs, as identified and described in [8][[ refid=''bib0008'' ]].'				100_classified_citeAsReview
cites_as_review	Introduction	D. Baccarini, The concept of project complexity—a review , Int J Project Manage , vol. 14 (1996), pp.201-204	http://dx.doi.org/10.1016/j.advengsoft.2009.11.006	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2009-11-006/br/bib6>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2009-11-006/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2009-11-006/ctx/ctx0003>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2009-11-006/itrp/0050	'The main feature of complexity is structural uncertainty, viewed in terms of differentiation and interdependence [6][[ refid=''bib6'' ]].'				100_classified_citeAsReview
extends	Related work	W.S. Xu, J.Z. Cha, M. Sobolewski, A service-oriented collaborative design platform for concurrent engineering , Adv Mater Res , vol. 44 (2008), pp.717-724	http://dx.doi.org/10.1016/j.advengsoft.2009.11.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2009-11-006/br/bib127>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2009-11-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2009-11-006/ctx/ctx0058>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2009-11-006/itrp/0075	'This paper is an updated and improved version of the conference paper [127][[ refid=''bib127'' ]].'				100_classified_extends
cites_as_review	Related work	Weiming Shen, Qi Hao, Weidong Li, Computer supported collaborative design: retrospective and perspective , Comput Ind , vol. 59 (2008), pp.855-862	http://dx.doi.org/10.1016/j.advengsoft.2009.11.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2009-11-006/br/bib101>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2009-11-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2009-11-006/ctx/ctx0037>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2009-11-006/itrp/0078	'A comprehensive review of the R&D literature on computer supported collaborative design (CSCD) can be found in [101][[ refid=''bib101'' ]], from the pre-CSCD technologies of the 1980s to today’s state-of-the-art CSCD.'				100_classified_citeAsReview
cites	Related work	OpenNEbula Project. <	http://dx.doi.org/10.1016/j.advengsoft.2011.05.007	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-05-007/br/b0085>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-05-007/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-05-007/ctx/ctx0005>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-05-007/itrp/0018	'The OpenNEbula system extends the benefits of virtualization platforms from a single physical resource to a pool of resources, decoupling the server, not only from the physical infrastructure but also from the physical location [17][[ refid=''b0085'' ]].'				100_classified_extends
cites_as_review	Introduction	C. Mateos, A. Zunino, M. Campo, A survey on approaches to gridification , Software: Pract Exp , vol. 38 (2008), pp.523-556	http://dx.doi.org/10.1016/j.advengsoft.2011.08.006	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-08-006/br/b0130>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-08-006/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-08-006/ctx/ctx0002>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-08-006/itrp/0023	'The inherent distributed and parallel nature of Grid applications, however, places a huge burden on regular users willing to exploit the hardware capabilities of such supercomputers, since a significant development effort and knowledge on distributed and parallel programming are required to put a Grid application to work [26][[ refid=''b0130'' ]].'				100_classified_citeAsReview
cites_as_review	Introduction	C. Mateos, A. Zunino, M. Campo, A survey on approaches to gridification , Software: Pract Exp , vol. 38 (2008), pp.523-556	http://dx.doi.org/10.1016/j.advengsoft.2011.08.006	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-08-006/br/b0130>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-08-006/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-08-006/ctx/ctx0005>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-08-006/itrp/0027	'Consequently, introducing purely algorithmic optimizations remain error prone and require a considerable amount of testing [26][[ refid=''b0130'' ]], which demands time and effort.'				100_classified_citeAsReview
cites_as_review	Introduction	C. Mateos, A. Zunino, M. Campo, A survey on approaches to gridification , Software: Pract Exp , vol. 38 (2008), pp.523-556	http://dx.doi.org/10.1016/j.advengsoft.2011.08.006	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-08-006/br/b0130>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-08-006/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-08-006/ctx/ctx0006>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2011-08-006/itrp/0028	'The recent notion of “gridification” [26][[ refid=''b0130'' ]] has introduced a radical twist in the way Grid applications are built.'				100_classified_citeAsReview
cites_as_review	Related work	Birkmeier D, Overhage S. On componenet identification approaches – classification, state of the art, and comparision. In: Lewis GA, Poernomo I, Hofmeister C. editors. 12th international symposium on component-based software engineering, vol. LNCS 5582. 2009. p. 1–18.	http://dx.doi.org/10.1016/j.advengsoft.2012.08.002	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/br/b0145>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/ctx/ctx0024>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/itrp/0007	'Birkmeier and Overhage [29][[ refid=''b0145'' ]] presented a survey on the state of the art in component identification and introduced a classification scheme to analyze the respective strengths and weaknesses of different approaches.'				100_classified_citeAsReview
cites_as_review	Related work	Land R, Blankers L, Chaudron M, Crnkovic I. Cots selection best practices in literature and in industry. In: Proceedings of the 10th international conference on software reuse: high confidence software reuse in large systems; 2008. p. 100–11.	http://dx.doi.org/10.1016/j.advengsoft.2012.08.002	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/br/b0180>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/ctx/ctx0031>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/itrp/0068	'For instance, Land et al. [36][[ refid=''b0180'' ]] provide a literature survey of component selection techniques and present a meta-model to compare existing component selection techniques.'				100_classified_citeAsReview
cites_as_review	Related work	Mohamed A, Ruhe G, Eberlein A. Cots selection: past, present, and future. In: Proceedings of the 14th annual IEEE international conference and workshops on the engineering of computer-based systems. 2007. p. 103–14.	http://dx.doi.org/10.1016/j.advengsoft.2012.08.002	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/br/b0185>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/ctx/ctx0032>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/itrp/0071	'In another survey paper, Mohamed et al. [37][[ refid=''b0185'' ]] evaluate eighteen different component selection approaches and present a set of open research questions surrounding the component selection problem.'				100_classified_citeAsReview
uses_method_in	Goal-oriented specification and model	A. van Lamsweerde, Requirements engineering from system goals to UML models to software specifications , None, Wiley (2009)	http://dx.doi.org/10.1016/j.advengsoft.2012.08.002	model		<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/br/b0070>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/ctx/ctx0050>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/itrp/0086	'In this paper, we adopt goal elicitation approach presented in [14][[ refid=''b0070'' ]].'				100_classified_extends
cites	Related work	M. Qureshi, S. Hussain, A reusable software component-based development process model , Adv Eng Software , vol. 39 (2008), pp.88-94	http://dx.doi.org/10.1016/j.advengsoft.2012.08.002	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/br/b0095>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/ctx/ctx0014>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-08-002/itrp/0099	'Fig. 1 gives an overview of the CBS development life cycle, adapted from [19][[ refid=''b0095'' ]].'				100_classified_citeAsReview
cites	Background and related work	A. Walker, M. Recker, K. Lawless, D. Wiley, Collaborative information filtering: a review and an educational application , Int J Artific Intell Educ , vol. 14 (2004), pp.1-26	http://dx.doi.org/10.1016/j.advengsoft.2012.10.005	related work	background	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-10-005/br/b0220>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-10-005/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-10-005/ctx/ctx0024>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2012-10-005/itrp/0007	'Altered Vista system, by Walker et al. [44][[ refid=''b0220'' ]], has been proposed for the recommendation of learning objects based on collaborative filtering applied in an educational setting.'				100_classified_citeAsReview
cites	Ultra large scale systems	Northrop L, Feiler P, Gabriel RP, Goodenough J, Linger R, Kazman R, et al. Ultra-large-scale systems-the software challenge of the future. Technical report Software Engineering Institute Carnegie Mellon University ISBN. 2006.	http://dx.doi.org/10.1016/j.advengsoft.2013.07.003			<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-07-003/br/b0005>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-07-003/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-07-003/ctx/ctx0001>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-07-003/itrp/0028	'As inferred from the name ‘ultra large scale systems’, this type of system includes those whose scale and size are far beyond today’s systems [1][[ refid=''b0005'' ]].'				100_classified_citeAsReview
cites	Ultra large scale systems	Northrop L, Feiler P, Gabriel RP, Goodenough J, Linger R, Kazman R, et al. Ultra-large-scale systems-the software challenge of the future. Technical report Software Engineering Institute Carnegie Mellon University ISBN. 2006.	http://dx.doi.org/10.1016/j.advengsoft.2013.07.003			<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-07-003/br/b0005>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-07-003/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-07-003/ctx/ctx0002>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-07-003/itrp/0029	'The scale in ultra large scale systems changes everything [1][[ refid=''b0005'' ]].'				100_classified_citeAsReview
cites_as_review	Introduction	S. Subashini, V. Kavitha, A survey on security issues in service delivery models of cloud computing , J Netw Comput Appl , vol. 34 (2011), pp.1-11	http://dx.doi.org/10.1016/j.advengsoft.2013.12.006	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-006/br/b0075>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-006/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-006/ctx/ctx0002>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-006/itrp/0009	'Many users are increasing realizing that they can use cloud services to gain applications and resources rapidly, flexibly, and cheaply [16][[ refid=''b0075'' ]].'				100_classified_citeAsReview
uses_method_in	Results and discussion	Liang J, Suganthan P, Deb K. Novel composition test functions for numerical global optimization. In: Swarm intelligence symposium, 2005. SIS 2005. Proceedings 2005 IEEE; 2005. p. 68–75.	http://dx.doi.org/10.1016/j.advengsoft.2013.12.007	discussion	results	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-007/br/b0260>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-007/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-007/ctx/ctx0022>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-007/itrp/0001	'Note that a detailed descriptions of the composite benchmark functions are available in the CEC 2005 technical report [52][[ refid=''b0260'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Results and discussion	Liang J, Suganthan P, Deb K. Novel composition test functions for numerical global optimization. In: Swarm intelligence symposium, 2005. SIS 2005. Proceedings 2005 IEEE; 2005. p. 68–75.	http://dx.doi.org/10.1016/j.advengsoft.2013.12.007	results	discussion	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-007/br/b0260>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-007/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-007/ctx/ctx0020>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-007/itrp/0004	'The other test beds that we have chosen are six composite benchmark functions from a CEC 2005 special session [52][[ refid=''b0260'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	GWO for classical engineering problems	X.S. Yang, Nature-inspired metaheuristic algorithms , None, Luniver Press (2011)	http://dx.doi.org/10.1016/j.advengsoft.2013.12.007			<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-007/br/b0315>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-007/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-007/ctx/ctx0031>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2013-12-007/itrp/0054	'Note that we use a similar penalty function for GWO to perform a fair comparison [63][[ refid=''b0315'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites_as_review	Addressing the semantic gap problem	Kristensen T, Lamo Y, Hole GO, Hinna K. Different E-learning paradigms – a survey; 2007. <	http://dx.doi.org/10.1016/j.advengsoft.2014.01.001			<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2014-01-001/br/b0085>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2014-01-001/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2014-01-001/ctx/ctx0015>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2014-01-001/itrp/0089	'A concept map is a tool for representing and organizing knowledge [17][[ refid=''b0085'' ]] which is usually formed by assembling a constellation of concepts.'				100_classified_citeAsReview
cites_as_review	Background and related work	R.T. Azuma, A survey of augmented reality , Presence: Teleoper Virtual Environ , vol. 6 (1997), pp.355-385	http://dx.doi.org/10.1016/j.advengsoft.2015.06.005	background	related work	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-06-005/br/bib0029>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-06-005/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-06-005/ctx/ctx0009>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-06-005/itrp/0018	'Augmented reality is therefore the middle segment of continuum where virtual elements are added to real world [29][[ refid=''bib0029'' ]].'				100_classified_citeAsReview
cites	Background and related work	C. Eastman, P. Teicholz, K. Liston, BIM handbocites as review , None, Wiley (2008)	http://dx.doi.org/10.1016/j.advengsoft.2015.06.005	background	related work	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-06-005/br/bib0009>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-06-005/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-06-005/ctx/ctx0015>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-06-005/itrp/0046	'Ideally it should include all the data needed for the construction instead of the data being scattered throughout numerous drawings, folders, tables, reports, documents, etc. [9][[ refid=''bib0009'' ]].'				100_classified_citeAsReview
cites_as_review	Research methods	S.O. Migiro, B.A. Magangi, Mixed methods: a review of literature and the future of the new research paradigm , Afr J Bus Manage Acad J Rev , vol. 5 (2011), pp.3757-3764	http://dx.doi.org/10.1016/j.advengsoft.2015.08.009	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-08-009/br/bib0041>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-08-009/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-08-009/ctx/ctx0004>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-08-009/itrp/0055	'Thirdly, mixed research methods make it possible to elicit supplemental data which bolster research effectiveness [41][[ refid=''bib0041'' ]].'				100_classified_citeAsReview
cites_as_review	BIM systems: a state-of-the-art classification	J. Wong, X. Wang, H. Li, G. Chan, H. Li, A review of cloud-based BIM technology in the construction sector , ITcon , vol. 19 (2014), pp.281-291	http://dx.doi.org/10.1016/j.advengsoft.2015.08.009			<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-08-009/br/bib0062>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-08-009/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-08-009/ctx/ctx0037>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2015-08-009/itrp/0062	'For other applications of cloud BIM, see Wong et al. [62][[ refid=''bib0062'' ]].'				100_classified_citeAsReview
cites_as_review	Introduction	C. Sun, S. Jiang, M.J. Skibniewski, Q. Man, L. Shen, A literature review of the factors limiting the application of BIM in the construction industry , None (2015)	http://dx.doi.org/10.1016/j.advengsoft.2016.07.006	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2016-07-006/br/bib0008>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2016-07-006/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2016-07-006/ctx/ctx0007>				http://www.scar.disi.unibo.it/r/10-1016-j-advengsoft-2016-07-006/itrp/0036	'Another deficiency limiting the application of BIM is the lack of functions to support remote collaboration [8][[ refid=''bib0008'' ]].'				100_classified_citeAsReview
cites	Introduction	P. Biddiscombe, 3D laser scan tunnel inspections keep expressway infrastructure project on schedule, White Paper, Trimble, 2005.	http://dx.doi.org/10.1016/j.aei.2009.08.006	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-08-006/br/bib8>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-08-006/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-08-006/ctx/ctx0018>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-08-006/itrp/0070	'Biddiscombe [8][[ refid=''bib8'' ]] reported the use of laser scanning on an actual tunneling project for controlling as-built dimensions.'				100_classified_citeAsReview
cites_as_review	Introduction	F. Arman, J.K. Aggarwal, Model-based object recognition in dense-range images: a review , Computing Surveys (CSUR) , vol. 25 (1993), pp.5-43	http://dx.doi.org/10.1016/j.aei.2009.08.006	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-08-006/br/bib4>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-08-006/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-08-006/ctx/ctx0016>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-08-006/itrp/0084	'Indeed, in object recognition, it is important that the data representation be unambiguous: No two objects should have the same representation [4][[ refid=''bib4'' ]].'				100_classified_citeAsReview
cites_as_review	Introduction	N. Bakis, G. Aouad, M. Kagioglou, Towards distributed product data sharing environments – progress so far and future challenges , Automation in Construction , vol. 16 (2007), pp.586-595	http://dx.doi.org/10.1016/j.aei.2009.09.001	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/br/bib7>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/ctx/ctx0008>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/itrp/0001	'Bakis et al. [7][[ refid=''bib7'' ]] conducted a comprehensive literature review on the development of standard building data models and model mapping languages.'				100_classified_citeAsReview
cites_as_review	Introduction	T. Froese, Z. Han, M. Alldritt, Study of information technology development for the Canadian construction industry , Canadian Journal of Civil Engineering , vol. 34 (2007), pp.817-829	http://dx.doi.org/10.1016/j.aei.2009.09.001	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/br/bib20>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/ctx/ctx0002>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/itrp/0005	'According to an industrial survey on the Canadian construction IT industry [20][[ refid=''bib20'' ]], “the most frequently identified issue is related to collaboration (including communications, document management, and interoperability)”.'				100_classified_citeAsReview
cites_as_review	Introduction	S. Boddy, Y. Rezgui, G. Cooper, M. Wetherill, Computer integrated construction: a review and proposals for future direction , Advances in Engineering Software , vol. 38 (2007), pp.677-687	http://dx.doi.org/10.1016/j.aei.2009.09.001	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/br/bib10>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/ctx/ctx0006>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/itrp/0013	'Boddy et al. [10][[ refid=''bib10'' ]] provided a review of the construction IT literature in general and drawn an excellent research landscape of the computer-integrated construction.'				100_classified_citeAsReview
cites_as_review	Introduction	U. Isikdag, G. Aouad, J. Underwood, S., Wu, Building information models: a review on storage and exchange mechanisms, in: Proceedings of the CIB W78’s 24th International Conference on IT in Construction, Maribor, Slovenia, June 26–29, 2007, pp. 135–143,	http://dx.doi.org/10.1016/j.aei.2009.09.001	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/br/bib35>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/ctx/ctx0007>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/itrp/0014	'Isikdag et al. [35][[ refid=''bib35'' ]] presented some historical background of building information modeling (BIM) and particularly reviewed the storage and exchange mechanisms for building information models.'				100_classified_citeAsReview
cites_as_review	Challenging research issues and state-of-the-art	H.V.D. Parunak, What can agents do in industry, and why? An overview of industrially-oriented R&D at CEC , Cooperative information agents II, Springer (1998)	http://dx.doi.org/10.1016/j.aei.2009.09.001			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/br/bib54>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/ctx/ctx0036>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/itrp/0042	'Parunak [54][[ refid=''bib54'' ]] has analyzed where agent technology can be best used in industrial applications: “agents are best suited for applications that are modular, decentralized, changeable, ill-structured, and complex”.'				100_classified_citeAsReview
cites_as_review	Challenging research issues and state-of-the-art	T. Froese, Z. Han, M. Alldritt, Study of information technology development for the Canadian construction industry , Canadian Journal of Civil Engineering , vol. 34 (2007), pp.817-829	http://dx.doi.org/10.1016/j.aei.2009.09.001			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/br/bib20>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/ctx/ctx0024>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/itrp/0076	'According to the industrial survey on the Canadian construction IT industry [20][[ refid=''bib20'' ]], about half (49%) of the construction IT tools developed in Canada use Web-based systems as their implementation technology.'				100_classified_citeAsReview
cites_as_review	Challenging research issues and state-of-the-art	N. Bakis, G. Aouad, M. Kagioglou, Towards distributed product data sharing environments – progress so far and future challenges , Automation in Construction , vol. 16 (2007), pp.586-595	http://dx.doi.org/10.1016/j.aei.2009.09.001			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/br/bib7>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/ctx/ctx0016>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-09-001/itrp/0144	'Bakis et al. [7][[ refid=''bib7'' ]] have done a comprehensive review of the research literature on data interoperability or “integration through product sharing and exchange”.'				100_classified_citeAsReview
cites_as_review	Knowledge sharing: first generation of KM in AEC	S. Boddy, Y. Rezgui, G. Cooper, M. Wetherill, Computer integrated construction: a review and proposals for future directions , Advances in Engineering Software , vol. 38 (2007), pp.677-687	http://dx.doi.org/10.1016/j.aei.2009.12.001			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-12-001/br/bib19>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-12-001/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-12-001/ctx/ctx0080>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-12-001/itrp/0058	'Here, the ability to share design data and drawings electronically through either proprietary drawing formats or via later de facto standards such as DXF (drawing/data exchange format), together with the added dimension of drawing layering had substantial impacts on business processes and workflows in the AEC industry [19][[ refid=''bib19'' ]].'				100_classified_citeAsReview
cites_as_review	Generation 2: knowledge conceptualization and nurturing	S. Boddy, Y. Rezgui, G. Cooper, M. Wetherill, Computer integrated construction: a review and proposals for future directions , Advances in Engineering Software , vol. 38 (2007), pp.677-687	http://dx.doi.org/10.1016/j.aei.2009.12.001			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-12-001/br/bib19>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-12-001/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-12-001/ctx/ctx0100>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2009-12-001/itrp/0086	'Users in AEC often find it difficult to see clearly how an “ontology” differs from what they already recognize as a “data model”, focusing on the formal nature and structuring mechanisms that seem to be characteristic of both [19][[ refid=''bib19'' ]].'				100_classified_citeAsReview
cites_as_review	Introduction	Y.F. Zhao, X. Xu, S.Q. Xie, Computer-aided inspection planning – the state of the art , Computers in Industry , vol. 60 (2009), pp.453-466	http://dx.doi.org/10.1016/j.aei.2010.05.009	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-009/br/bib13>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-009/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-009/ctx/ctx0009>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-009/itrp/0021	'After a thorough review on CAIP research [13][[ refid=''bib13'' ]], it is found that due to different configurations of the available facilities in various manufacturing environments, inspection processes for all three aforementioned measurement types are mostly planned separated from machining processes.'				100_classified_citeAsReview
cites_as_review	Integrated process planning system for cognitive manufacturing	S.C. Feng, Theodore H. Hopp, A Review of Current Geometric Tolerancing Theories and Inspection Data Analysis Algorithms , None, National Institute of Standard and Technology (NIST) (1991)	http://dx.doi.org/10.1016/j.aei.2010.05.009			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-009/br/bib43>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-009/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-009/ctx/ctx0032>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-009/itrp/0039	'Feng and Hopp [43][[ refid=''bib43'' ]] reviewed the existing inspection data fitting algorithms.'				100_classified_citeAsReview
cites	Research background	J. Nitzsche, T. van Lessen, D. Karastoyanova, F. Leymann, BPEL for semantic web services (BPEL4SWS), On the Move to meaningful Internet Systems 2007: OTM 2007 Workshops, Lecture Notes in Computer Science, 4805/2010, 2007, 179–188.	http://dx.doi.org/10.1016/j.aei.2010.05.012	background		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-012/br/bib44>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-012/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-012/ctx/ctx0057>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-012/itrp/0065	'Another approach that considerably resembles the methodology proposed in this paper is the BPEL for Semantic Web Services (BPEL4SWS) [44][[ refid=''bib44'' ]] language, which extends the standard WS-BPEL 2.0 specification.'				100_classified_extends
cites_as_review	Related work	Z. Bi, W. Zhang, Flexible fixture design and automation: review, issues and future directions , International Journal of Production Research , vol. 39 (2001), pp.2867-2894	http://dx.doi.org/10.1016/j.aei.2010.05.017	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-017/br/bib23>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-017/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-017/ctx/ctx0027>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-017/itrp/0007	'Despite advances in manufacturing systems, modern production is still limited in part flexibility and variety partly due to restricted hardware flexibility, where fixtures and handling systems contribute the most limitations [23][[ refid=''bib23'' ]].'				100_classified_citeAsReview
cites_as_review	Related work	Z. Bi, W. Zhang, Flexible fixture design and automation: review, issues and future directions , International Journal of Production Research , vol. 39 (2001), pp.2867-2894	http://dx.doi.org/10.1016/j.aei.2010.05.017	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-017/br/bib23>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-017/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-017/ctx/ctx0029>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-05-017/itrp/0013	'Bi et al. [23][[ refid=''bib23'' ]] state that fixture planning and configuration make up 10–20% of the total costs in FMSs.'				100_classified_citeAsReview
cites_as_review	Definitions of standpoints	Y. Rezgui, C.J. Hopfe, C. Vorakulpipat, Generations of knowledge management in the architecture, engineering and construction industry: an evolutionary perspective , Advanced Engineering Informatics , vol. 24 (2010), pp.219-228	http://dx.doi.org/10.1016/j.aei.2010.06.003			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-06-003/br/b0490>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-06-003/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-06-003/ctx/ctx0027>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-06-003/itrp/0078	'For related overview of knowledge sharing consult [98][[ refid=''b0490'' ]].'				100_classified_citeAsReview
cites_as_review	BIM from the standpoint of ‘standardisation with ISO STEP’	B.-C. Björk, M. Laakso, CAD standardisation in the construction industry – a process view, Automation in Construction, in press.	http://dx.doi.org/10.1016/j.aei.2010.06.003			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-06-003/br/b0080>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-06-003/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-06-003/ctx/ctx0050>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-06-003/itrp/0094	'For an overview of the development cycles of CAD standards also consult [16][[ refid=''b0080'' ]].'				100_classified_citeAsReview
cites_as_review	BIM from the standpoint of ‘standardisation with ISO STEP’	B.-C. Björk, M. Laakso, CAD standardisation in the construction industry – a process view, Automation in Construction, in press.	http://dx.doi.org/10.1016/j.aei.2010.06.003			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-06-003/br/b0080>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-06-003/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-06-003/ctx/ctx0041>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-06-003/itrp/0108	'A detailed process overview of the standardisation process, as relevant for BIM, is discussed in [16][[ refid=''b0080'' ]].'				100_classified_citeAsReview
cites_as_review	Introduction	N. Iyer, S. Jayanti, K. Lou, Y. Kalyanaraman, K. Ramani, Three-dimensional shape searching: state-of-the-art review and future trends , Comput. Aided Des. , vol. 37 (2005), pp.509-530	http://dx.doi.org/10.1016/j.aei.2010.07.003	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-07-003/br/b0015>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-07-003/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-07-003/ctx/ctx0008>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-07-003/itrp/0016	'Similarity is measured by comparing feature vectors or relational data structures – global features, manufacturing features, graph, histogram, and so on – of two parts with the preprocessing stage of a conversion into a canonical representation, which is invariant to rotation, translation, and scaling [3][[ refid=''b0015'' ]].'				100_classified_citeAsReview
cites_as_review	Introduction	A. Saaksvouri, A. Immonen, Business benefits of a PLM system, in: Product Lifecycle Management, 2005, pp. 99–122 (Chapter 7).	http://dx.doi.org/10.1016/j.aei.2010.07.005	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-07-005/br/b0185>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-07-005/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-07-005/ctx/ctx0006>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-07-005/itrp/0024	'It is also evident from another previous literature review that almost 30 percent of an engineer’s time is actually spent retrieving, distributing and maintaining information [37][[ refid=''b0185'' ]].'				100_classified_citeAsReview
cites	Related work	A. Craig, N. Soules, Gregory R. Ganger, Toward automatic context-based attribute assignment for semantic file systems, Technical report CMU-PDL-04-105. June 2004.	http://dx.doi.org/10.1016/j.aei.2010.08.005	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-08-005/br/b0025>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-08-005/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-08-005/ctx/ctx0021>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-08-005/itrp/0004	'[5][[ refid=''b0025'' ]] develops and evaluates several new approaches to automatically generate file attributes based on context.'				100_classified_citeAsReview
cites	Introduction	A. Craig, N. Soules, Gregory R. Ganger, Toward automatic context-based attribute assignment for semantic file systems, Technical report CMU-PDL-04-105. June 2004.	http://dx.doi.org/10.1016/j.aei.2010.08.005	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-08-005/br/b0025>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-08-005/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-08-005/ctx/ctx0003>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-08-005/itrp/0015	'Unfortunately, these traditional hierarchies often do not scale to large data collections and to the fine-grained classifications required [5][[ refid=''b0025'' ]].'				100_classified_citeAsReview
cites_as_review	Theory of supporting technologies	M.J. Wooldridge, N.R. Jennings, Agent theories, architectures and languages: a survey, in: ECAI94 Workshop on Agent Theories Architectures and Languages, Amsterdam, The Netherlands, 1994, pp. 1–32.	http://dx.doi.org/10.1016/j.aei.2010.11.002	background		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-11-002/br/b0045>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-11-002/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-11-002/ctx/ctx0024>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-11-002/itrp/0007	'Appropriate axiomisation is also relevant in other ways, for example for an agent i, knowing what it knows and what it does not know (the positive and negative introspection axioms 4: K i φ →K i K i φ and 5: ∼ K i φ → K i ∼ K i φ respectively) or believes [9][[ refid=''b0045'' ]], can contribute towards more efficient deliberation and coordination within an MAS.'				100_classified_citeAsReview
cites	Introduction	M.M. Nelson, C. Anumba, Z. Aziz, Towards next generation facilities management systems, in: Joint International Conference on Computing and Decision Making in Civil and Building Engineering, Montréal, Canada, 2006.	http://dx.doi.org/10.1016/j.aei.2010.11.002	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-11-002/br/b0035>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-11-002/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-11-002/ctx/ctx0008>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-11-002/itrp/0016	'• Although some FM tools show some integration with related (same lifecycle stage) systems, Nelson et al. [7][[ refid=''b0035'' ]] report “there are still limitations in the level of communication between different subsystems of an FM system and between the helpdesk and building management systems” as well as “inadequate links between FM and decision analysis tools”.'				100_classified_citeAsReview
cites	Related work	H. Schevers et al., Towards Digital Facility Modelling for Sydney Opera House Using Industry Foundation Classes (IFC) and Semantic Web Technology, ITcon, 2007, pp. 347–362.	http://dx.doi.org/10.1016/j.aei.2010.11.002	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-11-002/br/b0105>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-11-002/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-11-002/ctx/ctx0016>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2010-11-002/itrp/0081	'One specific FM application is reported by [20][[ refid=''b0105'' ]].'				100_classified_citeAsReview
cites	Background	C.H. Caldas, D.G. Torrent, C.T. Haas, Integration of automated data collection technologies for real-time field materials management, in: Proc. the 21st International Symposium on Automation and Robotics in Construction, Jeju, Korea, 2004.	http://dx.doi.org/10.1016/j.aei.2011.01.003	background		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-01-003/br/b0055>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-01-003/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-01-003/ctx/ctx0005>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-01-003/itrp/0035	'According to Caldas et al. [11][[ refid=''b0055'' ]], GPS applications have been applied to construction practices, such as positioning of equipment and surveying.'				100_classified_citeAsReview
uses_method_in	Background	J. Shotton, M. Johnson, R. Cipolla, Semantic texton forests for image categorization and segmentation, in: Proc. CVPR, 2008, pp. 1–8.	http://dx.doi.org/10.1016/j.aei.2011.01.003	background		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-01-003/br/b0185>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-01-003/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-01-003/ctx/ctx0033>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-01-003/itrp/0048	'In this paper, Semantic Texton Forests (STFs) [37][[ refid=''b0185'' ]] are used.'				100_classified_extends
cites	Literature review	X. Fiorentini et al., Towards an ontology for open assembly model, in: International Conference on Product Lifecycle Management, 2007, p. 445–456.	http://dx.doi.org/10.1016/j.aei.2011.02.001			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-02-001/br/b0165>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-02-001/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-02-001/ctx/ctx0019>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-02-001/itrp/0052	'OAM extends CPM to include the representation of assembly products and the relationships between products components [33][[ refid=''b0165'' ]].'				100_classified_extends
cites	Application to Retrieving Relevant Requirements for New Designs	I. Golden, Function based archival and retrieval: developing a repository of biologically inspired product concepts, in Department of Mechanical Engineering, University of Maryland, College Park, 2005.	http://dx.doi.org/10.1016/j.aei.2011.02.001	motivation		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-02-001/br/b0205>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-02-001/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-02-001/ctx/ctx0052>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-02-001/itrp/0058	'A study conducted by Golden reported significant variations in the style and content of the requirement statements as a part of his study [41][[ refid=''b0205'' ]].'				100_classified_citeAsReview
cites_as_review	Overview of RFID technology	RFID Journal, A summary of RFID standards.	http://dx.doi.org/10.1016/j.aei.2011.02.004			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-02-004/br/b0075>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-02-004/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-02-004/ctx/ctx0010>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-02-004/itrp/0089	'As the use of RFID technology for goods tracking becomes prevalent, ISO has also developed relevant standards to cover related air interface protocol (ISO 18000 series) [15][[ refid=''b0075'' ]].'				100_classified_citeAsReview
cites	Consolidated review findings: conceptual foundations & identified shortcomings	S. Ammar-Khodja, N. Perry, A. Bernard, Processing knowledge to support knowledge-based engineering systems specification , Concurrent Engineering-Research and Applications , vol. 16 (2008), pp.89-101	http://dx.doi.org/10.1016/j.aei.2011.06.004			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-06-004/br/b0100>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-06-004/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-06-004/ctx/ctx0024>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-06-004/itrp/0014	'Having reviewed the KBE definitions, the statement of Ammar-Khodja et al. [20][[ refid=''b0100'' ]] is indeed appropriate: the definitions available in literature are quite similar.'				100_classified_citeAsReview
cites_as_review	Related work	W. Shen, Q. Hao, H. Mak, J. Neelamkavil, H. Xie, J. Dickinson, R. Thomas, A. Pardasani, H. Xue, Systems integration and collaboration in architecture, engineering, construction, and facilities management: A review , Advanced Engineering Informatics , vol. 24 (2009), pp.196-207	http://dx.doi.org/10.1016/j.aei.2011.08.005	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-08-005/br/b0180>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-08-005/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-08-005/ctx/ctx0022>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-08-005/itrp/0001	'However, Shen et al. [36][[ refid=''b0180'' ]] noted that one of the major problems on systems interoperability in the construction industry is the difficulty to access accurate data, information, and knowledge in a timely manner in every phase of the construction project lifecycle.'				100_classified_citeAsReview
extends	Ontology framework for multi-model management	J. Wix, T. Liebich, P. Katranuschkov, A. Gehre, Defining the matrix of communication processes in construction to support IFC model development, in: Proceedings of eSM@RT and CISEMIC 2002 conference, Salford, UK, 2002.	http://dx.doi.org/10.1016/j.aei.2011.08.007	model		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-08-007/br/b0215>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-08-007/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-08-007/ctx/ctx0044>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-08-007/itrp/0083	'Moreover, a scenario matrix was developed that extends the process matrix [43][[ refid=''b0215'' ]] to handle multi-model information resources.'				100_classified_extends
cites	State of the art on product ontologies for interoperability	C. Bock, X. Zha, H. Suh, J.-H. Lee, Ontological product modelling for collaborative design , Advanced Engineering Informatics , vol. 24 (2010), pp.510-524	http://dx.doi.org/10.1016/j.aei.2011.12.002			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-12-002/br/b0155>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-12-002/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-12-002/ctx/ctx0028>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2011-12-002/itrp/0013	'In the last years, the research is increasingly focusing on the study of ontology-based approaches for product lifecycles interoperability in extended enterprise: Bock et al. [31][[ refid=''b0155'' ]] describe an example of a product modelling language to support collaborative design, combining the benefits of ontology with expanded capabilities in conventional product modelling language.'				100_classified_extends
cites	Related work	A.P. De Medeiros, D. Schwabe, Kuaba approach: integrating formal semantics and design rationale representation to support design reuse , Artif. Intell. Eng. Des. Anal. Manuf. , vol. 22 (2008), pp.399-419	http://dx.doi.org/10.1016/j.aei.2012.10.005	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2012-10-005/br/b0050>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2012-10-005/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2012-10-005/ctx/ctx0012>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2012-10-005/itrp/0043	'De Medeiros and Schwabe expanded IBIS and added the semantic relations by Kuaba approach, which provides an ontological vocabulary and a set of rules described in F-logic [10][[ refid=''b0050'' ]] in order to support software design reuse.'				100_classified_extends
cites	Related work	R.J. McCall, PHI: a conceptual foundation for design hypermedia , Des. Stud. , vol. 12 (1991), pp.30-41	http://dx.doi.org/10.1016/j.aei.2012.10.005	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2012-10-005/br/b0045>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2012-10-005/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2012-10-005/ctx/ctx0011>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2012-10-005/itrp/0044	'McCall [9][[ refid=''b0045'' ]] proposed the Procedural Hierarchy of Issues (PHI) model, which expands the range of issues in the IBIS model and improves their relationships.'				100_classified_extends
uses_method_in	Quality control methods and system teleonomy	A. Pudmetzky, Teleonomic entropy measuring the phase-space of end-directed system , Applied Mathematics and Computation , vol. 162 (2005), pp.695-705	http://dx.doi.org/10.1016/j.aei.2012.11.007	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2012-11-007/br/b0130>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2012-11-007/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2012-11-007/ctx/ctx0030>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2012-11-007/itrp/0034	'In the following section, we propose an information measure based on modified Carnap’s entropy concept [26][[ refid=''b0130'' ]] that we call expanded tessellation entropy.'				100_classified_extends
cites	System prototype: ConstraintSoup	R.A. Niemeijer, Constraint Specification in Architecture: A User-Oriented Approach for Mass Customization, PhD Thesis, Eindhoven University of Technology, 2011.	http://dx.doi.org/10.1016/j.aei.2013.11.003			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2013-11-003/br/b0135>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2013-11-003/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2013-11-003/ctx/ctx0018>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2013-11-003/itrp/0031	'This work has been documented in [30][[ refid=''b0135'' ]].'				100_classified_extends
cites	Related work	N. Alejandra Segura, E. García-Barriocanal, M. Prieto, An empirical analysis of ontology-based query expansion for learning resource searches using MERLOT and the Gene ontology , Knowl.-Based Syst. , vol. 24 (2011), pp.119-133	http://dx.doi.org/10.1016/j.aei.2014.04.002	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2014-04-002/br/b0060>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2014-04-002/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2014-04-002/ctx/ctx0034>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2014-04-002/itrp/0046	'Alejandra Segura et al. [12][[ refid=''b0060'' ]] revealed that search performance, such as novelty, coverage, and precision, are different according to the relations used when a query is expanded.'				100_classified_extends
uses_method_in	Methodology for developing the ontology-based TC	C.-C. Chang, C.-J. Lin, LIBSVM: a library for support vector machines , ACM Trans. Intell. Syst. Technol. , vol. 2 (2011), pp.1-27	http://dx.doi.org/10.1016/j.aei.2014.05.001	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2014-05-001/br/b0160>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2014-05-001/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2014-05-001/ctx/ctx0025>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2014-05-001/itrp/0009	'This module is constructed using LIBSVM [32][[ refid=''b0160'' ]], computer software designed to perform supervised machine learning based on the support vector machine (SVM) model.'			FDY+AGA	infered_pred1
cites	Introduction	G. Klyne, J.J. Carroll, Resource Description Framework (RDF): Concepts and Abstract Syntax, <	http://dx.doi.org/10.1016/j.aei.2015.08.002	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2015-08-002/br/b0060>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2015-08-002/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2015-08-002/ctx/ctx0013>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2015-08-002/itrp/0039	'OWL is a vocabulary extension for the Resource Description Framework (RDF) [12][[ refid=''b0060'' ]].'				100_classified_extends
uses_method_in	Discussion	R.R. Yager, On ordered weighted averaging operators in multicriteria decision making , IEEE Trans. Syst., Man, Cybern. , vol. 18 (1988), pp.183-190	http://dx.doi.org/10.1016/j.aei.2015.11.001	discussion		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2015-11-001/br/b0365>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2015-11-001/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2015-11-001/ctx/ctx0047>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2015-11-001/itrp/0031	'The operator is a scoring type based on Yager’s OWA operator [73][[ refid=''b0365'' ]], and the prioritized aggregation includes three complex calculation processes for priority analysis.'			FDY+AGA	infered_pred1
extends	Evaluation of OntoAMAS	A. Reymonet, J. Thomas, N. Aussenac-Gilles, Modelling ontological and terminological resources in owl dl , OntoLex 2007-Workshop at ISWC07, Busan, South-Korea (2007)	http://dx.doi.org/10.1016/j.aei.2016.05.002	results		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-05-002/br/b0165>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-05-002/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-05-002/ctx/ctx0051>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-05-002/itrp/0071	'OntoAMAS extends TextViz [33][[ refid=''b0165'' ]] another Protégé plug-in dedicated to documents semantic annotation.'				100_classified_extends
cites	State of the art and knowledge gaps	A. Bouramoul, M.K. Kholladi, B.L. Doan, An ontology-based approach for semantics ranking of the web search engines results , Proceedings of the 2012 International Conference on Multimedia Computing and Systems (ICMCS), IEEE (2012)	http://dx.doi.org/10.1016/j.aei.2016.08.004			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-08-004/br/b0120>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-08-004/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-08-004/ctx/ctx0026>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-08-004/itrp/0006	'Bouramoul et al. [24][[ refid=''b0120'' ]] improved the document ranking of current search engines (Google, Bing, and Yahoo) through re-ranking the top retrieved results based on the similarity between the expanded document vector and the query vector, where both vectors were expanded with WordNet concepts linked by semantic relations.'				100_classified_extends
cites	State of the art and knowledge gaps	M. ALMasri, K. Tan, C. Berrut, J.P. Chevallet, P. Mulhem, Integrating semantic term relations into information retrieval systems based on language models , Inform. Retriev. Technol. , vol. 8870 (2014), pp.136-147	http://dx.doi.org/10.1016/j.aei.2016.08.004			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-08-004/br/b0125>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-08-004/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-08-004/ctx/ctx0027>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-08-004/itrp/0007	'AlMasri et al. [25][[ refid=''b0125'' ]] tackled the term mismatch problem for document ranking through modifying documents according to a given query and semantic relations between terms, and adapted a number of language models to expand a document by the query terms that have semantically-related document terms but do not appear in the document.'				100_classified_extends
cites	Introduction	G. Gao, Y.S. Liu, M. Wang, M. Gu, J.H. Yong, A query expansion method for retrieving online BIM resources based on Industry Foundation Classes , Automat. Constr. , vol. 56 (2015), pp.14-25	http://dx.doi.org/10.1016/j.aei.2016.09.002	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-09-002/br/b0100>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-09-002/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-09-002/ctx/ctx0010>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-09-002/itrp/0052	'MMOY holds a domain-specific knowledge graph, so it can be used to expand user’s query [20][[ refid=''b0100'' ]] so as to improve the retrieval effectiveness.'				100_classified_extends
uses_method_in	Case study	C.-C. Chang, C.-J. Lin, LIBSVM: a library for support vector machines , ACM Trans. Intell. Syst. Technol. , vol. 2 (2011), pp.None	http://dx.doi.org/10.1016/j.aei.2016.11.001			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-11-001/br/b0035>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-11-001/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-11-001/ctx/ctx0034>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-11-001/itrp/0021	'In our case study, we used C-Support Vector Classification [7][[ refid=''b0035'' ]].'			FDY+AGA	infered_pred1
extends	Proposed gateway architecture	Aazam Mohammad, Eui-Nam Huh, Fog computing and smart gateway based communication for cloud of things , 2014 International Conference on Future Internet of Things and Cloud (FiCloud), IEEE (2014)	http://dx.doi.org/10.1016/j.aei.2016.11.003			<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-11-003/br/b0165>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-11-003/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-11-003/ctx/ctx0027>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2016-11-003/itrp/0006	'The use of the resources available on the Gateway has been expanded from those suggested in [33][[ refid=''b0165'' ]] with the introduction of context information such as region, network information and location information.'				100_classified_extends
cites	Introduction	Z. Dongmin, H. Dachao, X. Yuchun, Z. Hong, Computers in industry a framework for design knowledge management and reuse for product-service systems in construction machinery industry , Comput. Ind. , vol. 63 (2012), pp.328-337	http://dx.doi.org/10.1016/j.aei.2017.04.002	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-04-002/br/b0015>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-04-002/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-04-002/ctx/ctx0003>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-04-002/itrp/0035	'However, design practices are being applied to an expanding scope of activities which include from digital product interaction of graphic areas, product design, engineer design, product service design, even to business strategy and social policy [3][[ refid=''b0015'' ]].'				100_classified_extends
cites	Introduction	T. Wuest, Product requirement modeling and optimization method based on product configuration design , Procedia CIRP , vol. 36 (2015), pp.1-5	http://dx.doi.org/10.1016/j.aei.2017.04.002	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-04-002/br/b0030>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-04-002/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-04-002/ctx/ctx0006>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-04-002/itrp/0038	'In today’s competitive and expanding global marketplace, competitive advantage lies with those companies that understand and respond quickly to dynamic user requirements in product development while able to bring the product to the market sooner and guaranteeing the quality, reliability and performance [6][[ refid=''b0030'' ]].'				100_classified_extends
cites	Introduction	A. Bradley, H. Li, R. Lark, S. Dunn, BIM for infrastructure: an overall review and constructor perspective , Autom. Construct. , vol. 71 (2016), pp.139-152	http://dx.doi.org/10.1016/j.aei.2017.07.003	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-07-003/br/b0050>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-07-003/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-07-003/ctx/ctx0001>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-07-003/itrp/0020	'The ongoing digitization of planning processes in the building sector has become a major improvement for the AEC industry and is being expanded into the infrastructure domain [10][[ refid=''b0050'' ]].'				100_classified_extends
cites	Introduction	A. Borrmann, T.H. Kolbe, A. Donaubauer, H. Steuer, J.R. Jubierre, M. Flurl, Multi-scale geometric-semantic modeling of shield tunnels for GIS and BIM applications , Comp-Aided Civil Infrastruct Eng , vol. 30 (2014), pp.263-281	http://dx.doi.org/10.1016/j.aei.2017.07.003	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-07-003/br/b0045>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-07-003/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-07-003/ctx/ctx0004>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-07-003/itrp/0023	'Previous research extends the LoD concept used in the GIS domain towards multi-scale representations of building information models, particularly used for the modeling of shield tunnels [9][[ refid=''b0045'' ]].'				100_classified_extends
cites	Introduction	M. Callon, J. Courtial, W.A. Turner, S. Bauin, From translations to problematic networks: an introduction to co-word analysis , Soc. Sci. Inf. , vol. 22 (1983), pp.191-235	http://dx.doi.org/10.1016/j.aei.2017.08.001	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-08-001/br/b0020>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-08-001/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-08-001/ctx/ctx0004>				http://www.scar.disi.unibo.it/r/10-1016-j-aei-2017-08-001/itrp/0035	'It then expanded and enriched to co-word networks in the following researches [4][[ refid=''b0020'' ]].'				100_classified_extends
cites	Materials and methods	D.A. Gerke, J.-M. Brismee, P.S. Sizer, G.S. Dedrick, C.R. James, Change in spine height measurements following sustained mid-range and end-range flexion of the lumbar spine , Appl. Ergon. , vol. 42 (2011), pp.331-336	http://dx.doi.org/10.1016/j.apergo.2017.07.016	methods	materials	<http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/br/bib13>	<http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/ctx/ctx0022>				http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/itrp/0001	'Adjustable backboards, foam supports and wooden lateral guides were used for comfort, support, assisted in consistent postural alignment and minimized error during readings (Gerke et al., 2011[[ refid=''bib13'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Materials and methods	J.P. Stothart, S.M. McGill, Stadiometry: on measurement technique to reduce variability in spine shrinkage measurement , Clin. Biomech. , vol. 15 (2000), pp.546-548	http://dx.doi.org/10.1016/j.apergo.2017.07.016	methods	materials	<http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/br/bib48>	<http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/ctx/ctx0023>				http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/itrp/0002	'The subject then walked two laps around the room followed by repositioning and measurement on the stadiometer (Stothart and McGill, 2000[[ refid=''bib48'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Materials and methods	S.M. Bierma-Zeinstra, J.J. van Gool, R.M. Bernsen, K.H. Njoo, Measuring the sacral inclination angel in clinical practice is there an alternative to radiographs , J. Manip. Physiol. Ther. , vol. 24 (2001), pp.505-508	http://dx.doi.org/10.1016/j.apergo.2017.07.016	methods	materials	<http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/br/bib5>	<http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/ctx/ctx0026>				http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/itrp/0007	'Additionally, the DSI (angle between a line drawn parallel along the posterior aspect of the proximal sacrum and the horizontal plane) (Bierma-Zeinstra et al., 2001[[ refid=''bib5'' ]]) was recorded at the S1 spinous process.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Materials and methods	M. Magnusson, T. Hansson, M.H. Pope, The effect of seat back inclination on spine height changes , Appl. Ergon. , vol. 25 (1994), pp.294-298	http://dx.doi.org/10.1016/j.apergo.2017.07.016	methods	materials	<http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/br/bib28>	<http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/ctx/ctx0018>				http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-07-016/itrp/0083	'For an alpha level of 0.05, power of 80%, assumed spinal height increase of 1.7 mm (Magnusson et al., 1994[[ refid=''bib28'' ]]) and estimated standard deviation (SD) of 3.0 mm from pilot testing, it was calculated that 27 subjects would be required for detecting a significant difference in spinal height following the sustained PSS with or without lumbar support.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Overview of primary findings	S.W.J. Kozlowski, D.R. Ilgen, Enhancing the effectiveness of work groups and teams , Psychol. Sci. public interest , vol. 7 (2006), pp.77-124	http://dx.doi.org/10.1016/j.apergo.2017.10.020			http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/br/bib58	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/ctx/ctx0022		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/itrp/0001	'These communication differences may be a reflection of the team members having distinct responsibilities and complex interdependencies with one another (Kozlowski and Ilgen, 2006[[ refid=''bib58'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0190"""" view=""""all"""">Some studies have provided evidence that team members communicate differently depending on their job role. An association between job role and communication volume was found for 13 studied relationships, but not for 3 others (<ce:cross-refs refid=""""bib2 bib6 bib12 bib13 bib50 bib55 bib57 bib64 bib91 bib97 bib115"""" id=""""crosrefs0040"""">Allender et al., 2006; Barth et al., 2015; Chapanis et al., 1972; Chapanis and Overbey, 1974; Kanki and Foushee, 1989; Kim et al., 2011; Kolbe et al., 2012; Liu et al., 2013; Rowlands and Callen, 2013; Santos et al., 2012; Strang et al., 2011[[ refid=''''bib2 bib6 bib12 bib13 bib50 bib55 bib57 bib64 bib91 bib97 bib115'''' ]]</ce:cross-refs>). This means that the amount of communication usually varies among each singular role within a team. However, as shown in <ce:cross-ref refid=""""tbl4"""" id=""""crosref0145"""">Table 4</ce:cross-ref>, communication volume was measured in many ways. For instance, <ce:cross-ref refid=""""bib13"""" id=""""crosref0150"""">Chapanis and Overbey (1974)[[ refid=''''bib13'''' ]]</ce:cross-ref> included five different measures of communication volume (i.e., communication time, number of words, number of instances/unit of time, number of instances, number of words/unit of time), and only three of these were positively associated with role, which highlights the fact the way communication volume is measured can affect results. Additionally, job role was associated with the frequency of different content categories in eight studies (<ce:cross-refs refid=""""bib2 bib3 bib23 bib27 bib50 bib68 bib71 bib97"""" id=""""crosrefs0045"""">Allender et al., 2006; Apker et al., 2005; Espin and Lingard, 2001; Fincannon et al., 2011; Kanki and Foushee, 1989; Manser et al., 2013; Matzke et al., 2014; Santos et al., 2012[[ refid=''''bib2 bib3 bib23 bib27 bib50 bib68 bib71 bib97'''' ]]</ce:cross-refs>). Finally, one study found a positive relationship between job role and individual message length (<ce:cross-ref refid=""""bib13"""" id=""""crosref0155"""">Chapanis and Overbey, 1974[[ refid=''''bib13'''' ]]</ce:cross-ref>), and another found a positive relationship between job role and the amount of task irrelevant communication (<ce:cross-ref refid=""""bib100"""" id=""""crosref0160"""">Sevdalis et al., 2007[[ refid=''''bib100'''' ]]</ce:cross-ref>). Overall, the research studies suggest that people''''s functions and responsibilities on a team are related to how much they speak, and what they speak about. These communication differences may be a reflection of the team members having distinct responsibilities and complex interdependencies with one another (<ce:cross-ref refid=""""bib58"""" id=""""crosref0165"""">Kozlowski and Ilgen, 2006[[ refid=''''bib58'''' ]]</ce:cross-ref>).</ce:para>""''"'		ANG	
cites	Overview of primary findings	J.R. Kelly, J.E. McGrath, Effects of time limits and task types on task performance and interaction of four-person groups , J. Personality Soc. Psychol. , vol. 49 (1985), pp.395	http://dx.doi.org/10.1016/j.apergo.2017.10.020			http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/br/bib51	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/ctx/ctx0028		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/itrp/0036	'For example, Kelly and McGrath (1985)[[ refid=''bib51'' ]] found differences in the rate of occurrence of certain content categories based on cognitive demand levels when they evaluated ad hoc teams performing the same sets of tasks under two different time limits (a relaxed condition vs. a time pressure one in which participants had to complete the same task in half the time).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0195"""" view=""""all"""">Relationships in the reviewed literature indicate that situational stressors are related to both communication volume and the content of communication. Higher cognitive load was associated with longer individual messages in two instances (<ce:cross-refs refid=""""bib53 bib77"""" id=""""crosrefs0050"""">Khawaja et al., 2012; Morrow et al., 1993[[ refid=''''bib53 bib77'''' ]]</ce:cross-refs>), and with more “complex” messages in another (<ce:cross-ref refid=""""bib77"""" id=""""crosref0170"""">Morrow et al., 1993[[ refid=''''bib77'''' ]]</ce:cross-ref>). Two studies found a positive relationship between the use of plural pronouns and task cognitive load (<ce:cross-refs refid=""""bib53 bib111"""" id=""""crosrefs0055"""">Khawaja et al., 2012; Stokes et al., 1997[[ refid=''''bib53 bib111'''' ]]</ce:cross-refs>). Moreover, communication volume increased with task load in seven instances (<ce:cross-refs refid=""""bib6 bib65 bib74 bib87 bib88 bib110 bib111"""" id=""""crosrefs0060"""">Barth et al., 2015; Mackenzie et al., 1993; McKendrick et al., 2011; Pfaff, 2009, 2012; Stevens et al., 2011; Stokes et al., 1997[[ refid=''''bib6 bib65 bib74 bib87 bib88 bib110 bib111'''' ]]</ce:cross-refs>) but not in two (<ce:cross-refs refid=""""bib115 bib114"""" id=""""crosrefs0065"""">Strang et al., 2011, 2012b[[ refid=''''bib115 bib114'''' ]]</ce:cross-refs>). For example, <ce:cross-ref refid=""""bib65"""" id=""""crosref0175"""">Mackenzie et al. (1993)[[ refid=''''bib65'''' ]]</ce:cross-ref> observed real-world trauma teams (with 5 or more people) perform emergency intubations (prior resuscitations) or planned intubations (before surgeries). They found a significantly higher number of utterances (communication volume) during emergency intubations. Situational stressors were also associated with changes in communication content in five instances (<ce:cross-refs refid=""""bib6 bib51 bib55 bib87 bib88 bib114"""" id=""""crosrefs0070"""">Barth et al., 2015; Kelly and McGrath, 1985; Kim et al., 2011; Pfaff, 2009, 2012; Strang et al., 2012b[[ refid=''''bib6 bib51 bib55 bib87 bib88 bib114'''' ]]</ce:cross-refs>) but not in two (<ce:cross-refs refid=""""bib48 bib120 bib121"""" id=""""crosrefs0075"""">Johnston and Briggs, 1968; Urban et al., 1995, 1996[[ refid=''''bib48 bib120 bib121'''' ]]</ce:cross-refs>). For example, <ce:cross-ref refid=""""bib51"""" id=""""crosref0180"""">Kelly and McGrath (1985)[[ refid=''''bib51'''' ]]</ce:cross-ref> found differences in the rate of occurrence of certain content categories based on cognitive demand levels when they evaluated ad hoc teams performing the same sets of tasks under two different time limits (a relaxed condition vs. a time pressure one in which participants had to complete the same task in half the time). Also, <ce:cross-ref refid=""""bib99"""" id=""""crosref0185"""">Serfaty et al. (1993)[[ refid=''''bib99'''' ]]</ce:cross-ref> found that increased time pressure was associated with a higher “anticipation ratio”. <ce:cross-ref refid=""""bib70"""" id=""""crosref0190"""">Maruping and Magni (2014)[[ refid=''''bib70'''' ]]</ce:cross-ref> showed that communication problems decreased with task uncertainty. <ce:cross-ref refid=""""bib124"""" id=""""crosref0195"""">Xiao et al. (2003)[[ refid=''''bib124'''' ]]</ce:cross-ref> found that task urgency affected interaction pattern (the frequency of who talks to who). And finally, <ce:cross-ref refid=""""bib74"""" id=""""crosref0200"""">McKendrick et al. (2011)[[ refid=''''bib74'''' ]]</ce:cross-ref> reported more instances of task-irrelevant communication as task load increased.</ce:para>""''"'		ANG	
cites	Overview of primary findings	D. Serfaty, E.E. Entin, C. Volpe, Adaptation to stress in team decision-making and coordination , Proceedings of the Human Factors & Ergonomics Society Annual Meeting (1993)	http://dx.doi.org/10.1016/j.apergo.2017.10.020			http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/br/bib99	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/ctx/ctx0029		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/itrp/0037	'Also, Serfaty et al. (1993)[[ refid=''bib99'' ]] found that increased time pressure was associated with a higher “anticipation ratio”.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0195"""" view=""""all"""">Relationships in the reviewed literature indicate that situational stressors are related to both communication volume and the content of communication. Higher cognitive load was associated with longer individual messages in two instances (<ce:cross-refs refid=""""bib53 bib77"""" id=""""crosrefs0050"""">Khawaja et al., 2012; Morrow et al., 1993[[ refid=''''bib53 bib77'''' ]]</ce:cross-refs>), and with more “complex” messages in another (<ce:cross-ref refid=""""bib77"""" id=""""crosref0170"""">Morrow et al., 1993[[ refid=''''bib77'''' ]]</ce:cross-ref>). Two studies found a positive relationship between the use of plural pronouns and task cognitive load (<ce:cross-refs refid=""""bib53 bib111"""" id=""""crosrefs0055"""">Khawaja et al., 2012; Stokes et al., 1997[[ refid=''''bib53 bib111'''' ]]</ce:cross-refs>). Moreover, communication volume increased with task load in seven instances (<ce:cross-refs refid=""""bib6 bib65 bib74 bib87 bib88 bib110 bib111"""" id=""""crosrefs0060"""">Barth et al., 2015; Mackenzie et al., 1993; McKendrick et al., 2011; Pfaff, 2009, 2012; Stevens et al., 2011; Stokes et al., 1997[[ refid=''''bib6 bib65 bib74 bib87 bib88 bib110 bib111'''' ]]</ce:cross-refs>) but not in two (<ce:cross-refs refid=""""bib115 bib114"""" id=""""crosrefs0065"""">Strang et al., 2011, 2012b[[ refid=''''bib115 bib114'''' ]]</ce:cross-refs>). For example, <ce:cross-ref refid=""""bib65"""" id=""""crosref0175"""">Mackenzie et al. (1993)[[ refid=''''bib65'''' ]]</ce:cross-ref> observed real-world trauma teams (with 5 or more people) perform emergency intubations (prior resuscitations) or planned intubations (before surgeries). They found a significantly higher number of utterances (communication volume) during emergency intubations. Situational stressors were also associated with changes in communication content in five instances (<ce:cross-refs refid=""""bib6 bib51 bib55 bib87 bib88 bib114"""" id=""""crosrefs0070"""">Barth et al., 2015; Kelly and McGrath, 1985; Kim et al., 2011; Pfaff, 2009, 2012; Strang et al., 2012b[[ refid=''''bib6 bib51 bib55 bib87 bib88 bib114'''' ]]</ce:cross-refs>) but not in two (<ce:cross-refs refid=""""bib48 bib120 bib121"""" id=""""crosrefs0075"""">Johnston and Briggs, 1968; Urban et al., 1995, 1996[[ refid=''''bib48 bib120 bib121'''' ]]</ce:cross-refs>). For example, <ce:cross-ref refid=""""bib51"""" id=""""crosref0180"""">Kelly and McGrath (1985)[[ refid=''''bib51'''' ]]</ce:cross-ref> found differences in the rate of occurrence of certain content categories based on cognitive demand levels when they evaluated ad hoc teams performing the same sets of tasks under two different time limits (a relaxed condition vs. a time pressure one in which participants had to complete the same task in half the time). Also, <ce:cross-ref refid=""""bib99"""" id=""""crosref0185"""">Serfaty et al. (1993)[[ refid=''''bib99'''' ]]</ce:cross-ref> found that increased time pressure was associated with a higher “anticipation ratio”. <ce:cross-ref refid=""""bib70"""" id=""""crosref0190"""">Maruping and Magni (2014)[[ refid=''''bib70'''' ]]</ce:cross-ref> showed that communication problems decreased with task uncertainty. <ce:cross-ref refid=""""bib124"""" id=""""crosref0195"""">Xiao et al. (2003)[[ refid=''''bib124'''' ]]</ce:cross-ref> found that task urgency affected interaction pattern (the frequency of who talks to who). And finally, <ce:cross-ref refid=""""bib74"""" id=""""crosref0200"""">McKendrick et al. (2011)[[ refid=''''bib74'''' ]]</ce:cross-ref> reported more instances of task-irrelevant communication as task load increased.</ce:para>""''"'		ANG	
cites	Overview of primary findings	G.J. Funke, S.M. Galster, The Effects of Spatial Processing Load and Collaboration Technology on Team Performance in a Simulated C2 Environment, 25th Anniversary Conference of the European Association for Cognitive Ergonomics, EACE, August 28, 2007-August 31, 2007 , None, Association for Computing Machinery (2007)	http://dx.doi.org/10.1016/j.apergo.2017.10.020			http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/br/bib30	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/ctx/ctx0046		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/itrp/0042	'Likewise, Funke and Galster (2007b)[[ refid=''bib30'' ]] tested text only, voice only, and text & voice modes, and found that teams communicated less in the text only condition compared to the other two.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0210"""" view=""""all"""">Communication medium was associated with a change in the total volume of communication in 11 instances out of 12 (<ce:cross-refs refid=""""bib12 bib13 bib27 bib30 bib92 bib115"""" id=""""crosrefs0120"""">Chapanis et al., 1972; Chapanis and Overbey, 1974; Fincannon et al., 2011; Funke and Galster, 2007b; Russell et al., 2012; Strang et al., 2011[[ refid=''''bib12 bib13 bib27 bib30 bib92 bib115'''' ]]</ce:cross-refs>). <ce:cross-ref refid=""""bib12"""" id=""""crosref0240"""">Chapanis et al. (1972)[[ refid=''''bib12'''' ]]</ce:cross-ref> studied four modes of communication: typewritten notes, handwritten notes, voice only, and face-to-face. Total communication time was more than twice for typewritten notes mode than for voice only, and face-to-face modes. However, when communication time was measured as a percentage of task time, all modes were found to be approximately the same. Also, <ce:cross-ref refid=""""bib13"""" id=""""crosref0245"""">Chapanis and Overbey (1974)[[ refid=''''bib13'''' ]]</ce:cross-ref> investigated four modes of communication within teams with two roles (namely “seeker” and “source”): unmixed voice-voice, mixed “seeker” voice-“source” typewriter, mixed “seeker” typewriter -“source” voice, and unmixed typewriter. Communication volume was higher for unmixed voice, followed by the two mixed conditions and then by unmixed typewriter across the five different ways it was measured (i.e., communication time, total number of messages, total number of words, number of messages per minute, or number of words per minute). Similarly, <ce:cross-ref refid=""""bib27"""" id=""""crosref0250"""">Fincannon et al. (2011)[[ refid=''''bib27'''' ]]</ce:cross-ref> found that teams using voice only modes showed twice as many statements per participant than those using text only. Likewise, <ce:cross-ref refid=""""bib30"""" id=""""crosref0255"""">Funke and Galster (2007b)[[ refid=''''bib30'''' ]]</ce:cross-ref> tested text only, voice only, and text &amp; voice modes, and found that teams communicated less in the text only condition compared to the other two. Finally, <ce:cross-ref refid=""""bib92"""" id=""""crosref0260"""">Russell et al. (2012)[[ refid=''''bib92'''' ]]</ce:cross-ref> and <ce:cross-ref refid=""""bib115"""" id=""""crosref0265"""">Strang et al. (2011)[[ refid=''''bib115'''' ]]</ce:cross-ref> investigated two modes of communication: voice only, and voice enhanced with text and a virtual whiteboard. The number of messages per episode, the total communication time, and the number of messages was reduced when the voice-enhanced system was used. In general, voice-only based systems showed increased communication volume when compared with text-only base systems. From a common ground perspective this is not surprising since people shape their interactions according to the communication medium (<ce:cross-ref refid=""""bib14"""" id=""""crosref0270"""">Clark and Brennan, 1991[[ refid=''''bib14'''' ]]</ce:cross-ref>). The communication richness, the nature of team interactions and the requirements to support team communications and activities differ according to the characteristics of the communication medium used such as copresence, visibility, audibility, sequentiality reviewability, and revisability (<ce:cross-ref refid=""""bib89"""" id=""""crosref0275"""">Priest et al., 2006[[ refid=''''bib89'''' ]]</ce:cross-ref>).</ce:para>""''"'		ANG	
cites	Overview of primary findings	H.H. Clark, S.E. Brennan, Grounding in communication , Perspect. socially Shar. cognition , vol. 13 (1991), pp.127-149	http://dx.doi.org/10.1016/j.apergo.2017.10.020			http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/br/bib14	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/ctx/ctx0048		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/itrp/0087	'From a common ground perspective this is not surprising since people shape their interactions according to the communication medium (Clark and Brennan, 1991[[ refid=''bib14'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0210"""" view=""""all"""">Communication medium was associated with a change in the total volume of communication in 11 instances out of 12 (<ce:cross-refs refid=""""bib12 bib13 bib27 bib30 bib92 bib115"""" id=""""crosrefs0120"""">Chapanis et al., 1972; Chapanis and Overbey, 1974; Fincannon et al., 2011; Funke and Galster, 2007b; Russell et al., 2012; Strang et al., 2011[[ refid=''''bib12 bib13 bib27 bib30 bib92 bib115'''' ]]</ce:cross-refs>). <ce:cross-ref refid=""""bib12"""" id=""""crosref0240"""">Chapanis et al. (1972)[[ refid=''''bib12'''' ]]</ce:cross-ref> studied four modes of communication: typewritten notes, handwritten notes, voice only, and face-to-face. Total communication time was more than twice for typewritten notes mode than for voice only, and face-to-face modes. However, when communication time was measured as a percentage of task time, all modes were found to be approximately the same. Also, <ce:cross-ref refid=""""bib13"""" id=""""crosref0245"""">Chapanis and Overbey (1974)[[ refid=''''bib13'''' ]]</ce:cross-ref> investigated four modes of communication within teams with two roles (namely “seeker” and “source”): unmixed voice-voice, mixed “seeker” voice-“source” typewriter, mixed “seeker” typewriter -“source” voice, and unmixed typewriter. Communication volume was higher for unmixed voice, followed by the two mixed conditions and then by unmixed typewriter across the five different ways it was measured (i.e., communication time, total number of messages, total number of words, number of messages per minute, or number of words per minute). Similarly, <ce:cross-ref refid=""""bib27"""" id=""""crosref0250"""">Fincannon et al. (2011)[[ refid=''''bib27'''' ]]</ce:cross-ref> found that teams using voice only modes showed twice as many statements per participant than those using text only. Likewise, <ce:cross-ref refid=""""bib30"""" id=""""crosref0255"""">Funke and Galster (2007b)[[ refid=''''bib30'''' ]]</ce:cross-ref> tested text only, voice only, and text &amp; voice modes, and found that teams communicated less in the text only condition compared to the other two. Finally, <ce:cross-ref refid=""""bib92"""" id=""""crosref0260"""">Russell et al. (2012)[[ refid=''''bib92'''' ]]</ce:cross-ref> and <ce:cross-ref refid=""""bib115"""" id=""""crosref0265"""">Strang et al. (2011)[[ refid=''''bib115'''' ]]</ce:cross-ref> investigated two modes of communication: voice only, and voice enhanced with text and a virtual whiteboard. The number of messages per episode, the total communication time, and the number of messages was reduced when the voice-enhanced system was used. In general, voice-only based systems showed increased communication volume when compared with text-only base systems. From a common ground perspective this is not surprising since people shape their interactions according to the communication medium (<ce:cross-ref refid=""""bib14"""" id=""""crosref0270"""">Clark and Brennan, 1991[[ refid=''''bib14'''' ]]</ce:cross-ref>). The communication richness, the nature of team interactions and the requirements to support team communications and activities differ according to the characteristics of the communication medium used such as copresence, visibility, audibility, sequentiality reviewability, and revisability (<ce:cross-ref refid=""""bib89"""" id=""""crosref0275"""">Priest et al., 2006[[ refid=''''bib89'''' ]]</ce:cross-ref>).</ce:para>""''"'		ANG	
cites	Overview of primary findings	H.A. Priest, K.C. Stagl, C. Klein, E. Salas, Virtual teams: creating context for distributed teamwork , Creating High-tech Teams: Practical Guidance on Work Performance and Technology, American Psychological Association (2006)	http://dx.doi.org/10.1016/j.apergo.2017.10.020			http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/br/bib89	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/ctx/ctx0049		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/itrp/0088	'The communication richness, the nature of team interactions and the requirements to support team communications and activities differ according to the characteristics of the communication medium used such as copresence, visibility, audibility, sequentiality reviewability, and revisability (Priest et al., 2006[[ refid=''bib89'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0210"""" view=""""all"""">Communication medium was associated with a change in the total volume of communication in 11 instances out of 12 (<ce:cross-refs refid=""""bib12 bib13 bib27 bib30 bib92 bib115"""" id=""""crosrefs0120"""">Chapanis et al., 1972; Chapanis and Overbey, 1974; Fincannon et al., 2011; Funke and Galster, 2007b; Russell et al., 2012; Strang et al., 2011[[ refid=''''bib12 bib13 bib27 bib30 bib92 bib115'''' ]]</ce:cross-refs>). <ce:cross-ref refid=""""bib12"""" id=""""crosref0240"""">Chapanis et al. (1972)[[ refid=''''bib12'''' ]]</ce:cross-ref> studied four modes of communication: typewritten notes, handwritten notes, voice only, and face-to-face. Total communication time was more than twice for typewritten notes mode than for voice only, and face-to-face modes. However, when communication time was measured as a percentage of task time, all modes were found to be approximately the same. Also, <ce:cross-ref refid=""""bib13"""" id=""""crosref0245"""">Chapanis and Overbey (1974)[[ refid=''''bib13'''' ]]</ce:cross-ref> investigated four modes of communication within teams with two roles (namely “seeker” and “source”): unmixed voice-voice, mixed “seeker” voice-“source” typewriter, mixed “seeker” typewriter -“source” voice, and unmixed typewriter. Communication volume was higher for unmixed voice, followed by the two mixed conditions and then by unmixed typewriter across the five different ways it was measured (i.e., communication time, total number of messages, total number of words, number of messages per minute, or number of words per minute). Similarly, <ce:cross-ref refid=""""bib27"""" id=""""crosref0250"""">Fincannon et al. (2011)[[ refid=''''bib27'''' ]]</ce:cross-ref> found that teams using voice only modes showed twice as many statements per participant than those using text only. Likewise, <ce:cross-ref refid=""""bib30"""" id=""""crosref0255"""">Funke and Galster (2007b)[[ refid=''''bib30'''' ]]</ce:cross-ref> tested text only, voice only, and text &amp; voice modes, and found that teams communicated less in the text only condition compared to the other two. Finally, <ce:cross-ref refid=""""bib92"""" id=""""crosref0260"""">Russell et al. (2012)[[ refid=''''bib92'''' ]]</ce:cross-ref> and <ce:cross-ref refid=""""bib115"""" id=""""crosref0265"""">Strang et al. (2011)[[ refid=''''bib115'''' ]]</ce:cross-ref> investigated two modes of communication: voice only, and voice enhanced with text and a virtual whiteboard. The number of messages per episode, the total communication time, and the number of messages was reduced when the voice-enhanced system was used. In general, voice-only based systems showed increased communication volume when compared with text-only base systems. From a common ground perspective this is not surprising since people shape their interactions according to the communication medium (<ce:cross-ref refid=""""bib14"""" id=""""crosref0270"""">Clark and Brennan, 1991[[ refid=''''bib14'''' ]]</ce:cross-ref>). The communication richness, the nature of team interactions and the requirements to support team communications and activities differ according to the characteristics of the communication medium used such as copresence, visibility, audibility, sequentiality reviewability, and revisability (<ce:cross-ref refid=""""bib89"""" id=""""crosref0275"""">Priest et al., 2006[[ refid=''''bib89'''' ]]</ce:cross-ref>).</ce:para>""''"'		ANG	
cites	Discussion	S.T. Bell, Deep-level composition variables as predictors of team performance: a meta-analysis , J. Appl. Psychol. , vol. 92 (2007), pp.595	http://dx.doi.org/10.1016/j.apergo.2017.10.020	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/br/bib8	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/ctx/ctx0059		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/itrp/0089	'On a another meta-analysis, team tenure was not significantly correlated with team performance effects (Bell, 2007[[ refid=''bib8'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0265"""" view=""""all"""">This review did not attempt a statistical meta-analysis because the independent and dependent variables varied greatly across papers. Also, we did not report on the interactive effects of multiple team and context dimensions on communication properties. There were only a few studies which investigated and reported interactions making any general conclusions difficult. Additionally, this review focused on measured properties of communication, rather than team performance. Future work could extend this review to summarize the relationship between team communication properties and performance. With the exception of the “communication quality” property is it not clear if changes in any of the other communication properties are desirable or not, or how this could change depending on environmental conditions. Links between team communication properties and team performance were out of the scope of this review. However, the effects on performance of communication and some of the team and context dimensions identified here have been evaluated on some the meta-analyses. <ce:cross-ref refid=""""bib46"""" id=""""crosref0350"""">Hülsheger et al. (2009)[[ refid=''''bib46'''' ]]</ce:cross-ref> found that communication was correlated with team innovation and creativity, while team size and team longevity were not. <ce:cross-ref refid=""""bib75"""" id=""""crosref0355"""">Mesmer-Magnus and DeChurch (2009)[[ refid=''''bib75'''' ]]</ce:cross-ref> confirmed that when teams share information team performance improves. On a another meta-analysis, team tenure was not significantly correlated with team performance effects (<ce:cross-ref refid=""""bib8"""" id=""""crosref0360"""">Bell, 2007[[ refid=''''bib8'''' ]]</ce:cross-ref>). Team training interventions have a positive influence on outcomes, and this is moderated by training content, team membership stability, and team size (<ce:cross-ref refid=""""bib94"""" id=""""crosref0365"""">Salas et al., 2008[[ refid=''''bib94'''' ]]</ce:cross-ref>). Finally, while we have included null and negative results in this review, we do not know how many results may be missing because scientists are pressured to only report positive results (<ce:cross-refs refid=""""bib24 bib25"""" id=""""crosrefs0125"""">Fanelli, 2010, 2011[[ refid=''''bib24 bib25'''' ]]</ce:cross-refs>).</ce:para>""''"'		ANG	
cites	Discussion	J.R. Mesmer-Magnus, L.A. DeChurch, Information Sharing and Team Performance: a Meta-analysis , None, American Psychological Association (2009)	http://dx.doi.org/10.1016/j.apergo.2017.10.020	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/br/bib75	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/ctx/ctx0058		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/itrp/0091	'Mesmer-Magnus and DeChurch (2009)[[ refid=''bib75'' ]] confirmed that when teams share information team performance improves.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0265"""" view=""""all"""">This review did not attempt a statistical meta-analysis because the independent and dependent variables varied greatly across papers. Also, we did not report on the interactive effects of multiple team and context dimensions on communication properties. There were only a few studies which investigated and reported interactions making any general conclusions difficult. Additionally, this review focused on measured properties of communication, rather than team performance. Future work could extend this review to summarize the relationship between team communication properties and performance. With the exception of the “communication quality” property is it not clear if changes in any of the other communication properties are desirable or not, or how this could change depending on environmental conditions. Links between team communication properties and team performance were out of the scope of this review. However, the effects on performance of communication and some of the team and context dimensions identified here have been evaluated on some the meta-analyses. <ce:cross-ref refid=""""bib46"""" id=""""crosref0350"""">Hülsheger et al. (2009)[[ refid=''''bib46'''' ]]</ce:cross-ref> found that communication was correlated with team innovation and creativity, while team size and team longevity were not. <ce:cross-ref refid=""""bib75"""" id=""""crosref0355"""">Mesmer-Magnus and DeChurch (2009)[[ refid=''''bib75'''' ]]</ce:cross-ref> confirmed that when teams share information team performance improves. On a another meta-analysis, team tenure was not significantly correlated with team performance effects (<ce:cross-ref refid=""""bib8"""" id=""""crosref0360"""">Bell, 2007[[ refid=''''bib8'''' ]]</ce:cross-ref>). Team training interventions have a positive influence on outcomes, and this is moderated by training content, team membership stability, and team size (<ce:cross-ref refid=""""bib94"""" id=""""crosref0365"""">Salas et al., 2008[[ refid=''''bib94'''' ]]</ce:cross-ref>). Finally, while we have included null and negative results in this review, we do not know how many results may be missing because scientists are pressured to only report positive results (<ce:cross-refs refid=""""bib24 bib25"""" id=""""crosrefs0125"""">Fanelli, 2010, 2011[[ refid=''''bib24 bib25'''' ]]</ce:cross-refs>).</ce:para>""''"'		ANG	
cites	Discussion	Nyssen, A.-S., Blavier, A.l.d., 2009. Verbal Communication as a sign of adaptation in socio-technical systems: the case of robotic surgery, Proceedings of NDM9, the 9th International Conference on Naturalistic Decision Making.	http://dx.doi.org/10.1016/j.apergo.2017.10.020	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/br/bib82	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/ctx/ctx0052		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/itrp/0240	'For instance, Nyssen and Blavier (2009)[[ refid=''bib82'' ]] reported that teams with more experienced members talked less, however familiarity was not mentioned.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0230"""" view=""""all"""">For instance, the possible relationships between familiarity and experience among team members on team communication are not clear. First, few studies have investigated these two factors. Second, the results are conflicting. For example, team communication volume is negatively correlated with experience in one study (<ce:cross-ref refid=""""bib82"""" id=""""crosref0280"""">Nyssen and Blavier, 2009[[ refid=''''bib82'''' ]]</ce:cross-ref>), positively correlated with familiarity and experience (when they are combined) in another study (<ce:cross-ref refid=""""bib22"""" id=""""crosref0285"""">Espevik et al., 2011[[ refid=''''bib22'''' ]]</ce:cross-ref>), positively correlated with familiarity in one study (<ce:cross-ref refid=""""bib50"""" id=""""crosref0290"""">Kanki and Foushee, 1989[[ refid=''''bib50'''' ]]</ce:cross-ref>) but negatively in another (<ce:cross-ref refid=""""bib36"""" id=""""crosref0295"""">Gillespie et al., 2013[[ refid=''''bib36'''' ]]</ce:cross-ref>). Finally, familiarity and experience levels are not always reported together when they could be correlated (<ce:cross-ref refid=""""bib105"""" id=""""crosref0300"""">Smith-Jentsch et al., 2009[[ refid=''''bib105'''' ]]</ce:cross-ref>) or not (<ce:cross-ref refid=""""bib20"""" id=""""crosref0305"""">ElBardissi et al., 2008[[ refid=''''bib20'''' ]]</ce:cross-ref>). For instance, <ce:cross-ref refid=""""bib82"""" id=""""crosref0310"""">Nyssen and Blavier (2009)[[ refid=''''bib82'''' ]]</ce:cross-ref> reported that teams with more experienced members talked less, however familiarity was not mentioned. So, did teams with higher experience level also have higher familiarity? Did these teams talk less because their higher expertise, because they knew their team members better, or both? Moreover, the effects of some structural characteristics–such as geographic distribution, team size, and hierarchical structure–on communication have seen little study. Therefore, there is limited empirical information available to inform the design of teams in terms of these characteristics. These questions can be addressed through research targeted at the literature gaps revealed through this review.</ce:para>""''"'		ANG	
cites	Introduction	J.L. Wildman, A.L. Thayer, M.A. Rosen, E. Salas, J.E. Mathieu, S.R. Rayne, Task types and team-level attributes: synthesis of team classification literature , Hum. Resour. Dev. Rev. , vol. 11 (2012), pp.97-129	http://dx.doi.org/10.1016/j.apergo.2017.10.020	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/br/bib123	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/ctx/ctx0013		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/itrp/0247	'In a complementary study Wildman et al. (2012)[[ refid=''bib123'' ]] taxonomy includes a classification of team task types along with six team-level dimensions including: task interdependence, communication structure, physical distribution, role structure, leadership structure, and team life span.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0040"""" view=""""all"""">In contrast, <ce:cross-ref refid=""""bib43"""" id=""""crosref0065"""">Hollenbeck et al. (2012)[[ refid=''''bib43'''' ]]</ce:cross-ref> and <ce:cross-ref refid=""""bib123"""" id=""""crosref0070"""">Wildman et al. (2012)[[ refid=''''bib123'''' ]]</ce:cross-ref> have recently synthesized team taxonomies and have proposed new multidimensional classification systems. <ce:cross-ref refid=""""bib43"""" id=""""crosref0075"""">Hollenbeck et al. (2012)[[ refid=''''bib43'''' ]]</ce:cross-ref> proposed a three-dimensional framework based on three constructs: skill differentiation (from a team in which each team member has the same skills to a team in which each member has completely different skills), authority differentiation (from self-managing teams to those who have a “leader who has full authority”), and temporal stability (from newly formed teams to those whose members that have worked together for a long time). In a complementary study <ce:cross-ref refid=""""bib123"""" id=""""crosref0080"""">Wildman et al. (2012)[[ refid=''''bib123'''' ]]</ce:cross-ref> taxonomy includes a classification of team task types along with six team-level dimensions including: task interdependence, communication structure, physical distribution, role structure, leadership structure, and team life span. These last three characteristics closely match those identified by <ce:cross-ref refid=""""bib43"""" id=""""crosref0085"""">Hollenbeck et al. (2012)[[ refid=''''bib43'''' ]]</ce:cross-ref>. In summary, teams should be characterized in various dimensions that at least include: how tasks and skills are allocated (i.e. role structure); how authority, prestige, and power is distributed (hierarchical structure); and how long members have worked together (i.e., team familiarity).</ce:para>""''"'		ANG	
cites	Introduction	J.R. Hollenbeck, B. Beersma, M.E. Schouten, Beyond team types and taxonomies: a dimensional scaling conceptualization for team description , Acad. Manag. Rev. , vol. 37 (2012), pp.82-106	http://dx.doi.org/10.1016/j.apergo.2017.10.020	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/br/bib43	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/ctx/ctx0012		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2017-10-020/itrp/0248	'Hollenbeck et al. (2012)[[ refid=''bib43'' ]] proposed a three-dimensional framework based on three constructs: skill differentiation (from a team in which each team member has the same skills to a team in which each member has completely different skills), authority differentiation (from self-managing teams to those who have a “leader who has full authority”), and temporal stability (from newly formed teams to those whose members that have worked together for a long time).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0040"""" view=""""all"""">In contrast, <ce:cross-ref refid=""""bib43"""" id=""""crosref0065"""">Hollenbeck et al. (2012)[[ refid=''''bib43'''' ]]</ce:cross-ref> and <ce:cross-ref refid=""""bib123"""" id=""""crosref0070"""">Wildman et al. (2012)[[ refid=''''bib123'''' ]]</ce:cross-ref> have recently synthesized team taxonomies and have proposed new multidimensional classification systems. <ce:cross-ref refid=""""bib43"""" id=""""crosref0075"""">Hollenbeck et al. (2012)[[ refid=''''bib43'''' ]]</ce:cross-ref> proposed a three-dimensional framework based on three constructs: skill differentiation (from a team in which each team member has the same skills to a team in which each member has completely different skills), authority differentiation (from self-managing teams to those who have a “leader who has full authority”), and temporal stability (from newly formed teams to those whose members that have worked together for a long time). In a complementary study <ce:cross-ref refid=""""bib123"""" id=""""crosref0080"""">Wildman et al. (2012)[[ refid=''''bib123'''' ]]</ce:cross-ref> taxonomy includes a classification of team task types along with six team-level dimensions including: task interdependence, communication structure, physical distribution, role structure, leadership structure, and team life span. These last three characteristics closely match those identified by <ce:cross-ref refid=""""bib43"""" id=""""crosref0085"""">Hollenbeck et al. (2012)[[ refid=''''bib43'''' ]]</ce:cross-ref>. In summary, teams should be characterized in various dimensions that at least include: how tasks and skills are allocated (i.e. role structure); how authority, prestige, and power is distributed (hierarchical structure); and how long members have worked together (i.e., team familiarity).</ce:para>""''"'		ANG	
cites	Data analysis	S. Thorpe, D. Fize, C. Marlot, Speed of processing in the human visual system , Nature , vol. 381 (1996), pp.520-522	http://dx.doi.org/10.1016/j.apergo.2018.01.010	discussion	data	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib56	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0022		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0001	'A threshold of 200 ms was used for detecting dwells based on the minimum viewing time of 150 ms required to process and understand a complex pattern (Thorpe et al., 1996[[ refid=''bib56'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0115"""" view=""""all"""">Data analysis was performed in Matlab (The MathWorks). The [x,y] position for point of gaze for each frame was calculated as the average between the estimate for the left and right eye, filling frames with NaN if the validity code output by Tobii Studio stated that no eye was detected (validity code 4). The average number of such invalid samples amounted to a median [IQR] of 5.2 [12.9] % across conditions and participants. Point of gaze was then mapped to the nine ROIs on the UI using a look-up matrix. Small gaps in the data with a maximum length of 6 frames (0.1 s) were filled automatically based on the prior and subsequently attended ROI. From this data, a semantic ROI string was derived based on the dwell sequence rather than fixations (<ce:cross-ref refid=""""bib6"""" id=""""crosref0125"""">Brandt and Stark, 1997[[ refid=''''bib6'''' ]]</ce:cross-ref>), which can be described as a ‘compressed’ representation (<ce:cross-ref refid=""""bib23"""" id=""""crosref0130"""">Holmqvist et al., 2011[[ refid=''''bib23'''' ]]</ce:cross-ref>). A threshold of 200 ms was used for detecting dwells based on the minimum viewing time of 150 ms required to process and understand a complex pattern (<ce:cross-ref refid=""""bib56"""" id=""""crosref0135"""">Thorpe et al., 1996[[ refid=''''bib56'''' ]]</ce:cross-ref>).</ce:para>""''"'		IVA	
cites	Data analysis	J. Scott, Social Network Analysis , None, Sage (2013)	http://dx.doi.org/10.1016/j.apergo.2018.01.010	discussion	data	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib52	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0023		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0002	'Fundamentally, network analysis offers methods that explore the relationship between items in a connected system (Scott, 2013[[ refid=''bib52'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0135"""" view=""""all"""">Fundamentally, network analysis offers methods that explore the relationship between items in a connected system (<ce:cross-ref refid=""""bib52"""" id=""""crosref0150"""">Scott, 2013[[ refid=''''bib52'''' ]]</ce:cross-ref>). Associated metrics partially overlap with metrics related to transition matrices (<ce:cross-ref refid=""""bib23"""" id=""""crosref0155"""">Holmqvist et al., 2011[[ refid=''''bib23'''' ]]</ce:cross-ref>) already established in the vision literature. In network analysis as applied to vision research (<ce:cross-ref refid=""""bib54"""" id=""""crosref0160"""">Starke et al., 2017[[ refid=''''bib54'''' ]]</ce:cross-ref>), a ‘node’ is a ROI connected to another ROI through an ‘edge’ (gaze shift). A network can be directed or undirected: in a directed network, the gaze shift direction matters, e.g. a transition from ROI 1 to ROI 2 is not counted the same as a transition from ROI 2 to ROI 1. In an undirected network, this order does not matter and this approach was chosen in the present study. Graphic viewing networks were constructed to visualise the most common paths taken between the nine available information sources (<ce:cross-ref refid=""""bib54"""" id=""""crosref0165"""">Starke et al., 2017[[ refid=''''bib54'''' ]]</ce:cross-ref>).</ce:para>""''"'		IVA	
cites	Data analysis	S.D. Starke, C. Baber, N.J. Cooke, A. Howes, Workflows and individual differences during visually guided routine tasks in a road traffic management control room , Appl. Ergon. , vol. 61 (2017), pp.79-89	http://dx.doi.org/10.1016/j.apergo.2018.01.010	discussion	data	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib54	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0026		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0013	'Graphic viewing networks were constructed to visualise the most common paths taken between the nine available information sources (Starke et al., 2017[[ refid=''bib54'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0135"""" view=""""all"""">Fundamentally, network analysis offers methods that explore the relationship between items in a connected system (<ce:cross-ref refid=""""bib52"""" id=""""crosref0150"""">Scott, 2013[[ refid=''''bib52'''' ]]</ce:cross-ref>). Associated metrics partially overlap with metrics related to transition matrices (<ce:cross-ref refid=""""bib23"""" id=""""crosref0155"""">Holmqvist et al., 2011[[ refid=''''bib23'''' ]]</ce:cross-ref>) already established in the vision literature. In network analysis as applied to vision research (<ce:cross-ref refid=""""bib54"""" id=""""crosref0160"""">Starke et al., 2017[[ refid=''''bib54'''' ]]</ce:cross-ref>), a ‘node’ is a ROI connected to another ROI through an ‘edge’ (gaze shift). A network can be directed or undirected: in a directed network, the gaze shift direction matters, e.g. a transition from ROI 1 to ROI 2 is not counted the same as a transition from ROI 2 to ROI 1. In an undirected network, this order does not matter and this approach was chosen in the present study. Graphic viewing networks were constructed to visualise the most common paths taken between the nine available information sources (<ce:cross-ref refid=""""bib54"""" id=""""crosref0165"""">Starke et al., 2017[[ refid=''''bib54'''' ]]</ce:cross-ref>).</ce:para>""''"'		IVA	
cites	Data analysis	K. Holmqvist, M. Nyström, R. Andersson, R. Dewhurst, H. Jarodzka, J. Van de Weijer, Eye Tracking: a Comprehensive Guide to Methods and Measures , None, Oxford University Press (2011)	http://dx.doi.org/10.1016/j.apergo.2018.01.010	discussion	data	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib23	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0024		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0016	'Associated metrics partially overlap with metrics related to transition matrices (Holmqvist et al., 2011[[ refid=''bib23'' ]]) already established in the vision literature.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0135"""" view=""""all"""">Fundamentally, network analysis offers methods that explore the relationship between items in a connected system (<ce:cross-ref refid=""""bib52"""" id=""""crosref0150"""">Scott, 2013[[ refid=''''bib52'''' ]]</ce:cross-ref>). Associated metrics partially overlap with metrics related to transition matrices (<ce:cross-ref refid=""""bib23"""" id=""""crosref0155"""">Holmqvist et al., 2011[[ refid=''''bib23'''' ]]</ce:cross-ref>) already established in the vision literature. In network analysis as applied to vision research (<ce:cross-ref refid=""""bib54"""" id=""""crosref0160"""">Starke et al., 2017[[ refid=''''bib54'''' ]]</ce:cross-ref>), a ‘node’ is a ROI connected to another ROI through an ‘edge’ (gaze shift). A network can be directed or undirected: in a directed network, the gaze shift direction matters, e.g. a transition from ROI 1 to ROI 2 is not counted the same as a transition from ROI 2 to ROI 1. In an undirected network, this order does not matter and this approach was chosen in the present study. Graphic viewing networks were constructed to visualise the most common paths taken between the nine available information sources (<ce:cross-ref refid=""""bib54"""" id=""""crosref0165"""">Starke et al., 2017[[ refid=''''bib54'''' ]]</ce:cross-ref>).</ce:para>""''"'		IVA	
cites	Data analysis	S.D. Starke, C. Baber, N.J. Cooke, A. Howes, Workflows and individual differences during visually guided routine tasks in a road traffic management control room , Appl. Ergon. , vol. 61 (2017), pp.79-89	http://dx.doi.org/10.1016/j.apergo.2018.01.010	discussion	data	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib54	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0025		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0017	'In network analysis as applied to vision research (Starke et al., 2017[[ refid=''bib54'' ]]), a ‘node’ is a ROI connected to another ROI through an ‘edge’ (gaze shift).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0135"""" view=""""all"""">Fundamentally, network analysis offers methods that explore the relationship between items in a connected system (<ce:cross-ref refid=""""bib52"""" id=""""crosref0150"""">Scott, 2013[[ refid=''''bib52'''' ]]</ce:cross-ref>). Associated metrics partially overlap with metrics related to transition matrices (<ce:cross-ref refid=""""bib23"""" id=""""crosref0155"""">Holmqvist et al., 2011[[ refid=''''bib23'''' ]]</ce:cross-ref>) already established in the vision literature. In network analysis as applied to vision research (<ce:cross-ref refid=""""bib54"""" id=""""crosref0160"""">Starke et al., 2017[[ refid=''''bib54'''' ]]</ce:cross-ref>), a ‘node’ is a ROI connected to another ROI through an ‘edge’ (gaze shift). A network can be directed or undirected: in a directed network, the gaze shift direction matters, e.g. a transition from ROI 1 to ROI 2 is not counted the same as a transition from ROI 2 to ROI 1. In an undirected network, this order does not matter and this approach was chosen in the present study. Graphic viewing networks were constructed to visualise the most common paths taken between the nine available information sources (<ce:cross-ref refid=""""bib54"""" id=""""crosref0165"""">Starke et al., 2017[[ refid=''''bib54'''' ]]</ce:cross-ref>).</ce:para>""''"'		IVA	
uses_method_in	Data analysis	S. Josephson, M.E. Holmes, Clutter or content?: how on-screen enhancements affect how TV viewers scan and what they learn , Proceedings of the 2006 Symposium on Eye Tracking Research & Applications, ACM (2006)	http://dx.doi.org/10.1016/j.apergo.2018.01.010	discussion	data	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib28	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0028		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0018	'The normalised Levenshtein distance was calculated by dividing the calculated Levenshtein distance by the longest string (Josephson and Holmes, 2006[[ refid=''bib28'' ]]), where 100% means that two paths are completely different.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0150"""" view=""""all"""">Average <ce:italic>sequence length</ce:italic> counts the number of ROIs attended to as part of the scan pattern and holds the same information as switch count. The <ce:italic>Levenshtein distance</ce:italic> (also called string edit method) enumerates the number of changes necessary to convert one sequence of ROI dwells into another (<ce:cross-refs refid=""""bib6 bib13"""" id=""""crosrefs0060"""">Brandt and Stark, 1997; Feusner and Lukoff, 2008[[ refid=''''bib6 bib13'''' ]]</ce:cross-refs>). This quantifies how similar any two scan patterns are and was calculated between all pairwise trials using the function ‘strdist’<ce:cross-ref refid=""""fn1"""" id=""""crosref0170""""><ce:sup loc=""""post"""">1</ce:sup></ce:cross-ref><ce:footnote id=""""fn1""""><ce:label>1</ce:label><ce:note-para id=""""ntpara0010"""" view=""""all""""><ce:inter-ref xlink:href=""""http://uk.mathworks.com/matlabcentral/fileexchange/17585-calculation-of-distance-between-strings/content/strdist.m"""" id=""""intref0010"""" xlink:type=""""simple"""">http://uk.mathworks.com/matlabcentral/fileexchange/17585-calculation-of-distance-between-strings/content/strdist.m</ce:inter-ref>.</ce:note-para></ce:footnote> from Matlab Central (set penalty score: 1). The normalised Levenshtein distance was calculated by dividing the calculated Levenshtein distance by the longest string (<ce:cross-ref refid=""""bib28"""" id=""""crosref0175"""">Josephson and Holmes, 2006[[ refid=''''bib28'''' ]]</ce:cross-ref>), where 100% means that two paths are completely different.</ce:para>""''"'		IVA	
cites	Introduction	K. Holmqvist, M. Nyström, R. Andersson, R. Dewhurst, H. Jarodzka, J. Van de Weijer, Eye Tracking: a Comprehensive Guide to Methods and Measures , None, Oxford University Press (2011)	http://dx.doi.org/10.1016/j.apergo.2018.01.010	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib23	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0009		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0026	'Scan patterns are commonly defined as the sequence in which people attend to different regions of interest (ROIs) in a given display (Holmqvist et al., 2011[[ refid=''bib23'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0060"""" view=""""all"""">Scan patterns are commonly defined as the sequence in which people attend to different regions of interest (ROIs) in a given display (<ce:cross-ref refid=""""bib23"""" id=""""crosref0040"""">Holmqvist et al., 2011[[ refid=''''bib23'''' ]]</ce:cross-ref>). There is much evidence that such visual attention shifts are guided ‘top-down’ in goal directed tasks, where eye movements are strategically directed towards relevant information sources (<ce:cross-refs refid=""""bib21 bib22"""" id=""""crosrefs0035"""">Hayhoe and Ballard, 2005; Henderson, 2003[[ refid=''''bib21 bib22'''' ]]</ce:cross-refs>): i.e. people simply look where they expect to find information relevant to their agenda or question. This consensus roots in classic work which demonstrated that attended ROIs depend on the viewer''''s intention (<ce:cross-refs refid=""""bib5 bib64"""" id=""""crosrefs0040"""">Borji and Itti, 2014; Yarbus, 1967[[ refid=''''bib5 bib64'''' ]]</ce:cross-refs>). The definition of ‘viewer intention’ could relate to the mental model that the viewer has of the structural relations between information sources and decisions, but could equally relate to the probability that a given information source contributes to a given decision.</ce:para>""''"'		IVA	
cites	Discussion	X. Chen, S.D. Starke, C. Baber, A. Howes, A cognitive model of how people make decisions through interaction with visual displays , ACM CHI’17 Conference on Human Factors in Computing Systems, ACM (2017)	http://dx.doi.org/10.1016/j.apergo.2018.01.010	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib9	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0040		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0027	'Using cognitive modelling, we have recently shown that given a validity distribution akin to the present study and the need for eye movements, an optimum number of three to four ROIs would theoretically be attended to (Chen et al., 2017[[ refid=''bib9'' ]]) based on an assumed Markov Decision Process and the learning and integration of the three best cues.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0270"""" view=""""all"""">Different user interface concepts affected only selected aspects of task performance, where metrics associated with the required time investment were significantly different between UIs. Here, condition ‘FC’ stood out, resulting in fastest task completion (study completion and trial time around half or less of all other conditions, fastest information gathering time). However, neither accuracy for the last 15 trials nor rated task difficulty differed significantly between the four UI concepts. In the present study, best possible task performance would on average have been 86% when perfectly integrating all nine cues based on their true validities. By comparison, making a decision based on only the best cue would have resulted in 85% accuracy, while using a simple majority vote across all cues without any knowledge of validities would have resulted in 80% accuracy. Therefore, very different strategies and/or the attention to only a subset of cues would not substantially impact on task performance. Using cognitive modelling, we have recently shown that given a validity distribution akin to the present study and the need for eye movements, an optimum number of three to four ROIs would theoretically be attended to (<ce:cross-ref refid=""""bib9"""" id=""""crosref0285"""">Chen et al., 2017[[ refid=''''bib9'''' ]]</ce:cross-ref>) based on an assumed Markov Decision Process and the learning and integration of the three best cues. The exception in <ce:cross-ref refid=""""bib9"""" id=""""crosref0290"""">Chen et al. (2017)[[ refid=''''bib9'''' ]]</ce:cross-ref> was condition ‘FD’, where the predicted number of attended ROIs rose to six, while in the present study the observed average number of attended ROIs for condition ‘FD’ was even higher (eight out of nine). Given the above findings, we conclude that UI design may dictate information sampling behaviour through an implicit optimum trade-off between time expended and information gathered.</ce:para>""''"'		IVA	
cites	Discussion	X. Chen, S.D. Starke, C. Baber, A. Howes, A cognitive model of how people make decisions through interaction with visual displays , ACM CHI’17 Conference on Human Factors in Computing Systems, ACM (2017)	http://dx.doi.org/10.1016/j.apergo.2018.01.010	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib9	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0041		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0028	'The exception in Chen et al. (2017)[[ refid=''bib9'' ]] was condition ‘FD’, where the predicted number of attended ROIs rose to six, while in the present study the observed average number of attended ROIs for condition ‘FD’ was even higher (eight out of nine).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0270"""" view=""""all"""">Different user interface concepts affected only selected aspects of task performance, where metrics associated with the required time investment were significantly different between UIs. Here, condition ‘FC’ stood out, resulting in fastest task completion (study completion and trial time around half or less of all other conditions, fastest information gathering time). However, neither accuracy for the last 15 trials nor rated task difficulty differed significantly between the four UI concepts. In the present study, best possible task performance would on average have been 86% when perfectly integrating all nine cues based on their true validities. By comparison, making a decision based on only the best cue would have resulted in 85% accuracy, while using a simple majority vote across all cues without any knowledge of validities would have resulted in 80% accuracy. Therefore, very different strategies and/or the attention to only a subset of cues would not substantially impact on task performance. Using cognitive modelling, we have recently shown that given a validity distribution akin to the present study and the need for eye movements, an optimum number of three to four ROIs would theoretically be attended to (<ce:cross-ref refid=""""bib9"""" id=""""crosref0285"""">Chen et al., 2017[[ refid=''''bib9'''' ]]</ce:cross-ref>) based on an assumed Markov Decision Process and the learning and integration of the three best cues. The exception in <ce:cross-ref refid=""""bib9"""" id=""""crosref0290"""">Chen et al. (2017)[[ refid=''''bib9'''' ]]</ce:cross-ref> was condition ‘FD’, where the predicted number of attended ROIs rose to six, while in the present study the observed average number of attended ROIs for condition ‘FD’ was even higher (eight out of nine). Given the above findings, we conclude that UI design may dictate information sampling behaviour through an implicit optimum trade-off between time expended and information gathered.</ce:para>""''"'		IVA	
cites	Discussion	G. Gigerenzer, Rationality for Mortals: How People Cope with Uncertainty , None, Oxford University Press (2008)	http://dx.doi.org/10.1016/j.apergo.2018.01.010	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib16	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0042		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0029	'This finding is in line with the established literature on approximations in human decision making, where, given the nature of decision making under uncertainty, there may not be much benefit to complex cue integration, with heuristics and short-cuts often leading to comparable task performance (Gigerenzer, 2008[[ refid=''bib16'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0275"""" view=""""all"""">In the present study, accuracy across the last trials per condition ranged from a median of 67% (condition ‘RD’) to 80% (condition ‘RC’ and ‘FD’). This means that in condition ‘RD’, participants performed on average on par with using a selection of 3 or 4 random cues. The median number of revealed cues was 3.5 for that condition, providing further support for such a strategy. However, accuracy was not significantly different between conditions and between-participant variation was high. Therefore, the estimate for condition ‘RD’ may have been inaccurately low and may trend towards the other conditions with a greater sample size. From analysis of the questionnaires, we know that in condition ‘RD’, similar to the other conditions, four out of eight participants named the cue with the highest validity (‘purchase location’) in their top 2. Three participants, in fact, named this as their top one cue. Hence, one can assume that at least half of participants learned cue validity and did not act randomly. <ce:cross-ref refid=""""tbl2"""" id=""""crosref0295"""">Table 2</ce:cross-ref> however illustrates that combining the best cue (highest validity) with two or three random or even systematically unreliable cues would reduce task performance to between 68% and 77% accuracy, similar to that observed across conditions. This finding is in line with the established literature on approximations in human decision making, where, given the nature of decision making under uncertainty, there may not be much benefit to complex cue integration, with heuristics and short-cuts often leading to comparable task performance (<ce:cross-ref refid=""""bib16"""" id=""""crosref0300"""">Gigerenzer, 2008[[ refid=''''bib16'''' ]]</ce:cross-ref>). This demonstrates, akin to fast and frugal heuristics, that it can be preferential to rely on the single best cue, as integration of further (much less reliable) cues would reduce the overall accuracy of the decision. Simply put: combining a useful cue with an incorrectly chosen second one confounds the decision quality rather than improving it.</ce:para>""''"'		IVA	
cites	Introduction	C. Ehmke, S. Wilson, Identifying web usability problems from eye-tracking data , Proceedings of the 21st British HCI Group Annual Conference on People and Computers: HCI but Not as We Know it, British Computer Society, University of Lancaster , vol. vol. 1 (2007), pp.119-128	http://dx.doi.org/10.1016/j.apergo.2018.01.010	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib11	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0003		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0039	'Despite these efforts, our understanding of principles underlying visual interaction with UIs is considered under-developed (Ehmke and Wilson, 2007[[ refid=''bib11'' ]]), and comparatively little work systematically investigates the effect of data presentation on visual scanning approaches and information foraging.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0040"""" view=""""all"""">The analysis of interactions with visually displayed information has a rich history for consumer testing, where visual scanning of UIs can be investigated through eye tracking (<ce:cross-refs refid=""""bib25 bib47"""" id=""""crosrefs0015"""">Jacob and Karn, 2003; Poole and Ball, 2006[[ refid=''''bib25 bib47'''' ]]</ce:cross-refs>) to get an insight into ease of information acquisition (<ce:cross-ref refid=""""bib45"""" id=""""crosref0020"""">Pohl et al., 2009[[ refid=''''bib45'''' ]]</ce:cross-ref>) for example. Despite these efforts, our understanding of principles underlying visual interaction with UIs is considered under-developed (<ce:cross-ref refid=""""bib11"""" id=""""crosref0025"""">Ehmke and Wilson, 2007[[ refid=''''bib11'''' ]]</ce:cross-ref>), and comparatively little work systematically investigates the effect of data presentation on visual scanning approaches and information foraging. In a field study investigating visual sampling across multiple displays in a road traffic control room (<ce:cross-ref refid=""""bib54"""" id=""""crosref0030"""">Starke et al., 2017[[ refid=''''bib54'''' ]]</ce:cross-ref>), we recently showed that search activity was idiosyncratic (with individuals adopting different patterns of search) but also preferential (with some information displays being attended to more often than others). With the work reported here, the role of preferential information selection was tested in a controlled task.</ce:para>""''"'		IVA	
cites	Introduction	S.D. Starke, C. Baber, N.J. Cooke, A. Howes, Workflows and individual differences during visually guided routine tasks in a road traffic management control room , Appl. Ergon. , vol. 61 (2017), pp.79-89	http://dx.doi.org/10.1016/j.apergo.2018.01.010	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib54	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0004		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0040	'In a field study investigating visual sampling across multiple displays in a road traffic control room (Starke et al., 2017[[ refid=''bib54'' ]]), we recently showed that search activity was idiosyncratic (with individuals adopting different patterns of search) but also preferential (with some information displays being attended to more often than others).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0040"""" view=""""all"""">The analysis of interactions with visually displayed information has a rich history for consumer testing, where visual scanning of UIs can be investigated through eye tracking (<ce:cross-refs refid=""""bib25 bib47"""" id=""""crosrefs0015"""">Jacob and Karn, 2003; Poole and Ball, 2006[[ refid=''''bib25 bib47'''' ]]</ce:cross-refs>) to get an insight into ease of information acquisition (<ce:cross-ref refid=""""bib45"""" id=""""crosref0020"""">Pohl et al., 2009[[ refid=''''bib45'''' ]]</ce:cross-ref>) for example. Despite these efforts, our understanding of principles underlying visual interaction with UIs is considered under-developed (<ce:cross-ref refid=""""bib11"""" id=""""crosref0025"""">Ehmke and Wilson, 2007[[ refid=''''bib11'''' ]]</ce:cross-ref>), and comparatively little work systematically investigates the effect of data presentation on visual scanning approaches and information foraging. In a field study investigating visual sampling across multiple displays in a road traffic control room (<ce:cross-ref refid=""""bib54"""" id=""""crosref0030"""">Starke et al., 2017[[ refid=''''bib54'''' ]]</ce:cross-ref>), we recently showed that search activity was idiosyncratic (with individuals adopting different patterns of search) but also preferential (with some information displays being attended to more often than others). With the work reported here, the role of preferential information selection was tested in a controlled task.</ce:para>""''"'		IVA	
cites	Discussion	C. Paeye, A.C. Schütz, K.R. Gegenfurtner, Visual reinforcement shapes eye movements in visual search , J. Vis. , vol. 16 (2016), pp.15	http://dx.doi.org/10.1016/j.apergo.2018.01.010	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib41	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0037		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0056	'Similarly, Paeye et al. (2016)[[ refid=''bib41'' ]] showed that preferentially attended ROIs can be controlled through reinforcement learning when working with a gaze-contingent study design.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0255"""" view=""""all"""">We expect systematic aspects to scan pattern formation during feedback-based information foraging to be associated with learning. In line with this thinking, metrics indicated a reduction in attended information between the first and last 15 trials except for condition ‘FD’ (see below for further details). This is consistent with efficiency gains, where the relevance/value of information sources may have been consolidated through exposure, and ROIs considered less relevant were attended less frequently. Similarly, <ce:cross-ref refid=""""bib41"""" id=""""crosref0260"""">Paeye et al. (2016)[[ refid=''''bib41'''' ]]</ce:cross-ref> showed that preferentially attended ROIs can be controlled through reinforcement learning when working with a gaze-contingent study design. On average, the number of transitions between any two ROIs (edge count) almost matched the total sequence length. This indicates that ROIs were attended serially and usually not revisited, further reflected in the low link density and the low average nodal degree.</ce:para>""''"'		IVA	
cites	Discussion	S.A. Brandt, L.W. Stark, Spontaneous eye movements during visual imagery reflect the content of the visual scene , J. Cognit. Neurosci. , vol. 9 (1997), pp.27-38	http://dx.doi.org/10.1016/j.apergo.2018.01.010	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib6	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0036		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0057	'Higher similarity in scan patterns than this has previously been observed for repeated viewing and imagination of geometrical shapes, ranging from 18% to 25% (Brandt and Stark, 1997[[ refid=''bib6'' ]]) in a task which provides a reduced action and decision space.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0250"""" view=""""all"""">For all UI concepts, the Levenshtein distance indicated that more than half of the visual attention sequence (63% to 69%) had to be altered in order to be identical between a pairwise comparison of scan patterns for all UI concepts. Higher similarity in scan patterns than this has previously been observed for repeated viewing and imagination of geometrical shapes, ranging from 18% to 25% (<ce:cross-ref refid=""""bib6"""" id=""""crosref0250"""">Brandt and Stark, 1997[[ refid=''''bib6'''' ]]</ce:cross-ref>) in a task which provides a reduced action and decision space. In the present study, both Levenshtein distance and local sequence alignment score were significantly different from random data for all four interface concepts. Similarity in scan patterns was therefore higher than expected for random data and indicated a level of systematic order to the search. The repeatable scan pattern fragments had an average length across participants of 2–4 ROIs (out of 9), evidenced both by local sequence alignment and recurring n-mers. The overall length of the scan pattern was longer than this (sequence length ranging from 5 to 13, edge count and count of switches ranging from 4 to 11 and number of attended ROIs ranging from 4 to 8), hence substantiating an arbitrary and systematic component to the overall scan pattern. The systematic component often corresponded to those indicators which the participant noted down as most important (see viewing networks in <ce:cross-ref refid=""""fig5"""" id=""""crosref0255"""">Fig. 5</ce:cross-ref>).</ce:para>""''"'		IVA	
uses_method_in	Data analysis	A. Field, Discovering Statistics Using IBM SPSS Statistics , None, Sage (2013)	http://dx.doi.org/10.1016/j.apergo.2018.01.010	discussion	data	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib14	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0033		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0061	'In case of significance, post hoc Mann-Whitney U tests were performed for all pairwise comparisons (six per variable), corrected for multiple testing using the Bonferroni correction (Field, 2013[[ refid=''bib14'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0180"""" view=""""all"""">To examine whether outcome metrics changed between the first and last 15 trials, Wilcoxon signed-rank matched-pair tests were performed for each variable and each of the four UI concepts. To compare outcome metrics for the last 15 trials between the four UI design concepts, a Kruskall Wallis test was performed. In case of significance, post hoc Mann-Whitney U tests were performed for all pairwise comparisons (six per variable), corrected for multiple testing using the Bonferroni correction (<ce:cross-ref refid=""""bib14"""" id=""""crosref0190"""">Field, 2013[[ refid=''''bib14'''' ]]</ce:cross-ref>). To compare the number of attributes revealed in the two ‘reveal’ conditions, a Mann-Whitney U test was performed. Mann-Whitney U tests were further applied to test a) the effect of developing a mental model and b) the correct identification of the best cue as the top 1 cue on outcome metrics.</ce:para>""''"'		IVA	
cites	Discussion	K. Rayner, Eye movements in reading and information processing: 20 Years of research , Psychol. Bull. , vol. 124 (1998), pp.372-422	http://dx.doi.org/10.1016/j.apergo.2018.01.010	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib48	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0038		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0067	'When reading alphanumerical data, a participant has to foveate (attend with central vision) a ROI with often multiple saccades (eye movements) to gather information, since in reading only a few words are extracted at a time (Rayner, 1998[[ refid=''bib48'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0260"""" view=""""all"""">Different UI concepts did lead to differences in visual information foraging. Largest differences were found between condition ‘FD’ (user interface presenting alpha-numerical data in full view) and all other conditions. Condition ‘FD’ resulted in the longest scan patterns and the longest repeating sequence fragments, whereas condition ‘FC’ (colour maps in full view) resulted in the shortest scan patterns. This difference may be due to basic central and peripheral vision mechanics. When reading alphanumerical data, a participant has to foveate (attend with central vision) a ROI with often multiple saccades (eye movements) to gather information, since in reading only a few words are extracted at a time (<ce:cross-ref refid=""""bib48"""" id=""""crosref0265"""">Rayner, 1998[[ refid=''''bib48'''' ]]</ce:cross-ref>). When working with colour blocks, peripheral vision allows the viewer to gather an overview of the attribute pattern very quickly and over a broader field of view, where, for example, red-green or blue-yellow discrimination remains intact across virtually the whole horizontal peripheral field (<ce:cross-ref refid=""""bib40"""" id=""""crosref0270"""">Noorlander et al., 1983[[ refid=''''bib40'''' ]]</ce:cross-ref>) and the use of peripheral vision is assumed to benefit shape detection (<ce:cross-ref refid=""""bib30"""" id=""""crosref0275"""">Kieras and Hornof, 2014[[ refid=''''bib30'''' ]]</ce:cross-ref>) while also being heavily involved in pattern recognition (<ce:cross-ref refid=""""bib55"""" id=""""crosref0280"""">Strasburger et al., 2011[[ refid=''''bib55'''' ]]</ce:cross-ref>). Hence, alpha-numerical data have to be decoded, while colour blocks allow for quick near-instantaneous classification. The availability of colour-coded information in the periphery in condition ‘FC’ is assumed to be the driving factor behind the fast task- and decision making times and short scan patterns observed in this study. Further, in contrast to the stark difference between condition ‘FD’ and ‘FC’, visual scanning behaviour compared between the two interfaces where information had to be revealed (‘RD’, ‘RC’) was similar. Here, the participant was forced to attend ROIs with central vision to reveal information, and peripheral vision could not be used for quick classification or information extraction.</ce:para>""''"'		IVA	
cites	Introduction	K. Holmqvist, M. Nyström, R. Andersson, R. Dewhurst, H. Jarodzka, J. Van de Weijer, Eye Tracking: a Comprehensive Guide to Methods and Measures , None, Oxford University Press (2011)	http://dx.doi.org/10.1016/j.apergo.2018.01.010	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib23	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0018		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0070	'At present, some of the open questions in scan pattern analysis concern the meaningful comparison of scan patterns, the consistency of scan patterns, as well as the relationship between scan patterns and cognitive processes (Holmqvist et al., 2011[[ refid=''bib23'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0070"""" view=""""all"""">At present, some of the open questions in scan pattern analysis concern the meaningful comparison of scan patterns, the consistency of scan patterns, as well as the relationship between scan patterns and cognitive processes (<ce:cross-ref refid=""""bib23"""" id=""""crosref0070"""">Holmqvist et al., 2011[[ refid=''''bib23'''' ]]</ce:cross-ref>). Here we address some of these issues, applying conventional and recent methods to the visual interaction with user UIs.</ce:para>""''"'		IVA	
cites	Introduction	S.R. Ellis, L. Stark, Statistical dependency in visual scanning , Hum. Factors: The Journal of the Human Factors and Ergonomics Society , vol. 28 (1986), pp.421-438	http://dx.doi.org/10.1016/j.apergo.2018.01.010	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib12	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0013		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0071	'In air traffic monitoring, visual scanning shows a tendency towards repeatable patterns independent of changes in the locations of points of interest within a stationary display (Ellis and Stark, 1986[[ refid=''bib12'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0065"""" view=""""all"""">To date, it remains ambiguous whether people develop systematic scan patterns when examining familiar information sources. There is mounting evidence for the development of repeatable sequences of attended regions within a scene. During repeated viewing of natural images, scan patterns are reasonably consistent (<ce:cross-refs refid=""""bib15 bib31 bib43 bib58"""" id=""""crosrefs0045"""">Foulsham and Underwood, 2008; Laeng and Teodorescu, 2002; Pieters et al., 1999; Underwood et al., 2009[[ refid=''''bib15 bib31 bib43 bib58'''' ]]</ce:cross-refs>). In air traffic monitoring, visual scanning shows a tendency towards repeatable patterns independent of changes in the locations of points of interest within a stationary display (<ce:cross-ref refid=""""bib12"""" id=""""crosref0045"""">Ellis and Stark, 1986[[ refid=''''bib12'''' ]]</ce:cross-ref>). When looking at websites, there is evidence for similarity in (preferred) scan patterns for some participants (<ce:cross-ref refid=""""bib27"""" id=""""crosref0050"""">Josephson and Holmes, 2002[[ refid=''''bib27'''' ]]</ce:cross-ref>). However, no study has yet found evidence for perfect scan pattern repeatability; generally, humans retain a (sometimes high) level of variability. Familiarity and expertise may affect the consistency of scan patterns: in dynamic tasks, scan patterns can vary in consistency between novices and experts, when judging fish locomotion (<ce:cross-ref refid=""""bib26"""" id=""""crosref0055"""">Jarodzka et al., 2010[[ refid=''''bib26'''' ]]</ce:cross-ref>). The same holds true for static stimuli such as dermatology slides (<ce:cross-ref refid=""""bib59"""" id=""""crosref0060"""">Vaidyanathan et al., 2014[[ refid=''''bib59'''' ]]</ce:cross-ref>). Ultimately, the similarity of scan patterns depends on the study design and may – in part – arise from the consistency of image characteristics (<ce:cross-ref refid=""""bib27"""" id=""""crosref0065"""">Josephson and Holmes, 2002[[ refid=''''bib27'''' ]]</ce:cross-ref>). The latter usually results in scan patterns which are similar between participants.</ce:para>""''"'		IVA	
cites	Introduction	S. Josephson, M.E. Holmes, Visual attention to repeated internet images: testing the scanpath theory on the world wide web , Proceedings of the 2002 Symposium on Eye Tracking Research \& Applications, ACM (2002)	http://dx.doi.org/10.1016/j.apergo.2018.01.010	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib27	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0017		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0080	'Ultimately, the similarity of scan patterns depends on the study design and may – in part – arise from the consistency of image characteristics (Josephson and Holmes, 2002[[ refid=''bib27'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0065"""" view=""""all"""">To date, it remains ambiguous whether people develop systematic scan patterns when examining familiar information sources. There is mounting evidence for the development of repeatable sequences of attended regions within a scene. During repeated viewing of natural images, scan patterns are reasonably consistent (<ce:cross-refs refid=""""bib15 bib31 bib43 bib58"""" id=""""crosrefs0045"""">Foulsham and Underwood, 2008; Laeng and Teodorescu, 2002; Pieters et al., 1999; Underwood et al., 2009[[ refid=''''bib15 bib31 bib43 bib58'''' ]]</ce:cross-refs>). In air traffic monitoring, visual scanning shows a tendency towards repeatable patterns independent of changes in the locations of points of interest within a stationary display (<ce:cross-ref refid=""""bib12"""" id=""""crosref0045"""">Ellis and Stark, 1986[[ refid=''''bib12'''' ]]</ce:cross-ref>). When looking at websites, there is evidence for similarity in (preferred) scan patterns for some participants (<ce:cross-ref refid=""""bib27"""" id=""""crosref0050"""">Josephson and Holmes, 2002[[ refid=''''bib27'''' ]]</ce:cross-ref>). However, no study has yet found evidence for perfect scan pattern repeatability; generally, humans retain a (sometimes high) level of variability. Familiarity and expertise may affect the consistency of scan patterns: in dynamic tasks, scan patterns can vary in consistency between novices and experts, when judging fish locomotion (<ce:cross-ref refid=""""bib26"""" id=""""crosref0055"""">Jarodzka et al., 2010[[ refid=''''bib26'''' ]]</ce:cross-ref>). The same holds true for static stimuli such as dermatology slides (<ce:cross-ref refid=""""bib59"""" id=""""crosref0060"""">Vaidyanathan et al., 2014[[ refid=''''bib59'''' ]]</ce:cross-ref>). Ultimately, the similarity of scan patterns depends on the study design and may – in part – arise from the consistency of image characteristics (<ce:cross-ref refid=""""bib27"""" id=""""crosref0065"""">Josephson and Holmes, 2002[[ refid=''''bib27'''' ]]</ce:cross-ref>). The latter usually results in scan patterns which are similar between participants.</ce:para>""''"'		IVA	
cites	Introduction	P. Vaidyanathan, J. Pelz, C. Alm, P. Shi, A. Haake, Recurrence quantification analysis reveals eye-movement behavior differences between experts and novices , Proceedings of the Symposium on Eye Tracking Research and Applications, ACM, Safety Harbor (2014)	http://dx.doi.org/10.1016/j.apergo.2018.01.010	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib59	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0016		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0081	'The same holds true for static stimuli such as dermatology slides (Vaidyanathan et al., 2014[[ refid=''bib59'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0065"""" view=""""all"""">To date, it remains ambiguous whether people develop systematic scan patterns when examining familiar information sources. There is mounting evidence for the development of repeatable sequences of attended regions within a scene. During repeated viewing of natural images, scan patterns are reasonably consistent (<ce:cross-refs refid=""""bib15 bib31 bib43 bib58"""" id=""""crosrefs0045"""">Foulsham and Underwood, 2008; Laeng and Teodorescu, 2002; Pieters et al., 1999; Underwood et al., 2009[[ refid=''''bib15 bib31 bib43 bib58'''' ]]</ce:cross-refs>). In air traffic monitoring, visual scanning shows a tendency towards repeatable patterns independent of changes in the locations of points of interest within a stationary display (<ce:cross-ref refid=""""bib12"""" id=""""crosref0045"""">Ellis and Stark, 1986[[ refid=''''bib12'''' ]]</ce:cross-ref>). When looking at websites, there is evidence for similarity in (preferred) scan patterns for some participants (<ce:cross-ref refid=""""bib27"""" id=""""crosref0050"""">Josephson and Holmes, 2002[[ refid=''''bib27'''' ]]</ce:cross-ref>). However, no study has yet found evidence for perfect scan pattern repeatability; generally, humans retain a (sometimes high) level of variability. Familiarity and expertise may affect the consistency of scan patterns: in dynamic tasks, scan patterns can vary in consistency between novices and experts, when judging fish locomotion (<ce:cross-ref refid=""""bib26"""" id=""""crosref0055"""">Jarodzka et al., 2010[[ refid=''''bib26'''' ]]</ce:cross-ref>). The same holds true for static stimuli such as dermatology slides (<ce:cross-ref refid=""""bib59"""" id=""""crosref0060"""">Vaidyanathan et al., 2014[[ refid=''''bib59'''' ]]</ce:cross-ref>). Ultimately, the similarity of scan patterns depends on the study design and may – in part – arise from the consistency of image characteristics (<ce:cross-ref refid=""""bib27"""" id=""""crosref0065"""">Josephson and Holmes, 2002[[ refid=''''bib27'''' ]]</ce:cross-ref>). The latter usually results in scan patterns which are similar between participants.</ce:para>""''"'		IVA	
cites	Introduction	H. Jarodzka, K. Scheiter, P. Gerjets, T. van Gog, In the eyes of the beholder: how experts and novices interpret dynamic stimuli , Learn. InStruct. , vol. 20 (2010), pp.146-154	http://dx.doi.org/10.1016/j.apergo.2018.01.010	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib26	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0015		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0082	'Familiarity and expertise may affect the consistency of scan patterns: in dynamic tasks, scan patterns can vary in consistency between novices and experts, when judging fish locomotion (Jarodzka et al., 2010[[ refid=''bib26'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0065"""" view=""""all"""">To date, it remains ambiguous whether people develop systematic scan patterns when examining familiar information sources. There is mounting evidence for the development of repeatable sequences of attended regions within a scene. During repeated viewing of natural images, scan patterns are reasonably consistent (<ce:cross-refs refid=""""bib15 bib31 bib43 bib58"""" id=""""crosrefs0045"""">Foulsham and Underwood, 2008; Laeng and Teodorescu, 2002; Pieters et al., 1999; Underwood et al., 2009[[ refid=''''bib15 bib31 bib43 bib58'''' ]]</ce:cross-refs>). In air traffic monitoring, visual scanning shows a tendency towards repeatable patterns independent of changes in the locations of points of interest within a stationary display (<ce:cross-ref refid=""""bib12"""" id=""""crosref0045"""">Ellis and Stark, 1986[[ refid=''''bib12'''' ]]</ce:cross-ref>). When looking at websites, there is evidence for similarity in (preferred) scan patterns for some participants (<ce:cross-ref refid=""""bib27"""" id=""""crosref0050"""">Josephson and Holmes, 2002[[ refid=''''bib27'''' ]]</ce:cross-ref>). However, no study has yet found evidence for perfect scan pattern repeatability; generally, humans retain a (sometimes high) level of variability. Familiarity and expertise may affect the consistency of scan patterns: in dynamic tasks, scan patterns can vary in consistency between novices and experts, when judging fish locomotion (<ce:cross-ref refid=""""bib26"""" id=""""crosref0055"""">Jarodzka et al., 2010[[ refid=''''bib26'''' ]]</ce:cross-ref>). The same holds true for static stimuli such as dermatology slides (<ce:cross-ref refid=""""bib59"""" id=""""crosref0060"""">Vaidyanathan et al., 2014[[ refid=''''bib59'''' ]]</ce:cross-ref>). Ultimately, the similarity of scan patterns depends on the study design and may – in part – arise from the consistency of image characteristics (<ce:cross-ref refid=""""bib27"""" id=""""crosref0065"""">Josephson and Holmes, 2002[[ refid=''''bib27'''' ]]</ce:cross-ref>). The latter usually results in scan patterns which are similar between participants.</ce:para>""''"'		IVA	
cites	Introduction	S. Josephson, M.E. Holmes, Visual attention to repeated internet images: testing the scanpath theory on the world wide web , Proceedings of the 2002 Symposium on Eye Tracking Research \& Applications, ACM (2002)	http://dx.doi.org/10.1016/j.apergo.2018.01.010	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/br/bib27	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/ctx/ctx0014		44	4	http://www.scar.disi.unibo.it/r/10-1016-j-apergo-2018-01-010/itrp/0083	'When looking at websites, there is evidence for similarity in (preferred) scan patterns for some participants (Josephson and Holmes, 2002[[ refid=''bib27'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0065"""" view=""""all"""">To date, it remains ambiguous whether people develop systematic scan patterns when examining familiar information sources. There is mounting evidence for the development of repeatable sequences of attended regions within a scene. During repeated viewing of natural images, scan patterns are reasonably consistent (<ce:cross-refs refid=""""bib15 bib31 bib43 bib58"""" id=""""crosrefs0045"""">Foulsham and Underwood, 2008; Laeng and Teodorescu, 2002; Pieters et al., 1999; Underwood et al., 2009[[ refid=''''bib15 bib31 bib43 bib58'''' ]]</ce:cross-refs>). In air traffic monitoring, visual scanning shows a tendency towards repeatable patterns independent of changes in the locations of points of interest within a stationary display (<ce:cross-ref refid=""""bib12"""" id=""""crosref0045"""">Ellis and Stark, 1986[[ refid=''''bib12'''' ]]</ce:cross-ref>). When looking at websites, there is evidence for similarity in (preferred) scan patterns for some participants (<ce:cross-ref refid=""""bib27"""" id=""""crosref0050"""">Josephson and Holmes, 2002[[ refid=''''bib27'''' ]]</ce:cross-ref>). However, no study has yet found evidence for perfect scan pattern repeatability; generally, humans retain a (sometimes high) level of variability. Familiarity and expertise may affect the consistency of scan patterns: in dynamic tasks, scan patterns can vary in consistency between novices and experts, when judging fish locomotion (<ce:cross-ref refid=""""bib26"""" id=""""crosref0055"""">Jarodzka et al., 2010[[ refid=''''bib26'''' ]]</ce:cross-ref>). The same holds true for static stimuli such as dermatology slides (<ce:cross-ref refid=""""bib59"""" id=""""crosref0060"""">Vaidyanathan et al., 2014[[ refid=''''bib59'''' ]]</ce:cross-ref>). Ultimately, the similarity of scan patterns depends on the study design and may – in part – arise from the consistency of image characteristics (<ce:cross-ref refid=""""bib27"""" id=""""crosref0065"""">Josephson and Holmes, 2002[[ refid=''''bib27'''' ]]</ce:cross-ref>). The latter usually results in scan patterns which are similar between participants.</ce:para>""''"'		IVA	
extends	Related work	C. Kang, C. Molinaro, S. Kraus, Y. Shavitt, V.S. Subrahmanian, Diffusion centrality in social networks , Proc. International Conference on Advances in Social Networks Analysis and Mining (2012)	http://dx.doi.org/10.1016/j.artint.2016.06.008	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-06-008/br/br0310>	<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-06-008/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-06-008/ctx/ctx0017>				http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-06-008/itrp/0076	'This paper extends [31][[ refid=''br0310'' ]] in different respects.'				100_classified_extends
extends	Introduction	N. Bulling, M. Dastani, Verification and implementation of normative behaviours in multi-agent systems , Proc. of the 22nd Int. Joint Conf. on Artificial Intelligence (July 2011)	http://dx.doi.org/10.1016/j.artint.2016.07.001	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-001/br/br0190>	<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-001/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-001/ctx/ctx0015>				http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-001/itrp/0125	'This paper extends and revises the work presented in [19][[ refid=''br0190'' ]].'				100_classified_extends
uses_method_in	Deliberative architecture and knowledge model	M. Woolridge, Multiagent Systems. A Modern Approach to Distributed Artificial Intelligence , None, Massachusetts Institute of Technology (1999)	http://dx.doi.org/10.1016/j.artint.2016.07.002	model		<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-002/br/br0270>	<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-002/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-002/ctx/ctx0009>				http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-002/itrp/0026	'As put by Woolridge [27][[ refid=''br0270'' ]], BDI architectures are primarily focused on practical reasoning, i.e. the process of deciding, step by step, which action to perform to reach a goal.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Cognitive skills	S. Lemaignan, R. Ros, E.A. Sisbot, R. Alami, M. Beetz, Grounding the interaction: anchoring situated discourse in everyday human–robot interaction , Int. J. Soc. Robot. (2011)	http://dx.doi.org/10.1016/j.artint.2016.07.002			<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-002/br/br0740>	<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-002/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-002/ctx/ctx0043>				http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-002/itrp/0040	'Algorithms and implementation details are provided in [74][[ refid=''br0740'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Cognitive skills	S. Lemaignan, R. Ros, E.A. Sisbot, R. Alami, M. Beetz, Grounding the interaction: anchoring situated discourse in everyday human–robot interaction , Int. J. Soc. Robot. (2011)	http://dx.doi.org/10.1016/j.artint.2016.07.002			<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-002/br/br0740>	<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-002/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-002/ctx/ctx0044>				http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-002/itrp/0141	'A full account of the Dialogs features and the corresponding algorithms is available in [74][[ refid=''br0740'' ]].'			FDY+AGA	infered_pred1
cites_as_review	Introduction	R. Navigli, Word Sense Disambiguation: a survey , ACM Comput. Surv. , vol. 41 (2009), pp.1-69	http://dx.doi.org/10.1016/j.artint.2016.07.005	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-005/br/br0940>	<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-005/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-005/ctx/ctx0008>				http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-005/itrp/0001	'On the other hand, the performance of Word Sense Disambiguation (WSD) techniques is still far from ideal [93][[ refid=''br0940'' ]], which in its turn prevents a reliable automatic sense-annotation of large text corpora that can be used for modeling individual word senses.'			FDY+AGA	infered_pred1
cites_as_review	Related work	R. Navigli, Word Sense Disambiguation: a survey , ACM Comput. Surv. , vol. 41 (2009), pp.1-69	http://dx.doi.org/10.1016/j.artint.2016.07.005	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-005/br/br0940>	<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-005/sec/11>	<http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-005/ctx/ctx0126>				http://www.scar.disi.unibo.it/r/10-1016-j-artint-2016-07-005/itrp/0102	'Based on the type of resources they use, WSD techniques can be put into two main categories: knowledge-based and supervised [93][[ refid=''br0940'' ]].'			FDY+AGA	infered_pred1
cites	Background	N.F. Noy, M.A. Musen, Anchor-PROMPT: using non-local context for semantic matching , Proceedings of the Workshop on Ontologies and Information Sharing at the Seventeenth International Joint Conference on Artificial Intelligence (IJCAI-2001), Morgan Kaufmann (2001)	http://dx.doi.org/10.1016/j.artmed.2010.10.001	background		<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2010-10-001/br/bib0265>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2010-10-001/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2010-10-001/ctx/ctx0046>				http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2010-10-001/itrp/0020	'Using a set of “anchors” (pairs of related terms from the ontologies specified as related), Anchor-PROMPT extends these relations to analyze the non-local context by traversing the paths between those anchors, returning potential candidates for similarity, and computing cumulative similarity scores for the terms involved [53][[ refid=''bib0265'' ]] (as contrasted to a description of the similarities and differences of the ontologies themselves, as addressed by CAIS).'				100_classified_extends
cites	Introduction	R.A. Pagon, P. Tarczy-Hornoch, P.K. Baskin, J.E. Edwards, M.L. Covington, M. Espeseth, GeneTests-GeneClinics: genetic testing information for a growing audience , Hum. Mutat. , vol. 19 (2002), pp.501-509	http://dx.doi.org/10.1016/j.artmed.2010.10.001	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2010-10-001/br/bib0025>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2010-10-001/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2010-10-001/ctx/ctx0004>				http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2010-10-001/itrp/0031	'Accordingly, the audience for information has expanded to include, among others, patients and policy makers [5][[ refid=''bib0025'' ]].'				100_classified_extends
uses_method_in	Methods	A. Schwartz, M. Hearst, A simple algorithm for identifying abbreviation definitions in biomedical text , Proceedings of the pacific symposium on biocomputing, World Scientific Publishing , vol. vol. 8 (2003), pp.451-462	http://dx.doi.org/10.1016/j.artmed.2011.06.005	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2011-06-005/br/bib0240>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2011-06-005/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2011-06-005/ctx/ctx0047>				http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2011-06-005/itrp/0022	'• Third, to expand the acronyms and abbreviations not defined in the abbreviations section, the software for abbreviation definition recognition presented in [48][[ refid=''bib0240'' ]] is used.'				100_classified_extends
cites	Background	A.R. Aronson, T.C. Rindflesch, Query expansion using the UMLS Metathesaurus , Proceedings of the American medical informatics association annual symposium, Hanley & Belfus Inc. (1997)	http://dx.doi.org/10.1016/j.artmed.2011.06.005	background		<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2011-06-005/br/bib0215>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2011-06-005/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2011-06-005/ctx/ctx0043>				http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2011-06-005/itrp/0029	'Aronson and Rindflesch [43][[ refid=''bib0215'' ]] use MetaMap to expand queries with UMLS Metathesaurus concepts.'				100_classified_extends
cites	Introduction	, The handbook of discourse analysis, Blackwell Publishing , vol. vol. 24 (2004), pp.470-502	http://dx.doi.org/10.1016/j.artmed.2011.06.005	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2011-06-005/br/bib0060>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2011-06-005/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2011-06-005/ctx/ctx0011>				http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2011-06-005/itrp/0086	'Second, medical language, despite being highly specialised, is also highly interpretive, and it is constantly expanding [12][[ refid=''bib0060'' ]].'				100_classified_extends
cites	Our contribution within terminology-based indexing and retrieval for biomedical IR	W. Zhou, C.T. Yu, N.R. Smalheiser, V.I. Torvik, J. Hong, Knowledge-intensive conceptual retrieval and passage extraction of biomedical literature , Proceedings of the 30th annual international ACM SIGIR conference on research and development in information retrieval, SIGIR’07 (2007)	http://dx.doi.org/10.1016/j.artmed.2012.08.006			<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2012-08-006/br/bib0245>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2012-08-006/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2012-08-006/ctx/ctx0041>				http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2012-08-006/itrp/0036	'Concerning works dealing only with query expansion using multiple domain knowledge sources, the work in [49][[ refid=''bib0245'' ]] identified unique concepts issued from several terminologies such as MeSH, Entrez Gene and ADAM for expanding the original query with the synonyms, hypernyms, hyponyms, lexical variants and implicitly related concepts.'				100_classified_extends
cites	Our contribution within terminology-based indexing and retrieval for biomedical IR	N. Stokes, Y. Li, L. Cavedon, J. Zobel, Exploring criteria for successful query expansion in the genomic domain , Information Retrieval , vol. 12 (2009), pp.17-50	http://dx.doi.org/10.1016/j.artmed.2012.08.006			<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2012-08-006/br/bib0030>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2012-08-006/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2012-08-006/ctx/ctx0043>				http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2012-08-006/itrp/0039	'Similarly, authors in [6][[ refid=''bib0030'' ]] exploited several medical knowledge sources such MeSH, Entrez gene, SNOMED, UMLS, etc. for query expansion by expanding the original user query with synonyms, abbreviations and hierarchically related terms identified using PubMed.'				100_classified_extends
cites	Molecular software	G.M. Morris, R. Huey, W. Lindstrom, M.F. Sanner, R.K. Belew, D.S. Goodsell, AutoDock4 and AutoDockTools4: automated docking with selective receptor flexibility , J Comput Chem , vol. 30 (2009), pp.2785-2791	http://dx.doi.org/10.1016/j.artmed.2015.02.002			<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2015-02-002/br/bib0125>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2015-02-002/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2015-02-002/ctx/ctx0184>				http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2015-02-002/itrp/0097	'The ADT [25][[ refid=''bib0125'' ]] is the GUI interface of AutoDock4.'				100_classified_extends
cites	Introduction	J. Geller, Y. Perl, M. Halper, R. Cornet, Special issue on auditing of terminologies , J Biomed Inform , vol. 42 (2009), pp.407-411	http://dx.doi.org/10.1016/j.artmed.2015.03.002	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2015-03-002/br/bib0485>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2015-03-002/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2015-03-002/ctx/ctx0032>				http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2015-03-002/itrp/0047	'Omissions in terminologies are undesirable, and locating them is one of the goals of work in terminology auditing [42][[ refid=''bib0485'' ]].'				100_classified_extends
uses_method_in	Material and methods	Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J. Bethard, David McClosky, The Stanford CoreNLP natural language processing toolkit , Proceedings of 52nd annual meeting of the association for computational linguistics: system demonstrations, Association for Computational Linguistics (2014)	http://dx.doi.org/10.1016/j.artmed.2015.09.007	materials	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2015-09-007/br/bib0360>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2015-09-007/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2015-09-007/ctx/ctx0025>				http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2015-09-007/itrp/0008	'We used Stanford CoreNLP toolkit [31][[ refid=''bib0360'' ]] to extract word shapes.'			FDY+AGA	infered_pred1
uses_method_in	Conclusion and future research	S. El-Sappagh, M. Elmogy, A. Riad, A fuzzy-ontology-oriented case-based reasoning framework for semantic diabetes diagnosis , Artif Intell Med , vol. 65 (2015), pp.179-208	http://dx.doi.org/10.1016/j.artmed.2017.02.003	conclusion		<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2017-02-003/br/bib0180>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2017-02-003/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2017-02-003/ctx/ctx0066>				http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2017-02-003/itrp/0027	'In artificial intelligence and in the medical domain, there is a trend of using ontologies to better evaluate the difference between discrete attributes [36][[ refid=''bib0180'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Methods	A. Krizhevsky, I. Sutskever, G.E. Hinton, ImageNet classification with deep convolutional neural networks , Adv Neural Inf Process Syst , vol. 25 (2012), pp.1106-1114	http://dx.doi.org/10.1016/j.artmed.2017.03.008	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2017-03-008/br/bib0105>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2017-03-008/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2017-03-008/ctx/ctx0021>				http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2017-03-008/itrp/0005	'In this work, we converted AlexNet [21][[ refid=''bib0105'' ]] into a fully convolutional network by transforming fully connected layers into convolution layers.'			FDY+AGA	infered_pred1
cites	Related works	S. Grimm, B. Motik, Closed world reasoning in the semantic web through epistemic operators , Proceedings of the OWLED 2005 workshop on OWL: experiences and directions (2005)	http://dx.doi.org/10.1016/j.artmed.2017.07.002	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2017-07-002/br/bib0185>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2017-07-002/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2017-07-002/ctx/ctx0027>				http://www.scar.disi.unibo.it/r/10-1016-j-artmed-2017-07-002/itrp/0009	'Another approach is the extension of OWL by epistemic operators for non-monotonic features [37][[ refid=''bib0185'' ]].'				100_classified_extends
cites	Introduction	G.H. Tan, T.J. Cornwell, P.E. Dewdney, M. Waterson, The square kilometre array baseline design V2.0 , 2015 1st URSI Atlantic Radio Science Conference (URSI AT-RASC) (2015)	http://dx.doi.org/10.1016/j.ascom.2017.03.007	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-ascom-2017-03-007/br/b60>	<http://www.scar.disi.unibo.it/r/10-1016-j-ascom-2017-03-007/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-ascom-2017-03-007/ctx/ctx0002>				http://www.scar.disi.unibo.it/r/10-1016-j-ascom-2017-03-007/itrp/0028	'The first phase of the project – SKA1 (Tan et al., 2015)[[ refid=''b60'' ]] – will consist of hundreds of dishes and hundreds of thousands of antennas, enabling the monitoring and surveying of the sky in unprecedented detail and speed, with a second phase expanding these capabilities to at least an order of magnitude.'				100_classified_extends
cites	Introduction	J. Tai, S. Tseng, C. Lin, K. Song, Real-time image tracking for automatic traffic monitoring and enforcement applications , Image and Vision Computing , vol. 22 (2004), pp.485-501	http://dx.doi.org/10.1016/j.asoc.2009.08.002	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2009-08-002/br/bib35>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2009-08-002/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2009-08-002/ctx/ctx0014>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2009-08-002/itrp/0054	'Another work line is presented in [35][[ refid=''bib35'' ]].'				100_classified_extends
extends	Acknowledgements	Y.J. Du, Y. Xu, Z. Pei, H. Pen, H.M. Li, An algorithm retrieving rules from webpage based on concept lattice , Proceedings of the 2005 International Conference on Machine Learning and Cybernetics, vol. 4 (2005)	http://dx.doi.org/10.1016/j.asoc.2009.09.007	acknowledgements		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2009-09-007/br/bib28>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2009-09-007/sec/sec6>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2009-09-007/ctx/ctx0028>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2009-09-007/itrp/0011	'This work is an extension of reference [28][[ refid=''bib28'' ]].'				100_classified_extends
cites	Basic knowledge	P.P. Chen, The entity-relationship model: toward a unified view of data , ACM Transactions on Database Systems , vol. 1 (1976), pp.9-36	http://dx.doi.org/10.1016/j.asoc.2011.03.020			<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2011-03-020/br/bib0050>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2011-03-020/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2011-03-020/ctx/ctx0034>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2011-03-020/itrp/0037	'Consequently, fuzzy extension to the ER algebra [10][[ refid=''bib0050'' ]] has been sketched.'				100_classified_extends
extends	Introduction	M. Paukkeri, A.P. García-Plaza, S. Pessala, T. Honkela, Learning taxonomic relations from a set of text documents , Proceedings of the International Multiconference on Computer Science and Information Technology (IMCSIT 2010), IEEE (2010)	http://dx.doi.org/10.1016/j.asoc.2011.11.009	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2011-11-009/br/bib0165>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2011-11-009/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2011-11-009/ctx/ctx0028>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2011-11-009/itrp/0009	'A preliminary version of this work was originally published as a conference paper [33][[ refid=''bib0165'' ]].'				100_classified_extends
uses_method_in	Preliminaries	R.R. Yager, Quantifier guided aggregation using OWA operators , International Journal of Intelligent Systems , vol. 11 (1996), pp.49-73	http://dx.doi.org/10.1016/j.asoc.2013.05.008			<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-05-008/br/bib0335>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-05-008/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-05-008/ctx/ctx0026>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-05-008/itrp/0006	'In this section we will focus on one of the possibilities, proposed in the setting of quantifier-guided aggregation[67][[ refid=''bib0335'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Preliminaries	R.R. Yager, Quantifier guided aggregation using OWA operators , International Journal of Intelligent Systems , vol. 11 (1996), pp.49-73	http://dx.doi.org/10.1016/j.asoc.2013.05.008			<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-05-008/br/bib0335>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-05-008/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-05-008/ctx/ctx0029>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-05-008/itrp/0012	'The resulting OWA operator can be used to evaluate the degree of truth of quantifier propositions (see [67][[ refid=''bib0335'' ]] for details).'			FDY+AGA	infered_pred1
extends	Introduction	A. Alvarez-Alvarez, D. Sanchez-Valdes, G. Trivino, Automatic linguistic description about relevant features of the Mars’ surface, in: Proceedings of the 11th International Conference on Intelligent Systems Design and Applications (ISDA), Córdoba, Spain, 2011, pp. 154–159.	http://dx.doi.org/10.1016/j.asoc.2013.08.003	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-08-003/br/bib0090>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-08-003/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-08-003/ctx/ctx0012>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-08-003/itrp/0027	'This paper is an extension of a previous work presented in [18][[ refid=''bib0090'' ]].'				100_classified_extends
uses_method_in	Introduction	S.C. Yan, D. Xu, B.Y. Zhang, H.J. Zhang, Q. Yang, S. Lin, Graph embedding and extensions: a general framework for dimensionality reduction , IEEE Transactions on Pattern Analysis and Machine Intelligent , vol. 29 (2007), pp.40-51	http://dx.doi.org/10.1016/j.asoc.2013.12.004	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-12-004/br/bib0060>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-12-004/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-12-004/ctx/ctx0009>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2013-12-004/itrp/0009	'All of these methods mentioned above are variants of graph embedding [12][[ refid=''bib0060'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Evaluation and results	C.-C. Chang, C.-J. Lin, LIBSVM: a library for support vector machines , ACM Trans. Intell. Syst. Technol. (TIST) , vol. 2 (2011), pp.27	http://dx.doi.org/10.1016/j.asoc.2014.03.041	results		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-03-041/br/bib0210>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-03-041/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-03-041/ctx/ctx0037>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-03-041/itrp/0029	'To evaluate to the SVM classifier, we trained the data using the LibSVM tool developed by Chang and Lin [42][[ refid=''bib0210'' ]].'			FDY+AGA	infered_pred1
cites	Implementation and simulation results	X. Huang, C. Luo, R. van der Meyden, Symbolic model checking of probabilistic knowledge , Proceedings of the 13th Conference on Theoretical Aspects of Rationality and Knowledge. TARK XIII, ACM (2011)	http://dx.doi.org/10.1016/j.asoc.2014.04.014	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-04-014/br/bib0155>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-04-014/sec/sec4>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-04-014/ctx/ctx0077>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-04-014/itrp/0069	'This protocol has been the subject of analysis for some probabilistic properties [31][[ refid=''bib0155'' ]].'				100_classified_extends
cites	Related work	M.P. Singh, A social semantics for agent communication languages , Issues in Agent Communication, Springer-Verlag (2000)	http://dx.doi.org/10.1016/j.asoc.2014.04.014	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-04-014/br/bib0260>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-04-014/sec/sec1>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-04-014/ctx/ctx0030>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-04-014/itrp/0080	'Singh in [52][[ refid=''bib0260'' ]] extends CTL logic with modalities for social commitments, beliefs, and intentions in order to formally model the interactions between interacting parties in a MAS.'				100_classified_extends
uses_method_in	Experimental setup	X. Blasco, J. Herrero, J. Sanchis, M. Martínez, A new graphical visualization of n-dimensional Pareto front for decision-making in multiobjective optimization , Inf. Sci. , vol. 178 (2008), pp.3908-3924	http://dx.doi.org/10.1016/j.asoc.2014.07.009	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-07-009/br/bib0135>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-07-009/sec/sec3>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-07-009/ctx/ctx0043>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-07-009/itrp/0029	'The MOP statement described in [27][[ refid=''bib0135'' ]] is used.'				100_classified_extends
uses_method_in	Results of the proposed method evaluation	F. Sebastiani, Machine learning in automated text categorization , J. ACM Comp. Surv. (CSUR) , vol. 34 (2002), pp.1-47	http://dx.doi.org/10.1016/j.asoc.2014.10.027	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-10-027/br/bib0180>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-10-027/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-10-027/ctx/ctx0047>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-10-027/itrp/0030	'The classification effectiveness is usually measured in terms of four parameters [36][[ refid=''bib0180'' ]], Precision (P), Recall (R), F1 (as combination of P and R using Eq. (6)), and False Positive error rate (FP).'			FDY+AGA	infered_pred1
uses_method_in	Results of the proposed method evaluation	F. Sebastiani, Machine learning in automated text categorization , J. ACM Comp. Surv. (CSUR) , vol. 34 (2002), pp.1-47	http://dx.doi.org/10.1016/j.asoc.2014.10.027	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-10-027/br/bib0180>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-10-027/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-10-027/ctx/ctx0048>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2014-10-027/itrp/0048	'We use micro-averaging equations (see Eqs. (7) and (8)), because they are more precise than macro-averaging equations [36][[ refid=''bib0180'' ]].'			FDY+AGA	infered_pred1
cites	Related works	E. Lughofer, J.-L. Bouchot, A. Shaker, On-line elimination of local redundancies in evolving fuzzy systems , Evol. Syst. , vol. 2 (2011), pp.165-187	http://dx.doi.org/10.1016/j.asoc.2015.02.022	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-022/br/bib0240>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-022/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-022/ctx/ctx0021>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-022/itrp/0004	'This work was later expanded in Lughofer et al. [48][[ refid=''bib0240'' ]], where the authors propose new elimination techniques for rule redundancies, including merging of rules.'				100_classified_extends
extends	Trust propagation and aggregation in social network	R.R. Yager, D.P. Filev, Induced ordered weighted averaging operators , IEEE Trans. Syst. Man Cybern. , vol. 29 (1999), pp.141-150	http://dx.doi.org/10.1016/j.asoc.2015.02.023			<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-023/br/bib0300>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-023/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-023/ctx/ctx0023>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-023/itrp/0002	'To resolve this problem, the trust score induced ordered weighted operator (TS-IOWA) operator is proposed, which extends the induced ordered weighted averaging (IOWA) operator proposed by Yager [60][[ refid=''bib0300'' ]] to the aggregation of orthopairs of trust/distrust values:Definition 6IOWA OperatorAn IOWA operator is a mapping IOWAW:(ℝ×ℝ)n⟶ℝ, to which a set of positive and normalised vector is associated, W=(w1,…,wn), that aggregates the set of second arguments of a list of n 2-tuples {〈u1, p1〉, …, 〈un, pn〉} according to the following expression, [[ formulaid=''id15_pos0'' ]] being σ:{1, …, n}⟶{1, …, n} a permutation such that uσ(i)≥uσ(i+1), ∀i=1, …, n−1, i.e., 〈uσ(i), pσ(i)〉 is the 2-tuple with uσ(i) the ith highest value in the set {u1, …, un}.'				100_classified_extends
uses_method_in	Trust propagation and aggregation in social network	R.R. Yager, On ordered weighted averaging aggregation operators in multicriteria decision making , IEEE Trans. Syst. Man Cybern. , vol. 18 (1988), pp.183-190	http://dx.doi.org/10.1016/j.asoc.2015.02.023			<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-023/br/bib0290>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-023/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-023/ctx/ctx0020>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-023/itrp/0003	'In 1988, Yager introduced an aggregation technique based on the order weighted averaging (OWA) scheme [58][[ refid=''bib0290'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Trust propagation and aggregation in social network	R.R. Yager, Quantifier guided aggregation using OWA operators , Int. J. Intell. Syst. , vol. 11 (1996), pp.49-73	http://dx.doi.org/10.1016/j.asoc.2015.02.023			<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-023/br/bib0295>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-023/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-023/ctx/ctx0025>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-023/itrp/0014	'In [59][[ refid=''bib0295'' ]], Yager provided a procedure to evaluate the overall satisfaction of Q important criteria (experts) by an alternative x by computing the weighting vector associated to an OWA operator as follows: [[ formulaid=''id18_pos0'' ]] being Q the Basic Unit-interval Monotone (BUM) membership function (non-decreasing Q:[0, 1]→[0, 1] such that Q(0)=0, Q(1)=1) of the linguistic quantifier, S(h)=∑l=1hsσ(l),sl the importance degree of criterion l, and σ the permutation used to produce the ordering of the values to be aggregated.'			FDY+AGA	infered_pred1
uses_method_in	Experiments and evaluation	C.C. Chang, C.J. Lin, LIBSVM: a library for support vector machines , ACM Trans. Intell. Syst. Technol. , vol. 2 (2011), pp.27:1-27:27	http://dx.doi.org/10.1016/j.asoc.2015.02.029	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-029/br/bib0090>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-029/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-029/ctx/ctx0024>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-02-029/itrp/0007	'For SVM, the LibSVM library provided the functionality [18][[ refid=''bib0090'' ]], while the Neural Net Framework (NNF, http://nnf.sourceforge.net) was used for the NN model.'			FDY+AGA	infered_pred1
cites	Related work	J. Blackmore, R. Miikkulainen, Incremental grid growing: encoding highdimensional structure into a two-dimensional feature map , Proceedings of the IEEE International Conference on Neural Networks, vol. 1 (1993)	http://dx.doi.org/10.1016/j.asoc.2015.05.005	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-05-005/br/bib0105>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-05-005/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-05-005/ctx/ctx0009>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-05-005/itrp/0018	'For laterally expandable SOMs, one of the earliest work is the incremental grid growing proposed by Blackmore and Miikkulainen [21][[ refid=''bib0105'' ]].'				100_classified_extends
extends	Introduction	E. Vats, C.S. Chan, Early human actions detection using BK sub-triangle product , FUZZ-IEEE (2015)	http://dx.doi.org/10.1016/j.asoc.2015.11.007	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-11-007/br/bib0125>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-11-007/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-11-007/ctx/ctx0009>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-11-007/itrp/0022	'A preliminary version of this work was presented earlier [25][[ refid=''bib0125'' ]].'				100_classified_extends
uses_method_in	Related work and background	F. Bobillo, U. Straccia, , Fuzzy ontology representation using OWL 2 , vol. 52 (2011), pp.1073-1094	http://dx.doi.org/10.1016/j.asoc.2015.12.011	related work	background	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-12-011/br/bib0265>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-12-011/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-12-011/ctx/ctx0038>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2015-12-011/itrp/0075	'An extension of current semantic Web languages, for instance OWL 2 [53][[ refid=''bib0265'' ]], is used to represent such information.'				100_classified_extends
cites	Evaluation	'A.S. Sayyad, J. Ingram, T. Menzies, H. Ammar, Scalable product line configuration: a straw to break the camel''s back , ASE (2013)'	http://dx.doi.org/10.1016/j.asoc.2016.07.040	results		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-07-040/br/bib0090>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-07-040/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-07-040/ctx/ctx0091>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-07-040/itrp/0026	'This conforms to the observation in [18][[ refid=''bib0090'' ]].'				100_classified_extends
uses_method_in	Experimental results	C.-C. Chang, C.-J. Lin, Libsvm: a library for support vector machines , ACM Trans. Intell. Syst. Technol. , vol. 2 (2011), pp.27	http://dx.doi.org/10.1016/j.asoc.2016.08.031	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-08-031/br/bib0125>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-08-031/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-08-031/ctx/ctx0018>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-08-031/itrp/0025	'The SVM classifier was used based on default parameter values with a usual nonlinear kernel provided in the LIBSVM software package [25][[ refid=''bib0125'' ]].'			FDY+AGA	infered_pred1
extends	Our approach	J.A. Iglesias, A. Tiemblo, A. Ledezma, A. Sanchis, Web news mining in an evolving framework , Inf. Fusion , vol. 28 (2016), pp.90-98	http://dx.doi.org/10.1016/j.asoc.2016.11.034			<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-11-034/br/bib0055>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-11-034/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-11-034/ctx/ctx0075>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-11-034/itrp/0099	'Our approach extends the classification method that was developed in [11][[ refid=''bib0055'' ]] by embedding the evolving Classifier eT2Class, which employs type-2 fuzzy sets instead of type-1 to better model uncertainty in news article.'				100_classified_extends
cites	Introduction	J.C. Patra, A.C. Kot, Nonlinear dynamic system identification using Chebyshev functional link artificial neural networks , IEEE Trans. Syst. Man Cybern. Part B: Cybern. , vol. 32 (2002), pp.505-511	http://dx.doi.org/10.1016/j.asoc.2016.11.034	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-11-034/br/bib0140>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-11-034/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-11-034/ctx/ctx0017>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-11-034/itrp/0146	'The rule consequent is controlled by the Chebyshev polynomial [28][[ refid=''bib0140'' ]], expanding the degree of freedom of the Takagi Sugeno Kang (TSK) rule consequent.'				100_classified_extends
cites_as_review	Introduction	R. Navigli, Word sense disambiguation: a survey , ACM Comput. Surv. , vol. 41 (2009), pp.None	http://dx.doi.org/10.1016/j.asoc.2016.12.028	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-12-028/br/bib0045>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-12-028/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-12-028/ctx/ctx0006>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2016-12-028/itrp/0024	'One technique is based on the collocation of other words in which nearby words are used to provide consistent clues to the sense of a target word [9][[ refid=''bib0045'' ]].'			FDY+AGA	infered_pred1
cites	Introduction	F. Tao, Y. Cheng, L. Zhang, A.Y.C. Nee, Advanced manufacturing systems: socialization characteristics and trends , J. Intell. Manuf. , vol. 18 (2015), pp.1-16	http://dx.doi.org/10.1016/j.asoc.2017.03.017	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2017-03-017/br/bib0010>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2017-03-017/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2017-03-017/ctx/ctx0002>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2017-03-017/itrp/0039	'It is becoming more and more important for manufacturing partners to work together to expand their manufacturing capacity so as to quickly satisfy customer’s diverse and personalized needs [2][[ refid=''bib0010'' ]].'				100_classified_extends
uses_method_in	Method	F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, Scikit-Learn: machine learning in python , J. Mach. Learn. Res. , vol. 12 (2011), pp.2825-2830	http://dx.doi.org/10.1016/j.asoc.2017.05.065	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2017-05-065/br/bib0145>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2017-05-065/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2017-05-065/ctx/ctx0042>				http://www.scar.disi.unibo.it/r/10-1016-j-asoc-2017-05-065/itrp/0028	'The algorithms used in our experiments were developed on Python with the Scikit-Learn [29][[ refid=''bib0145'' ]] library, except the LLR classifier.5•Multinomial Naïve Bayes (MNB): is a probabilistic classifier based on Bayes’ theorem.'			FDY+AGA	infered_pred1
cites_as_review	Material and methods	C.L.P. Chen, C. Zhang, Data-intensive applications, challenges, techniques and technologies: a survey on Big Data , Inf. Sci. , vol. 275 (2014), pp.314-347	http://dx.doi.org/10.1016/j.bdr.2015.01.001	materials	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-bdr-2015-01-001/br/br0110>	<http://www.scar.disi.unibo.it/r/10-1016-j-bdr-2015-01-001/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-bdr-2015-01-001/ctx/ctx0007>				http://www.scar.disi.unibo.it/r/10-1016-j-bdr-2015-01-001/itrp/0020	'When a big data system is realised, important considerations include architecture design of the system, and utilization of underlying technologies and products/services [11][[ refid=''br0110'' ]].'			FDY+AGA	infered_pred1
uses_method_in	How to analyze Big Data	G.D. Bader, C.W. Hogue, An automated method for finding molecular complexes in large protein interaction networks , BMC Bioinform. , vol. 4 (2003), pp.2	http://dx.doi.org/10.1016/j.bdr.2015.02.002	data		<http://www.scar.disi.unibo.it/r/10-1016-j-bdr-2015-02-002/br/br0930>	<http://www.scar.disi.unibo.it/r/10-1016-j-bdr-2015-02-002/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-bdr-2015-02-002/ctx/ctx0083>				http://www.scar.disi.unibo.it/r/10-1016-j-bdr-2015-02-002/itrp/0057	'Basically, the nodes with high local neighborhood density are identified first and then expand from such nodes to get the densely connected regions, i.e., network modules [93][[ refid=''br0930'' ]].'				100_classified_extends
extends	Introduction	R. Shi, Q. Wu, Y. Ye, H. Shen-Shyang, A generative model with network regularization for semi-supervised collective classification , Proc. of the SIAM International Conference on Data Mining (2004)	http://dx.doi.org/10.1016/j.bdr.2015.04.002	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-bdr-2015-04-002/br/br0080>	<http://www.scar.disi.unibo.it/r/10-1016-j-bdr-2015-04-002/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-bdr-2015-04-002/ctx/ctx0005>				http://www.scar.disi.unibo.it/r/10-1016-j-bdr-2015-04-002/itrp/0042	'This paper extends our preliminary work [8][[ refid=''br0080'' ]] which considers single-label learning problem in CC.'				100_classified_extends
cites	Putting theory into work: results	Neil D. Lawrence, Gaussian process latent variable models for visualisation of high dimensional data , Advances in Neural Information Processing Systems , vol. 16 (2004), pp.3	http://dx.doi.org/10.1016/j.bica.2014.11.005	results	background	<http://www.scar.disi.unibo.it/r/10-1016-j-bica-2014-11-005/br/b0075>	<http://www.scar.disi.unibo.it/r/10-1016-j-bica-2014-11-005/sec/sec3>	<http://www.scar.disi.unibo.it/r/10-1016-j-bica-2014-11-005/ctx/ctx0035>				http://www.scar.disi.unibo.it/r/10-1016-j-bica-2014-11-005/itrp/0028	'The HGP-LVM is an extension of the original Gaussian Process Latent Variable Model (GP-LVM) (Lawrence, 2004[[ refid=''b0075'' ]]).'				100_classified_extends
cites	Conclusions	P. Wiemer-Hastings, All parts are not created equal: SIAM-LSA , Proceedings of the 26th annual conference of the cognitive science society, Erlbaum (2004)	http://dx.doi.org/10.1016/j.bica.2015.04.007	conclusion		<http://www.scar.disi.unibo.it/r/10-1016-j-bica-2015-04-007/br/b0130>	<http://www.scar.disi.unibo.it/r/10-1016-j-bica-2015-04-007/sec/sec4>	<http://www.scar.disi.unibo.it/r/10-1016-j-bica-2015-04-007/ctx/ctx0062>				http://www.scar.disi.unibo.it/r/10-1016-j-bica-2015-04-007/itrp/0056	'Besides, the evidenced influence of the syntactic roles has been characterized for English (Wiemer-Hastings, 2004[[ refid=''b0130'' ]]) and Spanish (this work).'				100_classified_extends
cites	Conclusions	E. Malaia, S. Newman, Neural bases of event knowledge and syntax integration in comprehension of complex sentences , Neurocase , vol. 20 (2014), pp.1-14	http://dx.doi.org/10.1016/j.bica.2015.04.007	conclusion		<http://www.scar.disi.unibo.it/r/10-1016-j-bica-2015-04-007/br/b0090>	<http://www.scar.disi.unibo.it/r/10-1016-j-bica-2015-04-007/sec/sec4>	<http://www.scar.disi.unibo.it/r/10-1016-j-bica-2015-04-007/ctx/ctx0063>				http://www.scar.disi.unibo.it/r/10-1016-j-bica-2015-04-007/itrp/0081	'This is in accordance with recent neurolinguistic findings (Malaia & Newman, 2014[[ refid=''b0090'' ]]) and contradicts the generative grammar theories.'				100_classified_extends
cites	Procedural–semantic memory and narrative	S.R. Goldman, A.C. Graesser, P. van den Broek, Narrative comprehension, causality, and coherence: Essays in honor of Tom Trabasso , None, Taylor & Francis (1999)	http://dx.doi.org/10.1016/j.bica.2016.04.002			<http://www.scar.disi.unibo.it/r/10-1016-j-bica-2016-04-002/br/b0065>	<http://www.scar.disi.unibo.it/r/10-1016-j-bica-2016-04-002/sec/sec4>	<http://www.scar.disi.unibo.it/r/10-1016-j-bica-2016-04-002/ctx/ctx0030>				http://www.scar.disi.unibo.it/r/10-1016-j-bica-2016-04-002/itrp/0028	'In narrative, this has been deeply studied (Goldman, Graesser, & van den Broek, 1999[[ refid=''b0065'' ]]).'				100_classified_extends
cites	LIDA-based agents	S. Franklin, IDA: a conscious artifact? , Journal of Consciousness Studies , vol. 10 (2003), pp.47-66	http://dx.doi.org/10.1016/j.bica.2016.04.003			<http://www.scar.disi.unibo.it/r/10-1016-j-bica-2016-04-003/br/b0285>	<http://www.scar.disi.unibo.it/r/10-1016-j-bica-2016-04-003/sec/sec6>	<http://www.scar.disi.unibo.it/r/10-1016-j-bica-2016-04-003/ctx/ctx0110>				http://www.scar.disi.unibo.it/r/10-1016-j-bica-2016-04-003/itrp/0177	'IDA is functionally conscious (Franklin, 2003[[ refid=''b0285'' ]]).'				100_classified_extends
extends	Introduction	S.W. Han, J. Kim, Preparing experiments with media-oriented service composition for future Internet, in: Proc. of Int. Conf. on Future Internet Technologies (CFI’10), Seoul, Korea, 2010, pp. 73–78.	http://dx.doi.org/10.1016/j.bjp.2013.12.025	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-bjp-2013-12-025/br/b0020>	<http://www.scar.disi.unibo.it/r/10-1016-j-bjp-2013-12-025/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-bjp-2013-12-025/ctx/ctx0007>				http://www.scar.disi.unibo.it/r/10-1016-j-bjp-2013-12-025/itrp/0025	'It extends a prior work, published in [4][[ refid=''b0020'' ]], which realized a basic idea to experiment with static service composition according to the inter-relationship of services.'				100_classified_extends
cites	Related work	Dey TK, Sun J. Normal and feature estimations from noisy point clouds. Technical Report OSU-CISRC-7/50-TR50, Ohio State; July 2005.	http://dx.doi.org/10.1016/j.cag.2011.03.036	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2011-03-036/br/bib9>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2011-03-036/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2011-03-036/ctx/ctx0006>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2011-03-036/itrp/0028	'Recent work [9][[ refid=''bib9'' ]] extends this approach to noisy data by using an adaptive threshold to cull Delaunay balls that arise due to noise.'				100_classified_extends
cites	Related work	Sandor C, Dey A, Cunningham A, Barbier S, Eck U, Urquhart D, et al. Egocentric space-distorting visualizations for rapid environment exploration in mobile mixed reality. In: Proceedings of the VR; 2010. p. 47–50.	http://dx.doi.org/10.1016/j.cag.2011.04.005	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2011-04-005/br/bib30>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2011-04-005/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2011-04-005/ctx/ctx0028>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2011-04-005/itrp/0011	'The radial distortion technique [30][[ refid=''bib30'' ]] expands the FOV in AR by distorting the whole scene into a fisheye view using a 3D-reconstructed model that even includes the off-screen area.'				100_classified_extends
extends	Related work	J. Shen, X. Jin, X. Mao, J. Feng, Completion-based texture design using deformation , Vis Comput , vol. 22 (2006), pp.936-945	http://dx.doi.org/10.1016/j.cag.2012.02.002	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2012-02-002/br/bib13>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2012-02-002/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2012-02-002/ctx/ctx0016>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2012-02-002/itrp/0005	'In a sense, our method extends the work of Shen et al. [13][[ refid=''bib13'' ]], where they synthesize general textures, by segmenting a sample texture to its main components.'				100_classified_extends
cites	Classification of selection techniques	'Vanacken L, Grossman T, Coninx K. Exploring the effects of environment density and target visibility on object selection in 3D virtual environments. In: IEEE symposium on 3D user interfaces, 3DUI ''07; 2007. p. 115–22.'	http://dx.doi.org/10.1016/j.cag.2012.12.003			<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2012-12-003/br/bib93>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2012-12-003/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2012-12-003/ctx/ctx0033>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2012-12-003/itrp/0048	'For example, the Bubble Cursor [93][[ refid=''bib93'' ]] employs a sphere-like selection tool that automatically expands to reach the object closest to its center.'				100_classified_extends
extends	Introduction	Panëels S, Roberts JC, Rodgers PJ. HITPROTO: a tool for the rapid prototyping of haptic interactions for haptic data visualization. In: IEEE haptics symposium, 2010. p. 261–8.	http://dx.doi.org/10.1016/j.cag.2013.01.009	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-01-009/br/bib2>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-01-009/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-01-009/ctx/ctx0002>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-01-009/itrp/0022	'This article describes our HITPROTO haptic data visualization tool (HDV) and it extends work presented in the haptic symposium conference [2][[ refid=''bib2'' ]].'				100_classified_extends
uses_method_in	Introduction	Huang H-C, Chuang Y-Y, Chen C-S. Affinity aggregation for spectral clustering. In: Computer vision and pattern recognition (CVPR). IEEE; 2012. p. 773–80.	http://dx.doi.org/10.1016/j.cag.2013.05.015	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-05-015/br/bib12>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-05-015/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-05-015/ctx/ctx0006>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-05-015/itrp/0045	'The proposed approach is based on the affinity aggregation spectral clustering (AASC) [12][[ refid=''bib12'' ]], which extends the spectral clustering to the setting where multiple affinities matrices are available.'				100_classified_extends
extends	Related work	de Aguiar E, Ukita N. Representing and manipulating mesh-based character animations. In: Proceedings of the 25th SIBGRAPI, Washington, DC, USA: IEEE Computer Society; 2012. p. 198–204.	http://dx.doi.org/10.1016/j.cag.2013.07.007	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-07-007/br/bib13>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-07-007/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-07-007/ctx/ctx0021>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-07-007/itrp/0010	'Our system extends the technique proposed in [13][[ refid=''bib13'' ]] to represent and manipulate cloth simulation data as well.'				100_classified_extends
cites	Related work	de Aguiar E, Ukita N. Representing and manipulating mesh-based character animations. In: Proceedings of the 25th SIBGRAPI, Washington, DC, USA: IEEE Computer Society; 2012. p. 198–204.	http://dx.doi.org/10.1016/j.cag.2013.07.007	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-07-007/br/bib13>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-07-007/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-07-007/ctx/ctx0013>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-07-007/itrp/0061	'The approach proposed in [13][[ refid=''bib13'' ]] extends these latter editing approaches by preserving the fine time-varying details during the manipulation process, which increases the quality of the final result (Fig. 1).'				100_classified_extends
cites	Related work	Monroe M, Lan R, Morales del Olmo J, Shneiderman B, Plaisant C, Millstein J. The challenges of specifying intervals and absences in temporal queries: a graphical language approach. In: Proceedings of the SIGCHI conference on human factors in computing systems. CHI ’13. New York, NY, USA: ACM; 2013. p. 2349–58.	http://dx.doi.org/10.1016/j.cag.2013.10.007	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-10-007/br/bib27>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-10-007/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-10-007/ctx/ctx0038>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-10-007/itrp/0056	'EventFlow [27][[ refid=''bib27'' ]] extends Lifelines2 with an overview display, events with duration, and more advanced queries.'				100_classified_extends
extends	Introduction	Chae J, Thom D, Jang Y, Kim SY, Ertl T, Ebert D. Visual analytics of microblog data for public behavior analysis in disaster events. In: EuroVis workshop on visual analytics; 2013. p. 67–71.	http://dx.doi.org/10.1016/j.cag.2013.10.008	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-10-008/br/bib4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-10-008/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-10-008/ctx/ctx0004>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-10-008/itrp/0013	'In this paper, we extend our previous work [4][[ refid=''bib4'' ]] with additional features of our system and examine their capabilities with several expanded examples in Section 4.2.'				100_classified_extends
uses_method_in	Hardware setup and system overview	D. Anguelov, P. Srinivasan, D. Koller, S. Thrun, J. Rodgers, J. Davis, Scape , ACM Trans Graph , vol. 24 (2005), pp.408-416	http://dx.doi.org/10.1016/j.cag.2013.10.023			<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-10-023/br/bib1>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-10-023/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-10-023/ctx/ctx0022>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-10-023/itrp/0001	'To enhance the representation ability on human pose space, we train a SCAPE model [1][[ refid=''bib1'' ]] based on an expanded pose training data combined with multiple pose database, which is described in Section 4.2.'				100_classified_extends
uses_data_from	Experimental results	CMU motion library.	http://dx.doi.org/10.1016/j.cag.2013.11.008	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-11-008/br/bib11	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-11-008/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-11-008/ctx/ctx0040		58	6	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-11-008/itrp/0024	'The first and second databases are from CMU [11][[ refid=''bib11'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0315"""" view=""""all"""">To examine the computation times and storage cost of EigenMR, we have tested it on the five database sizes shown in <ce:float-anchor refid=""""t0005""""/><ce:cross-ref id=""""cr0330"""" refid=""""t0005"""">Table 1</ce:cross-ref>. The first and second databases are from CMU <ce:cross-ref id=""""cr0335"""" refid=""""bib11"""">[11][[ refid=''''bib11'''' ]]</ce:cross-ref>. The other three databases are created by randomly duplicating some of the motion files in the first and second databases for the purpose of comparing the processing time.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_method_in	Equivalence for single-curved manifolds	K. Janisch, Topology , None, Springer (1984)	http://dx.doi.org/10.1016/j.cag.2013.12.002			<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-12-002/br/bib23>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-12-002/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-12-002/ctx/ctx0013>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2013-12-002/itrp/0039	'In this paper, isosurfaces are defined as follows [23][[ refid=''bib23'' ]].'				100_classified_extends
extends	Introduction	Semmo A, Döllner J. Image filtering for interactive level-of-abstraction visualization of 3D scenes. In: Proceedings of CAE. ACM; 2014. p. 5–14.	http://dx.doi.org/10.1016/j.cag.2015.02.001	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-02-001/br/bib17>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-02-001/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-02-001/ctx/ctx0011>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-02-001/itrp/0115	'This paper represents an extended journal version of the CAe 2014 paper by Semmo and Döllner [17][[ refid=''bib17'' ]].'				100_classified_extends
cites	Conclusion and future work	Schulz A, Velho L. ChoreoGraphics: an authoring environment for dance shows. In: ACM SIGGRAPH 2011 Posters. SIGGRAPH ׳11; New York, NY, USA: ACM; 2011. p. 1.	http://dx.doi.org/10.1016/j.cag.2015.02.009	conclusion		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-02-009/br/bib42>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-02-009/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-02-009/ctx/ctx0048>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-02-009/itrp/0037	'In terms of application, we want to expand the technique so that it can be used with different data sets that have a strong visual appeal, such as texture generation and dance choreography [42][[ refid=''bib42'' ]].'				100_classified_extends
cites	Related works	Liu Z, Zhang Y, Wu W, Liu K, Sun Z. Model-driven indoor scenes modeling from a single image. In: Proceedings of the 41st graphics interface conference. Halifax, NS, Canada: Canadian Information Processing Society; 2015. p. 25–32.	http://dx.doi.org/10.1016/j.cag.2015.10.004	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-10-004/br/bib27>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-10-004/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-10-004/ctx/ctx0021>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-10-004/itrp/0005	'Based on this idea, a version of this paper has been published in Graphics Interface 2015 [27][[ refid=''bib27'' ]].'				100_classified_extends
cites	Related works	Chaudhuri S, Kalogerakis E, Guibas L, Koltun V. Probabilistic reasoning for assembly-based 3d modeling. ACM Trans Graph 2011;30:35.	http://dx.doi.org/10.1016/j.cag.2015.10.004	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-10-004/br/bib4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-10-004/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-10-004/ctx/ctx0009>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2015-10-004/itrp/0018	'Further research can be found in paper [4][[ refid=''bib4'' ]], where they introduce assembly-based modeling which is a promising approach to broadening the accessibility of 3D modeling.'				100_classified_extends
cites	Related work	M. Okutomi, T. Kanade, A multiple-baseline stereo system , IEEE PAMI , vol. 15(4) (1993), pp.353-363	http://dx.doi.org/10.1016/j.cag.2017.11.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/br/bib0012	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/ctx/ctx0007		46	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/itrp/0037	'Starting in the 1990s, it gained in interest with the spread of acquisition devices and reconstruction techniques [12][[ refid=''bib0012'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0009"""" view=""""all"""">Semantic segmentation of point clouds is a well known problem in computational geometry and computer vision. Starting in the 1990s, it gained in interest with the spread of acquisition devices and reconstruction techniques <ce:cross-ref id=""""crf0025"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>. The objective is to identify the class membership of each 3D point. This problem is partially related to the 2D semantic segmentation, where the objective is to label each pixel of the image.</ce:para>""''"'		ANG	
cites	Experiments	J.A. Montoya, J.D. Wegner, L. Ladickỳ, K. Schindler, Mind the gap: modeling local and global context in (road) networks , Proceedings of german conference on pattern recognition, GCPR, Springer (2014)	http://dx.doi.org/10.1016/j.cag.2017.11.010	methods		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/br/bib0038	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/sec/8	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/ctx/ctx0035		46	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/itrp/0038	'[38][[ refid=''bib0038'' ]] is method for aerial images based segmentation on images descriptors and an energy minimization on a conditional random field.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0053"""" view=""""all"""">For comparison with existing methods we confront our approach to public results on either the full <ce:italic>semantic-8</ce:italic> or the <ce:italic>reduced-8</ce:italic> datasets. We present the results for <ce:italic>semantic-8</ce:italic> in <ce:cross-ref id=""""crf0091"""" refid=""""tbl0001"""">Table 1</ce:cross-ref>b. The three other methods are the publicly available results. <ce:cross-ref id=""""crf0092"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> is method for aerial images based segmentation on images descriptors and an energy minimization on a conditional random field. In <ce:cross-ref id=""""crf0093"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>, the authors use a random forest classifier trained on multi-scale 3D features taking into account both surface and context properties. Harris Net is briefly described as a Deep 3D Convolutional Network on the result board. Elaborating upon its name, we assume it might be a method based on 3D Harris point extraction followed by a classification using a deep framework. We present the results of two methods, SegNet with a purely random set of images, and a U-Net with zoom on snapshot strategy. To our knowledge the two networks performs equally and the main difference reside in the snapshot strategy. At redaction time, our U-Net took the first place in the leaderboard for global scores, average IoU and overall accuracy. Looking at the per class IoU, we take the lead on six out of eight categories. Among them, the performances on natural terrain, scanning artifacts and cars are drastically increased. On man-made terrain and buildings, we place second with a comparable score as <ce:cross-ref id=""""crf0094"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref> and Harris Net. The use of the zoom strategy greatly improves the score on cars and scanning artifacts. The reason is that compared to the random strategy, the training dataset (and the test dataset) contains more images with small details, which makes them possible to segment. The only relative failure of the deep segmentation networks are the scanning artifacts and the hardscape classes. Even though we place first on these categories, the IoU score is low: we discuss this in <ce:cross-ref id=""""crf0095"""" refid=""""sec0015"""">Section 8.4</ce:cross-ref>.</ce:para>""''"'		ANG	
uses_method_in	Experiments	K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale image recognition , CoRR (2014)	http://dx.doi.org/10.1016/j.cag.2017.11.010	methods		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/br/bib0035	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/sec/8	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/ctx/ctx0034		46	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/itrp/0039	'The encoder part of SegNet is initialized with the VGG16 weights [35][[ refid=''bib0035'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0045"""" view=""""all""""><ce:italic>Dataset and training.</ce:italic> In these experiments, we defined our own custom validation set by splitting the training set: 9 acquisitions for training and 6 for validation. For each training acquisition, we generated 400 image pairs, so that we optimize the deep networks with 3600 samples. We used a stochastic gradient descent with momentum (momentum is set to 0.9). The learning rate varies according to a step down policy starting at 0.01. It is multiplied by 0.2 every 30 epoch. The encoder part of SegNet is initialized with the VGG16 weights <ce:cross-ref id=""""crf0080"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref>.</ce:para>""''"'		ANG	
cites	Experiments	T. Hackel, J.D. Wegner, K. Schindler, Fast semantic segmentation of 3D point clouds with strongly varying density , ISPRS Ann Photogramm Remote Sens Spat Inf Sci , vol. 3 (2016), pp.177-184	http://dx.doi.org/10.1016/j.cag.2017.11.010	methods		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/br/bib0002	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/sec/8	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/ctx/ctx0037		46	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/itrp/0040	'On man-made terrain and buildings, we place second with a comparable score as [2][[ refid=''bib0002'' ]] and Harris Net.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0053"""" view=""""all"""">For comparison with existing methods we confront our approach to public results on either the full <ce:italic>semantic-8</ce:italic> or the <ce:italic>reduced-8</ce:italic> datasets. We present the results for <ce:italic>semantic-8</ce:italic> in <ce:cross-ref id=""""crf0091"""" refid=""""tbl0001"""">Table 1</ce:cross-ref>b. The three other methods are the publicly available results. <ce:cross-ref id=""""crf0092"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> is method for aerial images based segmentation on images descriptors and an energy minimization on a conditional random field. In <ce:cross-ref id=""""crf0093"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>, the authors use a random forest classifier trained on multi-scale 3D features taking into account both surface and context properties. Harris Net is briefly described as a Deep 3D Convolutional Network on the result board. Elaborating upon its name, we assume it might be a method based on 3D Harris point extraction followed by a classification using a deep framework. We present the results of two methods, SegNet with a purely random set of images, and a U-Net with zoom on snapshot strategy. To our knowledge the two networks performs equally and the main difference reside in the snapshot strategy. At redaction time, our U-Net took the first place in the leaderboard for global scores, average IoU and overall accuracy. Looking at the per class IoU, we take the lead on six out of eight categories. Among them, the performances on natural terrain, scanning artifacts and cars are drastically increased. On man-made terrain and buildings, we place second with a comparable score as <ce:cross-ref id=""""crf0094"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref> and Harris Net. The use of the zoom strategy greatly improves the score on cars and scanning artifacts. The reason is that compared to the random strategy, the training dataset (and the test dataset) contains more images with small details, which makes them possible to segment. The only relative failure of the deep segmentation networks are the scanning artifacts and the hardscape classes. Even though we place first on these categories, the IoU score is low: we discuss this in <ce:cross-ref id=""""crf0095"""" refid=""""sec0015"""">Section 8.4</ce:cross-ref>.</ce:para>""''"'		ANG	
cites	Experiments	T. Hackel, J.D. Wegner, K. Schindler, Fast semantic segmentation of 3D point clouds with strongly varying density , ISPRS Ann Photogramm Remote Sens Spat Inf Sci , vol. 3 (2016), pp.177-184	http://dx.doi.org/10.1016/j.cag.2017.11.010	methods		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/br/bib0002	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/sec/8	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/ctx/ctx0036		46	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/itrp/0041	'In [2][[ refid=''bib0002'' ]], the authors use a random forest classifier trained on multi-scale 3D features taking into account both surface and context properties.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0053"""" view=""""all"""">For comparison with existing methods we confront our approach to public results on either the full <ce:italic>semantic-8</ce:italic> or the <ce:italic>reduced-8</ce:italic> datasets. We present the results for <ce:italic>semantic-8</ce:italic> in <ce:cross-ref id=""""crf0091"""" refid=""""tbl0001"""">Table 1</ce:cross-ref>b. The three other methods are the publicly available results. <ce:cross-ref id=""""crf0092"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> is method for aerial images based segmentation on images descriptors and an energy minimization on a conditional random field. In <ce:cross-ref id=""""crf0093"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>, the authors use a random forest classifier trained on multi-scale 3D features taking into account both surface and context properties. Harris Net is briefly described as a Deep 3D Convolutional Network on the result board. Elaborating upon its name, we assume it might be a method based on 3D Harris point extraction followed by a classification using a deep framework. We present the results of two methods, SegNet with a purely random set of images, and a U-Net with zoom on snapshot strategy. To our knowledge the two networks performs equally and the main difference reside in the snapshot strategy. At redaction time, our U-Net took the first place in the leaderboard for global scores, average IoU and overall accuracy. Looking at the per class IoU, we take the lead on six out of eight categories. Among them, the performances on natural terrain, scanning artifacts and cars are drastically increased. On man-made terrain and buildings, we place second with a comparable score as <ce:cross-ref id=""""crf0094"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref> and Harris Net. The use of the zoom strategy greatly improves the score on cars and scanning artifacts. The reason is that compared to the random strategy, the training dataset (and the test dataset) contains more images with small details, which makes them possible to segment. The only relative failure of the deep segmentation networks are the scanning artifacts and the hardscape classes. Even though we place first on these categories, the IoU score is low: we discuss this in <ce:cross-ref id=""""crf0095"""" refid=""""sec0015"""">Section 8.4</ce:cross-ref>.</ce:para>""''"'		ANG	
uses_data_from	Experiments	T. Hackel, N. Savinov, L. Ladicky, J.-D. Wegner, K. Schindler, M. Pollefeys, Large-scale point cloud classification benchmark , Proceedings of conference on computer vision and pattern recognition, CVPR/ Large Scale 3D Data Workshop (2016)	http://dx.doi.org/10.1016/j.cag.2017.11.010	methods		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/br/bib0040	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/sec/8	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/ctx/ctx0033		46	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/itrp/0044	'We mainly experiment on the Semantic 3D dataset [40][[ refid=''bib0040'' ]] (http://semantic3d.net).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0042"""" view=""""all"""">In this section, we present the results of our experiments on semantic labeling of 3D point sets. In order to analyze and assess the genericity of our SnapNet approach, we used point clouds of various origins: Lidar sensors in <ce:cross-ref id=""""crf0076"""" refid=""""sec0009"""">Section 8.1</ce:cross-ref>, multiple 2D views and photogrammetry in <ce:cross-ref id=""""crf0077"""" refid=""""sec0012"""">Section 8.2</ce:cross-ref>, and low-cost RGB-D cameras in <ce:cross-ref id=""""crf0078"""" refid=""""sec0013"""">Section 8.3</ce:cross-ref>. We mainly experiment on the Semantic 3D dataset <ce:cross-ref id=""""crf0079"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref> (<ce:inter-ref id=""""interref0001"""" xlink:href=""""http://semantic3d.net"""" xlink:type=""""simple"""">http://semantic3d.net</ce:inter-ref>).</ce:para>""''"'		ANG	
uses_method_in	Semantic labeling	K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition , Proceedings of the IEEE conference on computer vision and pattern recognition (2016)	http://dx.doi.org/10.1016/j.cag.2017.11.010			http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/br/bib0037	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/ctx/ctx0032		46	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/itrp/0045	'A very short (3 layers) residual network [37][[ refid=''bib0037'' ]] is added at the end of the two SegNet.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0034"""" view=""""all"""">As we extract both RGB and depth composite information from the dataset, we want to fuse the data sources to improve the accuracy of the model, compared to only one source. We use several fusion strategies in order to exploit the complementarity of the depth and RGB information. Therefore, two parallel 3-channels segmentation networks are trained, one on the RGB data, the other on the composite data. The experimented strategies are the following:<ce:list id=""""celist0004""""><ce:list-item id=""""celistitem0012""""><ce:label>•</ce:label><ce:para id=""""para0035"""" view=""""all"""">Activation addition fusion, <ce:italic>i.e.</ce:italic> averaging of the two models (<ce:cross-ref id=""""crf0069"""" refid=""""fig0006"""">Fig. 6</ce:cross-ref>c). The predictions of the two SegNet are simply averaged pixel-wise.</ce:para></ce:list-item><ce:list-item id=""""celistitem0013""""><ce:label>•</ce:label><ce:para id=""""para0036"""" view=""""all"""">Prediction fusion using residual correction <ce:cross-ref id=""""crf0070"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref> (<ce:cross-ref id=""""crf0071"""" refid=""""fig0006"""">Fig. 6</ce:cross-ref>e). A very short (3 layers) residual network <ce:cross-ref id=""""crf0072"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref> is added at the end of the two SegNet. It takes in input the before last feature maps and learns a corrective term to apply to the averaged prediction.</ce:para></ce:list-item></ce:list></ce:para>""''"'		ANG	
cites	Experiments	F.J. Lawin, M. Danelljan, P. Tosteberg, G. Bhat, F.S. Khan, M. Felsberg, Deep projective 3D semantic segmentation , CoRR , vol. abs/1705.03428 (2017), pp.None	http://dx.doi.org/10.1016/j.cag.2017.11.010	methods		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/sec/8	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/ctx/ctx0039		46	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/itrp/0046	'DeePr3SS [39][[ refid=''bib0039'' ]] is also a multi-view approach, very similar to ours but later, with multi-stream fully convolutional networks for 2D classification of virtual views rendered by Gaussian point splattering.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0054"""" view=""""all"""">We also present the results for <ce:italic>reduced-8</ce:italic> in <ce:cross-ref id=""""crf0096"""" refid=""""tbl0001"""">Table 1</ce:cross-ref>. While <ce:cross-ref id=""""crf0097"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> and <ce:cross-ref id=""""crf0098"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref> are still present, different deep learning approaches are proposed for comparison. DeePr3SS <ce:cross-ref id=""""crf0099"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> is also a multi-view approach, very similar to ours but later, with multi-stream fully convolutional networks for 2D classification of virtual views rendered by Gaussian point splattering. DeepNet <ce:cross-ref id=""""crf0100"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> is a voxel-based approach with 3D convolutional networks applied to multiscale neighborhoods of each scan point. SnapNet obtains the best average IoU (59.1%), and is close second in Overall Accuracy (88.6%). It gets 4 out of 8 best per-class accuracies (including buildings, cars and trees). DeePr3SS is the main competitor with the best OA and 3 out of 8 best per-class accuracies, which shows the primacy of multi-view approaches on this dataset. The <ce:italic>reduced-8</ce:italic> data raise interesting problems. First the 4 test point clouds have been decimated and so are sparser than the previous experiment. Since we used he same parameters for meshing as on the denser, original data, some rendering artifacts may occur. The good performances show that parameter choice is somewhat robust to various 3D resolutions. Second, the 4 selected scenes are the ones with the more variety between them and also with respect to the training set: different types of buildings, quite rare natural terrain (e.g. cliffs). Again, this may explain slightly inferior results than on <ce:italic>semantic-8</ce:italic>, but performances are still good enough to prove the adaptation capacity of the classifiers.</ce:para>""''"'		ANG	
cites	Related work	I. Lim, A. Gehre, L. Kobbelt, Identifying style of 3D shapes using deep metric learning , Comput Graph Forum , vol. 35 (2016), pp.207-215	http://dx.doi.org/10.1016/j.cag.2017.11.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/br/bib0030	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/ctx/ctx0019		46	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/itrp/0049	'For example, in [30][[ refid=''bib0030'' ]], a deep framework is used to compute a metric for identifying architectural style distance between to building models.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">Third, the <ce:italic>multi-view</ce:italic> strategy consists in applying neural networks to 2D tensors which are selected views of the scene. For example, in <ce:cross-ref id=""""crf0042"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, a deep framework is used to compute a metric for identifying architectural style distance between to building models. On a shape retrieval task, the multi-view approach of <ce:cross-ref id=""""crf0043"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> takes several pictures of the 3D meshed object and then perform image classification using a deep network. The PANORAMA representation <ce:cross-ref id=""""crf0044"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> introduces another trick: projections on bounding cylinders oriented following the 3 principal directions of the volume. Our approach has common features with these last works: we generate snapshots of the 3D scene in order to use a 2D CNN with images as input. But unlike <ce:cross-ref id=""""crf0045"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> whose purpose is classification, i.e. giving a single label per 3D shape, we compute dense labeling in the images and back project the result of the semantic segmentation to the original point cloud, which results in dense 3D point labeling. Another conceptually different point is the strategy for choosing views. We do not aim to capture the whole scene (or object) in a few carefully selected views, but rather take lots of partial views and rely on the final vote to put together local predictions. This avoids introducing too much dataset-related bias into the algorithm.</ce:para>""''"'		ANG	
cites	Related work	T. Hackel, N. Savinov, L. Ladicky, J.D. Wegner, K. Schindler, M. Pollefeys, Semantic3d.net: a new large-scale point cloud classification benchmark , ISPRS Ann Photogramm Remote Sens Spat Inf Sci , vol. IV-1/W1 (2017), pp.None	http://dx.doi.org/10.1016/j.cag.2017.11.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/ctx/ctx0016		46	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-11-010/itrp/0061	'For this purpose, [27][[ refid=''bib0027'' ]] proposed to use local, multiscale 3D tensors around the actual 3D points.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all"""">First, a family of approaches use a voxelization of the space to create 3D tensors in order to feed a 3D convolutional neural network (CNN) <ce:cross-refs id=""""crfs0006"""" refid=""""bib0024 bib0025 bib0026"""">[24–26][[ refid=''''bib0024 bib0025 bib0026'''' ]]</ce:cross-refs>, mainly for object classification. However, those <ce:italic>voxel-based</ce:italic> approaches might be memory consuming. For this purpose, <ce:cross-ref id=""""crf0039"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> proposed to use local, multiscale 3D tensors around the actual 3D points.</ce:para>""''"'		ANG	
uses_data_from	Experiments	M. Eitz, J. Hays, M. Alexa, How do humans sketch objects , Proceedings of ACM SIGGRAPH (2012)	http://dx.doi.org/10.1016/j.cag.2017.12.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/br/bib0002	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/ctx/ctx0043		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/itrp/0026	'– TU-Berlin-Class [2][[ refid=''bib0002'' ]] (training stages 1–3) for sketch classification comprising 250 categories of sketches, 80 per category, crowd-sourced from 1350 different non-expert participants with diverse drawing styles;'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0037"""" view=""""all"""">– <ce:bold>TU-Berlin-Class</ce:bold> <ce:cross-ref id=""""crf0105"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref> (training stages 1–3) for sketch classification comprising 250 categories of sketches, 80 per category, crowd-sourced from 1350 different non-expert participants with diverse drawing styles;</ce:para>""''"'		ANG	
uses_method_in	Methodology	Y. Bengio, J. Louradour, R. Collobert, J. Weston, Curriculum learning , Proceedings of ICML, ACM (2009)	http://dx.doi.org/10.1016/j.cag.2017.12.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/ctx/ctx0039		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/itrp/0067	'Inspired from curriculum learning [39][[ refid=''bib0039'' ]], we trained our model by giving it multiple learning tasks, one-by-one with increasing difficulties.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0025"""" view=""""all"""">We now describe a multi-stage training strategy for all network configurations. Although this strategy is designed for sketch-photo mapping, it can be applied to other cross-domain learning problems. Inspired from curriculum learning <ce:cross-ref id=""""crf0093"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>, we trained our model by giving it multiple learning tasks, one-by-one with increasing difficulties. Denote <mml:math altimg=""""si17.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mi mathvariant=""""script"""">L</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:math> and <mml:math altimg=""""si18.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mi mathvariant=""""script"""">L</mml:mi><mml:mi>R</mml:mi></mml:msub></mml:math> the cross-entropy and regularization losses:<ce:display><ce:formula id=""""eq0005""""><ce:label>(5)</ce:label><mml:math altimg=""""si19.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd columnalign=""""right""""><mml:mrow><mml:msub><mml:mi mathvariant=""""script"""">L</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign=""""left""""><mml:mrow><mml:mo>−</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mstyle scriptlevel=""""0"""" displaystyle=""""true""""><mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:msub><mml:mi>z</mml:mi><mml:mi>y</mml:mi></mml:msub></mml:msup><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mi>e</mml:mi><mml:msub><mml:mi>z</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msup></mml:mrow></mml:mfrac></mml:mstyle><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display><ce:display><ce:formula id=""""eq0006""""><ce:label>(6)</ce:label><mml:math altimg=""""si20.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd columnalign=""""right""""><mml:mrow><mml:msub><mml:mi mathvariant=""""script"""">L</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant=""""bold-italic"""">θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign=""""left""""><mml:mrow><mml:mspace width=""""0.33em""""/><mml:mstyle scriptlevel=""""0"""" displaystyle=""""true""""><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle><mml:munder><mml:mo>∑</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>Our training procedure consists of four stages (<ce:cross-ref id=""""crf0094"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref>):</ce:para>""''"'		ANG	
cites	Methodology	T. Bui, L. Ribeiro, M. Ponti, J. Collomosse, Compact descriptors for sketch-based image retrieval using a triplet loss convolutional neural network , CVIU , vol. vol. 164 (2017), pp.27-37	http://dx.doi.org/10.1016/j.cag.2017.12.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/br/bib0031	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/ctx/ctx0038		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/itrp/0068	'Further gains in compactness could be explored e.g. via product quantization as [31][[ refid=''bib0031'' ]] but such optimizations are beyond the scope of this paper.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0024"""" view=""""all"""">A compact representation is often desirable to allow viable implementation of visual search in systems with processing, battery and memory constraints. In order to learn the dimensionality reduction during the training stage we add an intermediate fully-connected (FC) layer without post-activation. As illustrated in <ce:cross-ref id=""""crf0090"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref> for the SketchANet-AlexNet, an embedding layer <ce:italic>lowerdim</ce:italic> is added between layer FC7 (<mml:math altimg=""""si15.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>4096</mml:mn></mml:mrow></mml:math>) and the output layer FC8 (<mml:math altimg=""""si16.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>250</mml:mn></mml:mrow></mml:math>). By not adding an activation (ReLU) layer, we prevent the embedding layer to become a bottleneck in the network. Note that from the perspective of the softmax-loss layer the connection from FC7 to FC8 is linear. We empirically verify that during training the performance of the classification layer is not affected whether <ce:italic>lowerdim</ce:italic> is integrated in the architecture or not. Dimensionality reduction is tested in <ce:cross-ref id=""""crf0091"""" refid=""""sec0015"""">Section 4.5</ce:cross-ref>. Further gains in compactness could be explored e.g. via product quantization as <ce:cross-ref id=""""crf0092"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> but such optimizations are beyond the scope of this paper.</ce:para>""''"'		ANG	
uses_method_in	Experiments	M. Eitz, K. Hildebrand, T. Boubekeur, M. Alexa, Sketch-based image retrieval: benchmark and bag-of-features descriptors , IEEE Trans Visual Comput Graph , vol. 17 (2011), pp.1624-1636	http://dx.doi.org/10.1016/j.cag.2017.12.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/br/bib0015	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/ctx/ctx0057		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/itrp/0069	'Next, we evaluated over Saavedra-SBIR (using mAP) and TU-Berlin-Retr (using Tb proposed in [15][[ refid=''bib0015'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0060"""" view=""""all"""">Next, we evaluated over Saavedra-SBIR (using mAP) and TU-Berlin-Retr (using <mml:math altimg=""""si1.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mi mathvariant=""""script"""">T</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:math> proposed in <ce:cross-ref id=""""crf0154"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>). <ce:cross-ref id=""""crf0155"""" refid=""""tbl0003"""">Tables 3</ce:cross-ref><ce:float-anchor refid=""""tbl0003""""/> and <ce:cross-ref id=""""crf0156"""" refid=""""tbl0004"""">4</ce:cross-ref><ce:float-anchor refid=""""tbl0004""""/> show our final model also achieving state-of-art performance. While the training stages 2–3 is supplied with categorical-level data only, the finetuning stage 4 on Sketchy helps to learn more detailed representation of sketches and images, contributing to an improvement of 4% mAP on Saavedra-SBIR and 1.5 <mml:math altimg=""""si1.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mi mathvariant=""""script"""">T</mml:mi><mml:mi>b</mml:mi></mml:msub></mml:math> on TU-Berlin-Retr as opposed to the closest approaches.</ce:para>""''"'		ANG	
cites	Related work and contributions	J.P. Collomosse, G. McNeill, L. Watts, Free-hand sketch grouping for video retrieval , International conference on pattern recognition (ICPR) (2008)	http://dx.doi.org/10.1016/j.cag.2017.12.006	related work		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/br/bib0012	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/ctx/ctx0011		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/itrp/0083	'This early wave of SBIR systems was complemented in the late nineties by algorithms accepting line-art sketches, more closely resembling the free-hand sketches casually generated by lay users in the act of sketching a throw-away query [12][[ refid=''bib0012'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0008"""" view=""""all"""">Sketch based image retrieval (SBIR) began to gain momentum in the early nineties with color-blob based query systems such as Flickner et al. ’s QBIC <ce:cross-ref id=""""crf0050"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> that matched coarse attributes of color, shape and texture using region adjacency graphs. Several global image descriptors for matching blob based queries were subsequently proposed, using spectral signatures derived from Haar Wavelets <ce:cross-ref id=""""crf0051"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref> and the Short-Time Fourier Transform <ce:cross-ref id=""""crf0052"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>. This early wave of SBIR systems was complemented in the late nineties by algorithms accepting line-art sketches, more closely resembling the free-hand sketches casually generated by lay users in the act of sketching a throw-away query <ce:cross-ref id=""""crf0053"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>. Such systems are characterized by their optimization based matching approach; fitting the sketch under a deformable model to measure the support for sketched structure within each photograph in the database <ce:cross-refs id=""""crfs0006"""" refid=""""bib0013 bib0014"""">[13,14][[ refid=''''bib0013 bib0014'''' ]]</ce:cross-refs>. Despite good accuracy, such approaches are slow and scale at best linearly. It was not until the 2010 decade that global image descriptors were derived from line-art sketches, enabling more scalable indexing solutions.</ce:para>""''"'		ANG	
cites	Related work and contributions	Y. Qi, Y.-Z. Song, T. Xiang, H. Zhang, T. Hospedales, Y. Li, Making better use of edges via perceptual grouping , Proceedings of CVPR (2015)	http://dx.doi.org/10.1016/j.cag.2017.12.006	related work		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/br/bib0020	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/ctx/ctx0016		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/itrp/0089	'Qi et al. [20][[ refid=''bib0020'' ]] implemented an alternative edge detection pre-process delivering a performance gain in cluttered scenes.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0009"""" view=""""all"""">Mirroring the success of gradient domain features and dictionary learning methods in photo retrieval, both Eitz et al. <ce:cross-ref id=""""crf0054"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> and Hu et al. <ce:cross-ref id=""""crf0055"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> extended Bag of Visual Words (BoVW) to SBIR, also proposing the Flickr15k benchmark <ce:cross-ref id=""""crf0056"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>. Sparse features including the Structure Tensor <ce:cross-ref id=""""crf0057"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>, SHoG <ce:cross-ref id=""""crf0058"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>, Gradient Field Histogram of Oriented Gradients (GF-HOG) <ce:cross-ref id=""""crf0059"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref> and its extended version <ce:cross-ref id=""""crf0060"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> are extracted from images pre-processed via Canny edge detection. Chamfer Matching was employed in Mindfinder <ce:cross-ref id=""""crf0061"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>, later adopted by Sun et al. <ce:cross-ref id=""""crf0062"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> for scalable SBIR indexing billions of images. Qi et al. <ce:cross-ref id=""""crf0063"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> implemented an alternative edge detection pre-process delivering a performance gain in cluttered scenes. Mid-level features were explored through the HELO and key-shapes schemes of Saavedra and Barrios <ce:cross-refs id=""""crfs0007"""" refid=""""bib0007 bib0021 bib0022"""">[7,21,22][[ refid=''''bib0007 bib0021 bib0022'''' ]]</ce:cross-refs>. Their latest work <ce:cross-ref id=""""crf0064"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> uses learned key-shapes and leads the shallow learning approaches.</ce:para>""''"'		ANG	
uses_method_in	Experiments	M. Eitz, K. Hildebrand, T. Boubekeur, M. Alexa, Sketch-based image retrieval: benchmark and bag-of-features descriptors , IEEE Trans Visual Comput Graph , vol. 17 (2011), pp.1624-1636	http://dx.doi.org/10.1016/j.cag.2017.12.006	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/br/bib0015>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/ctx/ctx0044>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2017-12-006/itrp/0096	'– TU-Berlin-Retr [15][[ refid=''bib0015'' ]] (testing) takes into account not only the category of the retrieved images but also the relative order of the relevant images.'			FDY+AGA	infered_pred1
uses_method_in	Visual attention models	L. Itti, C. Koch, E. Niebur, A model of saliency-based visual attention for rapid scene analysis , IEEE Trans Pattern Anal Mach Intell , vol. 20 (1998), pp.1254-1259	http://dx.doi.org/10.1016/j.cag.2018.01.010	model		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/br/bib0004>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/ctx/ctx0026>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/itrp/0006	'Saliency was first determined for each voxel, and was then enhanced by center-surround operations between voxels inspired by the standard cognitive saliency model [4][[ refid=''bib0004'' ]].'			FDY+AGA	infered_pred1
cites	Discussion	S. Lee, M. Sips, H.P. Seidel, Perceptually driven visibility optimization for categorical data visualization , IEEE Trans Vis Comput Graph , vol. 19 (2013), pp.1746-1757	http://dx.doi.org/10.1016/j.cag.2018.01.010	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/br/bib0044	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/ctx/ctx0064		71	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/itrp/0012	'For instance, Lee et al. [44][[ refid=''bib0044'' ]] introduced point and class saliency measures to quantify the color saliency of a single data point or a class of data points in a categorical map visualization.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0093"""" view=""""all"""">In the field of information visualization, a few specialized saliency models quantifying the visual prominence of graphical marks have been proposed. For instance, Lee et al. <ce:cross-ref id=""""crf0147"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> introduced <ce:italic>point and class saliency</ce:italic> measures to quantify the color saliency of a single data point or a class of data points in a categorical map visualization. Waldner et al. <ce:cross-ref id=""""crf0148"""" refid=""""bib0063"""">[63][[ refid=''''bib0063'''' ]]</ce:cross-ref> derived a visual prominence measure of data points in scatterplots that use luminance and blur for highlighting. In the future, it will therefore be of interest to compare the prediction accuracy of these measures to classic saliency models, or to find ways how to combine them.</ce:para>""''"'		ANG	
uses_data_from	Introduction	M.A. Borkin, Z. Bylinskii, N.W. Kim, C.M. Bainbridge, C.S. Yeh, D. Borkin, Beyond memorability: visualization recognition and recall , IEEE Trans Vis Comput Graph , vol. 22 (2016), pp.519-528	http://dx.doi.org/10.1016/j.cag.2018.01.010	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/br/bib0002>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/ctx/ctx0008>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/itrp/0013	'We compared the data of this study with eye tracking data of the memorability experiment [2][[ refid=''bib0002'' ]] with conditions closer to natural image viewing.'			FDY+AGA	infered_pred1
uses_method_in	Task-based visual analysis experiment	M.A. Borkin, Z. Bylinskii, N.W. Kim, C.M. Bainbridge, C.S. Yeh, D. Borkin, Beyond memorability: visualization recognition and recall , IEEE Trans Vis Comput Graph , vol. 22 (2016), pp.519-528	http://dx.doi.org/10.1016/j.cag.2018.01.010	discussion	methods	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/br/bib0002	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/ctx/ctx0048		71	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/itrp/0038	'For comparing task-based visual analysis to more exploratory analysis, we additionally analyzed the eye tracking data of the memorability experiment [2][[ refid=''bib0002'' ]] (Mem-task).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0043"""" view=""""all"""">For comparing task-based visual analysis to more exploratory analysis, we additionally analyzed the eye tracking data of the memorability experiment <ce:cross-ref id=""""crf0075"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref> (Mem-task). The aim of the memorability experiment was to encode displayed visualizations and later recall as many details as possible. Participants were shown about 100 visualizations, each for 10 s. For the evaluation, we used fixations from the first phase (encoding phase) of the memorability experiment, when participants were shown visualizations for the first time.</ce:para>""''"'		ANG	
cites	Conclusions	L.E. Matzen, M.J. Haass, K.M. Divis, Z. Wang, A.T. Wilson, Data visualization saliency model: a tool for evaluating abstract data visualizations , IEEE Trans Vis Comput Graph , vol. 24 (2018), pp.563-573	http://dx.doi.org/10.1016/j.cag.2018.01.010	conclusion		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/br/bib0013	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/ctx/ctx0071		71	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/itrp/0039	'Our results show that despite having improved bottom-up saliency models for information visualization, like DVS [13][[ refid=''bib0013'' ]], the influence of bottom-up visual saliency is drastically reduced during task-based visual analysis.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0100"""" view=""""all"""">Our results show that despite having improved bottom-up saliency models for information visualization, like DVS <ce:cross-ref id=""""crf0157"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>, the influence of bottom-up visual saliency is drastically reduced during task-based visual analysis. We showed that users focus more on data areas of the visualization during task-based visual analysis than when trying to memorize a visualization. Therefore, the added text saliency in the DVS model did not increase the accuracy for task-based visual analysis in the same extent as for exploratory visual analysis. However, despite the increased attention in the data area, we did not find a strong correlation between a task-dependent area’s saliency and visual search efficiency. This means that visual attention is only slightly affected by early features when performing task-based visual analysis using information visualization – in contrast to observation of natural images or during exploratory visual analysis. Yet, fixations between users are more similar than during the memorability experiment. This means that task-based visual analysis is strongly guided by top-down factors imposed by the task.</ce:para>""''"'		ANG	
uses_method_in	Task-based visual analysis experiment	J. Goldberg, J. Helfman, Eye tracking for visualization evaluation: reading values on linear versus radial graphs , Inf Vis , vol. 10 (2011), pp.182-195	http://dx.doi.org/10.1016/j.cag.2018.01.010	discussion	methods	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/br/bib0054	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/ctx/ctx0049		71	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/itrp/0040	'For their eye tracking experiments, Goldberg and Helfman [54][[ refid=''bib0054'' ]] defined AOIs for three sequential steps required to retrieve values in linear or radial graphs: “find dimension”, “find associated datapoint”, “get datapoint value”.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0045"""" view=""""all"""">Depending on the task, there is an optimal viewing sequence in which these task-dependent AOIs should be examined in order to answer the question. For their eye tracking experiments, Goldberg and Helfman <ce:cross-ref id=""""crf0078"""" refid=""""bib0054"""">[54][[ refid=''''bib0054'''' ]]</ce:cross-ref> defined AOIs for three sequential steps required to retrieve values in linear or radial graphs: “find dimension”, “find associated datapoint”, “get datapoint value”. We adopted these three steps for the three low-level tasks in our experiment (<ce:cross-ref id=""""crf0079"""" refid=""""tbl0003"""">Table 3</ce:cross-ref><ce:float-anchor refid=""""tbl0003""""/>). Step 1 thereby is always a visual search for an item label, a value label, or a target data point, respectively. Item or value labels can be axis labels, listed in legends, or directly associated with a data point. In the second step, this label has to be mapped to the actual data point (i.e., the graphical mark). In Step 3, the associated value or item label has to be read.</ce:para>""''"'		ANG	
cites	Discussion	M.A. Borkin, Z. Bylinskii, N.W. Kim, C.M. Bainbridge, C.S. Yeh, D. Borkin, Beyond memorability: visualization recognition and recall , IEEE Trans Vis Comput Graph , vol. 22 (2016), pp.519-528	http://dx.doi.org/10.1016/j.cag.2018.01.010	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/br/bib0002	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/ctx/ctx0069		71	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/itrp/0041	'The participants of Borkin et al.’s [2][[ refid=''bib0002'' ]] experiment were “recruited from the local communities of Cambridge and Boston”, but no information about their visualization literacy is provided.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0098"""" view=""""all"""">Second, our user group was composed of data visualization students who have gained some experience in analyzing visualization compared to novices. As also shown in a prior study <ce:cross-ref id=""""crf0154"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref>, it can be expected that novices are less strongly guided by top-down factors when performing confirmatory analysis than more experienced users. The participants of Borkin et al.’s <ce:cross-ref id=""""crf0155"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref> experiment were “recruited from the local communities of Cambridge and Boston”, but no information about their visualization literacy is provided. If these participants were novices, an alternative explanation to the lower human IO scores could be that users of the memorability experiment analyzed the visualization in a less structured way than the users of our task-based visual analysis experiment.</ce:para>""''"'		ANG	
uses_method_in	Results	L. Itti, C. Koch, E. Niebur, A model of saliency-based visual attention for rapid scene analysis , IEEE Trans Pattern Anal Mach Intell , vol. 20 (1998), pp.1254-1259	http://dx.doi.org/10.1016/j.cag.2018.01.010	results		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/ctx/ctx0059		71	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/itrp/0042	'To test the influence of a target area’s visual saliency on visual search performance, we computed the correlation between the task-dependent AOI saliency (using the model by Itti et al. [4][[ refid=''bib0004'' ]]) and its FF for each of the three low-level analytical tasks.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0077"""" view=""""all"""">To test the influence of a target area’s visual saliency on visual search performance, we computed the correlation between the task-dependent <ce:italic>AOI saliency</ce:italic> (using the model by Itti et al. <ce:cross-ref id=""""crf0124"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>) and its <ce:italic>FF</ce:italic> for each of the three low-level analytical tasks. We only analyzed the first task-dependent AOI to be fixated according to the task-dependent AOI sequence shown as Step 1 in <ce:cross-ref id=""""crf0125"""" refid=""""tbl0003"""">Table 3</ce:cross-ref>. Since each task has a different optimal solution process, we set the target item label as visual search target for the RV-task, the target value label for the F-task, and the target data point for the FE-task. According to our hypothesis H2.1, there should be a negative correlation between the visual search target’s AOI saliency and its FF – in other words: the more salient the target, the faster it should be fixated by the user. As visualized in <ce:cross-ref id=""""crf0126"""" refid=""""fig0011"""">Fig. 11</ce:cross-ref><ce:float-anchor refid=""""fig0011""""/>, there is a negative correlation, but this correlation is weak. <ce:italic>In other words, the visual search efficiency for a target in the course of a low-level analytical task does not strongly correlate with its target saliency. Therefore, we have to reject hypothesis H2.1.</ce:italic></ce:para>""''"'		ANG	
cites	Discussion	M.A. Borkin, Z. Bylinskii, N.W. Kim, C.M. Bainbridge, C.S. Yeh, D. Borkin, Beyond memorability: visualization recognition and recall , IEEE Trans Vis Comput Graph , vol. 22 (2016), pp.519-528	http://dx.doi.org/10.1016/j.cag.2018.01.010	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/br/bib0002	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/ctx/ctx0060		71	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/itrp/0043	'This tendency is reflected in the selected descriptions of visualization content of users in Borkin et al.’s [2][[ refid=''bib0002'' ]] memorability experiment (supplemental material).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0086"""" view=""""all"""">An alternative explanation is that users were intentionally seeking for extrema as representative values to memorize the content of the visualization. This tendency is reflected in the selected descriptions of visualization content of users in Borkin et al.’s <ce:cross-ref id=""""crf0139"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref> memorability experiment (supplemental material). Most of the listed user descriptions contain a short summary of what is visualized together with one or more extreme items. This would mean that a memorability task would lead to similar top-down guidance as a find-extremum task.</ce:para>""''"'		ANG	
uses_method_in	Discussion	L. Itti, C. Koch, E. Niebur, A model of saliency-based visual attention for rapid scene analysis , IEEE Trans Pattern Anal Mach Intell , vol. 20 (1998), pp.1254-1259	http://dx.doi.org/10.1016/j.cag.2018.01.010	discussion		<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/br/bib0004>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/ctx/ctx0062>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/itrp/0059	'However, for the seminal saliency model by Itti et al. [4][[ refid=''bib0004'' ]], the fixation-saliency similarities are equally low for the low-level analytical tasks as for the memorability task.'			FDY+AGA	infered_pred1
uses_data_from	Task-based visual analysis experiment	M.A. Borkin, Z. Bylinskii, N.W. Kim, C.M. Bainbridge, C.S. Yeh, D. Borkin, Beyond memorability: visualization recognition and recall , IEEE Trans Vis Comput Graph , vol. 22 (2016), pp.519-528	http://dx.doi.org/10.1016/j.cag.2018.01.010	discussion	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/br/bib0002>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/ctx/ctx0053>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/itrp/0080	'Eye-tracking data of the original memorability experiment [2][[ refid=''bib0002'' ]] can be found at http://massvis.mit.edu/.'			FDY+AGA	infered_pred1
uses_method_in	Task-based visual analysis experiment	M.A. Borkin, Z. Bylinskii, N.W. Kim, C.M. Bainbridge, C.S. Yeh, D. Borkin, Beyond memorability: visualization recognition and recall , IEEE Trans Vis Comput Graph , vol. 22 (2016), pp.519-528	http://dx.doi.org/10.1016/j.cag.2018.01.010	discussion	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/br/bib0002>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/ctx/ctx0050>				http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/itrp/0096	'In order to keep the same viewing conditions as in the original memorability experiment [2][[ refid=''bib0002'' ]], the task description that would affect participants’ scanning sequence, was not displayed in this step of the experiment.'			FDY+AGA	infered_pred1
cites	Visual attention models	J. Harel, C. Koch, P. Perona, Graph-based visual saliency , Proceedings of the 19th international conference on neural information processing systems, NIPS’06, MIT Press (2006)	http://dx.doi.org/10.1016/j.cag.2018.01.010	model		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/br/bib0014	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/ctx/ctx0010		71	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/itrp/0100	'Harel et al. [14][[ refid=''bib0014'' ]] also followed this approach.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0010"""" view=""""all"""">In recent decades, various attention models have been proposed that differ in how they predict human visual attention. As pioneers, Itti et al. <ce:cross-ref id=""""crf0024"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref> defined a computational bottom-up saliency model using local center-surround differences of intensity, color and orientation features at multiple spatial scales. This approach of feature extraction has been adopted in many attention models. Harel et al. <ce:cross-ref id=""""crf0025"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> also followed this approach. Their model computes saliency using graph-based dissimilarity measures. Hou et al. <ce:cross-ref id=""""crf0026"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> introduced a model analyzing the frequency domain instead of the spatial domain to predict saliency. The bottom-up model presented by Zhang and Sclaroff <ce:cross-ref id=""""crf0027"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref> is based on the principle of figure-background segregation. The model identifies figures in a set of Boolean maps generated by thresholding feature maps. A work presented by Bruce and Tsotsos <ce:cross-ref id=""""crf0028"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> defines saliency as the self-information of visual features of the image. Zhang et al. <ce:cross-ref id=""""crf0029"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> proposed a Bayesian framework that incorporates top-down information dependent on the target’s features with bottom-up saliency that is represented as the self-information derived from the statistics of natural images. Goferman et al. <ce:cross-ref id=""""crf0030"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> proposed saliency detection based on patches with unique low-level features, visual organization rules according to which regions close to salient pixels are also salient and high-level factors, such as human faces. Vig et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> and Cornia et al. <ce:cross-ref id=""""crf0032"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> introduced saliency models that employ neural networks to predict fixations.</ce:para>""''"'		ANG	
cites	Visual attention models	S. Goferman, L. Zelnik-Manor, A. Tal, Context-aware saliency detection , IEEE Trans Pattern Anal Mach Intell , vol. 34 (2012), pp.1915-1926	http://dx.doi.org/10.1016/j.cag.2018.01.010	model		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/br/bib0019	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/ctx/ctx0015		71	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/itrp/0113	'Goferman et al. [19][[ refid=''bib0019'' ]] proposed saliency detection based on patches with unique low-level features, visual organization rules according to which regions close to salient pixels are also salient and high-level factors, such as human faces.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0010"""" view=""""all"""">In recent decades, various attention models have been proposed that differ in how they predict human visual attention. As pioneers, Itti et al. <ce:cross-ref id=""""crf0024"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref> defined a computational bottom-up saliency model using local center-surround differences of intensity, color and orientation features at multiple spatial scales. This approach of feature extraction has been adopted in many attention models. Harel et al. <ce:cross-ref id=""""crf0025"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> also followed this approach. Their model computes saliency using graph-based dissimilarity measures. Hou et al. <ce:cross-ref id=""""crf0026"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> introduced a model analyzing the frequency domain instead of the spatial domain to predict saliency. The bottom-up model presented by Zhang and Sclaroff <ce:cross-ref id=""""crf0027"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref> is based on the principle of figure-background segregation. The model identifies figures in a set of Boolean maps generated by thresholding feature maps. A work presented by Bruce and Tsotsos <ce:cross-ref id=""""crf0028"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> defines saliency as the self-information of visual features of the image. Zhang et al. <ce:cross-ref id=""""crf0029"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> proposed a Bayesian framework that incorporates top-down information dependent on the target’s features with bottom-up saliency that is represented as the self-information derived from the statistics of natural images. Goferman et al. <ce:cross-ref id=""""crf0030"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> proposed saliency detection based on patches with unique low-level features, visual organization rules according to which regions close to salient pixels are also salient and high-level factors, such as human faces. Vig et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> and Cornia et al. <ce:cross-ref id=""""crf0032"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> introduced saliency models that employ neural networks to predict fixations.</ce:para>""''"'		ANG	
cites	Visual attention models	L. Zhang, M.H. Tong, T.K. Marks, H. Shan, G.W. Cottrell, Sun: a bayesian framework for saliency using natural statistics , J Vis , vol. 8 (2008), pp.32	http://dx.doi.org/10.1016/j.cag.2018.01.010	model		http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/ctx/ctx0014		71	7	http://www.scar.disi.unibo.it/r/10-1016-j-cag-2018-01-010/itrp/0114	'Zhang et al. [18][[ refid=''bib0018'' ]] proposed a Bayesian framework that incorporates top-down information dependent on the target’s features with bottom-up saliency that is represented as the self-information derived from the statistics of natural images.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0010"""" view=""""all"""">In recent decades, various attention models have been proposed that differ in how they predict human visual attention. As pioneers, Itti et al. <ce:cross-ref id=""""crf0024"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref> defined a computational bottom-up saliency model using local center-surround differences of intensity, color and orientation features at multiple spatial scales. This approach of feature extraction has been adopted in many attention models. Harel et al. <ce:cross-ref id=""""crf0025"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> also followed this approach. Their model computes saliency using graph-based dissimilarity measures. Hou et al. <ce:cross-ref id=""""crf0026"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> introduced a model analyzing the frequency domain instead of the spatial domain to predict saliency. The bottom-up model presented by Zhang and Sclaroff <ce:cross-ref id=""""crf0027"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref> is based on the principle of figure-background segregation. The model identifies figures in a set of Boolean maps generated by thresholding feature maps. A work presented by Bruce and Tsotsos <ce:cross-ref id=""""crf0028"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> defines saliency as the self-information of visual features of the image. Zhang et al. <ce:cross-ref id=""""crf0029"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> proposed a Bayesian framework that incorporates top-down information dependent on the target’s features with bottom-up saliency that is represented as the self-information derived from the statistics of natural images. Goferman et al. <ce:cross-ref id=""""crf0030"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> proposed saliency detection based on patches with unique low-level features, visual organization rules according to which regions close to salient pixels are also salient and high-level factors, such as human faces. Vig et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> and Cornia et al. <ce:cross-ref id=""""crf0032"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> introduced saliency models that employ neural networks to predict fixations.</ce:para>""''"'		ANG	
cites	Related work	A. Frome, D. Huber, R. Kolluri, T. Bülow, J. Malik, Recognizing objects in range data using regional point descriptors , Computer Vision – ECCV 2004, Springer , vol. vol. 3023 (2004), pp.224-237	http://dx.doi.org/10.1016/j.cagd.2016.02.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-cagd-2016-02-006/br/br0160>	<http://www.scar.disi.unibo.it/r/10-1016-j-cagd-2016-02-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-cagd-2016-02-006/ctx/ctx0006>				http://www.scar.disi.unibo.it/r/10-1016-j-cagd-2016-02-006/itrp/0039	'The 3D shape context (Frome et al., 2004[[ refid=''br0160'' ]]) extends the concept of the shape context to 3D point clouds and offers a solution for constructing local 3D reference frames.'				100_classified_extends
uses_method_in	MCDA decision rule	R.R. Yager, Quantifier guided aggregation using OWA operators , International Journal of Intelligent Systems , vol. 11 (1996), pp.49-73	http://dx.doi.org/10.1016/j.cageo.2009.05.011			<http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/br/bib44>	<http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/ctx/ctx0037>				http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/itrp/0059	'To identify the quantifier for the MCDA decision rule, we employed one of the most frequently used methods for defining a parameterized subset on the unit interval (Yager, 1996[[ refid=''bib44'' ]]): [[ formulaid=''id19_pos0'' ]]'			FDY+AGA	infered_pred1
uses_method_in	MCDA decision rule	R.R. Yager, Quantifier guided aggregation using OWA operators , International Journal of Intelligent Systems , vol. 11 (1996), pp.49-73	http://dx.doi.org/10.1016/j.cageo.2009.05.011			<http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/br/bib44>	<http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/ctx/ctx0036>				http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/itrp/0060	'In this setting, function Q: I→ I where I=[0,1] in such a way that Q(0)=0, Q(1)=1 and Q( x)≥ Q( y) if x>y, corresponds to a fuzzy subset representation of the linguistic quantifier Q. Based on the function, the OWA operator is guided by Q. As a result, the order weights are defined as follows (Yager, 1996[[ refid=''bib44'' ]]): [[ formulaid=''id18_pos0'' ]]'			FDY+AGA	infered_pred1
uses_method_in	MCDA decision rule	R.R. Yager, On ordered weighted averaging aggregation operators in multi-criteria decision-making , IEEE Transactions Systems, Man and Cybernetics , vol. 18 (1988), pp.183-190	http://dx.doi.org/10.1016/j.cageo.2009.05.011			<http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/br/bib43>	<http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/ctx/ctx0033>				http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/itrp/0071	'Yager (1988)[[ refid=''bib43'' ]] proposed OWA as a parameterized family of combination operators.'			FDY+AGA	infered_pred1
uses_method_in	MCDA decision rule	R.R. Yager, Quantifier guided aggregation using OWA operators , International Journal of Intelligent Systems , vol. 11 (1996), pp.49-73	http://dx.doi.org/10.1016/j.cageo.2009.05.011			<http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/br/bib44>	<http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/ctx/ctx0038>				http://www.scar.disi.unibo.it/r/10-1016-j-cageo-2009-05-011/itrp/0081	'By changing the parameter, α, one can generate different types of quantifiers and their associated operators between the two extreme cases of the ‘ at least one’ and ‘ all’ linguistic quantifiers (Yager, 1996[[ refid=''bib44'' ]]).'			FDY+AGA	infered_pred1
cites	Extending	N. Li, J.C. Mitchell, W.H. Winsborough, Design of a role-based trust-management framework , Proc. of Security and Privacy, IEEE Computer Society (2002)	http://dx.doi.org/10.1016/j.camwa.2011.12.017			<http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2011-12-017/br/br000005>	<http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2011-12-017/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2011-12-017/ctx/ctx0036>				http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2011-12-017/itrp/0027	'This family uniformly extends the classical RT family [1][[ refid=''br000005'' ]] by associating a semiring value to the basic role definition.'				100_classified_extends
cites	Introduction	Y. Chen, Y. Yao, A multiview approach for intelligent data analysis based on data operators , Information Sciences , vol. 178 (2008), pp.1-20	http://dx.doi.org/10.1016/j.camwa.2012.03.087	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2012-03-087/br/br000020>	<http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2012-03-087/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2012-03-087/ctx/ctx0003>				http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2012-03-087/itrp/0030	'This extension is called the property-oriented concept lattice [4][[ refid=''br000020'' ]].'				100_classified_extends
cites	History of fractal geometry	H. Trochet, A History of Fractal Geometry , None, MacTutor History of Mathematics (2009)	http://dx.doi.org/10.1016/j.camwa.2013.01.017			<http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2013-01-017/br/br000040>	<http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2013-01-017/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2013-01-017/ctx/ctx0008>				http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2013-01-017/itrp/0007	'Very shortly after that work had been submitted (in March 1918), Felix Hausdorff expanded the definition of “dimension” significantly for the evolution of the definition of fractals, allowing sets to have non-integer dimensions [8][[ refid=''br000040'' ]].'				100_classified_extends
cites	Introduction	E.M. Garau, R. Vázquez, Algorithms for the implementation of adaptive isogeometric methods using hierarchical splines, in preparation.	http://dx.doi.org/10.1016/j.camwa.2016.05.010	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2016-05-010/br/br000045>	<http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2016-05-010/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2016-05-010/ctx/ctx0007>				http://www.scar.disi.unibo.it/r/10-1016-j-camwa-2016-05-010/itrp/0029	'Garau, on an extension of GeoPDEs to include adaptivity based on hierarchical splines [9][[ refid=''br000045'' ]].'				100_classified_extends
uses_method_in	Method	E. Diener, R. Emmons, R. Larsen, S. Griffin, The satisfaction with life scale , Journal of Personality Assessment , vol. 49 (1985), pp.71-75	http://dx.doi.org/10.1016/j.chb.2009.09.003	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2009-09-003/br/bib9>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2009-09-003/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2009-09-003/ctx/ctx0046>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2009-09-003/itrp/0022	'Level of personal contentment was measured by an additive scale of three items extracted from the Satisfaction with Life Scale developed by Diener, Emmons, Larsen, and Griffin (1985)[[ refid=''bib9'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method	S.D. Gosling, P.J. Rentfrow, W.B.J. Swann, A very brief measure of the big five personality domains , Journal of Research in Personality , vol. 37 (2003), pp.504-528	http://dx.doi.org/10.1016/j.chb.2009.09.003	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2009-09-003/br/bib14>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2009-09-003/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2009-09-003/ctx/ctx0040>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2009-09-003/itrp/0024	'The personality traits were measured using part of the 10-Item Personality Inventory (Gosling et al., 2003[[ refid=''bib14'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method	S.D. Gosling, P.J. Rentfrow, W.B.J. Swann, A very brief measure of the big five personality domains , Journal of Research in Personality , vol. 37 (2003), pp.504-528	http://dx.doi.org/10.1016/j.chb.2009.09.003	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2009-09-003/br/bib14>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2009-09-003/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2009-09-003/ctx/ctx0043>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2009-09-003/itrp/0027	'Therefore, it can be used as a proxy for the longer Big-Five instruments (Gosling et al., 2003[[ refid=''bib14'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Introduction	I. Nonaka, A dynamic theory of organizational knowledge creation , Organization Science , vol. 5 (1994), pp.14-37	http://dx.doi.org/10.1016/j.chb.2010.07.024	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2010-07-024/br/b0115>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2010-07-024/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2010-07-024/ctx/ctx0005>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2010-07-024/itrp/0017	'Socialization is one of the modes for transferring individual’s knowledge and for expanding organizational knowledge (Nonaka, 1994[[ refid=''b0115'' ]]).'				100_classified_extends
extends	Acknowledgements	H. Lee, J.W. Kim, R. Hackney, The determinants of the effectiveness of online discussion board systems in eLearning: A case study , Lecture Notes in Computer Science , vol. 5288 (2008), pp.271-277	http://dx.doi.org/10.1016/j.chb.2010.07.047	acknowledgements		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2010-07-047/br/b0070>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2010-07-047/sec/sec7>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2010-07-047/ctx/ctx0018>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2010-07-047/itrp/0007	'This paper is a significantly extended version of the paper which was presented at the 1st World Summit on the Knowledge Society at Athens, Greece in 2008 (Lee, Kim, & Hackney, 2008[[ refid=''b0070'' ]]).'				100_classified_extends
uses_method_in	Method	E. Diener, R.A. Emmons, R.J. Larsen, S. Griffin, The satisfaction with life scale , Journal of Personality Assessment , vol. 1 (1985), pp.71-75	http://dx.doi.org/10.1016/j.chb.2011.08.017	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2011-08-017/br/b0150>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2011-08-017/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2011-08-017/ctx/ctx0035>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2011-08-017/itrp/0043	'We used the life satisfaction scale developed by Diener, Emmons, Larsen, and Griffin (1985)[[ refid=''b0150'' ]], which contains items such as, “The conditions of my life today are excellent,” and “So far, I have gotten the important things I want in life.” Respondents in our sample reported a moderately high level of life satisfaction (see Fig. A4; Range 1–5, M = 3.48, SD = 0.77, α = 0.85).'			FDY+AGA	infered_pred1
cites	Development of the model and the hypotheses	P.M. Doney, J.P. Cannon, An examination of the nature of trust in buyer–seller relationships , Journal of Marketing , vol. 61 (1997), pp.35-51	http://dx.doi.org/10.1016/j.chb.2012.04.016	model		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/br/b0095>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/ctx/ctx0080>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/itrp/0043	'Trust also involves a “calculative process” (Doney & Cannon, 1997[[ refid=''b0095'' ]], p. 37) related to the value people receive from their relationships.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method	Y. Hsieh, H. Chiu, M. Chiang, Maintaining and committed online customer: A study across search-experience-credence products , Journal of Retailing , vol. 81 (2005), pp.75-82	http://dx.doi.org/10.1016/j.chb.2012.04.016	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/br/b0195>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/ctx/ctx0086>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/itrp/0055	'The scale was developed for use with an online store (Hsieh, Chiu, & Chiang, 2005[[ refid=''b0195'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method	J.H. Schau, M.A. Muniz, J.E. Arnould, How brand community practices create value , Journal of Marketing , vol. 73 (2009), pp.30-51	http://dx.doi.org/10.1016/j.chb.2012.04.016	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/br/b0325>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/ctx/ctx0088>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/itrp/0057	'The items were constructed from the definition of brand use practices given by Schau et al. (2009)[[ refid=''b0325'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method	J.H. Schau, M.A. Muniz, J.E. Arnould, How brand community practices create value , Journal of Marketing , vol. 73 (2009), pp.30-51	http://dx.doi.org/10.1016/j.chb.2012.04.016	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/br/b0325>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/ctx/ctx0089>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/itrp/0058	'It is derived from the definition given by Schau et al. (2009)[[ refid=''b0325'' ]].'			FDY+AGA	infered_pred1
cites	Limitations and future research	J.H. Schau, M.A. Muniz, J.E. Arnould, How brand community practices create value , Journal of Marketing , vol. 73 (2009), pp.30-51	http://dx.doi.org/10.1016/j.chb.2012.04.016			<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/br/b0325>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/ctx/ctx0106>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/itrp/0085	'For example, we mentioned that the effects of value creation practices evolve over time (Schau et al., 2009[[ refid=''b0325'' ]]); however; we do not know how these effects act over time and how they develop.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Development of the model and the hypotheses	M.A. Muniz, C.T. O’Guinn, Brand community , Journal of Consumer Research , vol. 27 (2001), pp.412-432	http://dx.doi.org/10.1016/j.chb.2012.04.016	model		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/br/b0285>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/ctx/ctx0046>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/itrp/0106	'After a review of the sociology literature, Muniz and O’Guinn (2001)[[ refid=''b0285'' ]] identify three core components or markers of a community; shared consciousness of kind, shared rituals and traditions, and moral responsibility or obligations to society.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Development of the model and the hypotheses	A. Chaudhuri, M.B. Holbrook, The chain of effects from brand trust and brand affect to brand performance: The role of brand loyalty , Journal of Marketing , vol. 65 (2001), pp.81-93	http://dx.doi.org/10.1016/j.chb.2012.04.016	model		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/br/b0050>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/ctx/ctx0073>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-04-016/itrp/0123	'Brand trust is “the willingness of the average consumer to rely on the ability of the brand to perform its stated function” (Chaudhuri & Holbrook, 2001[[ refid=''b0050'' ]], p. 82).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method	S.D. Gosling, P.J. Rentfrow, W.B. Swann, A very brief measure of the Big Five personality domains , Journal of Research in Personality , vol. 37 (2003), pp.504-528	http://dx.doi.org/10.1016/j.chb.2012.11.010	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-11-010/br/b0030>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-11-010/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-11-010/ctx/ctx0016>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2012-11-010/itrp/0005	'The Ten Item Personality Inventory (TIPI), a brief 10-item measure of the Big Five Personality domains (Gosling, Rentfrow, & Swann, 2003[[ refid=''b0030'' ]]), was administered to assess personality.'			FDY+AGA	infered_pred1
cites	Methodology	A. Lepp, J.E. Barkley, G.J. Sanders, M. Rebold, P. Gates, The relationship between cell phone use, physical and sedentary activity, and cardiorespiratory fitness in a sample of US college students , International Journal of Behavioral Nutrition and Physical Activity , vol. 10 (2013), pp.79	http://dx.doi.org/10.1016/j.chb.2013.10.049	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2013-10-049/br/b0160>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2013-10-049/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2013-10-049/ctx/ctx0035>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2013-10-049/itrp/0047	'For example, consider calling, texting, Facebook, e-mail, sending photos, gaming, surfing the Internet, watching videos, and all other uses driven by ‘apps’ and software” (Lepp et al., 2013[[ refid=''b0160'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Methodology	F.J. Fowler, Survey research methods , None, Sage Publications (2002)	http://dx.doi.org/10.1016/j.chb.2013.10.049	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2013-10-049/br/b0065>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2013-10-049/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2013-10-049/ctx/ctx0036>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2013-10-049/itrp/0052	'That is, two focus groups of undergraduate students reviewed these questions for several validity criteria including: (1) clarity in wording, (2) relevance of the items, (3) use of standard English, (4) absence of biased words and phrases, (5) formatting of items, and (6) clarity of the instructions (Fowler, 2002[[ refid=''b0065'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites_as_review	Introduction	A.L. Gross, B. Ballif, Children’s understanding of emotion from facial expression and situations: A review , Developmental Review , vol. 11 (1991), pp.368-398	http://dx.doi.org/10.1016/j.chb.2014.05.036	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/br/b0090>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/ctx/ctx0020>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/itrp/0003	'These means of learning are available only when a child can see another’s face and physical being (Gross & Ballif, 1991[[ refid=''b0090'' ]]).'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
uses_method_in	Method	S. Nowicki, J. Carton, The measurement of emotional intensity from facial expressions , The Journal of Social Psychology , vol. 133 (1993), pp.749-750	http://dx.doi.org/10.1016/j.chb.2014.05.036	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/br/b0155>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/ctx/ctx0026>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/itrp/0005	'Because the ability to accurately read emotion in the facial expression of others is one of the most important nonverbal communication skills, we used the Faces subtests of the second edition of the Diagnostic Analysis of Nonverbal Behavior (DANVA2) (Nowicki & Carton, 1993[[ refid=''b0155'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method	D. Wechsler, The Wechsler Intelligence Scale for children , None, Pearson Assessment (2004)	http://dx.doi.org/10.1016/j.chb.2014.05.036	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/br/b0210>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/ctx/ctx0029>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/itrp/0016	'The forward Digit Span (Wechsler, 2004[[ refid=''b0210'' ]]) a subset of the Wechsler Intelligence Scale for children, was administered as a distracter task between the CASP and the DANVA2.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method	D.M. Dimitrov, P.D. Rumrill, Pretest–posttest designs and measurement of change , IOS Press , vol. 20 (2003), pp.159-165	http://dx.doi.org/10.1016/j.chb.2014.05.036	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/br/b0055>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/ctx/ctx0031>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-05-036/itrp/0032	'For both dependent variables, we ran univariate analyses of covariance, the preferred method of analysis for this design (Dimitrov & Rumrill, 2003[[ refid=''b0055'' ]]), using gender, ethnicity, and age, as well as a composite variable called media-use sum (i.e., sum of time spent watching television, playing video games, using cell phones, and using computers) as covariates, in order to control for demographics and prior media use.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Methods	S.D. Gosling, P.J. Rentfrow, W.B. Swann, A very brief measure of the big-five personality domains , Journal of Research in Personality , vol. 37 (2003), pp.504-528	http://dx.doi.org/10.1016/j.chb.2014.07.015	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-07-015/br/b0080>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-07-015/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-07-015/ctx/ctx0039>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-07-015/itrp/0077	'A 5-item personality inventory adapted from Gosling, Rentfrow, and Swann (2003)[[ refid=''b0080'' ]]4 was used to measure the big-five personality traits, extroversion, agreeableness, conscientiousness, neuroticism, and openness to experiences.'			FDY+AGA	infered_pred1
uses_method_in	Results	C.M. Walker, B.R. Sockman, S. Koehn, An exploratory study of cyberbullying with undergraduate university students , TechTrends , vol. 55 (2011), pp.31-38	http://dx.doi.org/10.1016/j.chb.2014.09.028	results		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-09-028/br/b0110>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-09-028/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-09-028/ctx/ctx0029>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-09-028/itrp/0012	'Turkeys (Walker et al., 2011[[ refid=''b0110'' ]]) boxplot was used to visualise the variables in order to investigate the spread of data and highlight any outliers.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Methods	S.D. Gosling, P.J. Rentfrow, W.B. Swann, A very brief measure of the Big-Five personality domains , Journal of Research in Personality , vol. 37 (2003), pp.504-528	http://dx.doi.org/10.1016/j.chb.2014.11.014	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-11-014/br/b0045>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-11-014/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-11-014/ctx/ctx0043>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-11-014/itrp/0019	'The 10-item instrument has been found to be a reasonable substitute for the longer Big-Five inventory when research conditions means that a short measure is the only way (Gosling, Rentfrow, & Swann, 2003[[ refid=''b0045'' ]]).'			FDY+AGA	infered_pred1
uses_data_from	Experimental phase	Asuncion, A. & Newman, D. (2007). UCI machine learning repository. <	http://dx.doi.org/10.1016/j.chb.2014.11.091	methods		http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-11-091/br/b0020	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-11-091/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-11-091/ctx/ctx0038		51	8	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-11-091/itrp/0053	'These datasets were taken from the UCI machine learning repository (Asuncion & Newman, 2007[[ refid=''b0020'' ]]), from which full documentation for all datasets can be obtained.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0280"""" view=""""all"""">Five datasets were used as test set to estimate the classification performance of each one of the compared algorithms. These datasets were taken from the UCI machine learning repository (<ce:cross-ref id=""""c0140"""" refid=""""b0020"""">Asuncion &amp; Newman, 2007[[ refid=''''b0020'''' ]]</ce:cross-ref>), from which full documentation for all datasets can be obtained. The main characteristics of these datasets have been expounded in <ce:cross-ref id=""""c0410"""" refid=""""s0045"""">Section 5</ce:cross-ref>. Delta Associative Memory performance was compared against the performance achieved by twenty different algorithms which are included in WEKA 3: Data Mining Software in Java (<ce:cross-ref id=""""c0145"""" refid=""""b0090"""">Hall et al., 2009[[ refid=''''b0090'''' ]]</ce:cross-ref>). WEKA is an open source software issued under the GNU General Public License, freely available on the Web (<ce:cross-ref id=""""c0150"""" refid=""""b0080"""">Hall et al., 2010[[ refid=''''b0080'''' ]]</ce:cross-ref>). Further information on each of the algorithms that were used during the experimental phase can be found in <ce:cross-ref id=""""c0155"""" refid=""""b0290"""">Witten and Frank (2005)[[ refid=''''b0290'''' ]]</ce:cross-ref>. In order to carry out such a comparison, we applied the same conditions and validation schemes for each experiment. Classification accuracy of each one of the compared algorithms was calculated using 10-fold cross-validation.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_method_in	A framework supporting social recommendation	G. Adomavicius, R. Sankaranarayanan, S. Sen, A. Tuzhilin, Incorporating contextual information in recommender systems using a multidimensional approach , ACM Transactions on Information Systems (TOIS) , vol. 23 (2005), pp.103-145	http://dx.doi.org/10.1016/j.chb.2014.12.011			<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-12-011/br/b0005>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-12-011/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-12-011/ctx/ctx0033>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2014-12-011/itrp/0038	'The context is represented by means of the well-known key-value model (Adomavicius, Sankaranarayanan, Sen, & Tuzhilin, 2005[[ refid=''b0005'' ]]) using as dimensions some of the different feature spaces related to items.'			FDY+AGA	infered_pred1
uses_method_in	Methods	S.P. Walsh, K.M. White, R.M. Young, Needing to connect: The effect of self and others on young people’s involvement with their mobile phones , Australian Journal of Psychology , vol. 62 (2010), pp.194-203	http://dx.doi.org/10.1016/j.chb.2015.02.059	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/br/b0160>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/ctx/ctx0040>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/itrp/0018	'Mobile Phone Involvement Questionnaire (MPIQ): In addition to the NMP-Q, the 8-item MPIQ (Walsh et al., 2010[[ refid=''b0160'' ]]) was administered.'			FDY+AGA	infered_pred1
uses_method_in	Methods	R.F. DeVellis, , Scale development: Theory and applications, Sage , vol. Vol. 26 (2003), pp.None	http://dx.doi.org/10.1016/j.chb.2015.02.059	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/br/b0040>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/ctx/ctx0042>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/itrp/0020	'To determine how homogeneous the items in the NMP-Q were (DeVellis, 2003[[ refid=''b0040'' ]]), internal consistency reliability was examined using Cronbach’s alpha as the internal consistency reliability coefficient.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Methods	R.F. DeVellis, , Scale development: Theory and applications, Sage , vol. Vol. 26 (2003), pp.None	http://dx.doi.org/10.1016/j.chb.2015.02.059	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/br/b0040>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/ctx/ctx0043>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/itrp/0021	'The degree of the correlation between the scores provided evidence of similarity between the NMP-Q and MPIQ (DeVellis, 2003[[ refid=''b0040'' ]]); and thus, served as a means of checking for construct validity of the NMP-Q.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Introduction	A. Oulasvirta, T. Rattenbury, L. Ma, E. Raita, Habits make smartphone use more pervasive , Personal and Ubiquitous Computing , vol. 16 (2012), pp.105-114	http://dx.doi.org/10.1016/j.chb.2015.02.059	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/br/b0120>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/ctx/ctx0002>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/itrp/0025	'With the proliferation of inexpensive mobile devices, we are now living in a mobile age in which mobile ICTs are vigorously and quickly adopted (Oulasvirta, Rattenbury, Ma, & Raita, 2012[[ refid=''b0120'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Findings and results	B.G. Tabachnick, L.S. Fidell, Using multivariate statistics , None, Pearson (2013)	http://dx.doi.org/10.1016/j.chb.2015.02.059	results		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/br/b0150>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/ctx/ctx0049>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/itrp/0034	'The presence of simple structure supports the adequacy of rotation (Tabachnick & Fidell, 2013[[ refid=''b0150'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Methods	S.P. Walsh, K.M. White, R.M. Young, Needing to connect: The effect of self and others on young people’s involvement with their mobile phones , Australian Journal of Psychology , vol. 62 (2010), pp.194-203	http://dx.doi.org/10.1016/j.chb.2015.02.059	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/br/b0160>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/ctx/ctx0037>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/itrp/0041	'For this purpose, the 8-item Mobile Phone Involvement Questionnaire (MPIQ) developed by Walsh, White, and Young (2010)[[ refid=''b0160'' ]] was administered together with the NMP-Q. The MPIQ was just used for purposes of analysis and is not part of the NMP-Q.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Methods	J.W. Creswell, Qualitative inquiry and research design: Choosing among five traditions , None, Sage (2012)	http://dx.doi.org/10.1016/j.chb.2015.02.059	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/br/b0170>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/ctx/ctx0033>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/itrp/0046	'Through thematic clustering, these horizons were grouped into meaning units (Creswell, 2012[[ refid=''b0170'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Methods	C. Moustakas, Phenomenological research methods , None, Sage (1994)	http://dx.doi.org/10.1016/j.chb.2015.02.059	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/br/b0110>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/ctx/ctx0032>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/itrp/0047	'These transcriptions were analyzed following the phenomenological data analysis steps as described by Moustakas (1994)[[ refid=''b0110'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Methods	S.P. Walsh, K.M. White, R.M. Young, Needing to connect: The effect of self and others on young people’s involvement with their mobile phones , Australian Journal of Psychology , vol. 62 (2010), pp.194-203	http://dx.doi.org/10.1016/j.chb.2015.02.059	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/br/b0160>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/ctx/ctx0039>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/itrp/0049	'The Nomophobia Questionnaire and Mobile Phone Involvement Questionnaire (Walsh et al., 2010[[ refid=''b0160'' ]]) were employed in the present study.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Findings and results	J.C. Nunnally, Psychometric theory , None, McGraw-Hill (1978)	http://dx.doi.org/10.1016/j.chb.2015.02.059	results		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/br/b0115>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/ctx/ctx0052>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/itrp/0058	'They were all above the commonly accepted minimum value of .7 (Nunnally, 1978[[ refid=''b0115'' ]]), suggesting that they demonstrate good internal consistency.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Findings and results	B.G. Tabachnick, L.S. Fidell, Using multivariate statistics , None, Pearson (2013)	http://dx.doi.org/10.1016/j.chb.2015.02.059	results		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/br/b0150>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/ctx/ctx0045>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-02-059/itrp/0077	'As for the adequacy of sampling, the KMO index was .941, which is greater than the minimum acceptable value of .60 (Tabachnick & Fidell, 2013[[ refid=''b0150'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Methodology	A.O. Agho, Discriminant validity of measures of job satisfaction, positive affectivity and negative affectivity , Journal of Occupational and Organizational Psychology , vol. 65 (1992), pp.185-196	http://dx.doi.org/10.1016/j.chb.2015.03.020	methods		http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-03-020/br/b0010	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-03-020/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-03-020/ctx/ctx0070		76	4	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-03-020/itrp/0103	'“Negative Affectivity” was taken from Agho (1992)[[ refid=''b0010'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0130"""" view=""""all"""">Based on the literature survey, for this study items for the six constructs i.e. Technostress creators, Technostress Inhibitors, Job satisfaction, Organizational commitment, Negative Affectivity and Technology-enabled Performance are developed. Items for “Techno Stress Creators”, “Technology Inhibitor”, “Job satisfaction”, “Organizational commitment” were drawn from <ce:cross-ref refid=""""b0260"""" id=""""c0275"""">Ragu-Nathan et al. (2008)[[ refid=''''b0260'''' ]]</ce:cross-ref>. Items for “Technology-enabled Performance” developed to capture the performance that supposed to be most affected by teaching and learning technology in a collaborative environment were taken from <ce:cross-ref refid=""""b0340"""" id=""""c0280"""">Tarafdar et al. (2011)[[ refid=''''b0340'''' ]]</ce:cross-ref>. “Negative Affectivity” was taken from <ce:cross-ref refid=""""b0010"""" id=""""c0285"""">Agho (1992)[[ refid=''''b0010'''' ]]</ce:cross-ref>. The items for all six constructs were modified as appropriate for the context of this study. All items were measured on a five point Likert scale: 1 – strongly disagree to 5 – strongly agree. A sixth option of “Not Applicable” or “I do not know” was also provided to make the responses more flexible.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_method_in	Results	T. Asparouhov, B. Muthén, Exploratory structural equation modeling , Structural Equation Modeling: A Multidisciplinary Journal , vol. 16 (2009), pp.397-438	http://dx.doi.org/10.1016/j.chb.2015.05.037	results		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-05-037/br/b0015>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-05-037/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-05-037/ctx/ctx0086>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-05-037/itrp/0068	'As expected, a two-factor structure emerged from the EFA with ML method using the GEOMIN oblique rotation (Asparouhov & Muthén, 2009[[ refid=''b0015'' ]]).'			FDY+AGA	infered_pred1
cites	Recruitment of participants and data protection	R. Kraut, J. Olson, M. Banaji, A. Bruckman, J. Cohen, M. Couper, Psychological research online: Report of board of scientific affairs’ advisory group on the conduct of research on the internet , The American Psychologist , vol. 59 (2004), pp.105-117	http://dx.doi.org/10.1016/j.chb.2015.07.028	data		http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-07-028/br/b0175	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-07-028/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-07-028/ctx/ctx0046		53	5	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-07-028/itrp/0025	'Therefore, the risk associated with breaches of confidentiality and the possibility that data may be accessed by a third person should be considered by the researcher and the institutional review board when planning research (Kraut et al., 2004[[ refid=''b0175'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0130"""" view=""""all"""">Special care should be taken in balancing the information that will be collected (e.g., the individual’s name, the IP of the computer or device from where the questionnaire is filled out, etc.) with the requirements of the study and the protection of the participants’ identity. Once responses are collected, similar concerns apply to the storage of data, the encryption of responses, and the data backup procedures. While procedures exist for each of these steps (e.g., <ce:cross-ref refid=""""b0175"""" id=""""c0215"""">Kraut et al., 2004[[ refid=''''b0175'''' ]]</ce:cross-ref>), it should be noted that even if good data-management practices are taken, they can lessen but not eliminate the possibility of data leaks. Additionally, even if data are well managed, a breach of confidentiality may occur if it is known that a given individual is participating in a study involving only students with disabilities; more specifically, it will reveal the fact that the person has a disability. Therefore, the risk associated with breaches of confidentiality and the possibility that data may be accessed by a third person should be considered by the researcher and the institutional review board when planning research (<ce:cross-ref refid=""""b0175"""" id=""""c0220"""">Kraut et al., 2004[[ refid=''''b0175'''' ]]</ce:cross-ref>).</ce:para>""''"'	uses_data_from	AGA+ANG	50_classified_citesAsReview_semweb
cites	State-of-the-art	W. Hart-Davidson, M. McLeod, C. Klerkx, M. Wojcik, A method for measuring helpfulness in online peer review , Proceedings of the 28th ACM international conference on design of communication, ACM (2010, September)	http://dx.doi.org/10.1016/j.chb.2015.08.005			http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-08-005/br/bib29	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-08-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-08-005/ctx/ctx0040		51	3	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-08-005/itrp/0021	'Hart-Davidson, McLeod, Klerkx and Wojcik (2010)[[ refid=''bib29'' ]] identify 3 main challenges (1) inadequate workflow and data models for capturing the review activity, (2) lack of quality indicators and measures and (3) building a profile for the assessors.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0205"""" view=""""all"""">One of the cornerstones of building a peer assessment system is proposing the quality measure for the assessments. <ce:cross-ref refid=""""bib29"""" id=""""crosref0305"""">Hart-Davidson, McLeod, Klerkx and Wojcik (2010)[[ refid=''''bib29'''' ]]</ce:cross-ref> identify 3 main challenges (1) inadequate workflow and data models for capturing the review activity, (2) lack of quality indicators and measures and (3) building a profile for the assessors. The authors propose <ce:italic>helpfulness</ce:italic> as the best indicator of a review''''s or assessment''''s quality. To accommodate this indicator, a peer review process should provide the tools for the reviewer to provide their review and the learner and other reviewers to interact with it (either by further suggestions or endorsements).</ce:para>""''"'	uses_data_from	AGA+ANG	50_classified_citesAsReview_semweb
cites	Introduction	M. Lima, M.J. Koehler, R.J. Spiro, Organizational learning with a multi-perspective hypertextual interface for knowledge management , Paper presented at the 5th International Symposium on Knowledge Management, Brazil (2002)	http://dx.doi.org/10.1016/j.chb.2015.08.054	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-08-054/br/bib26	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-08-054/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-08-054/ctx/ctx0023		63	4	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-08-054/itrp/0004	'However, in networked hypermedia environments that particularly emphasize the multiperspectivity of a knowledge domain, namely in MHEs (cf. Lima et al., 2002[[ refid=''bib26'' ]]), it might not be sufficient to review task-relevant content in one systematic sequence because MHEs are not primarily designed to convey isolated factual knowledge in a specific order.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0060"""" view=""""all"""">Thus, navigational behaviors such as focusing on task-relevant pages and choosing a coherent or linear navigational path seem to be most effective for learning in (hierarchical and networked) hypermedia environments. However, in networked hypermedia environments that particularly emphasize the multiperspectivity of a knowledge domain, namely in MHEs (cf. <ce:cross-ref refid=""""bib26"""" id=""""crosref0145"""">Lima et al., 2002[[ refid=''''bib26'''' ]]</ce:cross-ref>), it might not be sufficient to review task-relevant content in one systematic sequence because MHEs are not primarily designed to convey isolated factual knowledge in a specific order. Rather, they aim to convey broad conceptual knowledge about a topic, that is, an overview and understanding about how different information elements are related to each other from different conceptual perspectives (e.g., <ce:cross-ref refid=""""bib14"""" id=""""crosref0150"""">Jacobson &amp; Spiro, 1995[[ refid=''''bib14'''' ]]</ce:cross-ref>). For this reason, usually two types of navigational choices can be distinguished in MHEs; namely, the processing of perspectives and the processing of isolated content. More precisely, on the one hand, the processing of perspectives implies the selection of conceptual overview pages that allow the comparison of different information elements within a certain perspective (perspective processing). On the other hand, the processing of content implies the selection of a specific content page (e.g., a text or video) without taking the context (i.e., the constellations shown on the overview pages, which allow the comparison of different information elements within a certain perspective) into account (content processing). In the context of MHEs, perspective processing should arguably be more effective than content processing for acquiring conceptual knowledge as learners who process the different perspectives learn how different information elements are related. Moreover, these learners can also capture specific information about several content units at the same time. Learners who separately process content elements (content processing), by contrast, only learn isolated information about one single content element at a time. Furthermore, these learners do not get an impression about how this content element is related to other content elements. Thus, content processing should be less effective than perspective processing. Still, content processing is not considered to be ineffective as it should not hamper learning. It is only considered to be not particularly effective as this navigational behavior does not tap the full potential of an MHE (i.e., acquiring conceptual overview knowledge).</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Introduction	D. DeStefano, J.-A. LeFevre, Cognitive load in hypertext reading: a review , Computers in Human Behavior , vol. 23 (2007), pp.1616-1641	http://dx.doi.org/10.1016/j.chb.2015.08.054	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-08-054/br/bib7	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-08-054/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-08-054/ctx/ctx0011		63	4	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-08-054/itrp/0087	'Generally, one can differentiate between two types of hypermedia structures: hierarchical and networked (DeStefano & LeFevre, 2007[[ refid=''bib7'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0045"""" view=""""all"""">Hypermedia environments are information systems containing multiple information nodes that are interconnected in a nonlinear fashion. Moreover, the information is displayed in different representational formats such as text, pictures, or videos (<ce:cross-ref refid=""""bib39"""" id=""""crosref0090"""">Scheiter &amp; Gerjets, 2007[[ refid=''''bib39'''' ]]</ce:cross-ref>). Navigating the nonlinear structure of hypermedia environments involves a high degree of learner control because not only can learners choose what information to access, but they can also decide the order and the format they prefer to process it in (e.g., as text or video; cf. <ce:cross-ref refid=""""bib11"""" id=""""crosref0095"""">Gerjets, Scheiter, Opfermann, Hesse, &amp; Eysink, 2009[[ refid=''''bib11'''' ]]</ce:cross-ref>). Generally, one can differentiate between two types of hypermedia structures: hierarchical and networked (<ce:cross-ref refid=""""bib7"""" id=""""crosref0100"""">DeStefano &amp; LeFevre, 2007[[ refid=''''bib7'''' ]]</ce:cross-ref>). In hierarchical hypermedia environments, the interconnections between information nodes can be described as a tree structure with broader topics at higher levels and subordinate topics at lower levels. Networked hypermedia environments, by contrast, have a nonsequential structure that is characterized by associative links relating semantically similar information in the environment. According to the framework of cognitive flexibility theory (<ce:cross-refs refid=""""bib14 bib41"""" id=""""crosrefs0015"""">Jacobson &amp; Spiro, 1995; Spiro &amp; Jehng, 1990[[ refid=''''bib14 bib41'''' ]]</ce:cross-refs>), networked hypermedia environments are ideal for displaying multifaceted knowledge domains that present the same content materials in a variety of different contexts. If these networked hypermedia environments are designed in a way that allows learners to simultaneously consider multiple viewpoints, they can also be referred to as multiperspective hypermedia environments (MHEs; cf. <ce:cross-ref refid=""""bib26"""" id=""""crosref0105"""">Lima et al., 2002[[ refid=''''bib26'''' ]]</ce:cross-ref>). As an example of an MHE, <ce:cross-ref refid=""""bib14"""" id=""""crosref0110"""">Jacobson and Spiro (1995)[[ refid=''''bib14'''' ]]</ce:cross-ref> asked learners to consider the impact of technology on 20<ce:sup loc=""""post"""">th</ce:sup>-century society and culture from multiple perspectives such as progress-problems, freedom-control, or technological efficiency. The content materials were displayed in a multiperspective hypermedia structure, thus making it easier for learners to consider them from different conceptual perspectives.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites	Introduction: social networks, social commerce and Facebook commerce	None Catvertiser, Demographic report: Facebook users in Europe , None (2014) , https://www.catvertiser.com/blog/demographic-report-facebook-users-in-europe/	http://dx.doi.org/10.1016/j.chb.2015.10.022	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-10-022/br/bib7	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-10-022/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-10-022/ctx/ctx0003		65	6	http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-10-022/itrp/0048	'According to the consultancy firm Catvertiser (2014)[[ refid=''bib7'' ]], Facebook population of Europe is almost 300 million.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0035"""" view=""""all"""">The emergence of social networks and the Web 2.0 in the information age has wrought one of the deepest social revolutions of the XXI century. Millions of users are engaged in the social network phenomenon every day, all over the world. The consultancy company <ce:cross-ref refid=""""bib101"""" id=""""crosref0030"""">Strategy Analytics (2015)[[ refid=''''bib101'''' ]]</ce:cross-ref> forecasts a sustained growth over the next five-year period that will exceed two million users in 2016 and will increase business opportunities for this new sales channel. According to the ‘<ce:cross-ref refid=""""bib99"""" id=""""crosref0035"""">Social, Digital &amp; Mobile in Europe in 2014[[ refid=''''bib99'''' ]]</ce:cross-ref>’ report, there are 293 million active social networks users, amounting to approximately 40% of the total population. This average is largely exceeded in Spain, a social country by nature, where it reaches 66% of the population. Among the Europeans, Spaniards also stand out for their activity on the Web 2.0 with an average of 66%, which means that only 6% of the Spanish Internet users are not present on any social network in the country. Spanish users dedicate no less than one hour and a half per day to this activity, Facebook being the predominating social network, with 87% of users having an account on this platform, followed by Google and Twitter with a quite similar percentage (57% and 54% respectively). According to the consultancy firm <ce:cross-ref refid=""""bib7"""" id=""""crosref0040"""">Catvertiser (2014)[[ refid=''''bib7'''' ]]</ce:cross-ref>, Facebook population of Europe is almost 300 million. Combining it with the fact that, on average, 35% of European citizens have their accounts on Facebook, it sounds really impressive. There are 7 countries in Europe where the population of Facebook users exceeds 10 million: Turkey (38 million), United Kingdom (36 million), France (30 million), Germany (28 million), Italy (26 million), Spain (20 million) and Poland (12 million).</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
uses_method_in	Method	E.D. Diener, R.A. Emmons, R.J. Larsen, S. Griffin, The satisfaction with life scale , Journal of personality assessment , vol. 49 (1985), pp.71-75	http://dx.doi.org/10.1016/j.chb.2015.11.032	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-11-032/br/bib7>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-11-032/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-11-032/ctx/ctx0027>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-11-032/itrp/0006	'Well-being has been evaluated using the Satisfaction With Life Scale (Diener, Emmons, Larsen, & Griffin, 1985[[ refid=''bib7'' ]]).'			FDY+AGA	infered_pred1
uses_method_in	Method	S. Cohen, T. Kamarck, R. Mermelstein, A global measure of perceived stress , Journal of health and social behavior (1983)	http://dx.doi.org/10.1016/j.chb.2015.12.045	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/br/bib11>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/ctx/ctx0022>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/itrp/0001	'The PSS, developed by (Cohen, Kamarck, & Mermelstein, 1983[[ refid=''bib11'' ]]), measures the perception of stress, i.e., the degree to which situations are appraised as stressful, by asking respondents to rate the frequency of their thoughts and feelings related to situations occurred in the last month (Cronbach''s alpha coefficient = .79).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method	M. Kwon, D.-J. Kim, H. Cho, S. Yang, The smartphone addiction scale: development and validation of a short version for adolescents , PloS one , vol. 8 (2013), pp.e83558	http://dx.doi.org/10.1016/j.chb.2015.12.045	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/br/bib30>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/ctx/ctx0020>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/itrp/0007	'We employed the SAS-SV in this study for its strong internal consistency, for which Cronbach''s alpha coefficient was .91 (Kwon et al., 2013a[[ refid=''bib30'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Discussion	K.S. Young, Internet addiction: the emergence of a new clinical disorder , CyberPsychology & Behavior , vol. 1 (1998), pp.237-244	http://dx.doi.org/10.1016/j.chb.2015.12.045	discussion		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/br/bib52>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/ctx/ctx0033>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/itrp/0054	'Furthermore, while many studies in the field used Kimberly Young''s Internet Addiction Test (Young, 1998[[ refid=''bib52'' ]]), in our study we employed the Smartphone Addiction Test – Short Version.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Method	M. Kwon, D.-J. Kim, H. Cho, S. Yang, The smartphone addiction scale: development and validation of a short version for adolescents , PloS one , vol. 8 (2013), pp.e83558	http://dx.doi.org/10.1016/j.chb.2015.12.045	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/br/bib30>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/ctx/ctx0018>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-045/itrp/0060	'The SAS-SV, developed by (Kwon, Kim, Cho, & Yang, 2013a[[ refid=''bib30'' ]])), looks at smartphone usage to identify the level of risk for smartphone addiction, but does not diagnose addiction.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Results	I.R. Mull, S. Lee, “PIN” pointing the motivational dimensions behind Pinterest , Computers in Human Behavior , vol. 33 (2014), pp.192-200	http://dx.doi.org/10.1016/j.chb.2015.12.059	results		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-059/br/bib29>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-059/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-059/ctx/ctx0044>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2015-12-059/itrp/0083	'Mull and Lee (2014)[[ refid=''bib29'' ]] found that “creative projects” were one of the reasons people use Pinterest – however, only for searching for and sharing the ideas for a do-it-yourself project.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Introduction	J.S. Lemmens, P.M. Valkenburg, D.A. Gentile, The internet gaming disorder scale , Psychological Assessment , vol. 72 (2015), pp.567-582 , http://dx.doi.org/10.1037/pas0000062	http://dx.doi.org/10.1016/j.chb.2016.03.038	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/br/bib35>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/ctx/ctx0021>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/itrp/0018	'Because of the important advantages of a short and easy to administer measurement instrument, such as the possibility to incorporate the scale into space-limited surveys, and in agreement with the findings by Lemmens et al. (2015)[[ refid=''bib35'' ]], the ultimate aim of the present study was to develop and validate a short 9-item scale to measure SMD.'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
uses_method_in	Method	M. Rosenberg, C. Schooler, C. Schoenbach, Self-esteem and adolescent problems: modeling reciprocal effects , American sociological review (1989)	http://dx.doi.org/10.1016/j.chb.2016.03.038	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/br/bib50>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/ctx/ctx0026>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/itrp/0019	'The degree of self-esteem was measured using the six-item self-esteem scale (Rosenberg, Schooler, & Schoenbach, 1989[[ refid=''bib50'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method	G.J. Meerkerk, R.J.J.M. Van den Eijnden, A.A. Vermulst, H.F. Garretsen, The compulsive Internet use scale (CIUS): some psychometric properties , CyberPsychology & Behavior , vol. 12 (2009), pp.1-6	http://dx.doi.org/10.1016/j.chb.2016.03.038	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/br/bib42>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/ctx/ctx0025>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/itrp/0024	'Compulsive Internet use was assessed in the first sample using the 14-item Compulsive Internet Use Scale (Meerkerk et al., 2009[[ refid=''bib42'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method	T. Asparouhov, B. Muthén, Exploratory structural equation modeling , Structural Equation Modeling: A Multidisciplinary Journal , vol. 16 (2009), pp.397-438	http://dx.doi.org/10.1016/j.chb.2016.03.038	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/br/bib3>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/ctx/ctx0032>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-03-038/itrp/0066	'We used structural equation modeling (SEM) with weighted least squares estimators to test these second-order factor models using CFA in MPlus (Asparouhov & Muthén, 2009[[ refid=''bib3'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Results and discussion	N. Smith, D. Read, S. López-Rodríguez, Consumer perceptions of corporate social responsibility: The CSR Halo Effect , SSRN Electronic Journal (2010)	http://dx.doi.org/10.1016/j.chb.2016.11.009	results	discussion	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/br/bib42>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/ctx/ctx0089>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/itrp/0056	'The Halo Effect can wield a powerful influence on the impressions we form of others (Smith et al., 2010[[ refid=''bib42'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Literature review	D. Scott, The new rules of marketing and PR: How to use social media, online video, mobile applications, blogs, news releases and viral marketing to reach buyers direct , None, Wiley (2011)	http://dx.doi.org/10.1016/j.chb.2016.11.009			<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/br/bib38>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/ctx/ctx0020>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/itrp/0059	'This is due to images being broadcasted to every follower who could, potentially, re-post the images on their own pages, thus expanding the visibility to an even wider audience (Scott, 2011[[ refid=''bib38'' ]]).'		<http://purl.org/spar/cito/extends>		top100compsc
cites	Literature review	Y. Chen, S. Fay, Q. Wang, The role of marketing in social media: How online consumer reviews evolve , Journal of Interactive Marketing , vol. 25 (2011), pp.85-94	http://dx.doi.org/10.1016/j.chb.2016.11.009			<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/br/bib8>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/ctx/ctx0021>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/itrp/0060	'Studies on social media advertising and online advertising also state that consumers'' attitudes towards social media advertising is an essential determinant of its effectiveness (Chen, Fay, & Wang, 2011[[ refid=''bib8'' ]]).'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites	Literature review	M. Cheung, C. Luo, C. Sia, H. Chen, Credibility of electronic word-of-mouth: Informational and normative determinants of on-line consumer recommendations , International Journal of Electronic Commerce , vol. 13 (2009), pp.9-38	http://dx.doi.org/10.1016/j.chb.2016.11.009			<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/br/bib10>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/ctx/ctx0057>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/itrp/0069	'Where the endorsed products are perceived as false and invalid, consumers develop a negative attitude towards the brand and also the celebrity endorser (Cheung, Luo, Sia, & Chen, 2009[[ refid=''bib10'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Research methods	M. Easterby-Smith, R. Thorpe, P. Jackson, Management and business research , None, SAGE edge (2015)	http://dx.doi.org/10.1016/j.chb.2016.11.009	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/br/bib14>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/ctx/ctx0068>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-009/itrp/0106	'Such sampling technique provides good sources of data in exploratory research (Easterby-Smith, Thorpe, & Jackson, 2015[[ refid=''bib14'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites_as_review	Methods	None GfK. KnowledgePanel, KnowledgePanel design summary , None (2013) , http://www.webcitation.org/6ajEWO5mb	http://dx.doi.org/10.1016/j.chb.2016.11.013	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/br/bib17>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/ctx/ctx0022>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/itrp/0001	'This GfK''s sampling strategy is a statistically valid method for surveying and analyzing health indicators from a nationally representative sample (GfK KnowledgePanel[[ refid=''bib17'' ]]®, 2013).'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites	Methods	D. Cella, W. Riley, A. Stone, N. Rothrock, B. Reeve, S. Yount, R. Hays, The patient-reported outcomes measurement information system (PROMIS) developed and tested its first wave of adult self-reported health outcome item banks: 2005-2008 , Journal of Clinical Epidemiology , vol. 63 (2010), pp.1179-1194	http://dx.doi.org/10.1016/j.chb.2016.11.013	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/br/bib9>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/ctx/ctx0023>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/itrp/0002	'PROMIS is a National Institutes of Health Roadmap initiative whose aim is to provide precise, valid, reliable, and standardized questionnaires measuring patient–reported outcomes across the domains of physical, mental, and social health (Cella et al., 2010[[ refid=''bib9'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Methods	None American Psychiatric Association, LEVEL 2—depression—adult (PROMIS emotional distress—depression—short form) , None (2013) , http://www.webcitation.org/6eVeBFb6E	http://dx.doi.org/10.1016/j.chb.2016.11.013	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/br/bib1>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/ctx/ctx0026>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/itrp/0005	'We then classified a “severe” group based on both the distribution of the data and the clinical cut-off for depression recommended by the American Psychiatry Association (APA) (American Psychiatric Association, 2013[[ refid=''bib1'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Methods	P.A. Pilkonis, S.W. Choi, S.P. Reise, A.M. Stover, W.T. Riley, D. Cella, Item banks for measuring emotional distress from the patient-reported outcomes measurement information System (PROMIS®): Depression, anxiety, and anger , Assessment , vol. 18 (2011), pp.263-283	http://dx.doi.org/10.1016/j.chb.2016.11.013	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/br/bib39>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/ctx/ctx0028>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/itrp/0009	'We assessed anxiety symptoms using the 4-item PROMIS anxiety scale (Pilkonis et al., 2011[[ refid=''bib39'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Methods	K.L. Johnston, S.M. Lawrence, N.E. Dodds, L. Yu, D.C. Daley, P.A. Pilkonis, Evaluating PROMIS® instruments and methods for patient-centered outcomes research: Patient and provider voices in a substance use treatment setting , Quality of Life Research , vol. 25 (2016), pp.615-624	http://dx.doi.org/10.1016/j.chb.2016.11.013	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/br/bib18>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/ctx/ctx0031>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-11-013/itrp/0044	'We then classified a severe group with a raw score of 9 or more (out of 20), which corresponds to a T-score of 57.7 (Johnston et al., 2016[[ refid=''bib18'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites_as_review	The promise of motivation through gamification	K. Seaborn, D.I. Fels, Gamification in theory and action: A survey , International Journal of Human-Computer Studies , vol. 74 (2015), pp.14-31	http://dx.doi.org/10.1016/j.chb.2016.12.033	motivation		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/br/bib64>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/ctx/ctx0009>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/itrp/0003	'Additionally, there is a lack of theoretical foundation to explain these motivational effects (Seaborn & Fels, 2015[[ refid=''bib64'' ]]); this means that the question how gamification motivates has not been addressed sufficiently until now.'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites	Outlook	K. Werbach, (Re)defining gamification: A process approach , Persuasive technology, Springer , vol. Vol. 8462 (2014), pp.266-272	http://dx.doi.org/10.1016/j.chb.2016.12.033	conclusion		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/br/bib72>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/ctx/ctx0097>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/itrp/0035	'In other words, the whole process of implementing gamification plays a crucial role, as emphasized by Werbach (2014)[[ refid=''bib72'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	A simulation study on the effects of different game design element groups	R.M. Ryan, V. Mims, R. Koestner, Relation of reward contingency and interpersonal context to intrinsic motivation: A review and test using cognitive evaluation theory , Journal of Personality and Social Psychology , vol. 45 (1983), pp.736-750	http://dx.doi.org/10.1016/j.chb.2016.12.033	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/br/bib59>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/ctx/ctx0085>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/itrp/0069	'Inspired by the intrinsic motivation inventory (cf. Ryan, Mims, & Koestner, 1983[[ refid=''bib59'' ]]), we included scales to assess psychological need satisfaction in the areas of competence, autonomy in regard to freedom of decision, autonomy in regard to task meaningfulness, and social relatedness.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	A simulation study on the effects of different game design element groups	E.J. Pedhazur, L.P. Schmelkin, Measurement, design, and analysis: An integrated approach , None, Lawrence Erlbaum Associates (1991)	http://dx.doi.org/10.1016/j.chb.2016.12.033	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/br/bib46>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/ctx/ctx0086>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/itrp/0070	'So to ensure that participants were actually aware of all game design elements relevant to the corresponding condition, we conducted a treatment check (or manipulation check, Pedhazur & Schmelkin, 1991[[ refid=''bib46'' ]]) for each element.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Gamification	Deterding, S., Dixon, D., Khaled, R., & Nacke, L. (2011). From Game Design Elements to Gamefulness: Defining “Gamification”. Paper presented at the 15th International Academic MindTrek Conference, Tampere.	http://dx.doi.org/10.1016/j.chb.2016.12.033			<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/br/bib18>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/ctx/ctx0022>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/itrp/0078	'The only context excluded by definition is the use of game design elements either within the games themselves or in the game design process (Deterding, Dixon, et al., 2011[[ refid=''bib18'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Matching psychological needs to game design elements	C.S. Rigby, R.M. Ryan, Glued to games: How video games draw us in and hold us spellbound , None, Praeger (2011)	http://dx.doi.org/10.1016/j.chb.2016.12.033			<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/br/bib54>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/ctx/ctx0074>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/itrp/0131	'Badges and leaderboards assess a series of player actions and in doing so provide cumulative feedback (cf. Rigby & Ryan, 2011[[ refid=''bib54'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Gamification	Deterding, S., Dixon, D., Khaled, R., & Nacke, L. (2011). From Game Design Elements to Gamefulness: Defining “Gamification”. Paper presented at the 15th International Academic MindTrek Conference, Tampere.	http://dx.doi.org/10.1016/j.chb.2016.12.033			<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/br/bib18>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/ctx/ctx0018>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2016-12-033/itrp/0164	'(2)The term elements allows us to distinguish gamification from serious games (Deterding, Dixon, et al., 2011[[ refid=''bib18'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Study 6	K.J. Preacher, M.J. Zyphur, Z. Zhang, A general multilevel SEM framework for assessing multilevel mediation , Psychological Methods , vol. 15 (2010), pp.209-233	http://dx.doi.org/10.1016/j.chb.2018.04.023			<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2018-04-023/br/bib59>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2018-04-023/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2018-04-023/ctx/ctx0070>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2018-04-023/itrp/0110	'To assess mediation, we used a procedure recommended by Preacher, Zyphur, and Zhang (2010)[[ refid=''bib59'' ]] for testing mediation in a multilevel data structure.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Study 6	N. Bolger, J.P. Laurenceau, Intensive longitudinal methods: An introduction to diary and experience sampling research , None, Guilford (2013)	http://dx.doi.org/10.1016/j.chb.2018.04.023			<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2018-04-023/br/bib20>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2018-04-023/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2018-04-023/ctx/ctx0069>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2018-04-023/itrp/0126	'Third, as advocated by Bolger and Laurenceau (2013)[[ refid=''bib20'' ]], to account for potential confounding between the within-person and the between-person levels of analysis, we included between-person averages (e.g., the average sexual desire aggregated across all 42-diary days) for all of the primary variables.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites_as_review	Study 6	H.T. Reis, S.L. Gable, Event-sampling and other methods for studying everyday experience , Handbook of research methods in social and personality psychology, Cambridge University Press (2000)	http://dx.doi.org/10.1016/j.chb.2018.04.023			<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2018-04-023/br/bib63>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2018-04-023/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-chb-2018-04-023/ctx/ctx0061>				http://www.scar.disi.unibo.it/r/10-1016-j-chb-2018-04-023/itrp/0135	'However, it did not use dyadic data and was cross-sectional in nature, and thus ignored interdependence between partners as well as cognitive and motivational biases that may affect global survey responses (e.g., motivated construal, sentiment override; Reis & Gable, 2000[[ refid=''bib63'' ]]).'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites	Introduction	L.W. Bassett, K. Conner, The Abnormal Mammogram , None, Holland-Frei Cancer Medicine (2003)	http://dx.doi.org/10.1016/j.cmpb.2015.10.017	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2015-10-017/br/bib0015	http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2015-10-017/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2015-10-017/ctx/ctx0006		50	4	http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2015-10-017/itrp/0037	'Typical examples of benign circumscribed masses are cysts and fibroadenomas [3][[ refid=''bib0015'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0025"""" view=""""all"""">The margins can be described as circumscribed, microlobulated, obscured (partially hidden by adjacent tissue), indistinct (ill-defined), or spiculated (characterized by lines radiating from the mass). Typical examples of benign circumscribed masses are cysts and fibroadenomas <ce:cross-ref id=""""crf0050"""" refid=""""bib0015"""">[3][[ refid=''''bib0015'''' ]]</ce:cross-ref>. <ce:cross-ref id=""""crf0055"""" refid=""""fig0005"""">Fig. 1</ce:cross-ref><ce:float-anchor refid=""""fig0005""""/> shows different masses according to their shapes and margins. Usually, the malignant mass will appear whiter than any tissue surrounding it. According to Basset et al., masses with irregular shapes and indistinct or spiculated margins have a higher likelihood of malignancy. Nonetheless, a small number of cancers may exhibit a round shape and relatively circumscribed margins <ce:cross-ref id=""""crf0060"""" refid=""""bib0015"""">[3][[ refid=''''bib0015'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
uses_method_in	Results	Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, Caffe: convolutional architecture for fast feature embedding , None (2014)	http://dx.doi.org/10.1016/j.cmpb.2016.09.018	results		<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2016-09-018/br/bib0235>	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2016-09-018/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2016-09-018/ctx/ctx0035>				http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2016-09-018/itrp/0037	'We used the Caffe deep learning toolkit [46][[ refid=''bib0235'' ]] in order to efficiently use the processing power of the Tesla graphics card for computation of convolutional neural network parameters.'			FDY+AGA	infered_pred1
uses_method_in	Experimental results	A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks , Advances in Neural Information Processing Systems 25, Curran Associates, Inc. (2012)	http://dx.doi.org/10.1016/j.cmpb.2017.06.016	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/br/bib0030>	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/ctx/ctx0071>				http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/itrp/0053	'We’ve made an experiment on the AlexNet [30][[ refid=''bib0030'' ]].'			FDY+AGA	infered_pred1
cites_as_review	Introduction	Y. Bengio, A. Courville, P. Vincent, Representation learning: a review and new perspectives , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 35 (2013), pp.1798-1828	http://dx.doi.org/10.1016/j.cmpb.2017.06.016	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/br/bib0028>	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/ctx/ctx0014>				http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/itrp/0106	'As introduced in [28][[ refid=''bib0028'' ]], deep learning methods are able to model higher-level abstractions from data by multiple layers.'			FDY+AGA	infered_pred1
uses_method_in	Methodology	R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, S. Ssstrunk, Slic superpixels compared to state-of-the-art superpixel methods , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 34 (2012), pp.2274-2282	http://dx.doi.org/10.1016/j.cmpb.2017.06.016	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/br/bib0045>	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/ctx/ctx0044>				http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/itrp/0107	'Given a training image, we apply Simple Linear Iterative Clustering (SLIC) [45][[ refid=''bib0045'' ]] to the green channel of the fundus image.'			FDY+AGA	infered_pred1
uses_method_in	Experimental results	Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, T. Darrell, Caffe: convolutional architecture for fast feature embedding, (2014), arXiv preprint 	http://dx.doi.org/10.1016/j.cmpb.2017.06.016	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/br/bib0053>	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/ctx/ctx0075>				http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2017-06-016/itrp/0117	'Both nets are implemented using Python and Caffe [53][[ refid=''bib0053'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Results: illustrative applications	Y. Hu, E. Gibson, L.-L. Lee, W. Xie, D.C. Barratt, T. Vercauteren, J.A. Noble, Freehand ultrasound image simulation with spatially-conditioned generative adversarial networks , Proceedings of MICCAI Workshop on Reconstruction and Analysis of Moving Body Organs (RAMBO) (2017)	http://dx.doi.org/10.1016/j.cmpb.2018.01.025	motivation	results	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2018-01-025/br/bib0026>	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2018-01-025/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2018-01-025/ctx/ctx0030>				http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2018-01-025/itrp/0047	'The network was originally trained outside of the NiftyNet platform as described in [26][[ refid=''bib0026'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	NiftyNet: a platform for deep learning in medical imaging	D. Mané, et al., TensorBoard: TensorFlow’s visualization toolkit, 2015,	http://dx.doi.org/10.1016/j.cmpb.2018.01.025			<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2018-01-025/br/bib0037>	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2018-01-025/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2018-01-025/ctx/ctx0017>				http://www.scar.disi.unibo.it/r/10-1016-j-cmpb-2018-01-025/itrp/0064	'This also enables automatic support for visualization of the network graph as a hierarchy at different levels of detail using the TensorBoard visualizer [37][[ refid=''bib0037'' ]] as shown in Fig. 3.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites_as_review	Classification	V. Chandola, A. Banerjee, V. Kumar, Anomaly detection: a survey , ACM Comput. Surv. , vol. 41 (2009), pp.15:1-15:58	http://dx.doi.org/10.1016/j.comcom.2014.01.012			<http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2014-01-012/br/b0195>	<http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2014-01-012/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2014-01-012/ctx/ctx0028>				http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2014-01-012/itrp/0132	'Chandola et al. [39][[ refid=''b0195'' ]] provide a comprehensive survey of anomaly based intrusion detection that is general to all applications.'			FDY+AGA	infered_pred1
cites	Research works	T. Wu, S. Member, F.A.N. Wu, S. Member, An autonomous wireless body area network implementation towards IoT connected healthcare applications , Access, IEEE , vol. 5 (2017), pp.11413-11422	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0031	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0022		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0001	'Wearable devices with solar-energy harvesting were presented to ease the implementation of an autonomous wireless body area network (WBAN) [31][[ refid=''bib0031'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">The IoT and wearable monitoring system is an emerging technology that is expected to contribute a wide range of healthcare applications in the future <ce:cross-refs id=""""crf0030"""" refid=""""bib0002 bib0003 bib0009 bib0020 bib0021"""">[2,3,9,20,21][[ refid=''''bib0002 bib0003 bib0009 bib0020 bib0021'''' ]]</ce:cross-refs>. A system to capture physiological data of a person under care using IoT sensors was presented by Chiang and Liang <ce:cross-ref id=""""crf0035"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>. This system combined a context-aware space with IoT technology to automate healthcare services and assist chronic patients. The main problem with their method is that when the chronic patient risk factors increase, the system is unable to find the correct risk value. In addition, a classic ontology approach is not useful in supporting a fuzzy logic–based system during information extraction from an uncertain patient disease history and unknown risk factors. The Mamdani inference method is used for heart disease diagnosis <ce:cross-ref id=""""crf0036"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>. This system has 13 input features and one output feature in order to find the presence of heart disease in a patient. However, the existing system needs semantic knowledge that is specific to each disease. An analysis of heart rate variability signals is computed using fuzzy measure entropy (FuzzyMEn) <ce:cross-ref id=""""crf0037"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. The system overcomes the poor statistical stability of two entropy measures, which are based on the Heaviside step function of the classical sets. This system used fuzzy logic instead of Heaviside, and achieved better results than approximate entropy (ApEn) and sample entropy (SampEn). Kumar and Kaur used a fuzzy expert system to detect heart disease in patients <ce:cross-ref id=""""crf0038"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>. This system contains six input fields (blood pressure, cholesterol, chest pain type, maximum heart rate, blood sugar, and old peak) and two output fields (heart disease and precautions). However, this system is insufficient in terms of factors and semantic relationships amongst the patient''''s medical data. A computational intelligence model based on fuzzy logic was proposed to handle ambiguity and vagueness in clinical knowledge and data <ce:cross-ref id=""""crf0039"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. This method overcomes the interpretation problem of the common monitoring system called a cardiotocograph (CTG), which is based on a fetal heart rate pattern and maternal contraction. A fuzzy logic–based method for fault-tolerant wireless sensor networks was proposed to monitor diagnosis and testing systems in a large-scale context <ce:cross-ref id=""""crf0040"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>. However, a large storage space in the IoT is used when small movement is detected by a sensor. The mentioned method extracts limited information because of limited semantic knowledge. A single ontology is insufficient to tolerate the IoT''''s faults. It is important to make multiple ontologies for diagnosis and testing, which can provide intelligent knowledge to retrieve precise data for fault-tolerance problems in the IoT. A fuzzy approach was used in an IoT-based healthcare monitoring system to find abnormal conditions in a patient <ce:cross-ref id=""""crf0041"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>. This system helps a physician to select the affected parameters and avoids unnecessary information transmission to the physician. A fuzzy logic and thermistor sensor–based approach was proposed for monitoring and early detection of residential fire <ce:cross-ref id=""""crf0042"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. This proposed system uses two fuzzy methods with temporal characteristics to monitor and determine confidence about the presence of fire in order to decrease and improve the number of rules that are employed to make correct decisions. A model driven approach was presented to design and develop smart IoT-based system <ce:cross-ref id=""""crf0043"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref>. A set of design pattern is defined in this method to syndicate cognitive and autonomic principals for providing a precise solution according to the system needs. A fuzzy prolog and ontology-based framework was proposed to detect health anomalies in real-time using IoT devices <ce:cross-ref id=""""crf0044"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. This existing ontology gives hints about diseases that are currently going on. However, simple ontology may not be able to handle real-time sensor''''s data for having a complete detail of a patient. Wearable devices with solar-energy harvesting were presented to ease the implementation of an autonomous wireless body area network (WBAN) <ce:cross-ref id=""""crf0045"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>. Different sensors are employed on various positions of the body to measure the heartbeat, temperature, and to detect falls. The data from sensors and fall notification is shown through web-based smart phone application. Systems based on wearable healthcare devices were reviewed both in commercial efforts and scientific papers <ce:cross-refs id=""""crf0046"""" refid=""""bib0032 bib0033 bib0034"""">[32–34][[ refid=''''bib0032 bib0033 bib0034'''' ]]</ce:cross-refs>. This review determined the design architecture of IoT in the medical field, including software and hardware dealing with sensors, medical application, and smart phones for diagnosis. A gateway between sensor network and the Internet in IoT-based healthcare system was proposed to translate the protocols used in sensor network and the Internet <ce:cross-ref id=""""crf0048"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref>. This gateway contains control knowledge for both the sensor network and the data transmitted through the Internet in healthcare IoT system.</ce:para>""''"'	cites	FDY	
cites	Research works	E. Mezghani, E. Exposito, K. Drira, A model-driven methodology for the design of autonomic and cognitive IoT-based systems : application to healthcare , IEEE Trans. Emerging Topics Comput. Intell. , vol. 1 (2017), pp.224-234	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0029	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0020		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0005	'A model driven approach was presented to design and develop smart IoT-based system [29][[ refid=''bib0029'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">The IoT and wearable monitoring system is an emerging technology that is expected to contribute a wide range of healthcare applications in the future <ce:cross-refs id=""""crf0030"""" refid=""""bib0002 bib0003 bib0009 bib0020 bib0021"""">[2,3,9,20,21][[ refid=''''bib0002 bib0003 bib0009 bib0020 bib0021'''' ]]</ce:cross-refs>. A system to capture physiological data of a person under care using IoT sensors was presented by Chiang and Liang <ce:cross-ref id=""""crf0035"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>. This system combined a context-aware space with IoT technology to automate healthcare services and assist chronic patients. The main problem with their method is that when the chronic patient risk factors increase, the system is unable to find the correct risk value. In addition, a classic ontology approach is not useful in supporting a fuzzy logic–based system during information extraction from an uncertain patient disease history and unknown risk factors. The Mamdani inference method is used for heart disease diagnosis <ce:cross-ref id=""""crf0036"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>. This system has 13 input features and one output feature in order to find the presence of heart disease in a patient. However, the existing system needs semantic knowledge that is specific to each disease. An analysis of heart rate variability signals is computed using fuzzy measure entropy (FuzzyMEn) <ce:cross-ref id=""""crf0037"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. The system overcomes the poor statistical stability of two entropy measures, which are based on the Heaviside step function of the classical sets. This system used fuzzy logic instead of Heaviside, and achieved better results than approximate entropy (ApEn) and sample entropy (SampEn). Kumar and Kaur used a fuzzy expert system to detect heart disease in patients <ce:cross-ref id=""""crf0038"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>. This system contains six input fields (blood pressure, cholesterol, chest pain type, maximum heart rate, blood sugar, and old peak) and two output fields (heart disease and precautions). However, this system is insufficient in terms of factors and semantic relationships amongst the patient''''s medical data. A computational intelligence model based on fuzzy logic was proposed to handle ambiguity and vagueness in clinical knowledge and data <ce:cross-ref id=""""crf0039"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. This method overcomes the interpretation problem of the common monitoring system called a cardiotocograph (CTG), which is based on a fetal heart rate pattern and maternal contraction. A fuzzy logic–based method for fault-tolerant wireless sensor networks was proposed to monitor diagnosis and testing systems in a large-scale context <ce:cross-ref id=""""crf0040"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>. However, a large storage space in the IoT is used when small movement is detected by a sensor. The mentioned method extracts limited information because of limited semantic knowledge. A single ontology is insufficient to tolerate the IoT''''s faults. It is important to make multiple ontologies for diagnosis and testing, which can provide intelligent knowledge to retrieve precise data for fault-tolerance problems in the IoT. A fuzzy approach was used in an IoT-based healthcare monitoring system to find abnormal conditions in a patient <ce:cross-ref id=""""crf0041"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>. This system helps a physician to select the affected parameters and avoids unnecessary information transmission to the physician. A fuzzy logic and thermistor sensor–based approach was proposed for monitoring and early detection of residential fire <ce:cross-ref id=""""crf0042"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. This proposed system uses two fuzzy methods with temporal characteristics to monitor and determine confidence about the presence of fire in order to decrease and improve the number of rules that are employed to make correct decisions. A model driven approach was presented to design and develop smart IoT-based system <ce:cross-ref id=""""crf0043"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref>. A set of design pattern is defined in this method to syndicate cognitive and autonomic principals for providing a precise solution according to the system needs. A fuzzy prolog and ontology-based framework was proposed to detect health anomalies in real-time using IoT devices <ce:cross-ref id=""""crf0044"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. This existing ontology gives hints about diseases that are currently going on. However, simple ontology may not be able to handle real-time sensor''''s data for having a complete detail of a patient. Wearable devices with solar-energy harvesting were presented to ease the implementation of an autonomous wireless body area network (WBAN) <ce:cross-ref id=""""crf0045"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>. Different sensors are employed on various positions of the body to measure the heartbeat, temperature, and to detect falls. The data from sensors and fall notification is shown through web-based smart phone application. Systems based on wearable healthcare devices were reviewed both in commercial efforts and scientific papers <ce:cross-refs id=""""crf0046"""" refid=""""bib0032 bib0033 bib0034"""">[32–34][[ refid=''''bib0032 bib0033 bib0034'''' ]]</ce:cross-refs>. This review determined the design architecture of IoT in the medical field, including software and hardware dealing with sensors, medical application, and smart phones for diagnosis. A gateway between sensor network and the Internet in IoT-based healthcare system was proposed to translate the protocols used in sensor network and the Internet <ce:cross-ref id=""""crf0048"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref>. This gateway contains control knowledge for both the sensor network and the data transmitted through the Internet in healthcare IoT system.</ce:para>""''"'	cites	FDY	
cites	Research works	None Abinaya, V. Kumar, None Swathika, Ontology based public healthcare system in internet of things (IoT) , Procedia Comput. Sci. , vol. 50 (2015), pp.99-102	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0026		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0007	'An ontology-based public healthcare system for the IoT was proposed to overcome security and privacy challenges in a healthcare information system [10][[ refid=''bib0010'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">The performance of ontology has been extensively investigated in the fields of healthcare and the IoT environment <ce:cross-refs id=""""crf0049"""" refid=""""bib0011 bib0036"""">[11,36][[ refid=''''bib0011 bib0036'''' ]]</ce:cross-refs>. An ontology-based public healthcare system for the IoT was proposed to overcome security and privacy challenges in a healthcare information system <ce:cross-ref id=""""crf0051"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. The system provides a way to collect, integrate, and interoperate via the IoT during an emergency. However, the hospitals’ data are almost always uncertain, and a classic ontology is unable to retrieve patient information efficiently. For example, a patient''''s condition maybe normal, good, or satisfactory, and the service may be fast, normal, or slow; the doctor may be busy, free, or unavailable. Therefore, a fuzzy ontology is needed to classify every point of the healthcare system for emergency medical–information sharing. A drug discovery investigation (DDI)-based ontology was proposed to assign a value to the information created during drug discovery in order to make it easier to reuse, retrieve, and integrate the created information. <ce:cross-ref id=""""crf0052"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref>. This proposed DDI system Ontology-based healthcare knowledge was produced to support clinical decisions for chronically ill patients. This system presents two personalized processes and a decision support tool. The first personalized process uses the contents of the ontology to detect the healthcare record of a patient, and systematically provides to healthcare professionals the clinical information relevant to managing the patient. The second personalized process systematically transforms a healthcare description for general treatment into an individual interference plan. However, this system needs intelligent knowledge to present various healthcare descriptions for different conditions in the patient. Domain ontology and rules reasoning was proposed to construct a clinical decision support system for patients undergoing surgery <ce:cross-ref id=""""crf0053"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. This ontology has 31 classes, 13 properties, and 38 Apache Jena rules to generate a recommendation system for hospitalized diabetes patients. The system called GalemOWL was used to present ontology-based drug recommendation discovery <ce:cross-ref id=""""crf0054"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>. This ontology demonstrated a semantic-enabled system that, together with standardized medical terminologies, provides a knowledge base for drug–drug and drug–disease interactions using rules and axioms. An ontological case–based engineering methodology was presented for diabetes management <ce:cross-ref id=""""crf0055"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>. This case-based ontology, employed to support case semantic retrieval, improves case-based reasoning for understanding the input query and to retrieve the desired case. An actor-profile ontology was presented for organizational knowledge in home-care assistance <ce:cross-ref id=""""crf0056"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref>. The work proposed organizational knowledge for complex healthcare and customization of a home healthcare model designed by a European consortium of homecare professionals. An ontology-based healthcare recommendation system was presented to provide accurate information according to the user queries <ce:cross-ref id=""""crf0057"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref>. This system uses a semantic framework to analyze user''''s preference and recommend food and exercise. However, the continual increase of food information creates difficulty for ontology to extract precise information from the Internet. A semantic interoperability model for big-data in IoT (SIMB-IoT) was presented to recommend medicine for various symptoms collected from different sensors <ce:cross-ref id=""""crf0058"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>. Two datasets are employed in the existing system. One dataset comprises medicines with side effects’ information, and the second dataset contains the information of diseases with drug. Semantic annotations are used efficiently to transfer the information between patient and physician.</ce:para>""''"'	cites	FDY	
cites	Research works	C.-T. Bau, R.-C. Chen, C.-Y. Huang, Construction of a clinical decision support system for undergoing surgery based on domain ontology and rules reasoning , Telemed. J. E-Health , vol. 20 (2014), pp.460-472	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0028		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0012	'Domain ontology and rules reasoning was proposed to construct a clinical decision support system for patients undergoing surgery [1][[ refid=''bib0001'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">The performance of ontology has been extensively investigated in the fields of healthcare and the IoT environment <ce:cross-refs id=""""crf0049"""" refid=""""bib0011 bib0036"""">[11,36][[ refid=''''bib0011 bib0036'''' ]]</ce:cross-refs>. An ontology-based public healthcare system for the IoT was proposed to overcome security and privacy challenges in a healthcare information system <ce:cross-ref id=""""crf0051"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. The system provides a way to collect, integrate, and interoperate via the IoT during an emergency. However, the hospitals’ data are almost always uncertain, and a classic ontology is unable to retrieve patient information efficiently. For example, a patient''''s condition maybe normal, good, or satisfactory, and the service may be fast, normal, or slow; the doctor may be busy, free, or unavailable. Therefore, a fuzzy ontology is needed to classify every point of the healthcare system for emergency medical–information sharing. A drug discovery investigation (DDI)-based ontology was proposed to assign a value to the information created during drug discovery in order to make it easier to reuse, retrieve, and integrate the created information. <ce:cross-ref id=""""crf0052"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref>. This proposed DDI system Ontology-based healthcare knowledge was produced to support clinical decisions for chronically ill patients. This system presents two personalized processes and a decision support tool. The first personalized process uses the contents of the ontology to detect the healthcare record of a patient, and systematically provides to healthcare professionals the clinical information relevant to managing the patient. The second personalized process systematically transforms a healthcare description for general treatment into an individual interference plan. However, this system needs intelligent knowledge to present various healthcare descriptions for different conditions in the patient. Domain ontology and rules reasoning was proposed to construct a clinical decision support system for patients undergoing surgery <ce:cross-ref id=""""crf0053"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. This ontology has 31 classes, 13 properties, and 38 Apache Jena rules to generate a recommendation system for hospitalized diabetes patients. The system called GalemOWL was used to present ontology-based drug recommendation discovery <ce:cross-ref id=""""crf0054"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>. This ontology demonstrated a semantic-enabled system that, together with standardized medical terminologies, provides a knowledge base for drug–drug and drug–disease interactions using rules and axioms. An ontological case–based engineering methodology was presented for diabetes management <ce:cross-ref id=""""crf0055"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>. This case-based ontology, employed to support case semantic retrieval, improves case-based reasoning for understanding the input query and to retrieve the desired case. An actor-profile ontology was presented for organizational knowledge in home-care assistance <ce:cross-ref id=""""crf0056"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref>. The work proposed organizational knowledge for complex healthcare and customization of a home healthcare model designed by a European consortium of homecare professionals. An ontology-based healthcare recommendation system was presented to provide accurate information according to the user queries <ce:cross-ref id=""""crf0057"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref>. This system uses a semantic framework to analyze user''''s preference and recommend food and exercise. However, the continual increase of food information creates difficulty for ontology to extract precise information from the Internet. A semantic interoperability model for big-data in IoT (SIMB-IoT) was presented to recommend medicine for various symptoms collected from different sensors <ce:cross-ref id=""""crf0058"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>. Two datasets are employed in the existing system. One dataset comprises medicines with side effects’ information, and the second dataset contains the information of diseases with drug. Semantic annotations are used efficiently to transfer the information between patient and physician.</ce:para>""''"'	cites	FDY	
uses_method_in	Type-2 fuzzy logic and fuzzy ontology–based decision-making knowledge layer	S. El-Sappagh, M. Elmogy, A.M. Riad, A fuzzy-ontology-oriented case-based reasoning framework for semantic diabetes diagnosis , Artif. Intell. Med. , vol. 65 (2015), pp.179-208	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0013	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0046		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0017	'Most of the patient data are ambiguous; therefore, classic elements of a patient ontology are fuzzified using fuzzy data types and fuzzy modifiers [13][[ refid=''bib0013'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0024"""" view=""""all"""">The history of a chronic patient is an important factor for decision-making by the physician. Therefore, all the information that could be required to supervise a chronic patient''''s condition is included in a classic patient ontology. This information includes patient personal data and disease history, which are easily acquired by physicians and patients. This classic patient ontology is a subsection of a fuzzy ontology, in which the membership degrees of all properties and relations are equal to 1. Most of the patient data are ambiguous; therefore, classic elements of a patient ontology are fuzzified using fuzzy data types and fuzzy modifiers <ce:cross-ref id=""""crf0092"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>. The proposed patient ontology contains fuzzy concepts and relations to express vague knowledge for imprecise data. The fuzzy concept is a concept where the instance belongs to a certain degree. For example, ‘heavy-patient’ (weight) is a fuzzy concept, where ‘heavy’ is an ambiguous predicate; the concept is also ambiguous, and therefore, ‘heavy’ can be represented as a fuzzy concept, such as ‘patient Goro is an instance heavy-patient at membership degree 0.8’. Object and data properties are fuzzy relations. An object relation connects instances at a membership degree and allows fuzzy role assertion, such as ‘Goro has-blood-pressure-sensor-test-result BP-very-high at a degree 0.8’. The property ‘has-blood-pressure-sensor-test-result’ connects instances ‘Goro’ and ‘BP-very-high’. Data type relations assign a literal value to instances or individuals at a certain degree; for example, ‘patient Goro has age old at degree 0.7’. Here, ‘has age’ is a data property that connects instances ‘Goro’ and ‘old’. The patient ontology contains five fuzzy variables: ‘age’, ‘weight’, ‘sex’, ‘height’ and ‘disease history’ in the concept of ‘patient profile’ <ce:cross-ref id=""""crf0093"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref>. The fuzzy variable ‘age’ has fuzzy sets ‘young’, ‘adult’, and ‘old’. Similarly, a fuzzy variable ‘weight’ has the fuzzy sets ‘light’, ‘normal’, and ‘heavy''''. These fuzzy variables are important factors for a diabetes patient''''s supervision, which are described in patient ontology using fuzzy OWL.</ce:para>""''"'	uses_data_from	FDY	
cites	Type-2 fuzzy logic and fuzzy ontology–based decision-making knowledge layer	C.S. Lee, M.H. Wang, H. Hagras, A type-2 fuzzy ontology and its application to personal diabetic-diet recommendation , IEEE Trans. Fuzzy Syst. , vol. 18 (2010), pp.374-395	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0047	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0047		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0018	'The patient ontology contains five fuzzy variables: ‘age’, ‘weight’, ‘sex’, ‘height’ and ‘disease history’ in the concept of ‘patient profile’ [47][[ refid=''bib0047'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0024"""" view=""""all"""">The history of a chronic patient is an important factor for decision-making by the physician. Therefore, all the information that could be required to supervise a chronic patient''''s condition is included in a classic patient ontology. This information includes patient personal data and disease history, which are easily acquired by physicians and patients. This classic patient ontology is a subsection of a fuzzy ontology, in which the membership degrees of all properties and relations are equal to 1. Most of the patient data are ambiguous; therefore, classic elements of a patient ontology are fuzzified using fuzzy data types and fuzzy modifiers <ce:cross-ref id=""""crf0092"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>. The proposed patient ontology contains fuzzy concepts and relations to express vague knowledge for imprecise data. The fuzzy concept is a concept where the instance belongs to a certain degree. For example, ‘heavy-patient’ (weight) is a fuzzy concept, where ‘heavy’ is an ambiguous predicate; the concept is also ambiguous, and therefore, ‘heavy’ can be represented as a fuzzy concept, such as ‘patient Goro is an instance heavy-patient at membership degree 0.8’. Object and data properties are fuzzy relations. An object relation connects instances at a membership degree and allows fuzzy role assertion, such as ‘Goro has-blood-pressure-sensor-test-result BP-very-high at a degree 0.8’. The property ‘has-blood-pressure-sensor-test-result’ connects instances ‘Goro’ and ‘BP-very-high’. Data type relations assign a literal value to instances or individuals at a certain degree; for example, ‘patient Goro has age old at degree 0.7’. Here, ‘has age’ is a data property that connects instances ‘Goro’ and ‘old’. The patient ontology contains five fuzzy variables: ‘age’, ‘weight’, ‘sex’, ‘height’ and ‘disease history’ in the concept of ‘patient profile’ <ce:cross-ref id=""""crf0093"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref>. The fuzzy variable ‘age’ has fuzzy sets ‘young’, ‘adult’, and ‘old’. Similarly, a fuzzy variable ‘weight’ has the fuzzy sets ‘light’, ‘normal’, and ‘heavy''''. These fuzzy variables are important factors for a diabetes patient''''s supervision, which are described in patient ontology using fuzzy OWL.</ce:para>""''"'	cites	FDY	
cites	Type-2 fuzzy logic-based patient health condition declaration	F. Ali, E.K. Kim, Y.-G. Kim, Type-2 fuzzy ontology-based semantic knowledge for collision avoidance of autonomous underwater vehicles , Inf. Sci. , vol. 295 (2015), pp.441-464	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0052	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0040		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0019	'(1) and (2), Jx⊆[0, 1] is a limitation that is equal to 0≤μA˜(x,μ)≤1 for type-1 membership functions (T1MFs), and Jx indicates primary membership ofA˜, where Jx⊆[0, 1]for x ∈ X. If x = x′ then, for each value of x, we have the following [52][[ refid=''bib0052'' ]]: [[ formulaid=''id9_pos1'' ]] [[ formulaid=''id9_pos2'' ]]'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0017"""" view=""""all""""><mml:math altimg=""""si3.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mover accent=""""true""""><mml:mi mathvariant=""""normal"""">A</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math> can also be expressed as<ce:display><ce:formula id=""""eqn0002""""><ce:label>(2)</ce:label><mml:math altimg=""""si6.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mover accent=""""true""""><mml:mi mathvariant=""""normal"""">A</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant=""""normal"""">X</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mo>∫</mml:mo><mml:mrow><mml:mi>μ</mml:mi><mml:mo>∈</mml:mo><mml:mspace width=""""0.16em""""/><mml:msub><mml:mi mathvariant=""""normal"""">J</mml:mi><mml:mi mathvariant=""""normal"""">x</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>μ</mml:mi><mml:mover accent=""""true""""><mml:mi mathvariant=""""normal"""">A</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:msub><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mspace width=""""0.33em""""/><mml:msub><mml:mi mathvariant=""""normal"""">J</mml:mi><mml:mi mathvariant=""""normal"""">x</mml:mi></mml:msub><mml:mo>⊆</mml:mo><mml:mrow><mml:mo stretchy=""""true"""">[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy=""""true"""">]</mml:mo></mml:mrow><mml:mspace width=""""0.16em""""/><mml:mspace width=""""0.16em""""/><mml:mspace width=""""0.16em""""/><mml:mtext>where</mml:mtext><mml:mspace width=""""0.16em""""/><mml:mspace width=""""0.16em""""/><mml:mn>0</mml:mn><mml:mspace width=""""0.16em""""/><mml:mspace width=""""0.16em""""/><mml:mo>≤</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mover accent=""""true""""><mml:mi mathvariant=""""normal"""">A</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:msub><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></ce:formula></ce:display>where <mml:math altimg=""""si7.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mo>∫</mml:mo><mml:mo>∫</mml:mo></mml:mrow></mml:math> shows the union of overall admissible <ce:italic>x</ce:italic> and <ce:italic>μ</ce:italic>. J<ce:inf loc=""""post"""">x</ce:inf> is called the primary membership of x. There is a secondary membership value for each primary membership value. From <ce:cross-ref id=""""crf0068"""" refid=""""eqn0001"""">Eqs. (1)</ce:cross-ref> and <ce:cross-ref id=""""crf0069"""" refid=""""eqn0002"""">(2)</ce:cross-ref>, J<ce:inf loc=""""post"""">x</ce:inf>⊆[0, 1] is a limitation that is equal to <mml:math altimg=""""si8.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mover accent=""""true""""><mml:mi mathvariant=""""normal"""">A</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mspace width=""""0.33em""""/><mml:mi>μ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math> for type-1 membership functions (T1MFs), and J<ce:inf loc=""""post"""">x</ce:inf> indicates primary membership of<mml:math altimg=""""si9.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mspace width=""""0.33em""""/><mml:mover accent=""""true""""><mml:mrow><mml:mspace width=""""0.33em""""/><mml:mi mathvariant=""""normal"""">A</mml:mi></mml:mrow><mml:mo>˜</mml:mo></mml:mover><mml:mo>,</mml:mo></mml:mrow></mml:math> where J<ce:inf loc=""""post"""">x</ce:inf>⊆[0, 1]for <ce:italic>x</ce:italic> ∈ X. If x = x′ then, for each value of <ce:italic>x</ce:italic>, we have the following <ce:cross-ref id=""""crf0070"""" refid=""""bib0052"""">[52][[ refid=''''bib0052'''' ]]</ce:cross-ref>:<ce:display><ce:formula id=""""eqn0003""""><ce:label>(3)</ce:label><mml:math altimg=""""si10.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mover accent=""""true""""><mml:mi mathvariant=""""normal"""">A</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:msub><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:msup><mml:mi mathvariant=""""normal"""">x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>∑</mml:mo><mml:mi>μ</mml:mi><mml:mspace width=""""0.16em""""/><mml:mi>ϵ</mml:mi><mml:mspace width=""""0.16em""""/><mml:msub><mml:mi mathvariant=""""normal"""">J</mml:mi><mml:msup><mml:mi mathvariant=""""normal"""">x</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msub><mml:mi mathvariant=""""normal"""">f</mml:mi><mml:mspace width=""""0.16em""""/><mml:msup><mml:mi mathvariant=""""normal"""">x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mi>μ</mml:mi><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mtext>for</mml:mtext><mml:mspace width=""""0.16em""""/><mml:mspace width=""""0.16em""""/><mml:mi>μ</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant=""""normal"""">J</mml:mi><mml:msup><mml:mi mathvariant=""""normal"""">x</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msub><mml:mo>⊆</mml:mo><mml:mrow><mml:mo stretchy=""""true"""">[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy=""""true"""">]</mml:mo></mml:mrow><mml:mrow><mml:mspace width=""""0.33em""""/><mml:mtext>and</mml:mtext></mml:mrow><mml:mspace width=""""0.16em""""/><mml:msup><mml:mi mathvariant=""""normal"""">x</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:math></ce:formula></ce:display><ce:display><ce:formula id=""""eqn0004""""><ce:label>(4)</ce:label><mml:math altimg=""""si11.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mtext>FOU</mml:mtext><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mover accent=""""true""""><mml:mi mathvariant=""""normal"""">A</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∪</mml:mo><mml:mrow><mml:mo>∀</mml:mo><mml:mi>x</mml:mi><mml:mo>∈</mml:mo><mml:mi mathvariant=""""normal"""">X</mml:mi></mml:mrow></mml:munder><mml:mspace width=""""0.33em""""/><mml:msub><mml:mi mathvariant=""""normal"""">J</mml:mi><mml:msup><mml:mi mathvariant=""""normal"""">x</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:mi>μ</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant=""""normal"""">J</mml:mi><mml:msup><mml:mi mathvariant=""""normal"""">x</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msub><mml:mo>⊆</mml:mo><mml:mrow><mml:mo stretchy=""""true"""">[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy=""""true"""">]</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></ce:formula></ce:display></ce:para>""''"'	cites	FDY	
cites	Introduction	S.M.R. Islam, D. Kwak, H. Kabir, M. Hossain, K.-S. Kwak, The internet of things for health care : a comprehensive survey, access , IEEE , vol. 3 (2015), pp.678-708	http://dx.doi.org/10.1016/j.comcom.2017.10.005	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0007	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0003		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0031	'A wearable sensor-based healthcare monitoring service via the Internet of Things (IoT) is more effective for long-term medical care, and for clinical access to extract precise physiological information about patients and for disease management [7][[ refid=''bib0007'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">In recent years, the healthcare industry has faced significant pressure due to the continuous increase in patients with chronic diseases and their long-term medical treatment. Many clinical applications have been proposed to overcome the load of chronic patients in hospital <ce:cross-refs id=""""crf0009"""" refid=""""bib0001 bib0002 bib0003 bib0004"""">[1–4][[ refid=''''bib0001 bib0002 bib0003 bib0004'''' ]]</ce:cross-refs>. However, the escalation in the number of diabetes patients and their risk factors may create confusion for physicians wishing to automatically extract physiological information for diagnoses. Furthermore, elderly patients with chronic diseases are unable to continuously visit physicians, which is in turn both inappropriate and costly <ce:cross-refs id=""""crf0011"""" refid=""""bib0005 bib0006"""">[5,6][[ refid=''''bib0005 bib0006'''' ]]</ce:cross-refs>. A wearable sensor-based healthcare monitoring service via the Internet of Things (IoT) is more effective for long-term medical care, and for clinical access to extract precise physiological information about patients and for disease management <ce:cross-ref id=""""crf0013"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>. However, the existing healthcare systems are inefficient at extracting accurate membership values for physical parameters of the patient''''s body, because most of the healthcare systems use conventional technologies and approaches, such as risk score calculators, a classic ontology, and fuzzy logic <ce:cross-ref id=""""crf0014"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_method_in	FDY	
cites	Introduction	C. T.-C., T.C. Chiang, W.H. Liang, A context-aware interactive health care system based on ontology and fuzzy inference , J. Med. Syst. , vol. 39 (2015), pp.None	http://dx.doi.org/10.1016/j.comcom.2017.10.005	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0008	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0004		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0032	'However, the existing healthcare systems are inefficient at extracting accurate membership values for physical parameters of the patient''s body, because most of the healthcare systems use conventional technologies and approaches, such as risk score calculators, a classic ontology, and fuzzy logic [8][[ refid=''bib0008'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">In recent years, the healthcare industry has faced significant pressure due to the continuous increase in patients with chronic diseases and their long-term medical treatment. Many clinical applications have been proposed to overcome the load of chronic patients in hospital <ce:cross-refs id=""""crf0009"""" refid=""""bib0001 bib0002 bib0003 bib0004"""">[1–4][[ refid=''''bib0001 bib0002 bib0003 bib0004'''' ]]</ce:cross-refs>. However, the escalation in the number of diabetes patients and their risk factors may create confusion for physicians wishing to automatically extract physiological information for diagnoses. Furthermore, elderly patients with chronic diseases are unable to continuously visit physicians, which is in turn both inappropriate and costly <ce:cross-refs id=""""crf0011"""" refid=""""bib0005 bib0006"""">[5,6][[ refid=''''bib0005 bib0006'''' ]]</ce:cross-refs>. A wearable sensor-based healthcare monitoring service via the Internet of Things (IoT) is more effective for long-term medical care, and for clinical access to extract precise physiological information about patients and for disease management <ce:cross-ref id=""""crf0013"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>. However, the existing healthcare systems are inefficient at extracting accurate membership values for physical parameters of the patient''''s body, because most of the healthcare systems use conventional technologies and approaches, such as risk score calculators, a classic ontology, and fuzzy logic <ce:cross-ref id=""""crf0014"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_method_in	FDY	
cites	Introduction	I. Azimi, A.M. Rahmani, P. Liljeberg, H. Tenhunen, Internet of things for remote elderly monitoring: a study from user-centered perspective , J. Ambient Intell. Hum. Comput. (2016)	http://dx.doi.org/10.1016/j.comcom.2017.10.005	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0009	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0005		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0033	'Dietary control and precise diabetes drug recommendations are another problem for the existing IoT-based healthcare monitoring architecture [9][[ refid=''bib0009'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0008"""" view=""""all"""">Dietary control and precise diabetes drug recommendations are another problem for the existing IoT-based healthcare monitoring architecture <ce:cross-ref id=""""crf0015"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>. Nowadays, diabetes patients use existing systems or consult with a nutrition expert to know a food''''s nutritional value. These existing systems are unable to provide precise information on nutritional diets without knowing the current physiological information about the diabetes patient, which can worsen the patient''''s condition. Diabetes patients access nutrition expert facilities when their blood glucose levels suddenly rise due to a lack of knowledge about the nutrient levels in the foods they eat. In addition, it is difficult for experts to extract all the risk factors about patients and to obtain meaningful information regarding their needs with regard to foods and drugs. Generally, the risk factors of a diabetes patient are unpredictable; where a drug or food type varies for every patient, depending on the patient''''s current condition. Both healthcare treatment and recommendations have complexity and uncertainty. One recent useful technique is fuzzy ontology–based semantic knowledge, which can help to address the uncertainty in healthcare monitoring and recommendation systems.</ce:para>""''"'	cites	FDY	
uses_method_in	Experiment and results	S. El-Sappagh, M. Elmogy, A.M. Riad, A fuzzy-ontology-oriented case-based reasoning framework for semantic diabetes diagnosis , Artif. Intell. Med. , vol. 65 (2015), pp.179-208	http://dx.doi.org/10.1016/j.comcom.2017.10.005	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0013>	<http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0061>				http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0039	'Agreement between the systems and the experts was measured by Cohen''s Kappa coefficient equation, as follows [13][[ refid=''bib0013'' ]]: [[ formulaid=''id30_pos0'' ]] where Pr (a) denotes the actual observed agreement, and Pr (e) denotes chance agreement.'			FDY+AGA	infered_pred1
cites	Type-2 fuzzy logic and fuzzy ontology–based decision-making knowledge layer	A. Goldfain, B. Smith, S. Arabandi, M. Brochhausen, W.R. Hogan, Vital Sign Ontology , Workshop on Bio-Ontologies (2011)	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0057	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0049		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0043	'These sensors (as input variables) and the fuzzy linguistic data types and MFs are described as follows.1.Blood pressure: The pressure exerted by circulating blood on the walls of blood vessels is called blood pressure [57][[ refid=''bib0057'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0025"""" view=""""all"""">A sensor ontology is a personalized solution for chronic patient monitoring. This ontology is linked to the patient ontology and the knowledge and rule–based ontology. Apart from instances (name, age, id, weight, etc.) of the patient ontology, different rules in the knowledge and rule–based ontology are defined for each sensor test. The main aim of this sensor ontology is to describe and mange those data that are needed for monitoring and task execution. There are two kinds of test for patient monitoring: questionnaires and body measurements. A lot of research has been done on questionnaires <ce:cross-refs id=""""crf0094"""" refid=""""bib0014 bib0015 bib0056"""">[14,15,56][[ refid=''''bib0014 bib0015 bib0056'''' ]]</ce:cross-refs>. However, there are still limitations to intelligent semantic knowledge for body measurements in IoT-based health prescription systems. Therefore, body measurement using sensors and their instances in the ontology are configured in order to know about patient activities and health conditions. This ontology contains 8 measurement sensors as instances of the class daily-sensor-test-results. The class daily-sensor-test-results has subclasses, and every subclass has instances with the same name of the class. These instances are blood sugar, glycated hemoglobin (HBA1C), blood pressure, cholesterol, heart rate, motion, weight, and height. With every measurement, the physician needs a camera to retrieve patient information like the patient''''s position (sitting, walking, sleeping, or standing), for which arm is used for the blood pressure sensor, and for the types of foods the patient ate and drank in the previous hour. These sensors (as input variables) and the fuzzy linguistic data types and MFs are described as follows.<ce:list id=""""celist0002""""><ce:list-item id=""""celistitem0007""""><ce:label>1.</ce:label><ce:para id=""""para0026"""" view=""""all"""">Blood pressure: The pressure exerted by circulating blood on the walls of blood vessels is called blood pressure <ce:cross-ref id=""""crf0097"""" refid=""""bib0057"""">[57][[ refid=''''bib0057'''' ]]</ce:cross-ref>. There are three types of blood pressure: systolic, diastolic, and mean arterial pressure (MAP), which are described as subclasses of blood pressure in the ontology. In our proposed system, systolic pressure is used for measurement. There are five fuzzy sets of blood pressure. These fuzzy sets with OWL data–range expressions are as follows: Very-Low (double [&gt; = 0.0] and double [&lt; = 90.0]), Low (double [&gt; = 71.0] and double [&lt; = 130.0]), Medium (double [&gt; = 125.0] and double [&lt; = 154.0]), High (double [&gt; = 142.0] and double [&lt; = 180.0]), and Very-High (double [&gt; = 165.0] and double [&lt; = 250.0]).</ce:para></ce:list-item><ce:list-item id=""""celistitem0008""""><ce:label>2.</ce:label><ce:para id=""""para0027"""" view=""""all"""">Blood sugar: Blood sugar, or blood glucose, supplies energy to all cells of the body. However, it is very important to keep it in a normal range. There are two ways to measure blood sugar: millimoles per liter (mmol/L) and milligrams per deciliter (mg/dL). This system uses milligrams per deciliter. The ontology contains five fuzzy sets for blood sugar. These fuzzy sets with fuzzy OWL data expressions are as follows: Very-Low (double [&gt; = 0.0] and double [&lt; = 45.0]), Low (double [&gt; = 30.0] and double [&lt; = 90.0]), Medium (double [&gt; = 75.0] and double [&lt; = 160.0]), High (double [&gt; = 140.0] and double [&lt; = 200.0]), and Very-High (double [&gt; = 180.0] and double [&lt; = 300.0]).</ce:para></ce:list-item><ce:list-item id=""""celistitem0009""""><ce:label>3.</ce:label><ce:para id=""""para0028"""" view=""""all"""">Cholesterol: Cholesterol is produced from food and the body. The physician always determines the chronic patient''''s cholesterol level before prescribing medication, because it predicts the patient''''s risk of heart disease <ce:cross-ref id=""""crf0098"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. There are two kinds of cholesterol, high-density lipoprotein (HDL), or “good” cholesterol, and low-density lipoprotein (LDL) or “bad” cholesterol. This system considers the LDL cholesterol level. The cholesterol fuzzy sets with ranges are as follows. Very-Low (double [&gt; = 0.0] and double [&lt; = 170.0]), Low (double [&gt; = 150.0] and double [&lt; = 200.0]), Medium (double [&gt; = 180.0] and double [&lt; = 250.0]), High (double [&gt; = 225.0] and double [&lt; = 315.0]), and Very-High (double [&gt; = 280.0] and double [&lt; = 400.0]).</ce:para></ce:list-item><ce:list-item id=""""celistitem0010""""><ce:label>4.</ce:label><ce:para id=""""para0029"""" view=""""all"""">Movement speed of the body: This input variable is used to find movement speed of an old patient''''s body. There are four types for range of motion (ROM), which can be used to examine the patient''''s body movement: passive ROM, active-assisted ROM, active ROM, and active self–assisted ROM <ce:cross-ref id=""""crf0099"""" refid=""""bib0058"""">[58][[ refid=''''bib0058'''' ]]</ce:cross-ref>. In this proposed system, active ROM (movement by the patient alone) is described to find the movement degree of the patient''''s body. There are five fuzzy linguistic sets for body movement. These sets, along with their ranges, are as follows: Very-Low (double [&gt; = 0.0] and double [&lt; = 10.0]), Low (double [&gt; = 8.0] and double [&lt; = 30.0]), Medium (double [&gt; = 25.0] and double [&lt; = 40.0]), High (double [&gt; = 35.0] and double [&lt; = 50.0]), and Very-High (double [&gt; = 45.0] and double [&lt; = 70.0]).</ce:para></ce:list-item><ce:list-item id=""""celistitem0011""""><ce:label>5.</ce:label><ce:para id=""""para0030"""" view=""""all"""">Heart rate: It has been confirmed that daily heart rate analysis of diabetes patients is important for detecting and treating heart disease in its early stages <ce:cross-ref id=""""crf0100"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. Therefore, this system uses three fuzzy variables for heart rate to compute the patient''''s health condition. These fuzzy sets, along with ranges, are as follows. Low (double [&gt; = 30] and double [&lt; = 60.0]), Medium (double [&gt; = 50.0] and double [&lt; = 100.0]) and High (double [&gt; = 95.0] and double [ &lt; = 120.0].</ce:para></ce:list-item><ce:list-item id=""""celistitem0012""""><ce:label>6.</ce:label><ce:para id=""""para0031"""" view=""""all"""">Age: This input variable is divided into five linguistic asset value variables (Very Young, Young, Mild, Old, Very Old). These linguistic variables, along with their ranges, are as follows: Very Young (double [&gt; = 0.0] and double [&lt; = 20.0]), Young (double [&gt; = 16.0] and double [&lt; = 38.0]), Mild (double [&gt; = 35.0] and double [&lt; = 50.0], Old (double [&gt; = 45.0] and double [ &lt; = 60.0] and Very Old (double [&gt; = 55.0] and double [&lt; = 65.0].</ce:para></ce:list-item><ce:list-item id=""""celistitem0013""""><ce:label>7.</ce:label><ce:para id=""""para0032"""" view=""""all"""">Weight: This input variable has three fuzzy sets (Light, Normal, and Heavy). The ranges of these variables in the ontology are: Light (double [&gt; = 0.0] and double [&lt; = 45.0]), Normal (double [&gt; = 35.0] and double [&lt; = 75.0]) and Heavy (double [&gt; = 95.0] and double [&lt; = 140.0].</ce:para></ce:list-item><ce:list-item id=""""celistitem0014""""><ce:label>8.</ce:label><ce:para id=""""para0033"""" view=""""all"""">Sex and Height: The variable sex is crisp and contains two values (0 and 1). Therefore, two subclasses of ‘sex’ along with instances (male and female) are described in the ontology. If the patient is male, then the value is 0, and if the patient is female, then 1 is assigned during computation of the patient condition. Height is also an important factor for diabetes patient treatment, because other variables, like weight, depend on it. However, very limited changes occur in patient height; therefore, it is described in the ontology for food recommendations, and is not considered during the patient condition value computation.</ce:para></ce:list-item><ce:list-item id=""""celistitem0015""""><ce:label>9.</ce:label><ce:para id=""""para0034"""" view=""""all"""">Patient health condition: This output variable defines the patient health condition. It is dependent on the type-2 fuzzy inference mechanism of the above-mentioned input variables. The fuzzy sets of this output variable are Healthy, Moderate, and Serious, and their ranges are: Healthy (double [&gt; = 0.0] and double [&lt; = 5.0]), Moderate (double [&gt; = 2.5] and double [&lt; = 7.5.0]), and Serious (double [&gt; = 5.0] and double [&lt; = 10.0]. The proposed system helps the medical staff by automatically informing them about the patient''''s health condition; for example, if the patient condition value is in range 0 ∼ 5, the system shows that the patient condition is healthy. If the value is in range of 2.5 ∼ 7.5, the system informs the medical staff to start regular services, and it automatically recommends drugs and foods for the patient using decision-making knowledge from the fuzzy ontology. If the patient condition value is in the range 5 ∼ 10, the system indicates that the patient''''s condition is serious, calls emergency services or rescue units, and spontaneously changes food and drug recommendations. The MFs of this output variable are shown in <ce:cross-ref id=""""crf0101"""" refid=""""fig0006"""">Fig. 6</ce:cross-ref><ce:float-anchor refid=""""fig0006""""/>(h). The type-1 fuzzy sets are shown as a thin line, whereas the interval type-2 fuzzy sets are shown as a thick line.</ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_data_from	FDY	
cites	Experiment and results	C.S. Lee, M.H. Wang, H. Hagras, A type-2 fuzzy ontology and its application to personal diabetic-diet recommendation , IEEE Trans. Fuzzy Syst. , vol. 18 (2010), pp.374-395	http://dx.doi.org/10.1016/j.comcom.2017.10.005	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0047	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0060		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0047	'A classic ontology with a rules-based system is presented for diabetes management to enhance accuracy [47][[ refid=''bib0047'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0089"""" view=""""all"""">Most of the existing diabetes patient health monitoring and recommendation systems are based on a classic ontology and type-1 fuzzy logic. The existing T1FL-based systems have various inputs and one output to diagnose heart disease <ce:cross-refs id=""""crf0130"""" refid=""""bib0014 bib0024 bib0047"""">[14,24,47][[ refid=''''bib0014 bib0024 bib0047'''' ]]</ce:cross-refs>. However, these existing systems are unable to extract the correct membership value from each input, and therefore, that affects the overall results. A classic ontology with a rules-based system is presented for diabetes management to enhance accuracy <ce:cross-ref id=""""crf0133"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref>. However, these systems are insufficient at defining fuzzy terms of patient factors (e.g., blood sugar {high, medium, low}). It is notable that these systems can determine the patient health value to some extent. However, they cannot perfectly monitor patients when there is intensive uncertainty in patient risk factors. They do not provide sufficient information to physicians and patients. In addition, there is a need for decision-making knowledge for IoT-based healthcare to automate the monitoring and recommendation process. A T2FS and fuzzy ontology have not been used before to compute the health condition value of a diabetes patient and to recommend foods and drugs. However, they have been used to develop other healthcare systems for diabetes patients.</ce:para>""''"'	cites	FDY	
uses_method_in	Experiment and results	J. Hartmann, P. Spyns, A. Giboin, D. Maynard, Methods for ontology evaluation , KWeb Deliverable (2005)	http://dx.doi.org/10.1016/j.comcom.2017.10.005	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0065	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0058		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0048	'A well-known method is used to evaluate an ontology in the form of questions and answers, such as the DL query and SPARQL query [65][[ refid=''bib0065'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0070"""" view=""""all"""">The performance of the proposed ontology was evaluated after the development of each phase to measure the improvement level. Evaluation of an ontology is essential, because the ontology information automatically declares the instances that might be duplicated or might not be identical. A well-known method is used to evaluate an ontology in the form of questions and answers, such as the DL query and SPARQL query <ce:cross-ref id=""""crf0124"""" refid=""""bib0065"""">[65][[ refid=''''bib0065'''' ]]</ce:cross-ref>. A DL query of Protégé is a dynamic and user-friendly plugin to construct valid instances or individuals in the required time for the input query. A SPARQL query combines the variables and properties to extract the needed instances or individuals. The DL and SPARQL queries are defined in the OWL syntax. Reasoners such as Pellet, Fact++++, Hermit, and RacePro must be run before any query execution. The Pellet reasoner was executed to evaluate this ontology. It is based on the Apache Jena application programming interface and allows users to write rules that are more complex. The proposed ontology has a lot of vagueness, because diabetes patient health information is always uncertain. Therefore, the Pellet reasoner converted the fuzzy ontology into a classic ontology and analyzed the performance of the proposed ontology. Various queries were designed to evaluate the overall efficiency of the system and to retrieve the instances. These queries are as follows.</ce:para>""''"'	uses_method_in	FDY	
cites	Type-2 fuzzy logic-based patient health condition declaration	L. a. Zadeh, Fuzzy sets , Inf. Control , vol. 8 (1965), pp.338-353	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0048	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0037		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0053	'Lofti Zadeh introduced the type-1 fuzzy set in 1965 to extract vague and blurred concepts [48][[ refid=''bib0048'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">In this Section, the basic concepts of type-2 fuzzy logic-based health condition declaration are given. Lofti Zadeh introduced the type-1 fuzzy set in 1965 to extract vague and blurred concepts <ce:cross-ref id=""""crf0064"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>. Zadeh extended the T1FS to the type-2 fuzzy set after 10 years <ce:cross-ref id=""""crf0065"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref>. A T2FS <mml:math altimg=""""si3.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mover accent=""""true""""><mml:mi mathvariant=""""normal"""">A</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:math> characterized by membership function (MF) <mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mover accent=""""true""""><mml:mi mathvariant=""""normal"""">A</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mspace width=""""0.33em""""/><mml:mi>μ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math>, where <ce:italic>x</ce:italic> ∈ X, <ce:italic>μ</ce:italic> ∈ J<ce:inf loc=""""post"""">x</ce:inf>⊆ [0, 1], is expressed as follows <ce:cross-refs id=""""crf0066"""" refid=""""bib0050 bib0051"""">[50,51][[ refid=''''bib0050 bib0051'''' ]]</ce:cross-refs>:<ce:display><ce:formula id=""""eqn0001""""><ce:label>(1)</ce:label><mml:math altimg=""""si5.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mover accent=""""true""""><mml:mi mathvariant=""""normal"""">A</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy=""""true"""">{</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mover accent=""""true""""><mml:mi mathvariant=""""normal"""">A</mml:mi><mml:mo>˜</mml:mo></mml:mover></mml:msub><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mo>∀</mml:mo><mml:mi>x</mml:mi><mml:mspace width=""""0.33em""""/><mml:mi>ϵ</mml:mi><mml:mrow><mml:mspace width=""""0.33em""""/><mml:mi mathvariant=""""normal"""">X</mml:mi><mml:mspace width=""""0.33em""""/></mml:mrow><mml:mo>∀</mml:mo><mml:mi>μ</mml:mi><mml:mo>∈</mml:mo><mml:mspace width=""""0.33em""""/><mml:msub><mml:mi mathvariant=""""normal"""">J</mml:mi><mml:mi mathvariant=""""normal"""">x</mml:mi></mml:msub><mml:mo>⊆</mml:mo><mml:mrow><mml:mo stretchy=""""true"""">[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy=""""true"""">]</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy=""""true"""">}</mml:mo></mml:mrow></mml:mrow></mml:math></ce:formula></ce:display></ce:para>""''"'	uses_method_in	FDY	
cites	Research works	C.S. Lee, M.H. Wang, H. Hagras, A type-2 fuzzy ontology and its application to personal diabetic-diet recommendation , IEEE Trans. Fuzzy Syst. , vol. 18 (2010), pp.374-395	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0047	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0036		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0054	'An ontology was used to present the design of a diet assessment system [47][[ refid=''bib0047'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all"""">It is understood that type-1 fuzzy logic (T1FL) <ce:cross-refs id=""""crf0059"""" refid=""""bib0043 bib0044"""">[43,44][[ refid=''''bib0043 bib0044'''' ]]</ce:cross-refs> and a classic ontology-based proposed system can monitor diabetes patients to some extent, and can classically provide health prescriptions. However, it cannot perfectly monitor when the risk factors of a patient increase and are intensively blurred. Besides, the IoT should be linked to semantic knowledge to automate the health prescription process for diabetes patients. Type-2 fuzzy logic (T2FL) with a fuzzy ontology is a solution to these problems. The three-dimensional structure of T2FL can easily handle vague data of risk factors <ce:cross-refs id=""""crf0061"""" refid=""""bib0045 bib0046"""">[45,46][[ refid=''''bib0045 bib0046'''' ]]</ce:cross-refs>, and a fuzzy ontology can represent decision knowledge to automate the overall health prescription system. An ontology was used to present the design of a diet assessment system <ce:cross-ref id=""""crf0063"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref>. In this study, fuzzy markup language was introduced to design type-2 fuzzy ontology–based knowledge for intelligent decision-making during food collection from the Internet and convenience stores. A T2FL and ontology model was proposed to personalize diabetes diet recommendations. This proposed approach retrieves meal records and a predefined food ontology to compile all kinds of foods for each person''''s diet goal. Type-2 fuzzy sets (T2FSs) were used to classify personal profiles and to categorize the calories in foods. However, these proposed ontologies are only concerned with an agent system to address diet goal–planning challenges by asking users to input eaten items and to exchange diet food information between users and domain experts.</ce:para>""''"'	cites	FDY	
cites	Research works	A. Valls, K. Gibert, D. Sánchez, M. Batet, Using ontologies for structuring organizational knowledge in Home Care assistance , Int. J. Med. Inf. , vol. 79 (2010), pp.370-387	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0040	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0031		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0055	'An actor-profile ontology was presented for organizational knowledge in home-care assistance [40][[ refid=''bib0040'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">The performance of ontology has been extensively investigated in the fields of healthcare and the IoT environment <ce:cross-refs id=""""crf0049"""" refid=""""bib0011 bib0036"""">[11,36][[ refid=''''bib0011 bib0036'''' ]]</ce:cross-refs>. An ontology-based public healthcare system for the IoT was proposed to overcome security and privacy challenges in a healthcare information system <ce:cross-ref id=""""crf0051"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. The system provides a way to collect, integrate, and interoperate via the IoT during an emergency. However, the hospitals’ data are almost always uncertain, and a classic ontology is unable to retrieve patient information efficiently. For example, a patient''''s condition maybe normal, good, or satisfactory, and the service may be fast, normal, or slow; the doctor may be busy, free, or unavailable. Therefore, a fuzzy ontology is needed to classify every point of the healthcare system for emergency medical–information sharing. A drug discovery investigation (DDI)-based ontology was proposed to assign a value to the information created during drug discovery in order to make it easier to reuse, retrieve, and integrate the created information. <ce:cross-ref id=""""crf0052"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref>. This proposed DDI system Ontology-based healthcare knowledge was produced to support clinical decisions for chronically ill patients. This system presents two personalized processes and a decision support tool. The first personalized process uses the contents of the ontology to detect the healthcare record of a patient, and systematically provides to healthcare professionals the clinical information relevant to managing the patient. The second personalized process systematically transforms a healthcare description for general treatment into an individual interference plan. However, this system needs intelligent knowledge to present various healthcare descriptions for different conditions in the patient. Domain ontology and rules reasoning was proposed to construct a clinical decision support system for patients undergoing surgery <ce:cross-ref id=""""crf0053"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. This ontology has 31 classes, 13 properties, and 38 Apache Jena rules to generate a recommendation system for hospitalized diabetes patients. The system called GalemOWL was used to present ontology-based drug recommendation discovery <ce:cross-ref id=""""crf0054"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>. This ontology demonstrated a semantic-enabled system that, together with standardized medical terminologies, provides a knowledge base for drug–drug and drug–disease interactions using rules and axioms. An ontological case–based engineering methodology was presented for diabetes management <ce:cross-ref id=""""crf0055"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>. This case-based ontology, employed to support case semantic retrieval, improves case-based reasoning for understanding the input query and to retrieve the desired case. An actor-profile ontology was presented for organizational knowledge in home-care assistance <ce:cross-ref id=""""crf0056"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref>. The work proposed organizational knowledge for complex healthcare and customization of a home healthcare model designed by a European consortium of homecare professionals. An ontology-based healthcare recommendation system was presented to provide accurate information according to the user queries <ce:cross-ref id=""""crf0057"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref>. This system uses a semantic framework to analyze user''''s preference and recommend food and exercise. However, the continual increase of food information creates difficulty for ontology to extract precise information from the Internet. A semantic interoperability model for big-data in IoT (SIMB-IoT) was presented to recommend medicine for various symptoms collected from different sensors <ce:cross-ref id=""""crf0058"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>. Two datasets are employed in the existing system. One dataset comprises medicines with side effects’ information, and the second dataset contains the information of diseases with drug. Semantic annotations are used efficiently to transfer the information between patient and physician.</ce:para>""''"'	cites	FDY	
cites	Research works	S.H. El-Sappagh, S. El-Masri, M. Elmogy, A.M. Riad, B. Saddik, An ontological case base engineering methodology for diabetes management , J. Med. Syst. , vol. 38 (2014), pp.None	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0030		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0056	'An ontological case–based engineering methodology was presented for diabetes management [39][[ refid=''bib0039'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">The performance of ontology has been extensively investigated in the fields of healthcare and the IoT environment <ce:cross-refs id=""""crf0049"""" refid=""""bib0011 bib0036"""">[11,36][[ refid=''''bib0011 bib0036'''' ]]</ce:cross-refs>. An ontology-based public healthcare system for the IoT was proposed to overcome security and privacy challenges in a healthcare information system <ce:cross-ref id=""""crf0051"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. The system provides a way to collect, integrate, and interoperate via the IoT during an emergency. However, the hospitals’ data are almost always uncertain, and a classic ontology is unable to retrieve patient information efficiently. For example, a patient''''s condition maybe normal, good, or satisfactory, and the service may be fast, normal, or slow; the doctor may be busy, free, or unavailable. Therefore, a fuzzy ontology is needed to classify every point of the healthcare system for emergency medical–information sharing. A drug discovery investigation (DDI)-based ontology was proposed to assign a value to the information created during drug discovery in order to make it easier to reuse, retrieve, and integrate the created information. <ce:cross-ref id=""""crf0052"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref>. This proposed DDI system Ontology-based healthcare knowledge was produced to support clinical decisions for chronically ill patients. This system presents two personalized processes and a decision support tool. The first personalized process uses the contents of the ontology to detect the healthcare record of a patient, and systematically provides to healthcare professionals the clinical information relevant to managing the patient. The second personalized process systematically transforms a healthcare description for general treatment into an individual interference plan. However, this system needs intelligent knowledge to present various healthcare descriptions for different conditions in the patient. Domain ontology and rules reasoning was proposed to construct a clinical decision support system for patients undergoing surgery <ce:cross-ref id=""""crf0053"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. This ontology has 31 classes, 13 properties, and 38 Apache Jena rules to generate a recommendation system for hospitalized diabetes patients. The system called GalemOWL was used to present ontology-based drug recommendation discovery <ce:cross-ref id=""""crf0054"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>. This ontology demonstrated a semantic-enabled system that, together with standardized medical terminologies, provides a knowledge base for drug–drug and drug–disease interactions using rules and axioms. An ontological case–based engineering methodology was presented for diabetes management <ce:cross-ref id=""""crf0055"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>. This case-based ontology, employed to support case semantic retrieval, improves case-based reasoning for understanding the input query and to retrieve the desired case. An actor-profile ontology was presented for organizational knowledge in home-care assistance <ce:cross-ref id=""""crf0056"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref>. The work proposed organizational knowledge for complex healthcare and customization of a home healthcare model designed by a European consortium of homecare professionals. An ontology-based healthcare recommendation system was presented to provide accurate information according to the user queries <ce:cross-ref id=""""crf0057"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref>. This system uses a semantic framework to analyze user''''s preference and recommend food and exercise. However, the continual increase of food information creates difficulty for ontology to extract precise information from the Internet. A semantic interoperability model for big-data in IoT (SIMB-IoT) was presented to recommend medicine for various symptoms collected from different sensors <ce:cross-ref id=""""crf0058"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>. Two datasets are employed in the existing system. One dataset comprises medicines with side effects’ information, and the second dataset contains the information of diseases with drug. Semantic annotations are used efficiently to transfer the information between patient and physician.</ce:para>""''"'	uses_method_in	FDY	
cites	Research works	F. Ullah, M. Asif, M. Farhan, S. Khalid, Semantic interoperability for big-data in heterogeneous IoT infrastructure for healthcare , Sustainable Cities Soc. , vol. 34 (2017), pp.90-96	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0042	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0033		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0057	'A semantic interoperability model for big-data in IoT (SIMB-IoT) was presented to recommend medicine for various symptoms collected from different sensors [42][[ refid=''bib0042'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">The performance of ontology has been extensively investigated in the fields of healthcare and the IoT environment <ce:cross-refs id=""""crf0049"""" refid=""""bib0011 bib0036"""">[11,36][[ refid=''''bib0011 bib0036'''' ]]</ce:cross-refs>. An ontology-based public healthcare system for the IoT was proposed to overcome security and privacy challenges in a healthcare information system <ce:cross-ref id=""""crf0051"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. The system provides a way to collect, integrate, and interoperate via the IoT during an emergency. However, the hospitals’ data are almost always uncertain, and a classic ontology is unable to retrieve patient information efficiently. For example, a patient''''s condition maybe normal, good, or satisfactory, and the service may be fast, normal, or slow; the doctor may be busy, free, or unavailable. Therefore, a fuzzy ontology is needed to classify every point of the healthcare system for emergency medical–information sharing. A drug discovery investigation (DDI)-based ontology was proposed to assign a value to the information created during drug discovery in order to make it easier to reuse, retrieve, and integrate the created information. <ce:cross-ref id=""""crf0052"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref>. This proposed DDI system Ontology-based healthcare knowledge was produced to support clinical decisions for chronically ill patients. This system presents two personalized processes and a decision support tool. The first personalized process uses the contents of the ontology to detect the healthcare record of a patient, and systematically provides to healthcare professionals the clinical information relevant to managing the patient. The second personalized process systematically transforms a healthcare description for general treatment into an individual interference plan. However, this system needs intelligent knowledge to present various healthcare descriptions for different conditions in the patient. Domain ontology and rules reasoning was proposed to construct a clinical decision support system for patients undergoing surgery <ce:cross-ref id=""""crf0053"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. This ontology has 31 classes, 13 properties, and 38 Apache Jena rules to generate a recommendation system for hospitalized diabetes patients. The system called GalemOWL was used to present ontology-based drug recommendation discovery <ce:cross-ref id=""""crf0054"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>. This ontology demonstrated a semantic-enabled system that, together with standardized medical terminologies, provides a knowledge base for drug–drug and drug–disease interactions using rules and axioms. An ontological case–based engineering methodology was presented for diabetes management <ce:cross-ref id=""""crf0055"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>. This case-based ontology, employed to support case semantic retrieval, improves case-based reasoning for understanding the input query and to retrieve the desired case. An actor-profile ontology was presented for organizational knowledge in home-care assistance <ce:cross-ref id=""""crf0056"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref>. The work proposed organizational knowledge for complex healthcare and customization of a home healthcare model designed by a European consortium of homecare professionals. An ontology-based healthcare recommendation system was presented to provide accurate information according to the user queries <ce:cross-ref id=""""crf0057"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref>. This system uses a semantic framework to analyze user''''s preference and recommend food and exercise. However, the continual increase of food information creates difficulty for ontology to extract precise information from the Internet. A semantic interoperability model for big-data in IoT (SIMB-IoT) was presented to recommend medicine for various symptoms collected from different sensors <ce:cross-ref id=""""crf0058"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>. Two datasets are employed in the existing system. One dataset comprises medicines with side effects’ information, and the second dataset contains the information of diseases with drug. Semantic annotations are used efficiently to transfer the information between patient and physician.</ce:para>""''"'	uses_data_from	FDY	
uses_method_in	Experiment and results	F. Ali, D. Kwak, P. Khan, S.M.R. Islam, K. Hyun, K.S. Kwak, Fuzzy ontology-based sentiment analysis of transportation and city feature reviews for safe traveling q , Transp. Res. Part C. , vol. 77 (2017), pp.33-48	http://dx.doi.org/10.1016/j.comcom.2017.10.005	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0066	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0062		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0059	'These metrics are used to evaluate the performance of prediction methods used in the experiments [66][[ refid=''bib0066'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0092"""" view=""""all"""">In this experiment, diabetes patients with varying conditions used wearable sensors to make inquiries of the proposed system. In addition, different types of queries were designed for each patient in order to extract the needed information from semantic knowledge. The system writes the patients’ records for performance metrics as <ce:italic>precision, recall, accuracy,</ce:italic> and <ce:italic>function measure</ce:italic>. These metrics are used to evaluate the performance of prediction methods used in the experiments <ce:cross-ref id=""""crf0139"""" refid=""""bib0066"""">[66][[ refid=''''bib0066'''' ]]</ce:cross-ref>. <ce:italic>Precision</ce:italic> measures the degree of closeness of two or more decisions each other, while <ce:italic>accuracy</ce:italic> describes the degree of closeness of a measured value to a targeted value or known value. At first, a classic ontology is used during the process of patient health-level prediction and recommendation, and the <ce:italic>precision, recall, accuracy,</ce:italic> and <ce:italic>function measure</ce:italic> are recorded. Later, T1FL with a classic ontology, and T2FL with a fuzzy ontology are used to compute the results. In each case, the health condition values and query results for each patient are compared with information provided by the experts. <ce:cross-ref id=""""crf0140"""" refid=""""eqn0018"""">Eqs. (16)</ce:cross-ref>–<ce:cross-ref id=""""crf0141"""" refid=""""eqn0021"""">(19)</ce:cross-ref> were used to calculate the metrics.<ce:display><ce:formula id=""""eqn0018""""><ce:label>(16)</ce:label><mml:math altimg=""""si33.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display><ce:display><ce:formula id=""""eqn0019""""><ce:label>(17)</ce:label><mml:math altimg=""""si34.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display><ce:display><ce:formula id=""""eqn0020""""><ce:label>(18)</ce:label><mml:math altimg=""""si35.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>A</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>P</mml:mi><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display><ce:display><ce:formula id=""""eqn0021""""><ce:label>(19)</ce:label><mml:math altimg=""""si36.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>F</mml:mi><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width=""""0.33em""""/><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>F</mml:mi><mml:mi>M</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>*</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>*</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display></ce:para>""''"'	uses_method_in	FDY	
uses_method_in	Type-2 fuzzy logic and fuzzy ontology–based decision-making knowledge layer	R. Wijaya, A. Setijadi, T.L. Mengko, M.V.G. Aziz, E. Hadiyatma, Design application to lose weight of overweight person (Steppy application) , Proceedings - 2015 IEEE International Conference on System Engineering and Technology, ICSET 2015 (2016)	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0063	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0056		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0064	'(13) and (14) (Harris–Benedict) are used to calculate the BMR for males and females, respectively [63][[ refid=''bib0063'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0063"""" view=""""all"""">The Calories class in the food ontology has three instances (High-Calories, Medium-Calories, and Low-Calories) which are used during food recommendation. The food ontology retrieves the patient''''s personal data (age, height, and weight) from the patient ontology and the movement speed of the body from the sensor ontology. These data are used to determine the basal metabolic rate (BMR) and daily calorie needs for blood sugar in the patient. <ce:cross-ref id=""""crf0120"""" refid=""""eqn0014"""">Eqs. (13)</ce:cross-ref> and <ce:cross-ref id=""""crf0121"""" refid=""""eqn0015"""">(14)</ce:cross-ref> (Harris–Benedict) are used to calculate the BMR for males and females, respectively <ce:cross-ref id=""""crf0122"""" refid=""""bib0063"""">[63][[ refid=''''bib0063'''' ]]</ce:cross-ref>.<ce:display><ce:formula id=""""eqn0014""""><ce:label>(13)</ce:label><mml:math altimg=""""si27.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>B</mml:mi><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:mo>*</mml:mo><mml:mi>w</mml:mi><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>6.25</mml:mn><mml:mo>*</mml:mo><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn><mml:mo>*</mml:mo><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></ce:formula></ce:display><ce:display><ce:formula id=""""eqn0015""""><ce:label>(14)</ce:label><mml:math altimg=""""si28.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>B</mml:mi><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:mo>*</mml:mo><mml:mi>w</mml:mi><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>6.25</mml:mn><mml:mo>*</mml:mo><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>5</mml:mn><mml:mo>*</mml:mo><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>161</mml:mn></mml:mrow></mml:math></ce:formula></ce:display></ce:para>""''"'	cites	FDY	
cites	Research works	S.S. Bhunia, S.K. Dhar, N. Mukherjee, Ihealth: a fuzzy approach for provisioning intelligent health-care system in smart city , International Conference on Wireless and Mobile Computing, Networking and Communications (2014)	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0018		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0066	'A fuzzy approach was used in an IoT-based healthcare monitoring system to find abnormal conditions in a patient [27][[ refid=''bib0027'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">The IoT and wearable monitoring system is an emerging technology that is expected to contribute a wide range of healthcare applications in the future <ce:cross-refs id=""""crf0030"""" refid=""""bib0002 bib0003 bib0009 bib0020 bib0021"""">[2,3,9,20,21][[ refid=''''bib0002 bib0003 bib0009 bib0020 bib0021'''' ]]</ce:cross-refs>. A system to capture physiological data of a person under care using IoT sensors was presented by Chiang and Liang <ce:cross-ref id=""""crf0035"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>. This system combined a context-aware space with IoT technology to automate healthcare services and assist chronic patients. The main problem with their method is that when the chronic patient risk factors increase, the system is unable to find the correct risk value. In addition, a classic ontology approach is not useful in supporting a fuzzy logic–based system during information extraction from an uncertain patient disease history and unknown risk factors. The Mamdani inference method is used for heart disease diagnosis <ce:cross-ref id=""""crf0036"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>. This system has 13 input features and one output feature in order to find the presence of heart disease in a patient. However, the existing system needs semantic knowledge that is specific to each disease. An analysis of heart rate variability signals is computed using fuzzy measure entropy (FuzzyMEn) <ce:cross-ref id=""""crf0037"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. The system overcomes the poor statistical stability of two entropy measures, which are based on the Heaviside step function of the classical sets. This system used fuzzy logic instead of Heaviside, and achieved better results than approximate entropy (ApEn) and sample entropy (SampEn). Kumar and Kaur used a fuzzy expert system to detect heart disease in patients <ce:cross-ref id=""""crf0038"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>. This system contains six input fields (blood pressure, cholesterol, chest pain type, maximum heart rate, blood sugar, and old peak) and two output fields (heart disease and precautions). However, this system is insufficient in terms of factors and semantic relationships amongst the patient''''s medical data. A computational intelligence model based on fuzzy logic was proposed to handle ambiguity and vagueness in clinical knowledge and data <ce:cross-ref id=""""crf0039"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. This method overcomes the interpretation problem of the common monitoring system called a cardiotocograph (CTG), which is based on a fetal heart rate pattern and maternal contraction. A fuzzy logic–based method for fault-tolerant wireless sensor networks was proposed to monitor diagnosis and testing systems in a large-scale context <ce:cross-ref id=""""crf0040"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>. However, a large storage space in the IoT is used when small movement is detected by a sensor. The mentioned method extracts limited information because of limited semantic knowledge. A single ontology is insufficient to tolerate the IoT''''s faults. It is important to make multiple ontologies for diagnosis and testing, which can provide intelligent knowledge to retrieve precise data for fault-tolerance problems in the IoT. A fuzzy approach was used in an IoT-based healthcare monitoring system to find abnormal conditions in a patient <ce:cross-ref id=""""crf0041"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>. This system helps a physician to select the affected parameters and avoids unnecessary information transmission to the physician. A fuzzy logic and thermistor sensor–based approach was proposed for monitoring and early detection of residential fire <ce:cross-ref id=""""crf0042"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. This proposed system uses two fuzzy methods with temporal characteristics to monitor and determine confidence about the presence of fire in order to decrease and improve the number of rules that are employed to make correct decisions. A model driven approach was presented to design and develop smart IoT-based system <ce:cross-ref id=""""crf0043"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref>. A set of design pattern is defined in this method to syndicate cognitive and autonomic principals for providing a precise solution according to the system needs. A fuzzy prolog and ontology-based framework was proposed to detect health anomalies in real-time using IoT devices <ce:cross-ref id=""""crf0044"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. This existing ontology gives hints about diseases that are currently going on. However, simple ontology may not be able to handle real-time sensor''''s data for having a complete detail of a patient. Wearable devices with solar-energy harvesting were presented to ease the implementation of an autonomous wireless body area network (WBAN) <ce:cross-ref id=""""crf0045"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>. Different sensors are employed on various positions of the body to measure the heartbeat, temperature, and to detect falls. The data from sensors and fall notification is shown through web-based smart phone application. Systems based on wearable healthcare devices were reviewed both in commercial efforts and scientific papers <ce:cross-refs id=""""crf0046"""" refid=""""bib0032 bib0033 bib0034"""">[32–34][[ refid=''''bib0032 bib0033 bib0034'''' ]]</ce:cross-refs>. This review determined the design architecture of IoT in the medical field, including software and hardware dealing with sensors, medical application, and smart phones for diagnosis. A gateway between sensor network and the Internet in IoT-based healthcare system was proposed to translate the protocols used in sensor network and the Internet <ce:cross-ref id=""""crf0048"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref>. This gateway contains control knowledge for both the sensor network and the data transmitted through the Internet in healthcare IoT system.</ce:para>""''"'	cites	FDY	
cites	Type-2 fuzzy logic and fuzzy ontology–based decision-making knowledge layer	J.J. Liu, M.C. Huang, W. Xu, N. Alshurafa, M. Sarrafzadeh, On-bed monitoring for range of motion exercises with a pressure sensitive bedsheet , None (2013)	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0058	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0051		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0070	'There are four types for range of motion (ROM), which can be used to examine the patient''s body movement: passive ROM, active-assisted ROM, active ROM, and active self–assisted ROM [58][[ refid=''bib0058'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0025"""" view=""""all"""">A sensor ontology is a personalized solution for chronic patient monitoring. This ontology is linked to the patient ontology and the knowledge and rule–based ontology. Apart from instances (name, age, id, weight, etc.) of the patient ontology, different rules in the knowledge and rule–based ontology are defined for each sensor test. The main aim of this sensor ontology is to describe and mange those data that are needed for monitoring and task execution. There are two kinds of test for patient monitoring: questionnaires and body measurements. A lot of research has been done on questionnaires <ce:cross-refs id=""""crf0094"""" refid=""""bib0014 bib0015 bib0056"""">[14,15,56][[ refid=''''bib0014 bib0015 bib0056'''' ]]</ce:cross-refs>. However, there are still limitations to intelligent semantic knowledge for body measurements in IoT-based health prescription systems. Therefore, body measurement using sensors and their instances in the ontology are configured in order to know about patient activities and health conditions. This ontology contains 8 measurement sensors as instances of the class daily-sensor-test-results. The class daily-sensor-test-results has subclasses, and every subclass has instances with the same name of the class. These instances are blood sugar, glycated hemoglobin (HBA1C), blood pressure, cholesterol, heart rate, motion, weight, and height. With every measurement, the physician needs a camera to retrieve patient information like the patient''''s position (sitting, walking, sleeping, or standing), for which arm is used for the blood pressure sensor, and for the types of foods the patient ate and drank in the previous hour. These sensors (as input variables) and the fuzzy linguistic data types and MFs are described as follows.<ce:list id=""""celist0002""""><ce:list-item id=""""celistitem0007""""><ce:label>1.</ce:label><ce:para id=""""para0026"""" view=""""all"""">Blood pressure: The pressure exerted by circulating blood on the walls of blood vessels is called blood pressure <ce:cross-ref id=""""crf0097"""" refid=""""bib0057"""">[57][[ refid=''''bib0057'''' ]]</ce:cross-ref>. There are three types of blood pressure: systolic, diastolic, and mean arterial pressure (MAP), which are described as subclasses of blood pressure in the ontology. In our proposed system, systolic pressure is used for measurement. There are five fuzzy sets of blood pressure. These fuzzy sets with OWL data–range expressions are as follows: Very-Low (double [&gt; = 0.0] and double [&lt; = 90.0]), Low (double [&gt; = 71.0] and double [&lt; = 130.0]), Medium (double [&gt; = 125.0] and double [&lt; = 154.0]), High (double [&gt; = 142.0] and double [&lt; = 180.0]), and Very-High (double [&gt; = 165.0] and double [&lt; = 250.0]).</ce:para></ce:list-item><ce:list-item id=""""celistitem0008""""><ce:label>2.</ce:label><ce:para id=""""para0027"""" view=""""all"""">Blood sugar: Blood sugar, or blood glucose, supplies energy to all cells of the body. However, it is very important to keep it in a normal range. There are two ways to measure blood sugar: millimoles per liter (mmol/L) and milligrams per deciliter (mg/dL). This system uses milligrams per deciliter. The ontology contains five fuzzy sets for blood sugar. These fuzzy sets with fuzzy OWL data expressions are as follows: Very-Low (double [&gt; = 0.0] and double [&lt; = 45.0]), Low (double [&gt; = 30.0] and double [&lt; = 90.0]), Medium (double [&gt; = 75.0] and double [&lt; = 160.0]), High (double [&gt; = 140.0] and double [&lt; = 200.0]), and Very-High (double [&gt; = 180.0] and double [&lt; = 300.0]).</ce:para></ce:list-item><ce:list-item id=""""celistitem0009""""><ce:label>3.</ce:label><ce:para id=""""para0028"""" view=""""all"""">Cholesterol: Cholesterol is produced from food and the body. The physician always determines the chronic patient''''s cholesterol level before prescribing medication, because it predicts the patient''''s risk of heart disease <ce:cross-ref id=""""crf0098"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. There are two kinds of cholesterol, high-density lipoprotein (HDL), or “good” cholesterol, and low-density lipoprotein (LDL) or “bad” cholesterol. This system considers the LDL cholesterol level. The cholesterol fuzzy sets with ranges are as follows. Very-Low (double [&gt; = 0.0] and double [&lt; = 170.0]), Low (double [&gt; = 150.0] and double [&lt; = 200.0]), Medium (double [&gt; = 180.0] and double [&lt; = 250.0]), High (double [&gt; = 225.0] and double [&lt; = 315.0]), and Very-High (double [&gt; = 280.0] and double [&lt; = 400.0]).</ce:para></ce:list-item><ce:list-item id=""""celistitem0010""""><ce:label>4.</ce:label><ce:para id=""""para0029"""" view=""""all"""">Movement speed of the body: This input variable is used to find movement speed of an old patient''''s body. There are four types for range of motion (ROM), which can be used to examine the patient''''s body movement: passive ROM, active-assisted ROM, active ROM, and active self–assisted ROM <ce:cross-ref id=""""crf0099"""" refid=""""bib0058"""">[58][[ refid=''''bib0058'''' ]]</ce:cross-ref>. In this proposed system, active ROM (movement by the patient alone) is described to find the movement degree of the patient''''s body. There are five fuzzy linguistic sets for body movement. These sets, along with their ranges, are as follows: Very-Low (double [&gt; = 0.0] and double [&lt; = 10.0]), Low (double [&gt; = 8.0] and double [&lt; = 30.0]), Medium (double [&gt; = 25.0] and double [&lt; = 40.0]), High (double [&gt; = 35.0] and double [&lt; = 50.0]), and Very-High (double [&gt; = 45.0] and double [&lt; = 70.0]).</ce:para></ce:list-item><ce:list-item id=""""celistitem0011""""><ce:label>5.</ce:label><ce:para id=""""para0030"""" view=""""all"""">Heart rate: It has been confirmed that daily heart rate analysis of diabetes patients is important for detecting and treating heart disease in its early stages <ce:cross-ref id=""""crf0100"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. Therefore, this system uses three fuzzy variables for heart rate to compute the patient''''s health condition. These fuzzy sets, along with ranges, are as follows. Low (double [&gt; = 30] and double [&lt; = 60.0]), Medium (double [&gt; = 50.0] and double [&lt; = 100.0]) and High (double [&gt; = 95.0] and double [ &lt; = 120.0].</ce:para></ce:list-item><ce:list-item id=""""celistitem0012""""><ce:label>6.</ce:label><ce:para id=""""para0031"""" view=""""all"""">Age: This input variable is divided into five linguistic asset value variables (Very Young, Young, Mild, Old, Very Old). These linguistic variables, along with their ranges, are as follows: Very Young (double [&gt; = 0.0] and double [&lt; = 20.0]), Young (double [&gt; = 16.0] and double [&lt; = 38.0]), Mild (double [&gt; = 35.0] and double [&lt; = 50.0], Old (double [&gt; = 45.0] and double [ &lt; = 60.0] and Very Old (double [&gt; = 55.0] and double [&lt; = 65.0].</ce:para></ce:list-item><ce:list-item id=""""celistitem0013""""><ce:label>7.</ce:label><ce:para id=""""para0032"""" view=""""all"""">Weight: This input variable has three fuzzy sets (Light, Normal, and Heavy). The ranges of these variables in the ontology are: Light (double [&gt; = 0.0] and double [&lt; = 45.0]), Normal (double [&gt; = 35.0] and double [&lt; = 75.0]) and Heavy (double [&gt; = 95.0] and double [&lt; = 140.0].</ce:para></ce:list-item><ce:list-item id=""""celistitem0014""""><ce:label>8.</ce:label><ce:para id=""""para0033"""" view=""""all"""">Sex and Height: The variable sex is crisp and contains two values (0 and 1). Therefore, two subclasses of ‘sex’ along with instances (male and female) are described in the ontology. If the patient is male, then the value is 0, and if the patient is female, then 1 is assigned during computation of the patient condition. Height is also an important factor for diabetes patient treatment, because other variables, like weight, depend on it. However, very limited changes occur in patient height; therefore, it is described in the ontology for food recommendations, and is not considered during the patient condition value computation.</ce:para></ce:list-item><ce:list-item id=""""celistitem0015""""><ce:label>9.</ce:label><ce:para id=""""para0034"""" view=""""all"""">Patient health condition: This output variable defines the patient health condition. It is dependent on the type-2 fuzzy inference mechanism of the above-mentioned input variables. The fuzzy sets of this output variable are Healthy, Moderate, and Serious, and their ranges are: Healthy (double [&gt; = 0.0] and double [&lt; = 5.0]), Moderate (double [&gt; = 2.5] and double [&lt; = 7.5.0]), and Serious (double [&gt; = 5.0] and double [&lt; = 10.0]. The proposed system helps the medical staff by automatically informing them about the patient''''s health condition; for example, if the patient condition value is in range 0 ∼ 5, the system shows that the patient condition is healthy. If the value is in range of 2.5 ∼ 7.5, the system informs the medical staff to start regular services, and it automatically recommends drugs and foods for the patient using decision-making knowledge from the fuzzy ontology. If the patient condition value is in the range 5 ∼ 10, the system indicates that the patient''''s condition is serious, calls emergency services or rescue units, and spontaneously changes food and drug recommendations. The MFs of this output variable are shown in <ce:cross-ref id=""""crf0101"""" refid=""""fig0006"""">Fig. 6</ce:cross-ref><ce:float-anchor refid=""""fig0006""""/>(h). The type-1 fuzzy sets are shown as a thin line, whereas the interval type-2 fuzzy sets are shown as a thick line.</ce:para></ce:list-item></ce:list></ce:para>""''"'	cites	FDY	
cites	Research works	A. Adeli, M. Neshat, A fuzzy expert system for heart disease diagnosis , Proceedings of the International MultiConference of Engineeers and Computer Scientists. I (2010)	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0022	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0013		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0072	'The Mamdani inference method is used for heart disease diagnosis [22][[ refid=''bib0022'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">The IoT and wearable monitoring system is an emerging technology that is expected to contribute a wide range of healthcare applications in the future <ce:cross-refs id=""""crf0030"""" refid=""""bib0002 bib0003 bib0009 bib0020 bib0021"""">[2,3,9,20,21][[ refid=''''bib0002 bib0003 bib0009 bib0020 bib0021'''' ]]</ce:cross-refs>. A system to capture physiological data of a person under care using IoT sensors was presented by Chiang and Liang <ce:cross-ref id=""""crf0035"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>. This system combined a context-aware space with IoT technology to automate healthcare services and assist chronic patients. The main problem with their method is that when the chronic patient risk factors increase, the system is unable to find the correct risk value. In addition, a classic ontology approach is not useful in supporting a fuzzy logic–based system during information extraction from an uncertain patient disease history and unknown risk factors. The Mamdani inference method is used for heart disease diagnosis <ce:cross-ref id=""""crf0036"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>. This system has 13 input features and one output feature in order to find the presence of heart disease in a patient. However, the existing system needs semantic knowledge that is specific to each disease. An analysis of heart rate variability signals is computed using fuzzy measure entropy (FuzzyMEn) <ce:cross-ref id=""""crf0037"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. The system overcomes the poor statistical stability of two entropy measures, which are based on the Heaviside step function of the classical sets. This system used fuzzy logic instead of Heaviside, and achieved better results than approximate entropy (ApEn) and sample entropy (SampEn). Kumar and Kaur used a fuzzy expert system to detect heart disease in patients <ce:cross-ref id=""""crf0038"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>. This system contains six input fields (blood pressure, cholesterol, chest pain type, maximum heart rate, blood sugar, and old peak) and two output fields (heart disease and precautions). However, this system is insufficient in terms of factors and semantic relationships amongst the patient''''s medical data. A computational intelligence model based on fuzzy logic was proposed to handle ambiguity and vagueness in clinical knowledge and data <ce:cross-ref id=""""crf0039"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. This method overcomes the interpretation problem of the common monitoring system called a cardiotocograph (CTG), which is based on a fetal heart rate pattern and maternal contraction. A fuzzy logic–based method for fault-tolerant wireless sensor networks was proposed to monitor diagnosis and testing systems in a large-scale context <ce:cross-ref id=""""crf0040"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>. However, a large storage space in the IoT is used when small movement is detected by a sensor. The mentioned method extracts limited information because of limited semantic knowledge. A single ontology is insufficient to tolerate the IoT''''s faults. It is important to make multiple ontologies for diagnosis and testing, which can provide intelligent knowledge to retrieve precise data for fault-tolerance problems in the IoT. A fuzzy approach was used in an IoT-based healthcare monitoring system to find abnormal conditions in a patient <ce:cross-ref id=""""crf0041"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>. This system helps a physician to select the affected parameters and avoids unnecessary information transmission to the physician. A fuzzy logic and thermistor sensor–based approach was proposed for monitoring and early detection of residential fire <ce:cross-ref id=""""crf0042"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. This proposed system uses two fuzzy methods with temporal characteristics to monitor and determine confidence about the presence of fire in order to decrease and improve the number of rules that are employed to make correct decisions. A model driven approach was presented to design and develop smart IoT-based system <ce:cross-ref id=""""crf0043"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref>. A set of design pattern is defined in this method to syndicate cognitive and autonomic principals for providing a precise solution according to the system needs. A fuzzy prolog and ontology-based framework was proposed to detect health anomalies in real-time using IoT devices <ce:cross-ref id=""""crf0044"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. This existing ontology gives hints about diseases that are currently going on. However, simple ontology may not be able to handle real-time sensor''''s data for having a complete detail of a patient. Wearable devices with solar-energy harvesting were presented to ease the implementation of an autonomous wireless body area network (WBAN) <ce:cross-ref id=""""crf0045"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>. Different sensors are employed on various positions of the body to measure the heartbeat, temperature, and to detect falls. The data from sensors and fall notification is shown through web-based smart phone application. Systems based on wearable healthcare devices were reviewed both in commercial efforts and scientific papers <ce:cross-refs id=""""crf0046"""" refid=""""bib0032 bib0033 bib0034"""">[32–34][[ refid=''''bib0032 bib0033 bib0034'''' ]]</ce:cross-refs>. This review determined the design architecture of IoT in the medical field, including software and hardware dealing with sensors, medical application, and smart phones for diagnosis. A gateway between sensor network and the Internet in IoT-based healthcare system was proposed to translate the protocols used in sensor network and the Internet <ce:cross-ref id=""""crf0048"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref>. This gateway contains control knowledge for both the sensor network and the data transmitted through the Internet in healthcare IoT system.</ce:para>""''"'	uses_method_in	FDY	
cites	Research works	C. T.-C., T.C. Chiang, W.H. Liang, A context-aware interactive health care system based on ontology and fuzzy inference , J. Med. Syst. , vol. 39 (2015), pp.None	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0008	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0012		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0073	'A system to capture physiological data of a person under care using IoT sensors was presented by Chiang and Liang [8][[ refid=''bib0008'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">The IoT and wearable monitoring system is an emerging technology that is expected to contribute a wide range of healthcare applications in the future <ce:cross-refs id=""""crf0030"""" refid=""""bib0002 bib0003 bib0009 bib0020 bib0021"""">[2,3,9,20,21][[ refid=''''bib0002 bib0003 bib0009 bib0020 bib0021'''' ]]</ce:cross-refs>. A system to capture physiological data of a person under care using IoT sensors was presented by Chiang and Liang <ce:cross-ref id=""""crf0035"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>. This system combined a context-aware space with IoT technology to automate healthcare services and assist chronic patients. The main problem with their method is that when the chronic patient risk factors increase, the system is unable to find the correct risk value. In addition, a classic ontology approach is not useful in supporting a fuzzy logic–based system during information extraction from an uncertain patient disease history and unknown risk factors. The Mamdani inference method is used for heart disease diagnosis <ce:cross-ref id=""""crf0036"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>. This system has 13 input features and one output feature in order to find the presence of heart disease in a patient. However, the existing system needs semantic knowledge that is specific to each disease. An analysis of heart rate variability signals is computed using fuzzy measure entropy (FuzzyMEn) <ce:cross-ref id=""""crf0037"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. The system overcomes the poor statistical stability of two entropy measures, which are based on the Heaviside step function of the classical sets. This system used fuzzy logic instead of Heaviside, and achieved better results than approximate entropy (ApEn) and sample entropy (SampEn). Kumar and Kaur used a fuzzy expert system to detect heart disease in patients <ce:cross-ref id=""""crf0038"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>. This system contains six input fields (blood pressure, cholesterol, chest pain type, maximum heart rate, blood sugar, and old peak) and two output fields (heart disease and precautions). However, this system is insufficient in terms of factors and semantic relationships amongst the patient''''s medical data. A computational intelligence model based on fuzzy logic was proposed to handle ambiguity and vagueness in clinical knowledge and data <ce:cross-ref id=""""crf0039"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. This method overcomes the interpretation problem of the common monitoring system called a cardiotocograph (CTG), which is based on a fetal heart rate pattern and maternal contraction. A fuzzy logic–based method for fault-tolerant wireless sensor networks was proposed to monitor diagnosis and testing systems in a large-scale context <ce:cross-ref id=""""crf0040"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>. However, a large storage space in the IoT is used when small movement is detected by a sensor. The mentioned method extracts limited information because of limited semantic knowledge. A single ontology is insufficient to tolerate the IoT''''s faults. It is important to make multiple ontologies for diagnosis and testing, which can provide intelligent knowledge to retrieve precise data for fault-tolerance problems in the IoT. A fuzzy approach was used in an IoT-based healthcare monitoring system to find abnormal conditions in a patient <ce:cross-ref id=""""crf0041"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>. This system helps a physician to select the affected parameters and avoids unnecessary information transmission to the physician. A fuzzy logic and thermistor sensor–based approach was proposed for monitoring and early detection of residential fire <ce:cross-ref id=""""crf0042"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. This proposed system uses two fuzzy methods with temporal characteristics to monitor and determine confidence about the presence of fire in order to decrease and improve the number of rules that are employed to make correct decisions. A model driven approach was presented to design and develop smart IoT-based system <ce:cross-ref id=""""crf0043"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref>. A set of design pattern is defined in this method to syndicate cognitive and autonomic principals for providing a precise solution according to the system needs. A fuzzy prolog and ontology-based framework was proposed to detect health anomalies in real-time using IoT devices <ce:cross-ref id=""""crf0044"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. This existing ontology gives hints about diseases that are currently going on. However, simple ontology may not be able to handle real-time sensor''''s data for having a complete detail of a patient. Wearable devices with solar-energy harvesting were presented to ease the implementation of an autonomous wireless body area network (WBAN) <ce:cross-ref id=""""crf0045"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>. Different sensors are employed on various positions of the body to measure the heartbeat, temperature, and to detect falls. The data from sensors and fall notification is shown through web-based smart phone application. Systems based on wearable healthcare devices were reviewed both in commercial efforts and scientific papers <ce:cross-refs id=""""crf0046"""" refid=""""bib0032 bib0033 bib0034"""">[32–34][[ refid=''''bib0032 bib0033 bib0034'''' ]]</ce:cross-refs>. This review determined the design architecture of IoT in the medical field, including software and hardware dealing with sensors, medical application, and smart phones for diagnosis. A gateway between sensor network and the Internet in IoT-based healthcare system was proposed to translate the protocols used in sensor network and the Internet <ce:cross-ref id=""""crf0048"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref>. This gateway contains control knowledge for both the sensor network and the data transmitted through the Internet in healthcare IoT system.</ce:para>""''"'	uses_data_from	FDY	
cites	Research works	Y. Benazzouz, O.E.K. Aktouf, I. Parissis, A fault fuzzy-ontology for large scale fault-tolerant wireless sensor networks , Procedia Comput. Sci. , vol. 35 (2014), pp.203-212	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0026	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0017		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0082	'A fuzzy logic–based method for fault-tolerant wireless sensor networks was proposed to monitor diagnosis and testing systems in a large-scale context [26][[ refid=''bib0026'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">The IoT and wearable monitoring system is an emerging technology that is expected to contribute a wide range of healthcare applications in the future <ce:cross-refs id=""""crf0030"""" refid=""""bib0002 bib0003 bib0009 bib0020 bib0021"""">[2,3,9,20,21][[ refid=''''bib0002 bib0003 bib0009 bib0020 bib0021'''' ]]</ce:cross-refs>. A system to capture physiological data of a person under care using IoT sensors was presented by Chiang and Liang <ce:cross-ref id=""""crf0035"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>. This system combined a context-aware space with IoT technology to automate healthcare services and assist chronic patients. The main problem with their method is that when the chronic patient risk factors increase, the system is unable to find the correct risk value. In addition, a classic ontology approach is not useful in supporting a fuzzy logic–based system during information extraction from an uncertain patient disease history and unknown risk factors. The Mamdani inference method is used for heart disease diagnosis <ce:cross-ref id=""""crf0036"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>. This system has 13 input features and one output feature in order to find the presence of heart disease in a patient. However, the existing system needs semantic knowledge that is specific to each disease. An analysis of heart rate variability signals is computed using fuzzy measure entropy (FuzzyMEn) <ce:cross-ref id=""""crf0037"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. The system overcomes the poor statistical stability of two entropy measures, which are based on the Heaviside step function of the classical sets. This system used fuzzy logic instead of Heaviside, and achieved better results than approximate entropy (ApEn) and sample entropy (SampEn). Kumar and Kaur used a fuzzy expert system to detect heart disease in patients <ce:cross-ref id=""""crf0038"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>. This system contains six input fields (blood pressure, cholesterol, chest pain type, maximum heart rate, blood sugar, and old peak) and two output fields (heart disease and precautions). However, this system is insufficient in terms of factors and semantic relationships amongst the patient''''s medical data. A computational intelligence model based on fuzzy logic was proposed to handle ambiguity and vagueness in clinical knowledge and data <ce:cross-ref id=""""crf0039"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. This method overcomes the interpretation problem of the common monitoring system called a cardiotocograph (CTG), which is based on a fetal heart rate pattern and maternal contraction. A fuzzy logic–based method for fault-tolerant wireless sensor networks was proposed to monitor diagnosis and testing systems in a large-scale context <ce:cross-ref id=""""crf0040"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>. However, a large storage space in the IoT is used when small movement is detected by a sensor. The mentioned method extracts limited information because of limited semantic knowledge. A single ontology is insufficient to tolerate the IoT''''s faults. It is important to make multiple ontologies for diagnosis and testing, which can provide intelligent knowledge to retrieve precise data for fault-tolerance problems in the IoT. A fuzzy approach was used in an IoT-based healthcare monitoring system to find abnormal conditions in a patient <ce:cross-ref id=""""crf0041"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>. This system helps a physician to select the affected parameters and avoids unnecessary information transmission to the physician. A fuzzy logic and thermistor sensor–based approach was proposed for monitoring and early detection of residential fire <ce:cross-ref id=""""crf0042"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. This proposed system uses two fuzzy methods with temporal characteristics to monitor and determine confidence about the presence of fire in order to decrease and improve the number of rules that are employed to make correct decisions. A model driven approach was presented to design and develop smart IoT-based system <ce:cross-ref id=""""crf0043"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref>. A set of design pattern is defined in this method to syndicate cognitive and autonomic principals for providing a precise solution according to the system needs. A fuzzy prolog and ontology-based framework was proposed to detect health anomalies in real-time using IoT devices <ce:cross-ref id=""""crf0044"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. This existing ontology gives hints about diseases that are currently going on. However, simple ontology may not be able to handle real-time sensor''''s data for having a complete detail of a patient. Wearable devices with solar-energy harvesting were presented to ease the implementation of an autonomous wireless body area network (WBAN) <ce:cross-ref id=""""crf0045"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>. Different sensors are employed on various positions of the body to measure the heartbeat, temperature, and to detect falls. The data from sensors and fall notification is shown through web-based smart phone application. Systems based on wearable healthcare devices were reviewed both in commercial efforts and scientific papers <ce:cross-refs id=""""crf0046"""" refid=""""bib0032 bib0033 bib0034"""">[32–34][[ refid=''''bib0032 bib0033 bib0034'''' ]]</ce:cross-refs>. This review determined the design architecture of IoT in the medical field, including software and hardware dealing with sensors, medical application, and smart phones for diagnosis. A gateway between sensor network and the Internet in IoT-based healthcare system was proposed to translate the protocols used in sensor network and the Internet <ce:cross-ref id=""""crf0048"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref>. This gateway contains control knowledge for both the sensor network and the data transmitted through the Internet in healthcare IoT system.</ce:para>""''"'	uses_method_in	FDY	
cites	Research works	E.C. Ifeachor, J.S.K. Curnow, N.J. Outram, J.F. Skinner, Models for handling uncertainty in fetal heart rate and ECG analysis , International Conference on EMBS , vol. 2 (2001), pp.1661-1667	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0025	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0016		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0083	'A computational intelligence model based on fuzzy logic was proposed to handle ambiguity and vagueness in clinical knowledge and data [25][[ refid=''bib0025'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">The IoT and wearable monitoring system is an emerging technology that is expected to contribute a wide range of healthcare applications in the future <ce:cross-refs id=""""crf0030"""" refid=""""bib0002 bib0003 bib0009 bib0020 bib0021"""">[2,3,9,20,21][[ refid=''''bib0002 bib0003 bib0009 bib0020 bib0021'''' ]]</ce:cross-refs>. A system to capture physiological data of a person under care using IoT sensors was presented by Chiang and Liang <ce:cross-ref id=""""crf0035"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>. This system combined a context-aware space with IoT technology to automate healthcare services and assist chronic patients. The main problem with their method is that when the chronic patient risk factors increase, the system is unable to find the correct risk value. In addition, a classic ontology approach is not useful in supporting a fuzzy logic–based system during information extraction from an uncertain patient disease history and unknown risk factors. The Mamdani inference method is used for heart disease diagnosis <ce:cross-ref id=""""crf0036"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>. This system has 13 input features and one output feature in order to find the presence of heart disease in a patient. However, the existing system needs semantic knowledge that is specific to each disease. An analysis of heart rate variability signals is computed using fuzzy measure entropy (FuzzyMEn) <ce:cross-ref id=""""crf0037"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. The system overcomes the poor statistical stability of two entropy measures, which are based on the Heaviside step function of the classical sets. This system used fuzzy logic instead of Heaviside, and achieved better results than approximate entropy (ApEn) and sample entropy (SampEn). Kumar and Kaur used a fuzzy expert system to detect heart disease in patients <ce:cross-ref id=""""crf0038"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>. This system contains six input fields (blood pressure, cholesterol, chest pain type, maximum heart rate, blood sugar, and old peak) and two output fields (heart disease and precautions). However, this system is insufficient in terms of factors and semantic relationships amongst the patient''''s medical data. A computational intelligence model based on fuzzy logic was proposed to handle ambiguity and vagueness in clinical knowledge and data <ce:cross-ref id=""""crf0039"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. This method overcomes the interpretation problem of the common monitoring system called a cardiotocograph (CTG), which is based on a fetal heart rate pattern and maternal contraction. A fuzzy logic–based method for fault-tolerant wireless sensor networks was proposed to monitor diagnosis and testing systems in a large-scale context <ce:cross-ref id=""""crf0040"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>. However, a large storage space in the IoT is used when small movement is detected by a sensor. The mentioned method extracts limited information because of limited semantic knowledge. A single ontology is insufficient to tolerate the IoT''''s faults. It is important to make multiple ontologies for diagnosis and testing, which can provide intelligent knowledge to retrieve precise data for fault-tolerance problems in the IoT. A fuzzy approach was used in an IoT-based healthcare monitoring system to find abnormal conditions in a patient <ce:cross-ref id=""""crf0041"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>. This system helps a physician to select the affected parameters and avoids unnecessary information transmission to the physician. A fuzzy logic and thermistor sensor–based approach was proposed for monitoring and early detection of residential fire <ce:cross-ref id=""""crf0042"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. This proposed system uses two fuzzy methods with temporal characteristics to monitor and determine confidence about the presence of fire in order to decrease and improve the number of rules that are employed to make correct decisions. A model driven approach was presented to design and develop smart IoT-based system <ce:cross-ref id=""""crf0043"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref>. A set of design pattern is defined in this method to syndicate cognitive and autonomic principals for providing a precise solution according to the system needs. A fuzzy prolog and ontology-based framework was proposed to detect health anomalies in real-time using IoT devices <ce:cross-ref id=""""crf0044"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. This existing ontology gives hints about diseases that are currently going on. However, simple ontology may not be able to handle real-time sensor''''s data for having a complete detail of a patient. Wearable devices with solar-energy harvesting were presented to ease the implementation of an autonomous wireless body area network (WBAN) <ce:cross-ref id=""""crf0045"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>. Different sensors are employed on various positions of the body to measure the heartbeat, temperature, and to detect falls. The data from sensors and fall notification is shown through web-based smart phone application. Systems based on wearable healthcare devices were reviewed both in commercial efforts and scientific papers <ce:cross-refs id=""""crf0046"""" refid=""""bib0032 bib0033 bib0034"""">[32–34][[ refid=''''bib0032 bib0033 bib0034'''' ]]</ce:cross-refs>. This review determined the design architecture of IoT in the medical field, including software and hardware dealing with sensors, medical application, and smart phones for diagnosis. A gateway between sensor network and the Internet in IoT-based healthcare system was proposed to translate the protocols used in sensor network and the Internet <ce:cross-ref id=""""crf0048"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref>. This gateway contains control knowledge for both the sensor network and the data transmitted through the Internet in healthcare IoT system.</ce:para>""''"'	uses_data_from	FDY	
cites	Research works	C. Liu, K. Li, L. Zhao, F. Liu, D. Zheng, C. Liu, S. Liu, Analysis of heart rate variability using fuzzy measure entropy , Comput. Biol. Med. , vol. 43 (2013), pp.100-108	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0014		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0085	'An analysis of heart rate variability signals is computed using fuzzy measure entropy (FuzzyMEn) [23][[ refid=''bib0023'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">The IoT and wearable monitoring system is an emerging technology that is expected to contribute a wide range of healthcare applications in the future <ce:cross-refs id=""""crf0030"""" refid=""""bib0002 bib0003 bib0009 bib0020 bib0021"""">[2,3,9,20,21][[ refid=''''bib0002 bib0003 bib0009 bib0020 bib0021'''' ]]</ce:cross-refs>. A system to capture physiological data of a person under care using IoT sensors was presented by Chiang and Liang <ce:cross-ref id=""""crf0035"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>. This system combined a context-aware space with IoT technology to automate healthcare services and assist chronic patients. The main problem with their method is that when the chronic patient risk factors increase, the system is unable to find the correct risk value. In addition, a classic ontology approach is not useful in supporting a fuzzy logic–based system during information extraction from an uncertain patient disease history and unknown risk factors. The Mamdani inference method is used for heart disease diagnosis <ce:cross-ref id=""""crf0036"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>. This system has 13 input features and one output feature in order to find the presence of heart disease in a patient. However, the existing system needs semantic knowledge that is specific to each disease. An analysis of heart rate variability signals is computed using fuzzy measure entropy (FuzzyMEn) <ce:cross-ref id=""""crf0037"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. The system overcomes the poor statistical stability of two entropy measures, which are based on the Heaviside step function of the classical sets. This system used fuzzy logic instead of Heaviside, and achieved better results than approximate entropy (ApEn) and sample entropy (SampEn). Kumar and Kaur used a fuzzy expert system to detect heart disease in patients <ce:cross-ref id=""""crf0038"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>. This system contains six input fields (blood pressure, cholesterol, chest pain type, maximum heart rate, blood sugar, and old peak) and two output fields (heart disease and precautions). However, this system is insufficient in terms of factors and semantic relationships amongst the patient''''s medical data. A computational intelligence model based on fuzzy logic was proposed to handle ambiguity and vagueness in clinical knowledge and data <ce:cross-ref id=""""crf0039"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. This method overcomes the interpretation problem of the common monitoring system called a cardiotocograph (CTG), which is based on a fetal heart rate pattern and maternal contraction. A fuzzy logic–based method for fault-tolerant wireless sensor networks was proposed to monitor diagnosis and testing systems in a large-scale context <ce:cross-ref id=""""crf0040"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>. However, a large storage space in the IoT is used when small movement is detected by a sensor. The mentioned method extracts limited information because of limited semantic knowledge. A single ontology is insufficient to tolerate the IoT''''s faults. It is important to make multiple ontologies for diagnosis and testing, which can provide intelligent knowledge to retrieve precise data for fault-tolerance problems in the IoT. A fuzzy approach was used in an IoT-based healthcare monitoring system to find abnormal conditions in a patient <ce:cross-ref id=""""crf0041"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>. This system helps a physician to select the affected parameters and avoids unnecessary information transmission to the physician. A fuzzy logic and thermistor sensor–based approach was proposed for monitoring and early detection of residential fire <ce:cross-ref id=""""crf0042"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. This proposed system uses two fuzzy methods with temporal characteristics to monitor and determine confidence about the presence of fire in order to decrease and improve the number of rules that are employed to make correct decisions. A model driven approach was presented to design and develop smart IoT-based system <ce:cross-ref id=""""crf0043"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref>. A set of design pattern is defined in this method to syndicate cognitive and autonomic principals for providing a precise solution according to the system needs. A fuzzy prolog and ontology-based framework was proposed to detect health anomalies in real-time using IoT devices <ce:cross-ref id=""""crf0044"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. This existing ontology gives hints about diseases that are currently going on. However, simple ontology may not be able to handle real-time sensor''''s data for having a complete detail of a patient. Wearable devices with solar-energy harvesting were presented to ease the implementation of an autonomous wireless body area network (WBAN) <ce:cross-ref id=""""crf0045"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>. Different sensors are employed on various positions of the body to measure the heartbeat, temperature, and to detect falls. The data from sensors and fall notification is shown through web-based smart phone application. Systems based on wearable healthcare devices were reviewed both in commercial efforts and scientific papers <ce:cross-refs id=""""crf0046"""" refid=""""bib0032 bib0033 bib0034"""">[32–34][[ refid=''''bib0032 bib0033 bib0034'''' ]]</ce:cross-refs>. This review determined the design architecture of IoT in the medical field, including software and hardware dealing with sensors, medical application, and smart phones for diagnosis. A gateway between sensor network and the Internet in IoT-based healthcare system was proposed to translate the protocols used in sensor network and the Internet <ce:cross-ref id=""""crf0048"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref>. This gateway contains control knowledge for both the sensor network and the data transmitted through the Internet in healthcare IoT system.</ce:para>""''"'	cites	FDY	
uses_method_in	The design architecture of the proposed system	R.C. Chen, Y.H. Huang, C.T. Bau, S.M. Chen, A recommendation system based on domain ontology and SWRL for anti-diabetic drugs selection , Expert Syst. Appl. , vol. 39 (2012), pp.3995-4006	http://dx.doi.org/10.1016/j.comcom.2017.10.005			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/br/bib0054	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/ctx/ctx0044		62	6	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2017-10-005/itrp/0086	'The diabetes drug and food information is gathered from the Internet and research articles, and classified manually under the supervision of domain experts [54][[ refid=''bib0054'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0022"""" view=""""all"""">In this section, we illustrate the proposed healthcare monitoring and recommendation system with the help of a functional diagram that can be considered as the internal workflow of the proposed architecture. In the IoT, the health prescription process for chronic patients (patients who deserve long-term treatment and assistance) needs the data simultaneously in order to evaluate the patient''''s health condition <ce:cross-refs id=""""crf0084"""" refid=""""bib0007 bib0053"""">[7,53][[ refid=''''bib0007 bib0053'''' ]]</ce:cross-refs>. These data are managed through decision-making knowledge provided by physicians. This decision-making knowledge includes instructions to evaluate the test results and to measure patient frequencies through sensors. These test results and frequency measurements are intelligently classified using type-2 fuzzy logic to describe the patient''''s health condition. Decision-making knowledge also includes instructions to recommend medicines and foods. It is connected to a smart medicine box and a smart refrigerator to effectively recommend drugs and foods according to the patient''''s health condition. All this information includes the patient''''s, nurses’, and physicians’ personal data, evaluation of test results, physicians’ instructions, T2FL-based classifications, and drug and food recommendations designed in an ontology to represent decision-making knowledge (as a health prescription system) for long-term care of chronic-disease patients. The architecture of this system is based on a security layer and a decision-making knowledge layer, as shown in <ce:cross-ref id=""""crf0086"""" refid=""""fig0003"""">Fig. 3</ce:cross-ref><ce:float-anchor refid=""""fig0003""""/>. The security layer prevents unauthorized access to medical devices, and investigates the true condition of the right patient before assigning drugs and food. The patient ontology retrieves the patient''''s personal information (age, weight, height, sex, etc.) and disease history from the database. Different sensors collect physical data (cholesterol and blood sugar levels, blood pressure, heart rate, body motion, kidney function, electromyography (EMG), electrocardiogram (ECG) etc.) storing them in a sensor ontology. These data are also the input variables for fuzzification, which maps these variables into a type-2 fuzzy membership function (T2FMF) to make a set of intervals for T1Fs. The inference part assigns fuzzy input variables to fuzzy output variables using the rules in the rule base and operators, such as join (˅) and meet (˄). The rules are described in the knowledge and rule–based ontology. The type reducer transforms the type-2 fuzzy output of the inference function for the T1FSs. Defuzzification calculates the average type reducer, which is the value of the patient health condition. This value is then assigned to the fuzzy ontology for further processing. In the ontologies, the data (output variables) are classified as Very Low (VL), Low (L), Medium (M), High (H), and Very High (VH) in order to recommend drugs and foods according to the patient''''s health condition. This system can handle any type of situation related to the diabetes health prescription domain. The drug and food recommendation ontology and the patient''''s personal ontology are executed offline and must be processed with a health prescription via the concepts of the fuzzy ontology. The recommendation ontology captures the information about diabetes medications, patient test results, and diabetes-friendly foods. Collection of data is a primary task and can help to speed up the construction process of this ontology. The diabetes drug and food information is gathered from the Internet and research articles, and classified manually under the supervision of domain experts <ce:cross-ref id=""""crf0087"""" refid=""""bib0054"""">[54][[ refid=''''bib0054'''' ]]</ce:cross-ref>. Physicians regularly modify the recommendation ontologies, and the smart medicine box and smart refrigerator connect to these ontologies to provide drugs and foods. The next sections elaborate on the internal workings of the proposed system, one by one.</ce:para>""''"'	cites	FDY	
cites	Related work	M.-H. Jang, C. Faloutsos, S.-W. Kim, U. Kang, J. Ha, Pin-trust: Fast trust propagation exploiting positive, implicit, and negative information , Proc. 25th ACM Int. Conf. Inf. Knowl. Manag., ACM (2016)	http://dx.doi.org/10.1016/j.comcom.2018.04.004	related work		http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/br/bib0046	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/ctx/ctx0023		49	7	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/itrp/0002	'Authors in [46][[ refid=''bib0046'' ]] proposed a method called PIN-TRUST to measure the trustworthiness of each user for a target user by employing belief propagation (BP).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0009"""" view=""""all"""">With a variation on the PageRank algorithm, Kamvar et al. <ce:cross-ref id=""""crf0038"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> proposed a distributed trust propagation model called EigenTrust for estimating trust values in P2P networks. EigenTrust measures trust values through iterative multiplication and aggregation of trust values along transitive chains until the trust values for all agents converge to stable values. While the EigenTrust algorithm shows a satisfied performance on simple threat models, it could not offer good attack resilience when encountering more sophisticated threat ones. Authors in <ce:cross-ref id=""""crf0039"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> analyzed the vulnerabilities of EigenTrust and proposed the trust model ServiceTrust which has a better performance on some sophisticated attack models by utilizing pairwise feedback similarity weighted trust propagation into the trust model. Kim and Song <ce:cross-ref id=""""crf0040"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> studied the impact of two factors: the length of trust paths and aggregation functions, on the trust inference accuracy and proposed four strategies for estimating trust based on reinforcement learning. They found that the best combination is the strategy of weighted mean aggregation among all trust paths. Based on this strategy, Kim also proposed an enhanced trust propagation approach by combining a homophily-based trust network with an expertise-based one <ce:cross-ref id=""""crf0041"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. Using this approach, author tackled the sparsity problem of trust networks. Work in <ce:cross-ref id=""""crf0042"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> presented a content-driven trust propagation framework that discovers credible claims and estimates trustworthiness of sources based on the quality of evidence. In fact, their proposed techniques for identifying and scoring relevant posts could be used to instantiate a model for computing the trustworthiness of medical claims and sources. Authors in <ce:cross-ref id=""""crf0043"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref> proposed a method called PIN-TRUST to measure the trustworthiness of each user for a target user by employing belief propagation (BP). PIN-TRUST exploits all kinds of interaction information, including explicit trust, implicit trust and explicit distrust, in the trust prediction process.</ce:para>""''"'	uses_method_in	AGA	
cites	Related work	Y.A. Kim, H.S. Song, Strategies for predicting local trust based on trust propagation in social networks , Knowl. Based Syst. , vol. 24 (2011), pp.1360-1371	http://dx.doi.org/10.1016/j.comcom.2018.04.004	related work		http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/br/bib0007	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/ctx/ctx0020		49	7	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/itrp/0003	'Kim and Song [7][[ refid=''bib0007'' ]] studied the impact of two factors: the length of trust paths and aggregation functions, on the trust inference accuracy and proposed four strategies for estimating trust based on reinforcement learning.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0009"""" view=""""all"""">With a variation on the PageRank algorithm, Kamvar et al. <ce:cross-ref id=""""crf0038"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> proposed a distributed trust propagation model called EigenTrust for estimating trust values in P2P networks. EigenTrust measures trust values through iterative multiplication and aggregation of trust values along transitive chains until the trust values for all agents converge to stable values. While the EigenTrust algorithm shows a satisfied performance on simple threat models, it could not offer good attack resilience when encountering more sophisticated threat ones. Authors in <ce:cross-ref id=""""crf0039"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> analyzed the vulnerabilities of EigenTrust and proposed the trust model ServiceTrust which has a better performance on some sophisticated attack models by utilizing pairwise feedback similarity weighted trust propagation into the trust model. Kim and Song <ce:cross-ref id=""""crf0040"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> studied the impact of two factors: the length of trust paths and aggregation functions, on the trust inference accuracy and proposed four strategies for estimating trust based on reinforcement learning. They found that the best combination is the strategy of weighted mean aggregation among all trust paths. Based on this strategy, Kim also proposed an enhanced trust propagation approach by combining a homophily-based trust network with an expertise-based one <ce:cross-ref id=""""crf0041"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. Using this approach, author tackled the sparsity problem of trust networks. Work in <ce:cross-ref id=""""crf0042"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> presented a content-driven trust propagation framework that discovers credible claims and estimates trustworthiness of sources based on the quality of evidence. In fact, their proposed techniques for identifying and scoring relevant posts could be used to instantiate a model for computing the trustworthiness of medical claims and sources. Authors in <ce:cross-ref id=""""crf0043"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref> proposed a method called PIN-TRUST to measure the trustworthiness of each user for a target user by employing belief propagation (BP). PIN-TRUST exploits all kinds of interaction information, including explicit trust, implicit trust and explicit distrust, in the trust prediction process.</ce:para>""''"'	cites	AGA	
cites	Related work	M. Ghavipour, M.R. Meybodi, Trust propagation algorithm based on learning automata for inferring local trust in online social networks , Knowl. Based Syst. (2017)	http://dx.doi.org/10.1016/j.comcom.2018.04.004	related work		http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/br/bib0009	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/ctx/ctx0026		49	7	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/itrp/0005	'In our previous work on trust propagation [9][[ refid=''bib0009'' ]], we proposed a heuristic trust propagation algorithm based on learning automata, called DLATrust, as well as a new aggregation strategy.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0010"""" view=""""all"""">Another example of trust model with propagation is MeTrust <ce:cross-ref id=""""crf0044"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>, a multi-dimensional evidence-based trust management system. MeTrust uses the Frank t-norm and the weighted average to combine trust values respectively along a path and among multiple paths. In this model, the weight of a trust path is deduced from uncertainty of trust along the path. Work in <ce:cross-ref id=""""crf0045"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref> presented a trust propagation model which includes a landmark based method with a pre-processing. In this method, at the first a small number of landmark users are chosen as referees in trust propagation process, and trust between the landmark users and the others are precomputed. Then, the referrals provided by the landmark users are aggregated to estimate trust between two indirectly connected users. In our previous work on trust propagation <ce:cross-ref id=""""crf0046"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>, we proposed a heuristic trust propagation algorithm based on learning automata, called DLATrust, as well as a new aggregation strategy. We indicated that using our developed aggregation strategy the DLATrust algorithm can efficiently discover reliable trust paths without any search constraints and precisely infer the trust value between two indirectly connected users.</ce:para>""''"'	cites	AGA	
cites	Related work	S. Lyu, J. Liu, M. Tang, Y. Xu, J. Chen, Efficiently predicting trustworthiness of mobile services based on trust propagation in social networks , Mob. Netw. Appl. , vol. 20 (2015), pp.840-852	http://dx.doi.org/10.1016/j.comcom.2018.04.004	related work		http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/br/bib0003	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/ctx/ctx0025		49	7	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/itrp/0008	'Work in [3][[ refid=''bib0003'' ]] presented a trust propagation model which includes a landmark based method with a pre-processing.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0010"""" view=""""all"""">Another example of trust model with propagation is MeTrust <ce:cross-ref id=""""crf0044"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>, a multi-dimensional evidence-based trust management system. MeTrust uses the Frank t-norm and the weighted average to combine trust values respectively along a path and among multiple paths. In this model, the weight of a trust path is deduced from uncertainty of trust along the path. Work in <ce:cross-ref id=""""crf0045"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref> presented a trust propagation model which includes a landmark based method with a pre-processing. In this method, at the first a small number of landmark users are chosen as referees in trust propagation process, and trust between the landmark users and the others are precomputed. Then, the referrals provided by the landmark users are aggregated to estimate trust between two indirectly connected users. In our previous work on trust propagation <ce:cross-ref id=""""crf0046"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>, we proposed a heuristic trust propagation algorithm based on learning automata, called DLATrust, as well as a new aggregation strategy. We indicated that using our developed aggregation strategy the DLATrust algorithm can efficiently discover reliable trust paths without any search constraints and precisely infer the trust value between two indirectly connected users.</ce:para>""''"'	uses_method_in	AGA	
cites	Related work	J.A.J.A. Golbeck, Computing and applying trust in web-based social networks, (2005). doi:	http://dx.doi.org/10.1016/j.comcom.2018.04.004	related work		http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/br/bib0011	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/ctx/ctx0002		49	7	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/itrp/0040	'In the context of a social web, Golbeck [11][[ refid=''bib0011'' ]] has defined trust in a person as “a commitment to an action based on a belief that the future actions of that person will lead to a good outcome”.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0005"""" view=""""all"""">Online social networks provide a convenient opportunity for people to interact with each other and share their information. Trust is considered as a vital factor in forming social interactions. Researchers have proposed various definitions for trust in different contexts. In the context of a social web, Golbeck <ce:cross-ref id=""""crf0010"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> has defined trust in a person as “a commitment to an action based on a belief that the future actions of that person will lead to a good outcome”. Therefore, reliability in previous interactions with a person give rise to positive expectations about that person''''s intentions <ce:cross-ref id=""""crf0011"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>. As two users interact with each other, trust between them evolves based on their interaction''''s experience, in such a way that the level of trust increases if the experience is positive and otherwise, it decreases. Trust may also decay with time. Experiences of more recent interactions are given higher importance than those of old ones, since experiences of old interactions may become irrelevant with time <ce:cross-ref id=""""crf0012"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>. This property refers to the dynamicity of trust.</ce:para>""''"'	cites	FDY	
cites	Related work	A. Abdul-Rahman, S. Hailes, Supporting trust in virtual communities , Syst. Sci. 2000. Proc. 33rd Annu. Hawaii Int. Conf., IEEE (2000)	http://dx.doi.org/10.1016/j.comcom.2018.04.004	related work		http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/br/bib0028	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/ctx/ctx0007		49	7	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/itrp/0058	'Another model without trust propagation process was proposed by work in [28][[ refid=''bib0028'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">Existing models for inferring trust are classified into two categories from the standpoint of trust propagation: non-propagating and propagating trust models. One of the famous models in the first category is PeerTrust <ce:cross-ref id=""""crf0023"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, which was the first to introduce the concept of feedback credibility and its role for defending against dishonest feedbacks. PeerTrust included a coherent adaptive trust model to quantify and compare the trustworthiness of peers by using a transaction-based feedback system. Another model without trust propagation process was proposed by work in <ce:cross-ref id=""""crf0024"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. In this paper, Authors provided a trust model for virtual communities based on a reputation mechanism and direct experiences. Liu et al. <ce:cross-ref id=""""crf0025"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> presented a supervised learning approach that automatically predicts trust among users of online communities using two factors: user factor and interaction factor, where the former refers to evidence derived from actions of individual users and the latter is interactions between pairs of users. Caverlee et al. <ce:cross-ref id=""""crf0026"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> proposed the SocialTrust framework for supporting tamper-resilient trust establishment in online social networks. SocialTrust initially gives all users the same level of trust. Then, it dynamically revises trust ratings according to three components: the current quality of trust, the interaction history, and the adaptation to change. Authors in <ce:cross-ref id=""""crf0027"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> proposed a decision support method for estimating trust in virtual teams. Their proposed trust estimation framework has two dimensions: Reputation and Collaboration, where the former represents the trustworthiness of members and the later represents the cooperation situations between members in a team. Works in <ce:cross-refs id=""""crf0028"""" refid=""""bib0032 bib0033 bib0034 bib0035"""">[32â€“35][[ refid=''''bib0032 bib0033 bib0034 bib0035'''' ]]</ce:cross-refs> are also subcategorized in non-propagating classification, since they discussed trust inference models relying on past observed behaviors. As another example of trust model without propagation, game theory <ce:cross-refs id=""""crf0030"""" refid=""""bib0036 bib0037 bib0038"""">[36â€“38][[ refid=''''bib0036 bib0037 bib0038'''' ]]</ce:cross-refs> has been utilized in recent years for inferring trust. Most of the work in this area has focused on designing some mechanism to make individuals cooperate with each other rather than defecting. Although there have been some attempts at using game theory for trust among agents <ce:cross-refs id=""""crf0032"""" refid=""""bib0039 bib0040"""">[39,40][[ refid=''''bib0039 bib0040'''' ]]</ce:cross-refs>, this approach is still not among the primary focuses of research in the scope of trust management.</ce:para>""''"'	cites	AGA	
uses_method_in	Discussion and conclusion	M. Ghavipour, M.R. Meybodi, Trust propagation algorithm based on learning automata for inferring local trust in online social networks , Knowl. Based Syst. (2017)	http://dx.doi.org/10.1016/j.comcom.2018.04.004	conclusion	discussion	<http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/br/bib0009>	<http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/ctx/ctx0049>				http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/itrp/0063	'In order to validate the effectiveness of our algorithm DyTrust, we conducted extensive experiments with the real trust network dataset, Kaitiaki and compared the results of DyTrust with those of the well-known trust propagation algorithms, as well as with those of our previous algorithms on trust propagation [9][[ refid=''bib0009'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Proposed dynamic algorithm for stochastic trust propagation	M. Ghavipour, M.R. Meybodi, Trust propagation algorithm based on learning automata for inferring local trust in online social networks , Knowl. Based Syst. (2017)	http://dx.doi.org/10.1016/j.comcom.2018.04.004			<http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/br/bib0009>	<http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/ctx/ctx0033>				http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/itrp/0077	'For this purpose, we use the aggregation function proposed in our previous work [9][[ refid=''bib0009'' ]], called MCFAvg, as given below.'			FDY+AGA	infered_pred1
uses_method_in	Proposed dynamic algorithm for stochastic trust propagation	H. Beigy, M.R. Meybodi, Utilizing distributed learning automata to solve stochastic shortest path problems , Int. J. Uncertainty Fuzziness Knowl. Based Syst. , vol. 14 (2006), pp.591-615	http://dx.doi.org/10.1016/j.comcom.2018.04.004			http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/br/bib0053	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/ctx/ctx0032		49	7	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/itrp/0078	'The value of the reward parameter a for each automaton Aj along the path is determined based on Eq. (12)[53][[ refid=''bib0053'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0054"""" view=""""all"""">If in the previous step the found path <ce:italic>Ï€</ce:italic> ends in the direct neighbor<mml:math altimg=""""si37.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mspace width=""""0.33em""""/><mml:msub><mml:mi>v</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msub></mml:mrow></mml:math> and the path strength <mml:math altimg=""""si43.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mspace width=""""0.33em""""/><mml:msub><mml:mi mathvariant=""""script"""">S</mml:mi><mml:mi>Ï€</mml:mi></mml:msub></mml:mrow></mml:math> is larger than or equal to the maximum strength <mml:math altimg=""""si47.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mspace width=""""0.33em""""/><mml:msub><mml:mi mathvariant=""""script"""">S</mml:mi><mml:msub><mml:mi>n</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msub></mml:mrow></mml:math>, the activated learning automata along the trust path <ce:italic>Ï€</ce:italic> will be rewarded. The value of the reward parameter <ce:italic>a</ce:italic> for each automaton <ce:italic>A<ce:inf loc=""""post"""">j</ce:inf></ce:italic> along the path is determined based on <ce:cross-ref id=""""crf0066"""" refid=""""eqn0012"""">Eq. (12)</ce:cross-ref><ce:cross-ref id=""""crf0067"""" refid=""""bib0053"""">[53][[ refid=''''bib0053'''' ]]</ce:cross-ref>.<ce:display><ce:formula id=""""eqn0012""""><ce:label>(12)</ce:label><mml:math altimg=""""si48.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mspace width=""""0.33em""""/></mml:mrow><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mspace width=""""0.33em""""/><mml:mo>âˆ€</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>âˆˆ</mml:mo><mml:mrow><mml:mspace width=""""0.33em""""/><mml:mi>Ï€</mml:mi><mml:mspace width=""""0.33em""""/></mml:mrow></mml:mrow></mml:math></ce:formula></ce:display>where <ce:italic>a<ce:inf loc=""""post"""">i</ce:inf></ce:italic>(<ce:italic>t</ce:italic>) denotes the reward parameter of automaton <ce:italic>A<ce:inf loc=""""post"""">i</ce:inf></ce:italic> activated along the path <ce:italic>Ï€</ce:italic> at time <ce:italic>t</ce:italic> and <mml:math altimg=""""si49.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is the probability of being chosen node <ce:italic>v<ce:inf loc=""""post"""">j</ce:inf></ce:italic> by <ce:italic>A<ce:inf loc=""""post"""">i</ce:inf></ce:italic> after rewarding the automaton.</ce:para>""''"'	cites	AGA	
cites	Convergence results	K.S. Narendra, M.A.L. Thathachar, Learning automata: an introduction , Cour. Corp. (2012)	http://dx.doi.org/10.1016/j.comcom.2018.04.004	results		http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/br/bib0048	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/ctx/ctx0038		49	7	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/itrp/0081	'ProofThis theorem has been proved in [48][[ refid=''bib0048'' ]] .'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para9017"""" view=""""all""""><ce:enunciation id=""""enun0017""""><ce:label>Proof</ce:label><ce:para id=""""para0083"""" view=""""all"""">This theorem has been proved in <ce:cross-ref id=""""crf0085"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> . â–¡</ce:para></ce:enunciation></ce:para>""''"'	cites	AGA	
cites	Related work	Z. Su, L. Liu, M. Li, X. Fan, Y. Zhou, Servicetrust: trust management in service provision networks , Serv. Comput. (SCC), 2013 IEEE Int. Conf., IEEE (2013)	http://dx.doi.org/10.1016/j.comcom.2018.04.004	related work		http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/br/bib0044	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/ctx/ctx0019		49	7	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/itrp/0082	'Authors in [44][[ refid=''bib0044'' ]] analyzed the vulnerabilities of EigenTrust and proposed the trust model ServiceTrust which has a better performance on some sophisticated attack models by utilizing pairwise feedback similarity weighted trust propagation into the trust model.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0009"""" view=""""all"""">With a variation on the PageRank algorithm, Kamvar et al. <ce:cross-ref id=""""crf0038"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> proposed a distributed trust propagation model called EigenTrust for estimating trust values in P2P networks. EigenTrust measures trust values through iterative multiplication and aggregation of trust values along transitive chains until the trust values for all agents converge to stable values. While the EigenTrust algorithm shows a satisfied performance on simple threat models, it could not offer good attack resilience when encountering more sophisticated threat ones. Authors in <ce:cross-ref id=""""crf0039"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> analyzed the vulnerabilities of EigenTrust and proposed the trust model ServiceTrust which has a better performance on some sophisticated attack models by utilizing pairwise feedback similarity weighted trust propagation into the trust model. Kim and Song <ce:cross-ref id=""""crf0040"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> studied the impact of two factors: the length of trust paths and aggregation functions, on the trust inference accuracy and proposed four strategies for estimating trust based on reinforcement learning. They found that the best combination is the strategy of weighted mean aggregation among all trust paths. Based on this strategy, Kim also proposed an enhanced trust propagation approach by combining a homophily-based trust network with an expertise-based one <ce:cross-ref id=""""crf0041"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. Using this approach, author tackled the sparsity problem of trust networks. Work in <ce:cross-ref id=""""crf0042"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> presented a content-driven trust propagation framework that discovers credible claims and estimates trustworthiness of sources based on the quality of evidence. In fact, their proposed techniques for identifying and scoring relevant posts could be used to instantiate a model for computing the trustworthiness of medical claims and sources. Authors in <ce:cross-ref id=""""crf0043"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref> proposed a method called PIN-TRUST to measure the trustworthiness of each user for a target user by employing belief propagation (BP). PIN-TRUST exploits all kinds of interaction information, including explicit trust, implicit trust and explicit distrust, in the trust prediction process.</ce:para>""''"'	uses_method_in	AGA	
cites	Related work	Z.-P. Fan, W.-L. Suo, B. Feng, Y. Liu, Trust estimation in a virtual team: a decision support method , Expert Syst. Appl. , vol. 38 (2011), pp.10240-10251	http://dx.doi.org/10.1016/j.comcom.2018.04.004	related work		http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/br/bib0031	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/ctx/ctx0010		49	7	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/itrp/0093	'Authors in [31][[ refid=''bib0031'' ]] proposed a decision support method for estimating trust in virtual teams.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">Existing models for inferring trust are classified into two categories from the standpoint of trust propagation: non-propagating and propagating trust models. One of the famous models in the first category is PeerTrust <ce:cross-ref id=""""crf0023"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, which was the first to introduce the concept of feedback credibility and its role for defending against dishonest feedbacks. PeerTrust included a coherent adaptive trust model to quantify and compare the trustworthiness of peers by using a transaction-based feedback system. Another model without trust propagation process was proposed by work in <ce:cross-ref id=""""crf0024"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. In this paper, Authors provided a trust model for virtual communities based on a reputation mechanism and direct experiences. Liu et al. <ce:cross-ref id=""""crf0025"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> presented a supervised learning approach that automatically predicts trust among users of online communities using two factors: user factor and interaction factor, where the former refers to evidence derived from actions of individual users and the latter is interactions between pairs of users. Caverlee et al. <ce:cross-ref id=""""crf0026"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> proposed the SocialTrust framework for supporting tamper-resilient trust establishment in online social networks. SocialTrust initially gives all users the same level of trust. Then, it dynamically revises trust ratings according to three components: the current quality of trust, the interaction history, and the adaptation to change. Authors in <ce:cross-ref id=""""crf0027"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> proposed a decision support method for estimating trust in virtual teams. Their proposed trust estimation framework has two dimensions: Reputation and Collaboration, where the former represents the trustworthiness of members and the later represents the cooperation situations between members in a team. Works in <ce:cross-refs id=""""crf0028"""" refid=""""bib0032 bib0033 bib0034 bib0035"""">[32â€“35][[ refid=''''bib0032 bib0033 bib0034 bib0035'''' ]]</ce:cross-refs> are also subcategorized in non-propagating classification, since they discussed trust inference models relying on past observed behaviors. As another example of trust model without propagation, game theory <ce:cross-refs id=""""crf0030"""" refid=""""bib0036 bib0037 bib0038"""">[36â€“38][[ refid=''''bib0036 bib0037 bib0038'''' ]]</ce:cross-refs> has been utilized in recent years for inferring trust. Most of the work in this area has focused on designing some mechanism to make individuals cooperate with each other rather than defecting. Although there have been some attempts at using game theory for trust among agents <ce:cross-refs id=""""crf0032"""" refid=""""bib0039 bib0040"""">[39,40][[ refid=''''bib0039 bib0040'''' ]]</ce:cross-refs>, this approach is still not among the primary focuses of research in the scope of trust management.</ce:para>""''"'	uses_method_in	AGA	
cites	Related work	P. Avesani, P. Massa, R. Tiella, A trust-enhanced recommender system application: Moleskiing , SAC (2005)	http://dx.doi.org/10.1016/j.comcom.2018.04.004	related work		http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/br/bib0041	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/ctx/ctx0015		49	7	http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/itrp/0096	'Another famous model based on trust propagation is MoleTrust [41][[ refid=''bib0041'' ]], which finds all shortest trust paths from a source to a target user and combines all direct trust values issued by users whose trustworthiness is more than 0.6.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0008"""" view=""""all"""">Trust models based on propagation are more popular than non-propagating trust models. In the trust propagation approach, users propagate their trust value to others through trust network following their direct trust relationships. One of the most famous trust models with propagation has been proposed by Golbeck <ce:cross-ref id=""""crf0034"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>. The author studied the concept of trust in web-based social networks and observed that the accuracy of trust inference decreases as the trust path length increases. Therefore, she suggested that the shortest and strongest paths are the best for the estimation of trust and presented a trust propagation model called TidalTrust for inferring the trust value of a source user related to a target one based on averaging trust values along the strongest shortest trust paths. Another famous model based on trust propagation is MoleTrust <ce:cross-ref id=""""crf0035"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref>, which finds all shortest trust paths from a source to a target user and combines all direct trust values issued by users whose trustworthiness is more than 0.6. Authors in <ce:cross-ref id=""""crf0036"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref> investigated the impact of the path length and strength on the accuracy of trust inference and observed that the strength of a trust path can be more important than its length, such that stronger trust paths are favored to weaker but shorter ones. Although their fuzzy trust inference algorithm considering all strongest paths performs more precisely the inference process, it has the time complexity of exponential and therefore cannot be applicable to large scale social networks. Work in <ce:cross-ref id=""""crf0037"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref> described a trust inference algorithm called SUNNY, which estimates the confidence by using a probabilistic sampling technique and computes trust only based on the information sources with highest confidence estimates. Actually, this algorithm executes the trust inference procedure from the TidalTrust algorithm on a more confident sub network.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments	M. Ghavipour, M.R. Meybodi, Trust propagation algorithm based on learning automata for inferring local trust in online social networks , Knowl. Based Syst. (2017)	http://dx.doi.org/10.1016/j.comcom.2018.04.004	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/br/bib0009>	<http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/ctx/ctx0044>				http://www.scar.disi.unibo.it/r/10-1016-j-comcom-2018-04-004/itrp/0098	'We also consider two algorithms proposed in our previous work on trust propagation [9][[ refid=''bib0009'' ]], namely Min-MCFAvg and DLATrust, for the performance comparison.'			FDY+AGA	infered_pred1
uses_method_in	Materials and methods	Vedaldi, A., Fulkerson, B., 2008. VLFeat: An Open and Portable Library of Computer Vision Algorithms. <	http://dx.doi.org/10.1016/j.compag.2015.08.027	materials	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-compag-2015-08-027/br/b0180>	<http://www.scar.disi.unibo.it/r/10-1016-j-compag-2015-08-027/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-compag-2015-08-027/ctx/ctx0047>				http://www.scar.disi.unibo.it/r/10-1016-j-compag-2015-08-027/itrp/0024	'The VLFeat package (Vedaldi and Fulkerson, 2008[[ refid=''b0180'' ]]) is used for efficient K-means clustering.•Learning details.'			FDY+AGA	infered_pred1
uses_method_in	Materials and methods	R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, S. Susstrunk, SLIC superpixels compared to state-of-the-art superpixel methods , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 34 (2012), pp.2274-2282	http://dx.doi.org/10.1016/j.compag.2016.07.006	materials	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-compag-2016-07-006/br/b0005>	<http://www.scar.disi.unibo.it/r/10-1016-j-compag-2016-07-006/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-compag-2016-07-006/ctx/ctx0013>				http://www.scar.disi.unibo.it/r/10-1016-j-compag-2016-07-006/itrp/0042	'Concerning low computational cost and validity, we make the images composed of superpixels with the simple linear iterative clustering (SLIC) method in CIELAB color space (Achanta et al., 2012[[ refid=''b0005'' ]]).'			FDY+AGA	infered_pred1
cites	Introduction	Y. LeCun, Y. Bengio, G. Hinton, Deep learning , Nature , vol. 521 (2015), pp.436-444	http://dx.doi.org/10.1016/j.compag.2017.12.001	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/br/b0160	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/ctx/ctx0022		43	3	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/itrp/0001	'Our aim is to facilitate the agricultural computer vision domain with the benefits of state-of-the-art machine learning, e.g. the supervised hierarchical feature representation learning and the performance increase that comes with large datasets (LeCun et al., 2015[[ refid=''b0160'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0050"""" view=""""all"""">With the advent of state-of-the-art machine learning methods for computer vision, most notably convolutional neural networks for image classification and segmentation, the training dataset size requirement has been further increased (<ce:cross-ref id=""""c0070"""" refid=""""b0185"""">Najafabadi et al., 2015[[ refid=''''b0185'''' ]]</ce:cross-ref>). Such learning models can have up to <mml:math altimg=""""si1.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> free parameters (<ce:cross-ref id=""""c0075"""" refid=""""b0075"""">Dean et al., 2012[[ refid=''''b0075'''' ]]</ce:cross-ref>), which depend upon a large number of distinct data samples for the optimisation to converge properly without overfitting to occur (<ce:cross-ref id=""""c0080"""" refid=""""b0250"""">Trask et al., 2015[[ refid=''''b0250'''' ]]</ce:cross-ref>). Without access to large datasets, domains such as agriculture previously used traditional computer vision methods using manual feature crafting (<ce:cross-ref id=""""c0085"""" refid=""""b0050"""">BolÃ³n-Canedo et al., 2013[[ refid=''''b0050'''' ]]</ce:cross-ref>) whilst capturing a limited subset of the variability. Our aim is to facilitate the agricultural computer vision domain with the benefits of state-of-the-art machine learning, e.g. the supervised hierarchical feature representation learning and the performance increase that comes with large datasets (<ce:cross-ref id=""""c0090"""" refid=""""b0160"""">LeCun et al., 2015[[ refid=''''b0160'''' ]]</ce:cross-ref>).</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Materials and methods	J. Hemming, J. Ruizendaal, J.W. Hofstee, E.J. van Henten, Fruit detectability analysis for different camera positions in sweet-pepper , Sensors (Basel) , vol. 14 (2014), pp.6032-6044, 24681670 , <http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4029692/>	http://dx.doi.org/10.1016/j.compag.2017.12.001	methods	materials	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/br/b0125	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/ctx/ctx0023		43	3	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/itrp/0002	'Furthermore, the camera was angled 20 degrees upwards as previous research suggested this would reduce occlusions (Hemming et al., 2014[[ refid=''b0125'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0065"""" view=""""all"""">From distances ranging from 50 cm to 10 cm (in 10 cm increments) in front of the plant stems, images were captured from âˆ’45, 0 and 45 degree orientations with the horizontal plane. Furthermore, the camera was angled 20 degrees upwards as previous research suggested this would reduce occlusions (<ce:cross-ref id=""""c0095"""" refid=""""b0125"""">Hemming et al., 2014[[ refid=''''b0125'''' ]]</ce:cross-ref>). In total 50 incremental positions of 20 cm along the row of plants were imaged in a 800Ã—600 binned pixel resolution under two conditions; (i) facing towards and (ii) away from the sun. The increment size of 20 cm along the row was chosen to reflect the plant spacing in the greenhouse in order to approximate one new plant in the field of view per image. Overall weather conditions were clear and sunny with occasional clouds (cumulus humilis). At the position of the camera, the average irradiance was 6,000 lx under a clear sky and 5,000 lx when the sun was occluded by a cloud. 3D meshes were obtained of 3 sweet pepper fruit, cultivar Kaite (E20B.0073, Enza Zaden, the Netherlands) with a Spider 3D scanner (Artec, Luxembourg) with a 3D point accuracy of 0.05 mm. Scanning was performed manually by covering all perspectives using a rotating platform. Bottom occlusions were solved by using multiple poses of the same fruit and merging the resulting meshes automatically with Artecâ€™s software package. A set of 10 leaves were flattened and scanned using a consumer flatbed color scanner to obtain their shape, color and texture. At the nodes of the plant, occasionally there were cuts present where fruit were harvested. Frontal photographs were taken to obtain textures for this plant part as well as for the stem.</ce:para>""''"'	cites	AGA	
cites	Introduction	V. BolÃ³n-Canedo, N. SÃ¡nchez-MaroÃ±o, A. Alonso-Betanzos, A review of feature selection methods on synthetic data , Knowl. Inf. Syst. , vol. 34 (2013), pp.483-519	http://dx.doi.org/10.1016/j.compag.2017.12.001	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/br/b0050	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/ctx/ctx0021		43	3	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/itrp/0005	'Without access to large datasets, domains such as agriculture previously used traditional computer vision methods using manual feature crafting (BolÃ³n-Canedo et al., 2013[[ refid=''b0050'' ]]) whilst capturing a limited subset of the variability.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0050"""" view=""""all"""">With the advent of state-of-the-art machine learning methods for computer vision, most notably convolutional neural networks for image classification and segmentation, the training dataset size requirement has been further increased (<ce:cross-ref id=""""c0070"""" refid=""""b0185"""">Najafabadi et al., 2015[[ refid=''''b0185'''' ]]</ce:cross-ref>). Such learning models can have up to <mml:math altimg=""""si1.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> free parameters (<ce:cross-ref id=""""c0075"""" refid=""""b0075"""">Dean et al., 2012[[ refid=''''b0075'''' ]]</ce:cross-ref>), which depend upon a large number of distinct data samples for the optimisation to converge properly without overfitting to occur (<ce:cross-ref id=""""c0080"""" refid=""""b0250"""">Trask et al., 2015[[ refid=''''b0250'''' ]]</ce:cross-ref>). Without access to large datasets, domains such as agriculture previously used traditional computer vision methods using manual feature crafting (<ce:cross-ref id=""""c0085"""" refid=""""b0050"""">BolÃ³n-Canedo et al., 2013[[ refid=''''b0050'''' ]]</ce:cross-ref>) whilst capturing a limited subset of the variability. Our aim is to facilitate the agricultural computer vision domain with the benefits of state-of-the-art machine learning, e.g. the supervised hierarchical feature representation learning and the performance increase that comes with large datasets (<ce:cross-ref id=""""c0090"""" refid=""""b0160"""">LeCun et al., 2015[[ refid=''''b0160'''' ]]</ce:cross-ref>).</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Materials and methods	EON Software, 2016. Plant factory.	http://dx.doi.org/10.1016/j.compag.2017.12.001	materials	methods	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/br/b0240	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/ctx/ctx0027		43	3	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/itrp/0008	'To model the plant and create object meshes, the commercial software PlantFactory 2015 Studio (EON Software, 2016[[ refid=''b0240'' ]]) on OSX 10.10 was used.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0095"""" view=""""all"""">To model the plant and create object meshes, the commercial software PlantFactory 2015 Studio (<ce:cross-ref id=""""c0105"""" refid=""""b0240"""">EON Software, 2016[[ refid=''''b0240'''' ]]</ce:cross-ref>) on OSX 10.10 was used. Originally intended for realistic game and video production modelling, it includes functionality to generate randomised plant instances based on plant parameter distributions, which can be exported as mesh models.</ce:para>""''"'	cites	AGA	
cites	Discussion	Caesar, H., Uijlings, J.R.R., Ferrari, V., 2015. Joint calibration for semantic segmentation, CoRR abs/1507.01581.	http://dx.doi.org/10.1016/j.compag.2017.12.001	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/br/b0055	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/ctx/ctx0040		43	3	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/itrp/0020	'Instead we looked at: (i) label set distributions, (ii) label image position distributions, (iii) part color spectra and (iv) illumination intensity distributions to gain a more quantitative insight into the similarity between sets.iWithin a dataset, label frequencies are often highly unbalanced (Caesar et al., 2015[[ refid=''b0055'' ]]), resulting in neglected classes in some type of computer vision approaches.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0285"""" view=""""all"""">Superordinate image similarity measures were previously not well defined in literature. However, studies of individual measures like color histogram comparison (<ce:cross-ref id=""""c0170"""" refid=""""b0245"""">Swain and Ballard, 1991[[ refid=''''b0245'''' ]]</ce:cross-ref>) or shape measures (<ce:cross-ref id=""""c0175"""" refid=""""b0170"""">Mehtre et al., 1997[[ refid=''''b0170'''' ]]</ce:cross-ref>) have been performed. In this paper, the similarity requirement was also not quantified in a single measure. Instead we looked at: (i) label set distributions, (ii) label image position distributions, (iii) part color spectra and (iv) illumination intensity distributions to gain a more quantitative insight into the similarity between sets.<ce:list id=""""l0015""""><ce:list-item id=""""o0030""""><ce:label>i</ce:label><ce:para id=""""p0430"""" view=""""all"""">Within a dataset, label frequencies are often highly unbalanced (<ce:cross-ref id=""""c0180"""" refid=""""b0055"""">Caesar et al., 2015[[ refid=''''b0055'''' ]]</ce:cross-ref>), resulting in neglected classes in some type of computer vision approaches. To counter that effect, object occurrence statistics can be used for normalisation (<ce:cross-ref id=""""c0185"""" refid=""""b0060"""">Chawla, 2010[[ refid=''''b0060'''' ]]</ce:cross-ref>). In <ce:cross-ref id=""""c0315"""" refid=""""f0050"""">Fig. 10</ce:cross-ref> we observe an unbalance within and between the sets. The latter can partially be explained by the methodological difference in obtaining the ground truth in both cases. For the synthetic dataset, the labels of all pixels in the color image were computable irregardless of illumination. For the empirical dataset, a subjective decision on the label in the dark edge areas was often not possible.</ce:para></ce:list-item><ce:list-item id=""""o0035""""><ce:label>ii</ce:label><ce:para id=""""p0435"""" view=""""all"""">In <ce:cross-ref id=""""c0320"""" refid=""""f0055"""">Fig. 11</ce:cross-ref> we compared the plant part spatial distribution in the images between sets. Overall, the sparsity in the empirical set is notable and was due to the small size of the annotated set. In the synthetic set, we note 3 vertical hotspots of stem+wire classes whereas in the empirical set the spatial variance of these classes was higher. This can be explained by a more regular plant distance in the synthetic set, due to the fact that our model did not take intra-plant properties into account.</ce:para><ce:para id=""""p0290"""" view=""""all"""">The distributions of the peppers between sets was similar, e.g. a hot spot in the center of both distributions and less to the left and right explained by the particular occlusions resulting from the chosen scanning path. Closely correlated with peppers are the peduncles, however the peduncle distributions were hard to compare due to their sparsity.</ce:para><ce:para id=""""p0295"""" view=""""all"""">Lastly, there was a difference between leaf class distributions. Whilst empirically more centered, in the synthetic set there was a higher occurrence at the top of the image. This can be explained by improper modelling the shapes and poses of the leaves, resulting in a discrepancy of silhouettes when viewed from a 20 degree upward angle.</ce:para></ce:list-item><ce:list-item id=""""o0040""""><ce:label>iii</ce:label><ce:para id=""""p0440"""" view=""""all"""">Evaluating <ce:cross-ref id=""""c0325"""" refid=""""f0060"""">Fig. 12</ce:cross-ref>, we observe plant part color similarities but also differences in our sets.</ce:para><ce:para id=""""p0300"""" view=""""all""""><ce:bold>Leaves:</ce:bold> The proportion of the left spectrum of the leaf class was similar, though the synthetic leaves should contain relatively less greens. The purple spectrum on the right of this class can be explained by the outward position of some leaves, leading to underexposure and therefore taking on the purple global background illumination color.</ce:para><ce:para id=""""p0305"""" view=""""all""""><ce:bold>Peppers:</ce:bold> The pepper colors seem far off at first, though the green peak height might be caused by the improper modelling of the percentage of green (50%) and yellow peppers (50%). In the empirical set, more ripe fruit were present because a part of the crop was selected in the greenhouse with abundance of yellow peppers to increase the spatial density of robot harvest trials. Irregardless of this ripeness imbalance, the color of the ripe peppers in the synthetic set needs to be adjusted towards the yellow end of the spectrum.</ce:para><ce:para id=""""p0310"""" view=""""all""""><ce:bold>Peduncles, stems and shoots:</ce:bold> All were modelled too green and lack yellows.</ce:para><ce:para id=""""p0315"""" view=""""all""""><ce:bold>Wires:</ce:bold> The synthetic wire color distribution shows a peak in green. By inspecting the data this was likely the result by the rendering a color interpolation at the edges of the wire class and background stem class. Furthermore, a relative large part of the wire pixels were edge pixels and these pixels were included in the ground truth of the wire class. A thicker synthetic wire might increase color similarity.</ce:para><ce:para id=""""p0320"""" view=""""all""""><ce:bold>Cuts:</ce:bold> Although the cuts were textured with a photograph, the absence of color calibration most likely resulted in the difference we observe in this class.</ce:para></ce:list-item><ce:list-item id=""""o0045""""><ce:label>iv</ce:label><ce:para id=""""p0445"""" view=""""all"""">When looking at the average illumination intensity distribution over all images in each set (<ce:cross-ref id=""""c0330"""" refid=""""f0065"""">Fig. 13</ce:cross-ref>) we observe a comparable heterogenous illumination distribution with a strong vignetting effect. This was caused by (i) an interaction of illumination hardware that focussed a centered beam on the scene and (ii) the lens type which had a default vignet. The average intensity of these images was similar.</ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	C.W. Bac, E.J. van Henten, J. Hemming, Y. Edan, Harvesting robots for high-value crops: state-of-the-art review and challenges ahead , J. Field Robot. , vol. 31 (2014), pp.888-911	http://dx.doi.org/10.1016/j.compag.2017.12.001	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/br/b0015	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/ctx/ctx0001		43	3	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/itrp/0025	'In recent years the need of robotisation in agriculture has been growing notably to keep up with the increasing demand of productivity and quality of food production whilst decreasing the pressure on resources required (Bac et al., 2014[[ refid=''b0015'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0005"""" view=""""all"""">In recent years the need of robotisation in agriculture has been growing notably to keep up with the increasing demand of productivity and quality of food production whilst decreasing the pressure on resources required (<ce:cross-ref id=""""c0005"""" refid=""""b0015"""">Bac et al., 2014[[ refid=''''b0015'''' ]]</ce:cross-ref>). Although mechanisation has been an ongoing human effort for centuries, the next leap forward to achieve these higher goals is by adding a degree of artificial intelligence to harvesting and crop management systems to enable increased selectivity, precision and robustness.</ce:para>""''"'	cites	AGA	
cites	Introduction	G. van der Heijden, Y. Song, G. Horgan, G. Polder, A. Dieleman, M. Bink, A. Palloix, F. van Eeuwijk, C. Glasbey, Spicy: towards automated phenotyping of large pepper plants in the greenhouse , Funct. Plant Biol. , vol. 39 (2012), pp.870-877	http://dx.doi.org/10.1016/j.compag.2017.12.001	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/br/b0255	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/ctx/ctx0006		43	3	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/itrp/0033	'Although collecting image data can be automated (van der Heijden et al., 2012[[ refid=''b0255'' ]]), it remains required and time consuming to manually annotate.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0030"""" view=""""all"""">In the domain of agriculture, progress in image classification performance has been lagging behind state-of-the-art results in other domains (<ce:cross-refs id=""""r0015"""" refid=""""b0115 b0190"""">Gongal et al., 2015; Nasir et al., 2012[[ refid=''''b0115 b0190'''' ]]</ce:cross-refs>). Although some progress in high level object detection or localisation have lately been accomplished (<ce:cross-ref id=""""c0010"""" refid=""""b0230"""">Sa et al., 2016[[ refid=''''b0230'''' ]]</ce:cross-ref>), lower level detailed object part recognition in scenes reflecting realistic structural object complexity, remains unsolved. The challenges of computer vision in the agricultural domain come from the high amount of variation within object classes and changing environment conditions, throughout the day and seasons (e.g. light, growth stages). To overcome this variability, large annotated and detailed datasets are needed for capture all different situations. Although collecting image data can be automated (<ce:cross-ref id=""""r0020"""" refid=""""b0255"""">van der Heijden et al., 2012[[ refid=''''b0255'''' ]]</ce:cross-ref>), it remains required and time consuming to manually annotate.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Materials and methods	Papandreou, G., Chen, L.-C., Murphy, K., Yuille, A.L., 2015. Weakly- and semi-supervised learning of a DCNN for semantic image segmentation. In: ICCV.	http://dx.doi.org/10.1016/j.compag.2017.12.001	methods	materials	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/br/b0195	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/ctx/ctx0034		43	3	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/itrp/0038	'Specifically we used the Deeplab VGG-16 Vanilla model (Papandreou et al., 2015[[ refid=''b0195'' ]]) with a receptive field of 128 pixels and a stride of 8 pixels.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0155"""" view=""""all"""">Specifically we used the Deeplab VGG-16 Vanilla model (<ce:cross-ref id=""""c0140"""" refid=""""b0195"""">Papandreou et al., 2015[[ refid=''''b0195'''' ]]</ce:cross-ref>) with a receptive field of 128 pixels and a stride of 8 pixels. The hyperparameters of the network were manually optimised as suggested by <ce:cross-ref id=""""c0145"""" refid=""""b0040"""">Bengio (2012)[[ refid=''''b0040'''' ]]</ce:cross-ref> and resulted in using Adaptive Moment Estimation (ADAM) (<ce:cross-ref id=""""c0150"""" refid=""""b0150"""">Kingma and Ba, 2015[[ refid=''''b0150'''' ]]</ce:cross-ref>) with <mml:math altimg=""""si6.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mrow><mml:mi>Î²</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn><mml:mtext>,</mml:mtext><mml:msub><mml:mrow><mml:mi>Î²</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.999</mml:mn><mml:mtext>,</mml:mtext><mml:mi>Îµ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> and a base learning rate of 0.00005 for 30,000 iterations with a batch size of 10.</ce:para>""''"'	cites	AGA	
cites	Materials and methods	Kainz, F., Bogart, R., Hess, D., 2004. The openexr image file format. GPU Gems: Programming Techniques, Tips and Tricks for Real-Time Graphics, R. Fernando, Ed. Pearson Higher Education.	http://dx.doi.org/10.1016/j.compag.2017.12.001	methods	materials	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/br/b0140	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/ctx/ctx0031		43	3	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/itrp/0043	'The resolution in depth of this ground truth is coarse, though an exact representation could be obtained if needed by exporting the sceneâ€™s Z-buffer in Blender to the OpenEXR (Kainz et al., 2004[[ refid=''b0140'' ]]) linear format.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0140"""" view=""""all"""">Ground truth depth images were rendered separately per frame by using the mist environment variable in Blender. For each pixel in the image, the light ray distance between the object and the cameraâ€™s projection center was obtained. Hence encoded distances were not equal to real world XYZ-coordinates, which could not be obtained due to the absence of corresponding camera poses. The distance was encoded in image grayscale values, ranging from 0 to 255. In this image, the distance in centimetres for each pixel <mml:math altimg=""""si3.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math> could be recovered by the function <mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mfenced open=""""("""" close="""")""""><mml:mrow><mml:mfrac><mml:mrow><mml:mn>255</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mfenced open=""""("""" close="""")""""><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>âˆ—</mml:mo><mml:mn>150</mml:mn></mml:mrow><mml:mrow><mml:mn>255</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math>, where the intensity of a pixel <mml:math altimg=""""si5.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math> decreases from the maximum intensity 255 with a factor based on the range of the mist in the render, which was set at 150 cm. The depth images were also rendered in a colorscale with high contrasts for intuitive viewing. The resolution in depth of this ground truth is coarse, though an exact representation could be obtained if needed by exporting the sceneâ€™s Z-buffer in Blender to the OpenEXR (<ce:cross-ref id=""""c0120"""" refid=""""b0140"""">Kainz et al., 2004[[ refid=''''b0140'''' ]]</ce:cross-ref>) linear format.</ce:para>""''"'	cites	AGA	
uses_method_in	Materials and methods	MVTech, 2016. Halcon.	http://dx.doi.org/10.1016/j.compag.2017.12.001	materials	methods	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/br/b0180	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/ctx/ctx0030		43	3	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/itrp/0044	'Therefore the synthetic image labels were post-processed in the commercial image processing software package Halcon 12 (MVTech, 2016[[ refid=''b0180'' ]]) by removing any interpolated color pixels and replacing them with the most frequent neighbour color in a 3Ã—3 patch If this convolution failed in case the majority of the neighbouring pixels also had been interpolated, the window was enlarged until all pixels were equal to one of the class labels.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0135"""" view=""""all"""">To obtain the per-pixel ground truth label images in which each plant part was represented by a unique color encoding, the scene was duplicated and the color mapping of each plant part was replaced by primary or secondary colors. The background of this duplicate scene was set to black. To avoid interaction of colors in the scene, which would result in more colors than labels, the virtual camera was set to only register a single direct ray of light without bounces. Unfortunately, rendered edges between plant parts still interpolated colors. Therefore the synthetic image labels were post-processed in the commercial image processing software package Halcon 12 (<ce:cross-ref id=""""c0115"""" refid=""""b0180"""">MVTech, 2016[[ refid=''''b0180'''' ]]</ce:cross-ref>) by removing any interpolated color pixels and replacing them with the most frequent neighbour color in a 3Ã—3 patch If this convolution failed in case the majority of the neighbouring pixels also had been interpolated, the window was enlarged until all pixels were equal to one of the class labels. Furthermore, the colors were replaced by grayscale values in a single channel to finally reduce the label image size by 98%.</ce:para>""''"'	cites	AGA	
cites	Introduction	M.M. Najafabadi, F. Villanustre, T.M. Khoshgoftaar, N. Seliya, R. Wald, E. Muharemagic, Deep learning applications and challenges in big data analytics , J. Big Data , vol. 2 (2015), pp.1-21	http://dx.doi.org/10.1016/j.compag.2017.12.001	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/br/b0185	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/ctx/ctx0019		43	3	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/itrp/0051	'With the advent of state-of-the-art machine learning methods for computer vision, most notably convolutional neural networks for image classification and segmentation, the training dataset size requirement has been further increased (Najafabadi et al., 2015[[ refid=''b0185'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0050"""" view=""""all"""">With the advent of state-of-the-art machine learning methods for computer vision, most notably convolutional neural networks for image classification and segmentation, the training dataset size requirement has been further increased (<ce:cross-ref id=""""c0070"""" refid=""""b0185"""">Najafabadi et al., 2015[[ refid=''''b0185'''' ]]</ce:cross-ref>). Such learning models can have up to <mml:math altimg=""""si1.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> free parameters (<ce:cross-ref id=""""c0075"""" refid=""""b0075"""">Dean et al., 2012[[ refid=''''b0075'''' ]]</ce:cross-ref>), which depend upon a large number of distinct data samples for the optimisation to converge properly without overfitting to occur (<ce:cross-ref id=""""c0080"""" refid=""""b0250"""">Trask et al., 2015[[ refid=''''b0250'''' ]]</ce:cross-ref>). Without access to large datasets, domains such as agriculture previously used traditional computer vision methods using manual feature crafting (<ce:cross-ref id=""""c0085"""" refid=""""b0050"""">BolÃ³n-Canedo et al., 2013[[ refid=''''b0050'''' ]]</ce:cross-ref>) whilst capturing a limited subset of the variability. Our aim is to facilitate the agricultural computer vision domain with the benefits of state-of-the-art machine learning, e.g. the supervised hierarchical feature representation learning and the performance increase that comes with large datasets (<ce:cross-ref id=""""c0090"""" refid=""""b0160"""">LeCun et al., 2015[[ refid=''''b0160'''' ]]</ce:cross-ref>).</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	M. Everingham, S.M. Eslami, L. Gool, C.K. Williams, J. Winn, A. Zisserman, The pascal visual object classes challenge: a retrospective , Int. J. Comput. Vision , vol. 111 (2015), pp.98-136	http://dx.doi.org/10.1016/j.compag.2017.12.001	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/br/b0090	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/ctx/ctx0012		43	3	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/itrp/0054	'One approach is to only label images on a high level using a single class or a few keywords per image in order to classify an image globally or give a shortlist of objects in the image (Everingham et al., 2015[[ refid=''b0090'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0045"""" view=""""all"""">The required level of labeling detail depends on the task and in turn determines how much annotation effort is needed. One approach is to only label images on a high level using a single class or a few keywords per image in order to classify an image globally or give a shortlist of objects in the image (<ce:cross-ref id=""""c0040"""" refid=""""b0090"""">Everingham et al., 2015[[ refid=''''b0090'''' ]]</ce:cross-ref>). This can be partially automated through combined image and label retrieval using context from search engines (<ce:cross-ref id=""""c0045"""" refid=""""b0095"""">Fergus et al., 2005[[ refid=''''b0095'''' ]]</ce:cross-ref>). For other datasets like ImageNet or PASCAL VOC, manual annotation was performed using crowd sourcing (<ce:cross-refs id=""""r0035"""" refid=""""b0085 b0225"""">Everingham et al., 2010; Russell et al., 2008[[ refid=''''b0085 b0225'''' ]]</ce:cross-refs>). A second approach is to weakly label the data with bounding boxes around objects or their parts (<ce:cross-ref id=""""c0050"""" refid=""""b0195"""">Papandreou et al., 2015[[ refid=''''b0195'''' ]]</ce:cross-ref>). However, some computer vision tasks require a per pixel level labeling of the image, also known as semantic segmentation. Specifically for agriculture, per-pixel segmentations are required for localisation in robotics for harvesting (<ce:cross-ref id=""""c0055"""" refid=""""b0010"""">Bac et al., 2013[[ refid=''''b0010'''' ]]</ce:cross-ref>), disease detection (<ce:cross-ref id=""""c0060"""" refid=""""b0205"""">Polder et al., 2014[[ refid=''''b0205'''' ]]</ce:cross-ref>) and phenotyping (<ce:cross-ref id=""""r0040"""" refid=""""b0255"""">van der Heijden et al., 2012[[ refid=''''b0255'''' ]]</ce:cross-ref>). For example in harvest robotics, obstacle maps on the plant part level resolution improves successful motion planning (<ce:cross-refs id=""""r0045"""" refid=""""b0020 b0025"""">Bac et al., 2014, 2016[[ refid=''''b0020 b0025'''' ]]</ce:cross-refs>). Registered depth images can provide an additional dimension for motion control (<ce:cross-ref id=""""c0065"""" refid=""""b0035"""">Barth et al., 2016[[ refid=''''b0035'''' ]]</ce:cross-ref>).</ce:para>""''"'	cites	AGA	
cites	Introduction	Cicco, M.D., Potena, C., Grisetti, G., Pretto, A., 2016. Automatic model based dataset generation for fast and accurate crop and weeds detection, CoRR abs/1612.03019.	http://dx.doi.org/10.1016/j.compag.2017.12.001	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/br/b0065	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/ctx/ctx0011		43	3	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/itrp/0055	'Furthermore, recently a method was created for automatic model based synthetic dataset generation for crop and weeds detection on a per-pixel level (Cicco et al., 2016[[ refid=''b0065'' ]]), though no plant parts could be differentiated.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0040"""" view=""""all"""">Previous work on methods for plant architecture modelling have been also successful for synthetic plant image generation. For example, OpenAlea (<ce:cross-refs id=""""r0030"""" refid=""""b0210 b0215"""">Pradal et al., 2015, 2017[[ refid=''''b0210 b0215'''' ]]</ce:cross-refs>) is able to generate anatomical and functional plant models and furthermore can be used to simulate images with a virtual camera. Other approaches such as ElonSim (<ce:cross-ref id=""""c0030"""" refid=""""b0045"""">Benoit et al., 2014[[ refid=''''b0045'''' ]]</ce:cross-ref>) provide a simulator of plant growth, specifically root systems, and a simulator of the image acquisition to generate synthetic images including ground truth. The simulator uses plant and camera parameters. Furthermore, recently a method was created for automatic model based synthetic dataset generation for crop and weeds detection on a per-pixel level (<ce:cross-ref id=""""c0035"""" refid=""""b0065"""">Cicco et al., 2016[[ refid=''''b0065'''' ]]</ce:cross-ref>), though no plant parts could be differentiated.</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	Papandreou, G., Chen, L.-C., Murphy, K., Yuille, A.L., 2015. Weakly- and semi-supervised learning of a DCNN for semantic image segmentation. In: ICCV.	http://dx.doi.org/10.1016/j.compag.2017.12.001	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/br/b0195	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/ctx/ctx0015		43	3	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2017-12-001/itrp/0062	'A second approach is to weakly label the data with bounding boxes around objects or their parts (Papandreou et al., 2015[[ refid=''b0195'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0045"""" view=""""all"""">The required level of labeling detail depends on the task and in turn determines how much annotation effort is needed. One approach is to only label images on a high level using a single class or a few keywords per image in order to classify an image globally or give a shortlist of objects in the image (<ce:cross-ref id=""""c0040"""" refid=""""b0090"""">Everingham et al., 2015[[ refid=''''b0090'''' ]]</ce:cross-ref>). This can be partially automated through combined image and label retrieval using context from search engines (<ce:cross-ref id=""""c0045"""" refid=""""b0095"""">Fergus et al., 2005[[ refid=''''b0095'''' ]]</ce:cross-ref>). For other datasets like ImageNet or PASCAL VOC, manual annotation was performed using crowd sourcing (<ce:cross-refs id=""""r0035"""" refid=""""b0085 b0225"""">Everingham et al., 2010; Russell et al., 2008[[ refid=''''b0085 b0225'''' ]]</ce:cross-refs>). A second approach is to weakly label the data with bounding boxes around objects or their parts (<ce:cross-ref id=""""c0050"""" refid=""""b0195"""">Papandreou et al., 2015[[ refid=''''b0195'''' ]]</ce:cross-ref>). However, some computer vision tasks require a per pixel level labeling of the image, also known as semantic segmentation. Specifically for agriculture, per-pixel segmentations are required for localisation in robotics for harvesting (<ce:cross-ref id=""""c0055"""" refid=""""b0010"""">Bac et al., 2013[[ refid=''''b0010'''' ]]</ce:cross-ref>), disease detection (<ce:cross-ref id=""""c0060"""" refid=""""b0205"""">Polder et al., 2014[[ refid=''''b0205'''' ]]</ce:cross-ref>) and phenotyping (<ce:cross-ref id=""""r0040"""" refid=""""b0255"""">van der Heijden et al., 2012[[ refid=''''b0255'''' ]]</ce:cross-ref>). For example in harvest robotics, obstacle maps on the plant part level resolution improves successful motion planning (<ce:cross-refs id=""""r0045"""" refid=""""b0020 b0025"""">Bac et al., 2014, 2016[[ refid=''''b0020 b0025'''' ]]</ce:cross-refs>). Registered depth images can provide an additional dimension for motion control (<ce:cross-ref id=""""c0065"""" refid=""""b0035"""">Barth et al., 2016[[ refid=''''b0035'''' ]]</ce:cross-ref>).</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	Simonyan, K., Zisserman, A., 2014. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556.	http://dx.doi.org/10.1016/j.compag.2018.01.023	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/br/b0190	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/ctx/ctx0009		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/itrp/0014	'The Faster R-CNN stated that the whole system can finish proposal and detection in 0.2 s using a deep VGG-16 model (Simonyan and Zisserman, 2014[[ refid=''b0190'' ]]) to generate high-quality object proposals.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0040"""" view=""""all"""">To recognize a posture from a sequence of extracted feature or a given feature set, a well-designed classifier is necessary from a combination of specific features. To hand design good feature extractors require a considerable amount of engineering skill and domain expertise. Unlike the vision systems, the methods of hand-design feature are rarely attempted to comprehensively recognize actions or behavioral states from images holistically. The deep-learning methods are feature-learning methods with multiple levels of representation, obtained by composing of simple but non-linear modules that each module transforms the representation at one level (starting with the raw input) into a representation at a higher and more abstract level. Compared to the hand design features, skill and expertise in designing feature extractors could be avoided by a deep learning procedure with the advantage of learning good features automatically (<ce:cross-ref refid=""""b0130"""" id=""""c0100"""">LeCun et al., 2015[[ refid=''''b0130'''' ]]</ce:cross-ref>). In deep learning, a convolutional neural network (CNN) is a class of deep, feed-forward artificial neural networks that have been progressive in identifying faces, objects and traffic signs apart from vision in robots and self-driving cars. In 2-D and 3-D human pose estimation (<ce:cross-refs refid=""""b0005 b0030"""" id=""""r0020"""">Afsar et al., 2015; ChÃ©ron et al., 2015[[ refid=''''b0005 b0030'''' ]]</ce:cross-refs>), and human action recognition such as jumping, walking, and reading (<ce:cross-ref refid=""""b0065"""" id=""""c0105"""">Gkioxari et al., 2014[[ refid=''''b0065'''' ]]</ce:cross-ref>), CNNs also become the leading technique of analyzing visual imagery. In object detection, the region-based CNN (R-CNN) methods based on deep learning have achieved great successes (<ce:cross-refs refid=""""b0055 b0060 b0080 b0135 b0175"""" id=""""r0025"""">Girshick, 2015; Girshick et al., 2014; He et al., 2014; Long et al., 2015; Ren et al., 2015[[ refid=''''b0055 b0060 b0080 b0135 b0175'''' ]]</ce:cross-refs>). Among them, the method named Faster R-CNN (<ce:cross-ref refid=""""b0175"""" id=""""c0110"""">Ren et al., 2015[[ refid=''''b0175'''' ]]</ce:cross-ref>), which shares the convolutional features in a Region Proposal Network (RPN) and a Fast R-CNN (<ce:cross-ref refid=""""b0055"""" id=""""c0115"""">Girshick, 2015[[ refid=''''b0055'''' ]]</ce:cross-ref>), won the champion of ILSVRC 2015. The Faster R-CNN stated that the whole system can finish proposal and detection in 0.2 s using a deep VGG-16 model (<ce:cross-ref refid=""""b0190"""" id=""""c0120"""">Simonyan and Zisserman, 2014[[ refid=''''b0190'''' ]]</ce:cross-ref>) to generate high-quality object proposals. Recent progress of object detection and recognition, which achieved a top-5 error of 4.49% (<ce:cross-ref refid=""""b0085"""" id=""""c0125"""">He et al., 2016[[ refid=''''b0085'''' ]]</ce:cross-ref>), has been very close to human-level performance. In the field of animal behavior, researches on computer vision are lagging behind the current development of automatic recognition. Typically, deep learning technologies are infrequently used in animal behavioral researches. Recent studies have shown that deep learning methods would be widely adopted by the animal behavior community (<ce:cross-ref refid=""""b0210"""" id=""""c0130"""">Valletta et al., 2017[[ refid=''''b0210'''' ]]</ce:cross-ref>).</ce:para>""''"'	cites	AGA	
cites	Introduction	D. Berckmans, Precision livestock farming technologies for welfare management in intensive livestock systems , Rev. Sci. Tech. Off. Int. Epiz. , vol. 33 (2014), pp.189-196	http://dx.doi.org/10.1016/j.compag.2018.01.023	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/br/b0015	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/ctx/ctx0001		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/itrp/0020	'Assessing the behavior of livestock is important as it can indicate their welfare status, well-being state and social interactions (Berckmans, 2014[[ refid=''b0015'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0025"""" view=""""all"""">Assessing the behavior of livestock is important as it can indicate their welfare status, well-being state and social interactions (<ce:cross-ref refid=""""b0015"""" id=""""c0065"""">Berckmans, 2014[[ refid=''''b0015'''' ]]</ce:cross-ref>). Producers have strong interests in maintaining their livestock welfare from both economic and ethical perspectives. However, animal welfare is difficult to monitor in practice, due to the inefficiencies in manual documenting, including animal behaviors, social interactions and health conditions of large numbers of animals. Currently, understanding livestock behaviors is achieved either by direct human observation or by videotaping, coding and determining the behaviors manually. However, human analysis of the videos is labor-intensive or subjectively error-prone. Therefore, it is desirable to adopt automatic identification to achieve acceptable ability to monitor animal behavior.</ce:para>""''"'	cites	AGA	
cites	Introduction	Y. LeCun, Y. Bengio, G. Hinton, Deep learning , Nature , vol. 521 (2015), pp.436-444	http://dx.doi.org/10.1016/j.compag.2018.01.023	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/br/b0130	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/ctx/ctx0005		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/itrp/0033	'Compared to the hand design features, skill and expertise in designing feature extractors could be avoided by a deep learning procedure with the advantage of learning good features automatically (LeCun et al., 2015[[ refid=''b0130'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0040"""" view=""""all"""">To recognize a posture from a sequence of extracted feature or a given feature set, a well-designed classifier is necessary from a combination of specific features. To hand design good feature extractors require a considerable amount of engineering skill and domain expertise. Unlike the vision systems, the methods of hand-design feature are rarely attempted to comprehensively recognize actions or behavioral states from images holistically. The deep-learning methods are feature-learning methods with multiple levels of representation, obtained by composing of simple but non-linear modules that each module transforms the representation at one level (starting with the raw input) into a representation at a higher and more abstract level. Compared to the hand design features, skill and expertise in designing feature extractors could be avoided by a deep learning procedure with the advantage of learning good features automatically (<ce:cross-ref refid=""""b0130"""" id=""""c0100"""">LeCun et al., 2015[[ refid=''''b0130'''' ]]</ce:cross-ref>). In deep learning, a convolutional neural network (CNN) is a class of deep, feed-forward artificial neural networks that have been progressive in identifying faces, objects and traffic signs apart from vision in robots and self-driving cars. In 2-D and 3-D human pose estimation (<ce:cross-refs refid=""""b0005 b0030"""" id=""""r0020"""">Afsar et al., 2015; ChÃ©ron et al., 2015[[ refid=''''b0005 b0030'''' ]]</ce:cross-refs>), and human action recognition such as jumping, walking, and reading (<ce:cross-ref refid=""""b0065"""" id=""""c0105"""">Gkioxari et al., 2014[[ refid=''''b0065'''' ]]</ce:cross-ref>), CNNs also become the leading technique of analyzing visual imagery. In object detection, the region-based CNN (R-CNN) methods based on deep learning have achieved great successes (<ce:cross-refs refid=""""b0055 b0060 b0080 b0135 b0175"""" id=""""r0025"""">Girshick, 2015; Girshick et al., 2014; He et al., 2014; Long et al., 2015; Ren et al., 2015[[ refid=''''b0055 b0060 b0080 b0135 b0175'''' ]]</ce:cross-refs>). Among them, the method named Faster R-CNN (<ce:cross-ref refid=""""b0175"""" id=""""c0110"""">Ren et al., 2015[[ refid=''''b0175'''' ]]</ce:cross-ref>), which shares the convolutional features in a Region Proposal Network (RPN) and a Fast R-CNN (<ce:cross-ref refid=""""b0055"""" id=""""c0115"""">Girshick, 2015[[ refid=''''b0055'''' ]]</ce:cross-ref>), won the champion of ILSVRC 2015. The Faster R-CNN stated that the whole system can finish proposal and detection in 0.2 s using a deep VGG-16 model (<ce:cross-ref refid=""""b0190"""" id=""""c0120"""">Simonyan and Zisserman, 2014[[ refid=''''b0190'''' ]]</ce:cross-ref>) to generate high-quality object proposals. Recent progress of object detection and recognition, which achieved a top-5 error of 4.49% (<ce:cross-ref refid=""""b0085"""" id=""""c0125"""">He et al., 2016[[ refid=''''b0085'''' ]]</ce:cross-ref>), has been very close to human-level performance. In the field of animal behavior, researches on computer vision are lagging behind the current development of automatic recognition. Typically, deep learning technologies are infrequently used in animal behavioral researches. Recent studies have shown that deep learning methods would be widely adopted by the animal behavior community (<ce:cross-ref refid=""""b0210"""" id=""""c0130"""">Valletta et al., 2017[[ refid=''''b0210'''' ]]</ce:cross-ref>).</ce:para>""''"'	uses_method_in	AGA	
cites	Introduction	J.J. Valletta, C. Torney, M. Kings, A. Thornton, J. Madden, Applications of machine learning in animal behaviour studies , Anim. Behav. , vol. 124 (2017), pp.203-220	http://dx.doi.org/10.1016/j.compag.2018.01.023	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/br/b0210	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/ctx/ctx0011		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/itrp/0062	'Recent studies have shown that deep learning methods would be widely adopted by the animal behavior community (Valletta et al., 2017[[ refid=''b0210'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0040"""" view=""""all"""">To recognize a posture from a sequence of extracted feature or a given feature set, a well-designed classifier is necessary from a combination of specific features. To hand design good feature extractors require a considerable amount of engineering skill and domain expertise. Unlike the vision systems, the methods of hand-design feature are rarely attempted to comprehensively recognize actions or behavioral states from images holistically. The deep-learning methods are feature-learning methods with multiple levels of representation, obtained by composing of simple but non-linear modules that each module transforms the representation at one level (starting with the raw input) into a representation at a higher and more abstract level. Compared to the hand design features, skill and expertise in designing feature extractors could be avoided by a deep learning procedure with the advantage of learning good features automatically (<ce:cross-ref refid=""""b0130"""" id=""""c0100"""">LeCun et al., 2015[[ refid=''''b0130'''' ]]</ce:cross-ref>). In deep learning, a convolutional neural network (CNN) is a class of deep, feed-forward artificial neural networks that have been progressive in identifying faces, objects and traffic signs apart from vision in robots and self-driving cars. In 2-D and 3-D human pose estimation (<ce:cross-refs refid=""""b0005 b0030"""" id=""""r0020"""">Afsar et al., 2015; ChÃ©ron et al., 2015[[ refid=''''b0005 b0030'''' ]]</ce:cross-refs>), and human action recognition such as jumping, walking, and reading (<ce:cross-ref refid=""""b0065"""" id=""""c0105"""">Gkioxari et al., 2014[[ refid=''''b0065'''' ]]</ce:cross-ref>), CNNs also become the leading technique of analyzing visual imagery. In object detection, the region-based CNN (R-CNN) methods based on deep learning have achieved great successes (<ce:cross-refs refid=""""b0055 b0060 b0080 b0135 b0175"""" id=""""r0025"""">Girshick, 2015; Girshick et al., 2014; He et al., 2014; Long et al., 2015; Ren et al., 2015[[ refid=''''b0055 b0060 b0080 b0135 b0175'''' ]]</ce:cross-refs>). Among them, the method named Faster R-CNN (<ce:cross-ref refid=""""b0175"""" id=""""c0110"""">Ren et al., 2015[[ refid=''''b0175'''' ]]</ce:cross-ref>), which shares the convolutional features in a Region Proposal Network (RPN) and a Fast R-CNN (<ce:cross-ref refid=""""b0055"""" id=""""c0115"""">Girshick, 2015[[ refid=''''b0055'''' ]]</ce:cross-ref>), won the champion of ILSVRC 2015. The Faster R-CNN stated that the whole system can finish proposal and detection in 0.2 s using a deep VGG-16 model (<ce:cross-ref refid=""""b0190"""" id=""""c0120"""">Simonyan and Zisserman, 2014[[ refid=''''b0190'''' ]]</ce:cross-ref>) to generate high-quality object proposals. Recent progress of object detection and recognition, which achieved a top-5 error of 4.49% (<ce:cross-ref refid=""""b0085"""" id=""""c0125"""">He et al., 2016[[ refid=''''b0085'''' ]]</ce:cross-ref>), has been very close to human-level performance. In the field of animal behavior, researches on computer vision are lagging behind the current development of automatic recognition. Typically, deep learning technologies are infrequently used in animal behavioral researches. Recent studies have shown that deep learning methods would be widely adopted by the animal behavior community (<ce:cross-ref refid=""""b0210"""" id=""""c0130"""">Valletta et al., 2017[[ refid=''''b0210'''' ]]</ce:cross-ref>).</ce:para>""''"'	uses_method_in	AGA	
cites	Introduction	He, K., Zhang, X., Ren, S., Sun, J., 2016. Deep residual learning for image recognition. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770â€“778.	http://dx.doi.org/10.1016/j.compag.2018.01.023	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/br/b0085	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/ctx/ctx0010		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-compag-2018-01-023/itrp/0063	'Recent progress of object detection and recognition, which achieved a top-5 error of 4.49% (He et al., 2016[[ refid=''b0085'' ]]), has been very close to human-level performance.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0040"""" view=""""all"""">To recognize a posture from a sequence of extracted feature or a given feature set, a well-designed classifier is necessary from a combination of specific features. To hand design good feature extractors require a considerable amount of engineering skill and domain expertise. Unlike the vision systems, the methods of hand-design feature are rarely attempted to comprehensively recognize actions or behavioral states from images holistically. The deep-learning methods are feature-learning methods with multiple levels of representation, obtained by composing of simple but non-linear modules that each module transforms the representation at one level (starting with the raw input) into a representation at a higher and more abstract level. Compared to the hand design features, skill and expertise in designing feature extractors could be avoided by a deep learning procedure with the advantage of learning good features automatically (<ce:cross-ref refid=""""b0130"""" id=""""c0100"""">LeCun et al., 2015[[ refid=''''b0130'''' ]]</ce:cross-ref>). In deep learning, a convolutional neural network (CNN) is a class of deep, feed-forward artificial neural networks that have been progressive in identifying faces, objects and traffic signs apart from vision in robots and self-driving cars. In 2-D and 3-D human pose estimation (<ce:cross-refs refid=""""b0005 b0030"""" id=""""r0020"""">Afsar et al., 2015; ChÃ©ron et al., 2015[[ refid=''''b0005 b0030'''' ]]</ce:cross-refs>), and human action recognition such as jumping, walking, and reading (<ce:cross-ref refid=""""b0065"""" id=""""c0105"""">Gkioxari et al., 2014[[ refid=''''b0065'''' ]]</ce:cross-ref>), CNNs also become the leading technique of analyzing visual imagery. In object detection, the region-based CNN (R-CNN) methods based on deep learning have achieved great successes (<ce:cross-refs refid=""""b0055 b0060 b0080 b0135 b0175"""" id=""""r0025"""">Girshick, 2015; Girshick et al., 2014; He et al., 2014; Long et al., 2015; Ren et al., 2015[[ refid=''''b0055 b0060 b0080 b0135 b0175'''' ]]</ce:cross-refs>). Among them, the method named Faster R-CNN (<ce:cross-ref refid=""""b0175"""" id=""""c0110"""">Ren et al., 2015[[ refid=''''b0175'''' ]]</ce:cross-ref>), which shares the convolutional features in a Region Proposal Network (RPN) and a Fast R-CNN (<ce:cross-ref refid=""""b0055"""" id=""""c0115"""">Girshick, 2015[[ refid=''''b0055'''' ]]</ce:cross-ref>), won the champion of ILSVRC 2015. The Faster R-CNN stated that the whole system can finish proposal and detection in 0.2 s using a deep VGG-16 model (<ce:cross-ref refid=""""b0190"""" id=""""c0120"""">Simonyan and Zisserman, 2014[[ refid=''''b0190'''' ]]</ce:cross-ref>) to generate high-quality object proposals. Recent progress of object detection and recognition, which achieved a top-5 error of 4.49% (<ce:cross-ref refid=""""b0085"""" id=""""c0125"""">He et al., 2016[[ refid=''''b0085'''' ]]</ce:cross-ref>), has been very close to human-level performance. In the field of animal behavior, researches on computer vision are lagging behind the current development of automatic recognition. Typically, deep learning technologies are infrequently used in animal behavioral researches. Recent studies have shown that deep learning methods would be widely adopted by the animal behavior community (<ce:cross-ref refid=""""b0210"""" id=""""c0130"""">Valletta et al., 2017[[ refid=''''b0210'''' ]]</ce:cross-ref>).</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Implementation	A. Vedaldi, B. Fulkerson, Vlfeat: an open and portable library of computer vision algorithms , MM׳10 Proc. ICM (2010)	http://dx.doi.org/10.1016/j.compbiomed.2015.11.006	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2015-11-006/br/bib36>	<http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2015-11-006/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2015-11-006/ctx/ctx0039>				http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2015-11-006/itrp/0046	'SIFT features were computed using the VL-SIFT library version 0.9.17 [36][[ refid=''bib36'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Superpixel-based MRF model	R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, S. Susstrunk, SLIC superpixels compared to state-of-the-art superpixel methods , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 34 (2012), pp.2274-2282	http://dx.doi.org/10.1016/j.compbiomed.2016.01.025	model		<http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-01-025/br/bib37>	<http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-01-025/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-01-025/ctx/ctx0022>				http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-01-025/itrp/0001	'There are many superpixel generated algorithms and we used SLIC [37][[ refid=''bib37'' ]], a simple line iterative clustering algorithm, to generate superpixels.'			FDY+AGA	infered_pred1
uses_method_in	Materials and methods	Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, et al., Caffe: Convolutional architecture for fast feature embedding. arXiv preprint 	http://dx.doi.org/10.1016/j.compbiomed.2016.05.004	materials	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-05-004/br/bib32>	<http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-05-004/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-05-004/ctx/ctx0021>				http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-05-004/itrp/0004	'This function has a fixed form defined in the “CIFAR10 Quick” example provided with the software Caffe [32][[ refid=''bib32'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Experimental setup	F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, Scikit-learn: machine learning in Python , J. Mach. Learn. Res. , vol. 12 (2011), pp.2825-2830	http://dx.doi.org/10.1016/j.compbiomed.2016.06.019	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-06-019/br/bib32>	<http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-06-019/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-06-019/ctx/ctx0029>				http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-06-019/itrp/0013	'The algorithms are used off-the-shelf using the Python module scikit-learn [32][[ refid=''bib32'' ]], with parameters chosen as follows, after extensive tuning.'			FDY+AGA	infered_pred1
uses_method_in	Image representation	A. Vedaldi, B. Fulkerson, VLFeat: An Open and Portable Library of Computer Vision Algorithms, 2008, 〈	http://dx.doi.org/10.1016/j.compbiomed.2016.07.006			<http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-07-006/br/bib106>	<http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-07-006/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-07-006/ctx/ctx0096>				http://www.scar.disi.unibo.it/r/10-1016-j-compbiomed-2016-07-006/itrp/0046	'In our experiments VLFeat [106][[ refid=''bib106'' ]] library has been used to extract SIFT keypoints.'			FDY+AGA	infered_pred1
uses_method_in	Methodology	L. Itti, C. Koch, E. Niebur, A model of saliency-based visual attention for rapid scene analysis , IEEE Trans Pattern Anal Mach Intell , vol. 20 (1998), pp.1254-1259	http://dx.doi.org/10.1016/j.compeleceng.2013.10.005	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-compeleceng-2013-10-005/br/b0135>	<http://www.scar.disi.unibo.it/r/10-1016-j-compeleceng-2013-10-005/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-compeleceng-2013-10-005/ctx/ctx0021>				http://www.scar.disi.unibo.it/r/10-1016-j-compeleceng-2013-10-005/itrp/0005	'The four broadly tuned color tunnels are then defined as [27][[ refid=''b0135'' ]]: [[ formulaid=''id7_pos0'' ]] [[ formulaid=''id7_pos1'' ]] [[ formulaid=''id7_pos2'' ]] [[ formulaid=''id7_pos3'' ]]'			FDY+AGA	infered_pred1
uses_method_in	Experimental results	C.C. Chang, C.J. Lin, LIBSVM: a library for support vector machines , ACM Trans Intell Syst Technol , vol. 2 (2011), pp.1-27	http://dx.doi.org/10.1016/j.compeleceng.2016.01.011	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-compeleceng-2016-01-011/br/bib0015>	<http://www.scar.disi.unibo.it/r/10-1016-j-compeleceng-2016-01-011/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-compeleceng-2016-01-011/ctx/ctx0020>				http://www.scar.disi.unibo.it/r/10-1016-j-compeleceng-2016-01-011/itrp/0012	'As a baseline, we also present the results using the popular Support Vector Machines (SVMs) with radial basis function kernel [14][[ refid=''bib0015'' ]], in which the optimal values for the parameters C and γ are adopted.'			FDY+AGA	infered_pred1
cites	Related literatures	M. Yamamoto, K. Kaneko, Parallel image database processing with mapreduce and performance evaluation in pseudo distributed mode , Int. J. Electron Commerce Stud , vol. 13 (2012), pp.211-228	http://dx.doi.org/10.1016/j.compeleceng.2016.04.015			http://www.scar.disi.unibo.it/r/10-1016-j-compeleceng-2016-04-015/br/bib0019	http://www.scar.disi.unibo.it/r/10-1016-j-compeleceng-2016-04-015/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-compeleceng-2016-04-015/ctx/ctx0021		36	5	http://www.scar.disi.unibo.it/r/10-1016-j-compeleceng-2016-04-015/itrp/0004	'Yamamoto et al. (2012) delivered a set of experiments targeting image-processing tasks using MapReduce like creating a grayscale image from an original-colored image utilizing Ruby and octave languages for database of video shots upon Hadoop [19][[ refid=''bib0019'' ]].•C.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0031"""" view=""""all"""">Like others, CBIR systems have been affected by the new theories and trends of the big data. As becoming the de-facto standard for distributed computing and storage of big-data applications, Hadoop-based systems have spread widely during the last years. As a matter of fact the multimedia-based systems require high-intensive computing. Consequently, researchers seek Hadoop facilities to serve in CBIR field. For instance, but not limited to those, we mention some of the recent works related to this area.<ce:list id=""""celist0003""""><ce:list-item id=""""celistitem0013""""><ce:label>•</ce:label><ce:para id=""""para0032"""" view=""""all"""">M. Yamamoto <ce:italic>et al.</ce:italic> (2012) delivered a set of experiments targeting image-processing tasks using MapReduce like creating a grayscale image from an original-colored image utilizing Ruby and octave languages for database of video shots upon Hadoop <ce:cross-ref id=""""crf0032"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0014""""><ce:label>•</ce:label><ce:para id=""""para0033"""" view=""""all"""">C. GU <ce:italic>et al.</ce:italic> (2012) proposed CBIR system upon Hadoop and Lucene frameworks, and nominated HBASE which is an Apache open-source non-relational database. They used MapReduce to implement the feature extraction and the inverted indexing jobs <ce:cross-ref id=""""crf0033"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0015""""><ce:label>•</ce:label><ce:para id=""""para0034"""" view=""""all"""">D. Yin <ce:italic>et al.</ce:italic> (2013) presented an implementation for a distributed-CBIR system upon Hadoop. They exploited SURF for feature extraction and representation and used LSH for performing the feature matching. They used Hadoop MapReduce for implementing the feature-matching tasks <ce:cross-ref id=""""crf0034"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0016""""><ce:label>•</ce:label><ce:para id=""""para0035"""" view=""""all"""">D. Moses <ce:italic>et al.</ce:italic> (2013) built CBIR system on the top of the extended cluster-pruning (eCP) algorithm, and introduced an index-search scheme for large batches of queries <ce:cross-ref id=""""crf0035"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0017""""><ce:label>•</ce:label><ce:para id=""""para0036"""" view=""""all"""">Darsana <ce:italic>et al.</ce:italic> (2013) proposed a CBIR system based on Hadoop using particle swarm. They considered the visual-content features and the textual-information features for estimating the similarity between the images <ce:cross-ref id=""""crf0036"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0018""""><ce:label>•</ce:label><ce:para id=""""para0037"""" view=""""all"""">S. Dravyakar (2014) introduced a private CBIR system based on Hadoop framework using the local-tetra patterns (LTrPs) for processing the query image and storing it in the database, and later using it to search for the similarities of the query image among the dataset images <ce:cross-ref id=""""crf0037"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0019""""><ce:label>•</ce:label><ce:para id=""""para0038"""" view=""""all"""">U.S.N. Raju <ce:italic>et al.</ce:italic> (2015) proposed an approach for CBIR system based on Hadoop MapReduce. They utilized the local-tetra patterns (LTPr) as a feature-descriptor technique for representing the images in the CBIR system. And for reading the input of the Hadoop, they used the SequenceFile <ce:cross-ref id=""""crf0038"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>.</ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_method_in	Case studies	A.G. Cohn, N.M. Gotts, The ‘egg-yolk’ representation of regions with indeterminate boundaries , Geographic objects with indeterminate boundaries, Taylor & Francis (1996)	http://dx.doi.org/10.1016/j.compenvurbsys.2009.05.001			http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-05-001/br/bib1a	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-05-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-05-001/ctx/ctx0043		54	6	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-05-001/itrp/0022	'In other words, we can consider the 0.5-cut set to be the “egg”, according to the “egg yolk” model (Cohn & Gotts, 1996[[ refid=''bib1a'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""">According to common geographical knowledge, South China includes the five provinces Guangxi, Guangdong, Taiwan, Hainan, and Fujian (<ce:cross-ref refid=""""fig8"""">Fig. 8</ce:cross-ref>a) in a broad sense, and excludes Taiwan and Fujian in a narrow sense. As shown in <ce:cross-ref refid=""""fig8"""">Fig. 8</ce:cross-ref>b, the gray regions indicate membership values higher than 0.5. According to the experimental design, a point with a degree higher than 0.5 implies that more than half of the participants agree that this point is inside South China. It is thus reasonable to assert that the 0.5-cut set corresponds to the outer boundary of South China. In other words, we can consider the 0.5-cut set to be the “egg”, according to the “egg yolk” model (<ce:cross-ref refid=""""bib1a"""">Cohn &amp; Gotts, 1996[[ refid=''''bib1a'''' ]]</ce:cross-ref>). It is highly coherent with the broad concept. The membership value is greater than 0.8 in the dark-gray regions. It is consistent in the narrow sense, and can be viewed as the “yolk part” in the “egg yolk” model. <ce:cross-ref refid=""""fig8"""">Fig. 8</ce:cross-ref>b introduces the land territory of China as the limiting region of the PSBR model, so that the concept of South China does not extend into other neighboring countries, such as Vietnam. Note that different interpolation methods will yield different membership functions. These functions will generally have similar patterns, and their differences therefore do not influence our discussion. This case study demonstrates that the PSBR model can be a valuable representation for vague objects by taking human conceptualization into account. </ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Computing spatial relationships between two PSBRs	T. Behr, M. Schneider, Topological relationships of complex points and complex regions , ER 2001, lecture notes in computer sciences 2224, Springer-Verlag (2001)	http://dx.doi.org/10.1016/j.compenvurbsys.2009.05.001			http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-05-001/br/bib3	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-05-001/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-05-001/ctx/ctx0039		54	6	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-05-001/itrp/0046	'We thus define the relationships that follow Behr and Schneider (2001)[[ refid=''bib3'' ]] to be “direct topological relationships”, and the relationships based on areal approximations to be “deduced topological relationships”.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""">Researchers in artificial intelligence (AI) and GIS have extensively investigated topological relationships between two spatial objects. The region connection calculus (RCC) (<ce:cross-ref refid=""""bib35"""">Randell, Cui, &amp; Cohn, 1992[[ refid=''''bib35'''' ]]</ce:cross-ref>) and the 9-intersection model (9-IM) (<ce:cross-ref refid=""""bib12"""">Egenhofer &amp; Franzosa, 1991[[ refid=''''bib12'''' ]]</ce:cross-ref>) are two major topological models. <ce:cross-ref refid=""""bib3"""">Behr and Schneider (2001)[[ refid=''''bib3'''' ]]</ce:cross-ref> extended the 9-IM to model topological relationships between complex objects, which may be multi-points or multi-regions. In terms of complex points, five relationships can be identified: disjoint, overlap, contain, inside, and equal (<ce:cross-ref refid=""""fig5"""">Fig. 5</ce:cross-ref> <ce:float-anchor refid=""""fig5""""/>a–d). Clearly, they can also model the topological relationships between two PSBRs. Such relationships are easy to examine; however, they may be intuitively incorrect. In <ce:cross-ref refid=""""fig5"""">Fig. 5</ce:cross-ref>e, the relationship between <ce:italic>R</ce:italic> <ce:inf loc=""""post"""">1</ce:inf> and <ce:italic>R</ce:italic> <ce:inf loc=""""post"""">2</ce:inf> is “disjoint” according to the model of <ce:cross-ref refid=""""bib3"""">Behr and Schneider (2001)[[ refid=''''bib3'''' ]]</ce:cross-ref>. However, they are usually perceived to be “ <ce:italic>R</ce:italic> <ce:inf loc=""""post"""">1</ce:inf> overlaps <ce:italic>R</ce:italic> <ce:inf loc=""""post"""">2</ce:inf>” when considering their areal approximations, such as convex hulls. We thus define the relationships that follow <ce:cross-ref refid=""""bib3"""">Behr and Schneider (2001)[[ refid=''''bib3'''' ]]</ce:cross-ref> to be “direct topological relationships”, and the relationships based on areal approximations to be “deduced topological relationships”. Direct overlap (or inside/contain) implies stronger geographical semantics than deduced overlap, especially when the coincident points are instances of the same feature type. </ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
uses_method_in	The case study	52° North, 52° North Geoprocessing Community (2007).	http://dx.doi.org/10.1016/j.compenvurbsys.2009.06.003			http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-06-003/br/bib58	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-06-003/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-06-003/ctx/ctx0059		65	5	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-06-003/itrp/0041	'Both process scenarios were implemented with WPS instances using the 52°North WPS framework (North Geoprocessing Community, 2007[[ refid=''bib58'' ]]) running at both locations.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""">The architecture for the case study is illustrated in <ce:cross-ref refid=""""fig8"""">Fig. 8</ce:cross-ref> <ce:float-anchor refid=""""fig8""""/>. To compare Web Service-based geoprocessing in different organizations, the services for our implementation ran at two locations: the International Institute for Geo-Information Science and Earth Observation (ITC) and the Finnish Geodetic Institute (FGI). Both process scenarios were implemented with WPS instances using the 52°North WPS framework (<ce:cross-ref refid=""""bib58"""">North Geoprocessing Community, 2007[[ refid=''''bib58'''' ]]</ce:cross-ref>) running at both locations. Additionally, we wrapped the schema transformation process (Step 2, <ce:cross-ref refid=""""fig8"""">Fig. 8</ce:cross-ref>) (Schema Transformation Service), as a Web Map Service (WMS) (based on GeoServer application server, <ce:cross-ref refid=""""bib57"""">GeoServer, 2008[[ refid=''''bib57'''' ]]</ce:cross-ref>) by using a special GeoServer concept for wrapping resources called <ce:italic>data stores</ce:italic>. Any WPS instance can be published as a WMS by applying the concept of data stores. This provides WPS functionality through a standardized and already well-established interface (i.e., WMS), enabling a seamless integration of this new type of service into already existing client applications. </ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
uses_method_in	The case study	GeoServer (2008).	http://dx.doi.org/10.1016/j.compenvurbsys.2009.06.003			http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-06-003/br/bib57	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-06-003/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-06-003/ctx/ctx0060		65	5	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2009-06-003/itrp/0042	'Additionally, we wrapped the schema transformation process (Step 2, Fig. 8) (Schema Transformation Service), as a Web Map Service (WMS) (based on GeoServer application server, GeoServer, 2008[[ refid=''bib57'' ]]) by using a special GeoServer concept for wrapping resources called data stores.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""">The architecture for the case study is illustrated in <ce:cross-ref refid=""""fig8"""">Fig. 8</ce:cross-ref> <ce:float-anchor refid=""""fig8""""/>. To compare Web Service-based geoprocessing in different organizations, the services for our implementation ran at two locations: the International Institute for Geo-Information Science and Earth Observation (ITC) and the Finnish Geodetic Institute (FGI). Both process scenarios were implemented with WPS instances using the 52°North WPS framework (<ce:cross-ref refid=""""bib58"""">North Geoprocessing Community, 2007[[ refid=''''bib58'''' ]]</ce:cross-ref>) running at both locations. Additionally, we wrapped the schema transformation process (Step 2, <ce:cross-ref refid=""""fig8"""">Fig. 8</ce:cross-ref>) (Schema Transformation Service), as a Web Map Service (WMS) (based on GeoServer application server, <ce:cross-ref refid=""""bib57"""">GeoServer, 2008[[ refid=''''bib57'''' ]]</ce:cross-ref>) by using a special GeoServer concept for wrapping resources called <ce:italic>data stores</ce:italic>. Any WPS instance can be published as a WMS by applying the concept of data stores. This provides WPS functionality through a standardized and already well-established interface (i.e., WMS), enabling a seamless integration of this new type of service into already existing client applications. </ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Discussion and conclusions	B. Smith, D.M. Mark, Geographical categories: An ontological investigation , International Journal of Geographic Information Science , vol. 15 (2001), pp.591-612	http://dx.doi.org/10.1016/j.compenvurbsys.2010.02.008	conclusion	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-02-008/br/bib50	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-02-008/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-02-008/ctx/ctx0029		32	4	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-02-008/itrp/0015	'As a consequence, it does not currently make the necessary allowances for a wider depiction of reality (Smith & Mark, 2001[[ refid=''bib50'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""">With respect to the elaborated ontology, its application focus leaves it open to the critique voiced by <ce:cross-ref refid=""""bib50"""">Smith and Mark (2001)[[ refid=''''bib50'''' ]]</ce:cross-ref> pertaining to what constitutes a ‘good’ ontology. While partially informed by a published vocabulary, <ce:cross-ref refid=""""fn14""""> <ce:sup loc=""""post"""">14</ce:sup> </ce:cross-ref> the present ontology was specifically tailored to meet the initial requirements of the current proof of concept. As a consequence, it does not currently make the necessary allowances for a wider depiction of reality (<ce:cross-ref refid=""""bib50"""">Smith &amp; Mark, 2001[[ refid=''''bib50'''' ]]</ce:cross-ref>). While such a consideration is not to be dismissed, the present aim was to demonstrate a pragmatic solution to implementing a semantically enabled system within a specific context. As <ce:cross-ref refid=""""bib15"""">Dean (2007)[[ refid=''''bib15'''' ]]</ce:cross-ref> observed, however, ontologies facilitate mark-up in a manner that does not modify the data depicted; replacing the incumbent vocabulary with one more ‘aware’ of the wider world remains an option in future work. In any case, a consideration of the broader discussion surrounding such inclusive ontological initiatives serves as a reminder that Semantic Web technologies do not offer a panacea for issues of interoperability. Challenges still exist not only in accommodating conflicting perspectives with regards to data representation and interpretation but also in catering to the varying levels of granularity and breadth of scope used to frame abstractions of the real world, as dictated by the context in which they are made. </ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Discussion and conclusions	M.F. Goodchild, M. Yuan, T.J. Cova, Towards a general theory of geographic representation in GIS , International Journal of Geographical Information Science , vol. 21 (2007), pp.239-260	http://dx.doi.org/10.1016/j.compenvurbsys.2010.02.008	conclusion	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-02-008/br/bib24	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-02-008/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-02-008/ctx/ctx0032		32	4	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-02-008/itrp/0042	'For example, we could extend the geo-atom of Goodchild et al. (2007)[[ refid=''bib24'' ]] with the addition of a URI: 〈x, Z, z(x), URI〉.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""">Finally, this paper has focused on dealing with legacy data, yet it represents an opportunity to reconsider how we capture and represent the semantics of spatial data in general. Our traditional geospatial data model involves associating with a point or region in space and time some measurable quality, such as temperature, or an observable feature like as a building, as has been recently reviewed by <ce:cross-ref refid=""""bib24"""">Goodchild, Yuan, and Cova (2007)[[ refid=''''bib24'''' ]]</ce:cross-ref>. When capturing data, we implicitly subscribe to some kind of conceptualization. If we can make this explicit in an ontology, we can then extend our fundamental representation of the geospatial data to take advantage of our conceptualization and the potential for reasoning with formal semantics. By including a URI in our basic data model that links it to our ontology that defines our conceptualization, we gain the power of formal semantics to reason with the concepts represented in our spatial datasets. For example, we could extend the geo-atom of <ce:cross-ref refid=""""bib24"""">Goodchild et al. (2007)[[ refid=''''bib24'''' ]]</ce:cross-ref> with the addition of a URI: 〈x, <ce:hsp sp=""""0.25""""/>Z, <ce:hsp sp=""""0.25""""/>z(x), <ce:hsp sp=""""0.25""""/>URI〉. In the future, we could have ontologies associated with our measurement instruments that would automatically associate their ontology with the data captured, providing a kind of feature level metadata that can be reasoned with as per the example provided in this paper. </ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Enabling technologies	M. Bambacus, P. Yang, J. Evans, M. Cole, N. Alameh, S. Marley, ESG: An interoperable portal for prototyping applications , URISA Journal , vol. 19 (2007), pp.15-21	http://dx.doi.org/10.1016/j.compenvurbsys.2010.04.001			http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-04-001/br/bib7a	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-04-001/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-04-001/ctx/ctx0035		138	5	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-04-001/itrp/0032	'Interoperability lays out a foundation for easily integrating heterogeneous components in a plug-and-play fashion or for mashup with minor scripting of the interfaces (Bambacus et al., 2007[[ refid=''bib7a'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""">Four major architectures have been widely researched and adopted for GCI system integration (<ce:cross-ref refid=""""bib157"""">Yang &amp; Raskin, 2009[[ refid=''''bib157'''' ]]</ce:cross-ref>). <ce:list> <ce:list-item> <ce:label>•</ce:label> <ce:para view=""""all"""">Multi-tier/layer organizations support and implement CI objectives through layers of functions with community-specific knowledge environments for research and education. The <ce:cross-ref refid=""""bib108"""">NSF (2003)[[ refid=''''bib108'''' ]]</ce:cross-ref> Atkins report laid out a four-layer architecture emphasizing the following: (a) core technologies, such as HPC, incorporated into CI services, (b) CI supporting applications, (c) applications of IT to science and engineering research, and (d) science and engineering research activities. The <ce:cross-ref refid=""""bib109"""">NSF (2007)[[ refid=''''bib109'''' ]]</ce:cross-ref> CI report further emphasizes HPC, visualization and data/information/knowledge, virtual organizations, and education and workforce training. <ce:cross-ref refid=""""bib163"""">Zhang and Tsou (2009)[[ refid=''''bib163'''' ]]</ce:cross-ref> and <ce:cross-ref refid=""""bib142"""">Wang and Liu (2009)[[ refid=''''bib142'''' ]]</ce:cross-ref> described layered architectures for integrating geospatial components to support GCI. These layered views of GCI are in alignment with those of the Federal Enterprise Architecture (FEA) and provide good guidance for the logic design of the components necessary to implement a GCI. Challenges remain in this architecture; for example, how to utilize a knowledge-oriented layered framework for integrating/interoperating multiple infrastructures (<ce:cross-ref refid=""""bib63"""">Jabeur, McCarthy, Xing, &amp; Graniero, 2009[[ refid=''''bib63'''' ]]</ce:cross-ref>). </ce:para> </ce:list-item> <ce:list-item> <ce:label>•</ce:label> <ce:para view=""""all"""">Mashup and plug-and-play leverage the achievements of geospatial interoperability over the past few decades. Interoperability lays out a foundation for easily integrating heterogeneous components in a plug-and-play fashion or for mashup with minor scripting of the interfaces (<ce:cross-ref refid=""""bib7a"""">Bambacus et al., 2007[[ refid=''''bib7a'''' ]]</ce:cross-ref>). This plug-and-play integration has become an ideal illustration of the achievements of interoperability and provides new system integration methods that are envisioned to be critical to effective system integration in the coming decades (<ce:cross-ref refid=""""bib105"""">Nebert, 2004[[ refid=''''bib105'''' ]]</ce:cross-ref>). </ce:para> </ce:list-item> <ce:list-item> <ce:label>•</ce:label> <ce:para view=""""all"""">SOA is based on the assumption that all components can be built as services and the SOA can facilitate service registration, discovery, and binding to form new functional and/or scientific applications. For example, <ce:cross-ref refid=""""bib60"""">Hey and Trefethen (2005)[[ refid=''''bib60'''' ]]</ce:cross-ref> described how the United Kingdom’s e-science program utilized SOA to compose an e-Infrastructure or CI to support multiple science domains. <ce:cross-ref refid=""""bib12"""">Bogden et al. (2006)[[ refid=''''bib12'''' ]]</ce:cross-ref> described how an SOA was used to design the Southeastern Universities Research Association (SURA) Coastal Ocean Observing and Prediction (SCOOP) program to support coastal real-time decision making. <ce:cross-ref refid=""""bib161"""">Zhang, Tsou, Qiao, and Xu (2006)[[ refid=''''bib161'''' ]]</ce:cross-ref> discussed the need of GCI for the development of future geospatial information services based on Grid computing, Web services, and OGC standards. </ce:para> </ce:list-item> <ce:list-item> <ce:label>•</ce:label> <ce:para view=""""all"""">Workflow chaining utilizes business logic in integrating applications to construct a GCI application and was popularized with OGC service proliferation within geospatial domains using BPEL, eBRIM, Kepler, and other generic- or geospatial-specific chaining engines and description languages. <ce:cross-ref refid=""""bib101"""">Minsker et al. (2006)[[ refid=''''bib101'''' ]]</ce:cross-ref> described a workflow chaining service that integrates heterogeneous tools to support environmental engineering and hydrological science communities to (a) share data and research through interactive provenance and (b) discover, share, analyze, and evaluate research tools. <ce:cross-ref refid=""""bib114"""">Pennington et al. (2008)[[ refid=''''bib114'''' ]]</ce:cross-ref> used workflow chaining to chain services that educate scientists to better leverage resources in their scientific research. Workflow chaining also provides an interesting architectural method for scientific experimentation (<ce:cross-ref refid=""""bib140"""">von Laszewski, Younge, Xi, Mahinthakumar, &amp; Lizhe, 2009[[ refid=''''bib140'''' ]]</ce:cross-ref>). An important task in the workflow chaining process is to compare the capabilities of the various available tools to compose scientifically sound applications (<ce:cross-ref refid=""""bib32"""">Deelman, Gannon, Shields, &amp; Taylor, 2009[[ refid=''''bib32'''' ]]</ce:cross-ref>). </ce:para> </ce:list-item> </ce:list> </ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Introduction history, origin, and status	NSF. (2009).	http://dx.doi.org/10.1016/j.compenvurbsys.2010.04.001	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-04-001/br/bib110	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-04-001/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-04-001/ctx/ctx0011		138	5	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2010-04-001/itrp/0196	'To answer complex questions, we must effectively utilize facilities, instruments, and other resources to pursue fundamental and transformational questions, unravel newly revealed mysteries, and expand our understanding of the Earth and the universe (NSF., 2009[[ refid=''bib110'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""">Humanity in the 21st century faces great challenges to better understand why and how the Earth is changing (<ce:inter-ref xlink:href=""""http://nasascience.nasa.gov"""" xlink:type=""""simple"""">http://nasascience.nasa.gov</ce:inter-ref>) and to make better decisions at global to personal levels (<ce:cross-ref refid=""""bib75"""">Lannotta, 2007[[ refid=''''bib75'''' ]]</ce:cross-ref>). Representative challenges include strategies to reduce energy consumption and stabilize atmospheric emissions so that the global temperature will not increase several degrees in the next century; choose a housing site that minimizes the risks of forest fire, flooding, and other natural/man-made hazards; and more generally, improve the quality of life. These practical questions require us to utilize most available geospatial data, information, and knowledge to produce scientifically sound decision supporting information and require capabilities to achieve the following (<ce:cross-ref refid=""""bib157"""">Yang &amp; Raskin, 2009[[ refid=''''bib157'''' ]]</ce:cross-ref>): (1) integrate real-time and historical data resources, (2) leverage both traditional and fully interoperable and open resources, (3) interpret data and information that cross-domains, regions, and cultures, and (4) capture and utilize knowledge autonomously so that the most appropriate inputs can be utilized and the best decision supporting information can be generated. To answer complex questions, we must effectively utilize facilities, instruments, and other resources to pursue fundamental and transformational questions, unravel newly revealed mysteries, and expand our understanding of the Earth and the universe (<ce:cross-ref refid=""""bib110"""">NSF., 2009[[ refid=''''bib110'''' ]]</ce:cross-ref>). As a long-term objective, GCI will facilitate answering these daunting questions and build the capacity to leverage existing geospatial knowledge and resources, transform how we conduct research, pursue scientific and application questions, and collaborate across geographic regions, cultural differences, and domain turfs. </ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
uses_method_in	Qualitative spatial representation and reasoning	A. Frank, Qualitative spatial reasoning: Cardinal directions as an example , Twenty years of the Intel, CRC Press (2006)	http://dx.doi.org/10.1016/j.compenvurbsys.2011.04.002			http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2011-04-002/br/b0045	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2011-04-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2011-04-002/ctx/ctx0022		34	3	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2011-04-002/itrp/0001	'Correspondingly, we adopt from (Frank, 2006[[ refid=''b0045'' ]]) the five-step distance with five symbols: very close (VC), close (Cl), medium (Me), far (Fa), and very far (VF).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0095"""" view=""""all"""">Correspondingly, we adopt from (<ce:cross-ref refid=""""b0045"""">Frank, 2006[[ refid=''''b0045'''' ]]</ce:cross-ref>) the five-step distance with five symbols: <ce:italic>very close</ce:italic> (<ce:italic>VC</ce:italic>), <ce:italic>close</ce:italic> (<ce:italic>Cl</ce:italic>), <ce:italic>medium</ce:italic> (<ce:italic>Me</ce:italic>), <ce:italic>far</ce:italic> (<ce:italic>Fa</ce:italic>), and <ce:italic>very far</ce:italic> (<ce:italic>VF</ce:italic>). The concept of distance in <ce:cross-ref refid=""""b0045"""">Frank (2006)[[ refid=''''b0045'''' ]]</ce:cross-ref> is defined as the straight line length between two point objects. For example, in <ce:cross-ref refid=""""f0015"""">Fig. 3</ce:cross-ref> the distance is <ce:italic>very close</ce:italic> from <ce:italic>TCOON</ce:italic> 051 to <ce:italic>TCOON</ce:italic> 018, <ce:italic>close</ce:italic> from <ce:italic>TCOON</ce:italic> 017 to <ce:italic>TCOON</ce:italic> 047, <ce:italic>medium</ce:italic> from <ce:italic>TCOON</ce:italic> 051 to <ce:italic>TABS K</ce:italic>, and <ce:italic>far</ce:italic> from <ce:italic>TABS K</ce:italic> to <ce:italic>NDBC</ce:italic> 42002. The last symbol <ce:italic>very far</ce:italic> is used to describe the distance that is farther than <ce:italic>far</ce:italic>, for example, between two ocean stations (not shown in <ce:cross-ref refid=""""f0015"""">Fig. 3</ce:cross-ref>). The perception and cognition of distances is context–contingent. The conversion relationship between the qualitative distance and quantitative distance is beyond the scope of this paper. For interested readers, refer to <ce:cross-refs refid=""""b0160 b0165"""">Yao and Thill (2006, 2007)[[ refid=''''b0160 b0165'''' ]]</ce:cross-refs>. </ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
uses_method_in	Qualitative spatial representation and reasoning	H. Stuckenschmidt, F.V. Harmelen, Information sharing on the semantic web , None, Springer (2004)	http://dx.doi.org/10.1016/j.compenvurbsys.2011.04.002			http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2011-04-002/br/b0140	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2011-04-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2011-04-002/ctx/ctx0021		34	3	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2011-04-002/itrp/0004	'We consider areas A 1, … , A n as a partition of a larger area A if (1) A 1 ∪ … ∪ A n = A and (2) A i ∩ A j = 0 for all i ≠ j from (1, … , n) (Stuckenschmidt & Harmelen, 2004[[ refid=''b0140'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0080"""" view=""""all"""">We consider areas <ce:italic>A</ce:italic> <ce:inf loc=""""post"""">1</ce:inf>, <ce:hsp sp=""""0.12""""/>… <ce:hsp sp=""""0.12""""/>, <ce:hsp sp=""""0.12""""/> <ce:italic>A</ce:italic> <ce:inf loc=""""post""""> <ce:italic>n</ce:italic> </ce:inf> as a partition of a larger area <ce:italic>A</ce:italic> if <ce:cross-ref refid=""""e0005"""">(1)</ce:cross-ref> <ce:italic>A</ce:italic> <ce:inf loc=""""post"""">1</ce:inf> <ce:hsp sp=""""0.25""""/>∪ <ce:hsp sp=""""0.25""""/> <ce:inf loc=""""post"""">…</ce:inf> <ce:hsp sp=""""0.25""""/>∪ <ce:hsp sp=""""0.25""""/> <ce:italic>A</ce:italic> <ce:inf loc=""""post""""> <ce:italic>n</ce:italic> </ce:inf> <ce:hsp sp=""""0.25""""/>= <ce:hsp sp=""""0.25""""/> <ce:italic>A</ce:italic> and <ce:cross-ref refid=""""e0010"""">(2)</ce:cross-ref> <ce:italic>A</ce:italic> <ce:inf loc=""""post""""> <ce:italic>i</ce:italic> </ce:inf> <ce:hsp sp=""""0.25""""/>∩<ce:hsp sp=""""0.25""""/> <ce:italic>A</ce:italic> <ce:inf loc=""""post""""> <ce:italic>j</ce:italic> </ce:inf> <ce:hsp sp=""""0.25""""/>= <ce:hsp sp=""""0.25""""/>0 for all <ce:italic>i</ce:italic> <ce:hsp sp=""""0.25""""/>≠ <ce:hsp sp=""""0.25""""/> <ce:italic>j</ce:italic> from (1, <ce:hsp sp=""""0.12""""/>… <ce:hsp sp=""""0.12""""/>, <ce:hsp sp=""""0.12""""/> <ce:italic>n</ce:italic>) (<ce:cross-ref refid=""""b0140"""">Stuckenschmidt &amp; Harmelen, 2004[[ refid=''''b0140'''' ]]</ce:cross-ref>). Partonomies are created by recursively applying the above partition method to divide an area, such as <ce:italic>A</ce:italic> <ce:inf loc=""""post"""">1</ce:inf>, to multiple smaller areas <ce:italic>A</ce:italic> <ce:inf loc=""""post"""">11</ce:inf>, <ce:hsp sp=""""0.12""""/>… <ce:hsp sp=""""0.12""""/>, <ce:hsp sp=""""0.12""""/> <ce:italic>A</ce:italic> <ce:inf loc=""""post"""">1 <ce:italic>m</ce:italic> </ce:inf>. In Texas, the ocean observing stations are deployed from north to south along four cities, <ce:italic>Beaumont</ce:italic>, <ce:italic>Houston</ce:italic>, <ce:italic>Corpus Christi</ce:italic>, and <ce:italic>Brownville</ce:italic>. As a result, four station partonomies in Texas coastal region are shown in <ce:cross-ref refid=""""f0010"""">Fig. 2</ce:cross-ref>a: 1. <ce:italic>Beaumont</ce:italic>, 2. <ce:italic>Houston</ce:italic>, 3. <ce:italic>Corpus Christi</ce:italic>, and 4. <ce:italic>Brownsville</ce:italic>, and <ce:cross-ref refid=""""f0010"""">Fig. 2</ce:cross-ref>b shows the corresponding decomposition tree, where <ce:italic>S</ce:italic> represents a station or a buoy. Each partonomy contains several different types of stations, and one type of station can appear in more than one partonomy. For example, <ce:italic>TABS</ce:italic>, <ce:italic>TCOON</ce:italic>, and <ce:italic>NWLON</ce:italic> stations can be found in all four partonomies, and the partonomy <ce:italic>Corpus Christi</ce:italic> includes <ce:italic>TABS</ce:italic>, <ce:italic>TCOON</ce:italic>, <ce:italic>NWLON</ce:italic>, and <ce:italic>NDBC Moored</ce:italic> (<ce:italic>NDBCM</ce:italic>) buoys. </ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
uses_method_in	Mobile ECS architecture	T. Schierl, T. Wiegand, M. Kampmann, 3gpp Compliant adaptive wireless video streaming using h.264/avc , IEEE International Image Processing, ICIP , vol. 3 (2005), pp.696-699	http://dx.doi.org/10.1016/j.compenvurbsys.2011.07.001			http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2011-07-001/br/b0075	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2011-07-001/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2011-07-001/ctx/ctx0015		21	6	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2011-07-001/itrp/0012	'The frame rate is maintained at 25 fps and the resolution at 720 × 576 pixels (Schierl, Wiegand, & Kampmann, 2005[[ refid=''b0075'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0185"""" view=""""all"""">In the city of Valencia, High-Speed Uplink Packet Access (HSUPA) is the most advanced public wireless technology, and it also has sufficient coverage. HSUPA is specified in the UMTS release 6, and is an evolution of High Speed Downlink Packet Access (HSDPA) which is focused on improving upload speed through the use of an enhanced dedicated channel (E-DCH) in the upstream. Using this technology, it is possible to achieve rates of 7.2 <ce:hsp sp=""""0.25""""/>Mbps of downlink and 2 <ce:hsp sp=""""0.25""""/>Mbps of uplink, giving an improvement of five times the uplink rate of its predecessor. The UCCAR, which generates content for the network, will use this improved uplink channel. With this new rate of transfer, it is theoretically possible to transmit one video flow at a rate of 1.95 <ce:hsp sp=""""0.25""""/>Mbps with a frame rate of 25 <ce:hsp sp=""""0.25""""/>fps and a coding bit rate of 1500 <ce:hsp sp=""""0.25""""/>Kbps, or three simultaneous flows with a frame rate of 5 <ce:hsp sp=""""0.25""""/>fps and a coding bitrate of 500 <ce:hsp sp=""""0.25""""/>Kbps, which significantly improves the quality of the system. It is important to remember that all these data are theoretical, and that the video transfer rates of the real system are conditioned by factors such as coverage, distance from the antenna, capacity and quantity of users, environmental factors, interference, etc. Therefore, the configuration of the video server is kept at dynamic bitrate, in such a way that it adapts the coding rate to the uplink bandwidth of the channel. The frame rate is maintained at 25 <ce:hsp sp=""""0.25""""/>fps and the resolution at 720 <ce:hsp sp=""""0.25""""/>× <ce:hsp sp=""""0.25""""/>576 pixels (<ce:cross-ref refid=""""b0075"""">Schierl, Wiegand, &amp; Kampmann, 2005[[ refid=''''b0075'''' ]]</ce:cross-ref>). </ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
uses_method_in	Results	V. Meyer, C. Kuhlicke, J. Luther, S. Fuchs, S. Priest, W. Dorner, Recommendations for the user-specific enhancement of flood maps , Natural Hazards and Earth Systems Sciences , vol. 56 (2012), pp.1701-1716	http://dx.doi.org/10.1016/j.compenvurbsys.2012.07.007	results		http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-07-007/br/b0230	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-07-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-07-007/ctx/ctx0046		55	4	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-07-007/itrp/0037	'In two workshop rounds, 12 and 6 stakeholders participated, respectively, and 15 interviews were conducted (Meyer et al., 2012[[ refid=''b0230'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0120"""" view=""""all"""">To elicit empirical local knowledge, stakeholders from the Mulde river basin – heavily affected by the 2002 flood – in Saxony, Germany were invited to participate in round-table workshops and face-to-face interviews. In two workshop rounds, 12 and 6 stakeholders participated, respectively, and 15 interviews were conducted (<ce:cross-ref refid=""""b0230"""">Meyer et al., 2012[[ refid=''''b0230'''' ]]</ce:cross-ref>). The invited stakeholders came from different authorities, being responsible for different administrative levels (i.e., the Wurzen and Bennewitz municipalities, the rural districts of Leipzig and Nordsachsen, the administrative district of Leipzig, the federal flood protection agency of Saxony). They had different work objectives (e.g., emergency management, planning, strategic risk management). The stakeholders were asked about the intensity parameters, at-risk elements and deliverables most relevant to their work. All stakeholder information was considered and treated equally, i.e., no importance ranking was conducted. Instead, stakeholder knowledge was integrated if a common agreement could be found and it fit the scope and purpose of the ontology.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
uses_method_in	Results	Kollarits, S., & Wergles, N. (2008).	http://dx.doi.org/10.1016/j.compenvurbsys.2012.07.007	results		http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-07-007/br/b0190	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-07-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-07-007/ctx/ctx0047		55	4	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-07-007/itrp/0038	'We refer to the SWEET ontologies using the prefix SWEET and to the MONITOR ontology by Kollarits and Wergles (2008)[[ refid=''b0190'' ]] using the prefix MONITOR.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0130"""" view=""""all"""">Flood is only a particular type, i.e., a subclass, of <ce:italic>Event</ce:italic>. <ce:cross-ref refid=""""f0015"""">Fig. 3</ce:cross-ref><ce:float-anchor refid=""""f0015""""/> shows a semantic network of these core concepts. In these networks, named classes (e.g. <ce:italic>Flood</ce:italic>) are shown as labeled ellipses. Unlabeled ellipses represent anonymous classes. The taxonomic structure between classes, i.e., subclass relations, is indicated by unlabeled, bold arcs, with the arrowhead pointing to the respective superclass. Non-taxonomic object and datatype properties are depicted as labeled arcs, with the arrowhead pointing at the property range. Rectangles represent literals, i.e., values for OWL object or datatype properties. <ce:cross-ref refid=""""f0015"""">Fig. 3</ce:cross-ref>A resembles the definition of <ce:italic>Flood</ce:italic> as shown above; it becomes clear that a flood is defined as a subclass of <ce:italic>Event</ce:italic> and is further integrated with the SWEET ontologies as appropriate. We refer to the SWEET ontologies using the prefix <ce:monospace>SWEET</ce:monospace> and to the MONITOR ontology by <ce:cross-ref refid=""""b0190"""">Kollarits and Wergles (2008)[[ refid=''''b0190'''' ]]</ce:cross-ref> using the prefix <ce:monospace>MONITOR</ce:monospace>. Hence, <ce:italic>Flood</ce:italic> is devised as a subclass of <ce:italic>SWEET:Inundation</ce:italic> and <ce:italic>SWEET:HydrospherePhenomena</ce:italic>.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
uses_method_in	Building the flood risk assessment ontology	V. Meyer, C. Kuhlicke, J. Luther, S. Fuchs, S. Priest, W. Dorner, Recommendations for the user-specific enhancement of flood maps , Natural Hazards and Earth Systems Sciences , vol. 56 (2012), pp.1701-1716	http://dx.doi.org/10.1016/j.compenvurbsys.2012.07.007			http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-07-007/br/b0230	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-07-007/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-07-007/ctx/ctx0042		55	4	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-07-007/itrp/0051	'Participatory means were also used to collect and review further terms and concepts as part of the RISK MAP project (Meyer et al., 2012[[ refid=''b0230'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0110"""" view=""""all"""">Further terms and relations were gathered, and the relative importance of previously elicited terms was reviewed using Text-to-Onto. This is a tool for automatically extracting lexica from textual sources. Selected peer-reviewed articles (<ce:cross-refs refid=""""b0005 b0035 b0125 b0155 b0150 b0165 b0170 b0320"""">Akter &amp; Simonovic, 2005; Brouwer &amp; van Ek, 2004; Hansson, Danielson, &amp; Ekenberg, 2008; Jonkman, Kok, &amp; Vrijling, 2008; Jonkman, van Gelder, &amp; Vrijling, 2003; Kenyon, 2007; Kienberger, Lang, &amp; Zeil, 2009; Tkach &amp; Simonovic, 1997[[ refid=''''b0005 b0035 b0125 b0155 b0150 b0165 b0170 b0320'''' ]]</ce:cross-refs>) and other documents like directives and research reports (<ce:cross-refs refid=""""b0075 b0280"""">The European Parliament and the Council of the European Union, 2007; Samuels et al., 2009[[ refid=''''b0075 b0280'''' ]]</ce:cross-refs>) were analyzed using Text-to-Onto to determine the number of occurrences of specific terms and linguistic relations between them. No explicit numeric threshold has been defined to distinguish more relevant from less relevant terms. Instead, already elicited terms were checked against Text-to-Onto’s list of terms, and additional terms were added to the lexicon if they fit the purpose and scope of the ontology. Participatory means were also used to collect and review further terms and concepts as part of the RISK MAP project (<ce:cross-ref refid=""""b0230"""">Meyer et al., 2012[[ refid=''''b0230'''' ]]</ce:cross-ref>). To build the glossary, community-agreed definitions were added to each lexicon term. Finally, the elicited concepts were matched against their semantic counterparts in the SWEET ontologies.</ce:para>""''"'	cites_as_review	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Ontology-enabled framework for geospatial PSE	G. Babitski, S. Bergweiler, J. Hoffmann, D. Schön, C. Stasch, A. Walkowski, Ontology-based integration of sensor web services in disaster management , GeoSpatial semantics 2009, LNCS 5892, Springer-Verlag (2009)	http://dx.doi.org/10.1016/j.compenvurbsys.2012.10.008			http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-10-008/br/b0025	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-10-008/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-10-008/ctx/ctx0029		47	4	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-10-008/itrp/0013	'The “OGC Abstract Specification Topic 2: Spatial Referencing by Coordinates” extends the classes under the SRS, such as Datum and Projection, to declare the classification (Babitski et al., 2009[[ refid=''b0025'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0095"""" view=""""all"""">The “OGC Abstract Specification Topic 2: Spatial Referencing by Coordinates” extends the classes under the <ce:italic>SRS</ce:italic>, such as <ce:italic>Datum</ce:italic> and <ce:italic>Projection</ce:italic>, to declare the classification (<ce:cross-ref refid=""""b0025"""">Babitski et al., 2009[[ refid=''''b0025'''' ]]</ce:cross-ref>). Various SRSs (e.g., WGS84, a SRS for the latitude and longitude) can be created as individuals under the extended classes for further reference.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Ontology-enabled framework for geospatial PSE	OGC (2006a). OpenGIS implementation specification for geographic information – Simple feature access – Part 1: Common architecture technical report 06-103r4.	http://dx.doi.org/10.1016/j.compenvurbsys.2012.10.008			http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-10-008/br/b0245	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-10-008/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-10-008/ctx/ctx0030		47	4	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2012-10-008/itrp/0068	'The “OGC Simple Feature Access Part 1: Common Architecture” provides a categorization of common geospatial geometries that can be expanded into classes under the Geometry class (OGC, 2006a[[ refid=''b0245'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0100"""" view=""""all"""">The “OGC Simple Feature Access Part 1: Common Architecture” provides a categorization of common geospatial geometries that can be expanded into classes under the <ce:italic>Geometry</ce:italic> class (<ce:cross-ref refid=""""b0245"""">OGC, 2006a[[ refid=''''b0245'''' ]]</ce:cross-ref>). However, we consider only vector-type geometries such as points, polylines, and polygons and leave raster geometry for future work.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Application domain: mega-urbanization and water resources	K. Wiethoff, K. Baier, Megacities – Areas in transition. Abandoned sites as an expression of a continuously changing mega-urban landscape , Proceedings of Megacities – Interactions Between Land Use and Water Management – Mitteilungen zur Ingenieurgeologie und Hydrogeologie , vol. 99 (2009), pp.83-92	http://dx.doi.org/10.1016/j.compenvurbsys.2015.01.006	motivation		http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2015-01-006/br/b0260	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2015-01-006/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2015-01-006/ctx/ctx0010		44	7	http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2015-01-006/itrp/0062	'Massive land use and land cover changes initially take place within already existing build-up areas; then they expand outwards in the adjacent suburban region and the urban fringe (Wiethoff & Baier, 2009[[ refid=''b0260'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0045"""" view=""""all"""">This high-speed urbanization describes a mostly uncontrollable interplay between processes of land use transformation and large-scale migration with far-reaching consequences for the environment and society (<ce:cross-ref id=""""c0050"""" refid=""""b0250"""">Wehrhahn et al., 2008[[ refid=''''b0250'''' ]]</ce:cross-ref>). Massive land use and land cover changes initially take place within already existing build-up areas; then they expand outwards in the adjacent suburban region and the urban fringe (<ce:cross-ref id=""""c0055"""" refid=""""b0260"""">Wiethoff &amp; Baier, 2009[[ refid=''''b0260'''' ]]</ce:cross-ref>).</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
uses_method_in	Methodology and data	F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, É. Duchesnay, Scikit-learn: Machine learning in Python , Journal of Machine Learning Research , vol. 12 (2011), pp.2825-2830	http://dx.doi.org/10.1016/j.compenvurbsys.2017.01.001	data	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2017-01-001/br/bb0455>	<http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2017-01-001/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2017-01-001/ctx/ctx0032>				http://www.scar.disi.unibo.it/r/10-1016-j-compenvurbsys-2017-01-001/itrp/0089	'For the implementation, we have used Scikit-learn, an open-source Python module for machine learning (Pedregosa et al., 2011[[ refid=''bb0455'' ]]).'			FDY+AGA	infered_pred1
uses_data_from	Experiments evaluating NER and RE	I. Segura-Bedmar, R. Revert, P. Martínez, Detecting drugs and adverse events from Spanish social media streams , Proceedings of the 5th International Workshop on Health Document Text Mining and Information Analysis (Louhi), EACL (2014)	http://dx.doi.org/10.1016/j.compind.2015.10.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2015-10-006/br/bib0330	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2015-10-006/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2015-10-006/ctx/ctx0032		40	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2015-10-006/itrp/0030	'SpanishADR [26][[ refid=''bib0330'' ]] is the first Spanish corpus annotated with drugs and effects by two annotators expert in the field; it consists of 400 user messages collected from ForumClínic.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0395"""" view=""""all"""">SpanishADR <ce:cross-ref id=""""crf0510"""" refid=""""bib0330"""">[26][[ refid=''''bib0330'''' ]]</ce:cross-ref> is the first Spanish corpus annotated with drugs and effects by two annotators expert in the field; it consists of 400 user messages collected from ForumClínic. The size of the corpus is 26,519 tokens, whereas each message contains an average of 3.15 annotations (0.48 drugs, 1.42 effects and 1.25 relations). Moreover, it contains 189 drug annotations, 568 effect annotations and 164 drug–effect relations (the extension of SpanishADR corpus with drug-effect annotations is described in <ce:cross-ref id=""""crf0515"""" refid=""""bib0320"""">[24][[ refid=''''bib0320'''' ]]</ce:cross-ref>). An assessment of the inter-annotator agreement (IAA) revealed that while drugs showed a high IAA (0.89), their effects pointed to moderate agreement (0.59). This may be due to drugs having specific names and being limited in number, while their effects are expressed by patients in many different ways due to the variability and richness of natural language.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesDataFrom_semweb
cites_as_review	Related works	P. Min, M. Kazhdan, T. Funkhouser, A comparison of text and shape matching for retrieval of online 3D models , Res. Adv. Technol. Digit. Libr. (2004)	http://dx.doi.org/10.1016/j.compind.2016.01.002	related work		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-01-002/br/bib0305	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-01-002/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-01-002/ctx/ctx0022		46	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-01-002/itrp/0001	'Min et al. [12][[ refid=''bib0305'' ]] evaluated text and shape matching methods for retrieval of online 3D models; they also reviewed the combination of text and shape matching.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0110"""" view=""""all"""">Several studies have been proposed to recognize semantic information in text of 3D models and CAD drawings. Min et al. <ce:cross-ref id=""""crf0195"""" refid=""""bib0305"""">[12][[ refid=''''bib0305'''' ]]</ce:cross-ref> evaluated text and shape matching methods for retrieval of online 3D models; they also reviewed the combination of text and shape matching. For text matching, they collected several sources of text associated with a particular 3D model from a web page. The text sources included file names, labels in the 3D model, link text, web page context, and web page title. They used WordNet to disambiguate the meaning of extracted text. Yu and Hsu <ce:cross-ref id=""""crf0200"""" refid=""""bib0310"""">[13][[ refid=''''bib0310'''' ]]</ce:cross-ref> proposed a content-based CAD drawing retrieval system using the text mining technique. They extracted the textual characteristic content from CAD drawings and stored it in an indexed database. They represented the characteristic contents of the CAD drawings using a Vector Space Model. Based on the characteristic contents, similarity calculation was conducted between a query description and indexed CAD drawings to retrieve the most relevant CAD drawings. They used a domain corpus to moderate semantic ambiguity in the text of CAD drawings.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Related works	B. Gao, H. Zheng, S. Zhang, An overview of semantics processing in content-based 3D model retrieval , 2009 Int. Conf. Artif. Intell. Comput. Intell., IEEE (2009)	http://dx.doi.org/10.1016/j.compind.2016.01.002	related work		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-01-002/br/bib0400	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-01-002/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-01-002/ctx/ctx0019		46	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-01-002/itrp/0042	'Gao et al. [31][[ refid=''bib0400'' ]] surveyed semantic processing in content-based 3D model retrieval.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0105"""" view=""""all"""">In the area of 3D model retrieval, there have been several studies that have attempted to reduce the semantic gap between low-level features (e.g., color, shape, texture) and high-level semantics (concepts). Gao et al. <ce:cross-ref id=""""crf0180"""" refid=""""bib0400"""">[31][[ refid=''''bib0400'''' ]]</ce:cross-ref> surveyed semantic processing in content-based 3D model retrieval. They divided high-level semantic processing into three main categories: (1) using relevant feedback based online learning; (2) using offline machine learning; (3) using an ontology. The online and machine learning based approaches classify low-level features into specific high-level semantics using machine learning techniques. The ontology based approach divides 3D models into different classes by mapping low-level features to high-level semantics according to a predefined ontology. Wang et al. <ce:cross-ref id=""""crf0185"""" refid=""""bib0315"""">[14][[ refid=''''bib0315'''' ]]</ce:cross-ref> proposed an ontology and rule-based 3D model retrieval system (Onto3D) to reflect the semantic information of 3D models. Using a rule engine, Onto3D can infer the semantic properties of 3D models (e.g., hasPart) and retrieve the target models using a predefined ontology. Symonova et al. <ce:cross-ref id=""""crf0190"""" refid=""""bib0405"""">[32][[ refid=''''bib0405'''' ]]</ce:cross-ref> described a method for the retrieval of 3D shapes (furniture models) using ontology-based shape annotation. They decomposed a 3D shape into its components and extracted shape distribution vectors from each component. Based on mapping between the shape distribution vectors and ontology concepts, semantic labels of the 3D shapes were annotated. These studies focused only on annotating the meaning of the 3D shape; they did not exploit detailed 3D information such as relationships between 3D objects.</ce:para>""''"'	cites_as_review	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Architecture of MESSRS	G. Mountrakis, J. Im, C. Ogole, Support vector machines in remote sensing: a review , ISPRS J. Photogramm. Remote Sens. , vol. 66 (2011), pp.247-259	http://dx.doi.org/10.1016/j.compind.2016.04.005			http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-04-005/br/bib0095	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-04-005/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-04-005/ctx/ctx0016		22	3	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-04-005/itrp/0024	'The Classification sub-process converts raw data into meaningful, useful and understandable information [19][[ refid=''bib0095'' ]], that is to say, each object is classified with the corresponding geometric primitive according to its features, in turn obtained by calculating the percentage of the fit of each primitive (cylinder, tori, sphere and plane); these percentages are then evaluated and the primitive type with the highest fitting percentage is selected and assigned.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0110"""" view=""""all"""">The semi-automatic process of recognizing geometric primitives in MESSRS was inspired by the work presented by <ce:cross-ref id=""""crf0085"""" refid=""""bib0005"""">[1][[ refid=''''bib0005'''' ]]</ce:cross-ref>. However, some characteristics were adapted to the needs of MESSRS. MESSRS is a semi-automatic model which suggests a classification of objects into the point cloud, in other words, an expert can reclassify items according to their knowledge. The Primitive Recognition process is divided into three sub-processes: 1) Preprocess. This aims to reduce information to improve the quality of the original scene <ce:cross-ref id=""""crf0090"""" refid=""""bib0040"""">[8][[ refid=''''bib0040'''' ]]</ce:cross-ref>. Duplicated information was removed in this sub-process and points were ordered with a space-partitioning data structure. 2) Descriptor extraction. This sub-process extracts geometric features that allow mathematical descriptions for each object <ce:cross-ref id=""""crf0095"""" refid=""""bib0010"""">[2][[ refid=''''bib0010'''' ]]</ce:cross-ref>, and 3) Classification. The Classification sub-process converts raw data into meaningful, useful and understandable information <ce:cross-ref id=""""crf0100"""" refid=""""bib0095"""">[19][[ refid=''''bib0095'''' ]]</ce:cross-ref>, that is to say, each object is classified with the corresponding geometric primitive according to its features, in turn obtained by calculating the percentage of the fit of each primitive (cylinder, tori, sphere and plane); these percentages are then evaluated and the primitive type with the highest fitting percentage is selected and assigned. The combination of geometric primitives allows the generation of complex geometric shapes, which describe real-world objects. This paper focuses on an industrial environment; therefore, each primitive has been assigned to a real element according to their similarity.</ce:para>""''"'	uses_data_from	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Smart, safe and sustainable industrial systems	S. Kriaa, L. Pietre-Cambacedes, M. Bouissou, Y. Halgand, A survey of approaches combining safety and security for industrial control systems , Reliab. Eng. Syst. Saf. , vol. 139 (2015), pp.156-178	http://dx.doi.org/10.1016/j.compind.2016.05.001			http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-05-001/br/bib0185	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-05-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-05-001/ctx/ctx0004		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-05-001/itrp/0028	'This vision is not new; it was initially designed for complex systems when designers were seeking to develop systems from a functional point of view, possibly including Integrated Logistics Support (ILS), and co-designed to ensure functional support of the complex system [37][[ refid=''bib0185'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0035"""" view=""""all"""">“<ce:bold>Safe</ce:bold>” is taken here in the broad sense, referring for example to the <ce:italic>reliability</ce:italic>, <ce:italic>availability, security, testability and maintainability dimensions</ce:italic> of products, processes and industrial systems that are evaluated through dependability studies <ce:cross-ref id=""""crf0085"""" refid=""""bib0035"""">[7][[ refid=''''bib0035'''' ]]</ce:cross-ref>. This dimension aims at ensuring the correct functioning and the permanent safety of the three types of entities, in whichever lifecycle phase they evolve or are studied. <ce:italic>Robustness</ce:italic> and <ce:italic>resilience</ce:italic> are also relevant concepts when dealing with reaction and adaptation to perturbations during their use, whether localized or more global <ce:cross-ref id=""""crf0090"""" refid=""""bib0045"""">[9][[ refid=''''bib0045'''' ]]</ce:cross-ref>. This vision is not new; it was initially designed for complex systems when designers were seeking to develop systems from a functional point of view, possibly including Integrated Logistics Support (ILS), and co-designed to ensure functional support of the complex system <ce:cross-ref id=""""crf0095"""" refid=""""bib0185"""">[37][[ refid=''''bib0185'''' ]]</ce:cross-ref>. We think it is crucial to consider safety as a whole and through this, to look at future products, processes and industrial systems with a global, functional view of their lifecycle. In such a context, it is worth mentioning that only few studies have been carried out to ensure the safety and the dependability of future industrial systems characterized by the “bottom-up” approaches introduced <ce:cross-ref id=""""crf0100"""" refid=""""bib0330"""">[66][[ refid=''''bib0330'''' ]]</ce:cross-ref>. Some of the papers in this special issue address this dimension, thanks to which future industrial systems, products and processes will be predictable: They will be doing what they are designed to do in a safe way, they will perform safe production processes, and their interaction with humans will not be dangerous or will not result in hazardous decisions being made.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Perspectives of future research in the ‘3S’ dimension	A. Giret, D. Trentesaux, V. Prabhu, Sustainability in manufacturing operations scheduling: a state of the art review , J. Manuf. Syst. (2015)	http://dx.doi.org/10.1016/j.compind.2016.05.001	motivation		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-05-001/br/bib0155	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-05-001/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-05-001/ctx/ctx0038		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-05-001/itrp/0065	'Despite some efforts at high levels (typically supply chain level) or at technical level (e.g., “green” technologies), intermediary levels that typically deal with intelligent and smart planning, scheduling and control, are still not addressed from a sustainability perspective [31][[ refid=''bib0155'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0180"""" view=""""all"""">The sustainable dimension is also rarely addressed when working on future products, processes and industrial systems. Despite some efforts at high levels (typically supply chain level) or at technical level (e.g., “green” technologies), intermediary levels that typically deal with intelligent and smart planning, scheduling and control, are still not addressed from a sustainability perspective <ce:cross-ref id=""""crf0360"""" refid=""""bib0155"""">[31][[ refid=''''bib0155'''' ]]</ce:cross-ref>. Until now, the most studied field relevant to sustainability at this level is energy <ce:cross-ref id=""""crf0365"""" refid=""""bib0300"""">[60,[[ refid=''''bib0300'''' ]]</ce:cross-ref><ce:cross-ref id=""""crf0370"""" refid=""""bib0310"""">62][[ refid=''''bib0310'''' ]]</ce:cross-ref>. The question is how smart entities, intelligent products or future industrial systems can provide new solutions to achieve “green” functioning or liveable industrial conditions.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites	Introduction	A. Rese, D. Baier, What methods and instruments do innovation networks use? Findings from a survey , Hands-On Methods for Developing Innovation Communities, Springer (2012)	http://dx.doi.org/10.1016/j.compind.2016.06.002	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/br/bib0455	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/ctx/ctx0002		140	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/itrp/0013	'Rese and Baier [91][[ refid=''bib0455'' ]] highlight how TRIZ is seldom used in innovation networks, as well as its exploitation has resulted in several unsuccessful experiences.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0035"""" view=""""all"""">On the other hand, several works remark the limited employment of TRIZ in industrial settings and argue about its effectiveness. Rese and Baier <ce:cross-ref id=""""crf0020"""" refid=""""bib0455"""">[91][[ refid=''''bib0455'''' ]]</ce:cross-ref> highlight how TRIZ is seldom used in innovation networks, as well as its exploitation has resulted in several unsuccessful experiences. Similar results had already emerged in the analysis of German industry performed by Schneider et al. <ce:cross-ref id=""""crf0025"""" refid=""""bib0475"""">[95][[ refid=''''bib0475'''' ]]</ce:cross-ref>. Sakao <ce:cross-ref id=""""crf0030"""" refid=""""bib0470"""">[94][[ refid=''''bib0470'''' ]]</ce:cross-ref> mentions an experiment within eco-design, in which solutions obtained through TRIZ were outperformed by concepts elaborated with other design methodologies. Howard et al. <ce:cross-ref id=""""crf0035"""" refid=""""bib0240"""">[48][[ refid=''''bib0240'''' ]]</ce:cross-ref> underline that the use of TRIZ for concept generation is effective just when designers master the theory proficiently. Most significantly, the limited use of TRIZ in the industrial environment clearly emerges in Graner and Mißler-Behr’s <ce:cross-ref id=""""crf0040"""" refid=""""bib0215"""">[43][[ refid=''''bib0215'''' ]]</ce:cross-ref> review of the literature concerning the diffusion of New Product Development methods in the practice.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites	Research about TRIZ: selection and clustering of relevant contributions	L.I. Meho, K. Yang, Impact of data sources on citation counts and rankings of LIS faculty: web of Science versus Scopus and Google Scholar , J. Am. Soc. Inf. Sci. Technol. , vol. 58 (2007), pp.2105-2125	http://dx.doi.org/10.1016/j.compind.2016.06.002			http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/br/bib0400	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/ctx/ctx0020		140	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/itrp/0070	'For instance, while the indexing of Web of Science resulted too restrictive, thus excluding supposedly relevant peer-reviewed material, the employment of Google Scholar would have led to difficulties in identifying the fundamental literature due to overabundance of data [80][[ refid=''bib0400'' ]], likely populated by a large number of divulgations characterized by loose review processes.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0110"""" view=""""all"""">Consistently with this vision, the authors extracted the publications to be analysed from an acknowledged scientific dataset, i.e. Scopus, in January 2016. The authors opted to use this database by attempting to find a compromise between reliability of the sources, availability of a large number of publications, ease of cataloguing the results according to certain criteria, provided support in processing bibliographic data. For instance, while the indexing of Web of Science resulted too restrictive, thus excluding supposedly relevant peer-reviewed material, the employment of Google Scholar would have led to difficulties in identifying the fundamental literature due to overabundance of data <ce:cross-ref id=""""crf0110"""" refid=""""bib0400"""">[80][[ refid=''''bib0400'''' ]]</ce:cross-ref>, likely populated by a large number of divulgations characterized by loose review processes. Besides, the latter does not allow the search of keywords in the main parts of papers (abstract, keywords) and this implies the overwhelming number of poorly pertinent results potentially obtained through this instrument.</ce:para>""''"'	uses_data_from	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Review of the most cited TRIZ-related contributions	J.F.V. Vincent, Biomimetics − a review proceedings of the institution of mechanical engineers , Part H: J. Eng. Med. , vol. 223 (2009), pp.919-939	http://dx.doi.org/10.1016/j.compind.2016.06.002			http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/br/bib0580	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/ctx/ctx0040		140	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/itrp/0118	'Finally, a review on biomimetics [116][[ refid=''bib0580'' ]] includes a chapter on TRIZ, where the peculiarities of using TRIZ in the field are discussed.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0265"""" view=""""all"""">There is no surprise that the creation of a taxonomy of biology effects is still an ongoing process and TRIZ is found useful in addressing this kind of studies. The idea was taken up mostly by Julian Vincent with co-authors and produced a series of papers (included in the bottom cluster of <ce:cross-ref id=""""crf0235"""" refid=""""fig0005"""">Fig. 1</ce:cross-ref>). First, Vincent and Mann <ce:cross-ref id=""""crf0240"""" refid=""""bib0590"""">[118][[ refid=''''bib0590'''' ]]</ce:cross-ref> acknowledge the potential of specific TRIZ tools for systematic technology transfer from biology to engineering. In Ref. <ce:cross-ref id=""""crf0245"""" refid=""""bib0575"""">[115][[ refid=''''bib0575'''' ]]</ce:cross-ref>, the “design” of biological material (arthropod cuticle) is analysed from the perspective of contradiction elimination: it is shown how certain smart cuticle’s features can be “reinvented” by IPs application. However, the study shows also that the reconstruction of contradictions would often recommend different IPs. In other words, it is shown that there is a difference in resolution of design conflicts in biology and technology. This resulted in the construction of a biology-tailored contradiction matrix (named BioTRIZ) in a subsequent paper <ce:cross-ref id=""""crf0250"""" refid=""""bib0585"""">[117][[ refid=''''bib0585'''' ]]</ce:cross-ref>. The difference between BioTRIZ matrix and Altshuller’s original one is highlighted through a systematic biology-based idea generation process concerning a winter tire design. Statistics of patents’ growth according to bio-inspired principles are presented in <ce:cross-ref id=""""crf0255"""" refid=""""bib0060"""">[12][[ refid=''''bib0060'''' ]]</ce:cross-ref>, which discusses, besides, biomimetics’ main characteristics at that time and its possible future developments. Craig et al. <ce:cross-ref id=""""crf0260"""" refid=""""bib0155"""">[31][[ refid=''''bib0155'''' ]]</ce:cross-ref> provide an exhaustive case study (inventive design in the field of roof insulation) about the use of the abovementioned BioTRIZ. Finally, a review on biomimetics <ce:cross-ref id=""""crf0265"""" refid=""""bib0580"""">[116][[ refid=''''bib0580'''' ]]</ce:cross-ref> includes a chapter on TRIZ, where the peculiarities of using TRIZ in the field are discussed. In particular, it is pointed out how biology can enrich TRIZ-based design and which measures should be undertaken to ease the technology transfer between technical and biological domains.</ce:para>""''"'	cites_as_review	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Review of the most cited TRIZ-related contributions	N. Leon, The future of computer-aided innovation , Comput. Ind. , vol. 60 (2009), pp.539-550	http://dx.doi.org/10.1016/j.compind.2016.06.002			http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/br/bib0325	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/ctx/ctx0042		140	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/itrp/0120	'Leon [65][[ refid=''bib0325'' ]] presents an overview on the CAI concept, its main components, approaches and perspectives.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0275"""" view=""""all"""">Leon <ce:cross-ref id=""""crf0275"""" refid=""""bib0325"""">[65][[ refid=''''bib0325'''' ]]</ce:cross-ref> presents an overview on the CAI concept, its main components, approaches and perspectives. It is an interesting attempt to connect TRIZ capabilities with other concepts and techniques classically belonging to the conceptual design field: optimization techniques and evolution algorithms, sematic web and data mining, integration to Product Lifecycle Management and even chaos theory. In a certain sense, the work attempts to delineate the extent of the domain in which CAI can operate. Consistently with this view, Cugini et al. <ce:cross-ref id=""""crf0280"""" refid=""""bib0160"""">[32][[ refid=''''bib0160'''' ]]</ce:cross-ref> and Albers et al. <ce:cross-ref id=""""crf0285"""" refid=""""bib0010"""">[2][[ refid=''''bib0010'''' ]]</ce:cross-ref> already present interesting examples of CAI-based mechanical designs: a scooter wheel and an engine crankshaft, respectively. The former presents the design flow, integrating stages of new concept generation (based on TRIZ) and optimization. Further integration to PLM is also discussed. The latter develops previous findings of León-Rovira et al. <ce:cross-ref id=""""crf0290"""" refid=""""bib0330"""">[66][[ refid=''''bib0330'''' ]]</ce:cross-ref> and suggests genetic algorithms to be used for embedding the new conceptual solutions into a CAD interface. Both the papers highlight the possibility of using computational (topology) optimization to retrieve design contradictions, which can be seen as an important contribution for design automation development.</ce:para>""''"'	cites_as_review	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Review of the most cited TRIZ-related contributions	G. Cortes Robles, S. Negny, J.M. Le Lann, Case-based reasoning and TRIZ: a coupling for innovative conception in Chemical Engineering , Chem. Eng. Process. Process Intensif. , vol. 48 (2009), pp.239-249	http://dx.doi.org/10.1016/j.compind.2016.06.002			http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/br/bib0150	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/ctx/ctx0063		140	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-06-002/itrp/0246	'Cortes Robles et al. [30][[ refid=''bib0150'' ]] provide an extensive comparative review on CBR and TRIZ.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0335"""" view=""""all"""">Cortes Robles et al. <ce:cross-ref id=""""crf0395"""" refid=""""bib0150"""">[30][[ refid=''''bib0150'''' ]]</ce:cross-ref> provide an extensive comparative review on CBR and TRIZ. A roadmap and an algorithm are presented in which TRIZ formulates problem’s contradiction(s), while CBR retrieves previous successful cases based on contradiction similarity. A case study from chemical process engineering is given. Another paper from the same research team <ce:cross-ref id=""""crf0400"""" refid=""""bib0425"""">[85][[ refid=''''bib0425'''' ]]</ce:cross-ref> further develops the previous study: environmental aspects are included, case-similarity criteria comprise more features and adaptability is introduced and discussed as an evaluation parameter. The approach is illustrated through a case study from chemical process engineering too. Jou et al. <ce:cross-ref id=""""crf0405"""" refid=""""bib0265"""">[53][[ refid=''''bib0265'''' ]]</ce:cross-ref> face problems in a similar way. First, CBR and TRIZ are compared and TRIZ is claimed to lack memory (dissimilarly from the opinion of the authors of the present paper). Then, a design procedure is suggested, in which TRIZ is integrated to look for solutions outside of the given engineering domain covered by the CBR database. The whole article is devoted to the design of an educational system for a robotics class. A roadmap including CBR and TRIZ is also the focus of <ce:cross-ref id=""""crf0410"""" refid=""""bib0620"""">[124][[ refid=''''bib0620'''' ]]</ce:cross-ref>, which integrates environmental considerations with respect to the above contributions. The paper evolves in <ce:cross-ref id=""""crf0415"""" refid=""""bib0625"""">[125][[ refid=''''bib0625'''' ]]</ce:cross-ref>, where a simplified Life Cycle Assessment is used to judge if a new concept is better than the currently available ones. The design of a mobile phone display serves as an illustrative example.</ce:para>""''"'	cites_as_review	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Introduction	A. Josang, R. Ismail, C. Boyd, A survey of trust and reputation systems for online service provision , Decis. Support Syst. , vol. 43 (2007), pp.618-644	http://dx.doi.org/10.1016/j.compind.2016.08.002	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-08-002/br/bib0055	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-08-002/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-08-002/ctx/ctx0005		45	4	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-08-002/itrp/0041	'One of the significant issues in single source based reputation systems is the vulnerability to falsifying information [11][[ refid=''bib0055'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0040"""" view=""""all"""">Most of these reputation systems are based on single web source. One of the significant issues in single source based reputation systems is the vulnerability to falsifying information <ce:cross-ref id=""""crf0055"""" refid=""""bib0055"""">[11][[ refid=''''bib0055'''' ]]</ce:cross-ref>. Since the ratings are obtained and stored on a single location, therefore the malicious users can easily post false ratings. In addition, sometimes single source based reputation systems lack evaluation information because these systems have only one source to obtain ratings. Furthermore, the credibility of the source or central server is another issue <ce:cross-ref id=""""crf0060"""" refid=""""bib0055"""">[11][[ refid=''''bib0055'''' ]]</ce:cross-ref>. When the source itself is a buyer, seller or intermediate then how we can trust the reputation system? Does the source adopt sophisticated security measures so that the credibility of evaluation information can be trusted?</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Backgrounds	C. Mair, M. Martincova, M. Shepperd, A literature review of expert problem solving using analogy , Eval. Assess. Softw. Eng. (2009) , http://bura.brunel.ac.uk/handle/2438/3468	http://dx.doi.org/10.1016/j.compind.2016.08.004	background		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-08-004/br/bib0065	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-08-004/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-08-004/ctx/ctx0007		69	6	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-08-004/itrp/0040	'Mair et al. [13][[ refid=''bib0065'' ]] state that an electronic form of Case-based reasoning cycle allows the development of an altered and approved outcome.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0045"""" view=""""all"""">The process of cost estimation incorporates a great deal of subjectivity and specialist input is generally required whether a basic spreadsheet or intricate cost modelling system is used. An estimate is a specialist’s view of an expected future cost. While expert problem solving is not a specific cost estimation procedure, it is well understood and often used <ce:cross-refs id=""""crfs0010"""" refid=""""bib0010 bib0015"""">[2,3][[ refid=''''bib0010 bib0015'''' ]]</ce:cross-refs>. Specialists in the field generally reach estimated figures through the use of analogies and comparisons <ce:cross-refs id=""""crfs0015"""" refid=""""bib0020 bib0025 bib0030 bib0035 bib0040 bib0045 bib0050"""">[4–10][[ refid=''''bib0020 bib0025 bib0030 bib0035 bib0040 bib0045 bib0050'''' ]]</ce:cross-refs>. Studies undertaken by Sinclair et al. <ce:cross-ref id=""""crf0100"""" refid=""""bib0055"""">[11][[ refid=''''bib0055'''' ]]</ce:cross-ref> reached the conclusion that existing methods of reasoned application were overly simplified throughout the construction industry. These methods regularly use existing items (with known specifics) to draw comparisons with new items (with unknown specifics). Once the details have been allocated to the item it then moves from being new to existing <ce:cross-ref id=""""crf0105"""" refid=""""bib0060"""">[12][[ refid=''''bib0060'''' ]]</ce:cross-ref>. The National Aeronautics and Space Administration utilises a valuable cost estimation model that is similar to this, which incorporates clear processes for undertaking estimation. This style of process does, however, provide only an abstract portrayal of estimation requirements. This is particularly clear when considering the Eurostat survey method, which cannot be analysed by computers. Quantity surveying, in relation to project cost estimation, requires the completion of systematic or analogical tasks. They undertake these processes, using historical data, to build a cost estimate. In general, cost estimation activities require the detection of an analogical link between the project in question and the previous work, associating the specifics of the project with their equivalent points, leading to a clear result. Mair et al. <ce:cross-ref id=""""crf0110"""" refid=""""bib0065"""">[13][[ refid=''''bib0065'''' ]]</ce:cross-ref> state that an electronic form of Case-based reasoning cycle allows the development of an altered and approved outcome. As a result, as highlighted by RSMeans <ce:cross-ref id=""""crf0115"""" refid=""""bib0070"""">[14][[ refid=''''bib0070'''' ]]</ce:cross-ref> and The Building Cost Information Service <ce:cross-ref id=""""crf0120"""" refid=""""bib0075"""">[15][[ refid=''''bib0075'''' ]]</ce:cross-ref> problems are solved by linking the outcomes of previous work to current challenges.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Recent research in product modeling	S.E. Kadiri, D. Kiritsis, Ontologies in the context of product lifecycle management: state of the art literature review , Int. J. Prod. Res. , vol. 53 (2015), pp.5657-5668	http://dx.doi.org/10.1016/j.compind.2016.11.001	model		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-11-001/br/bib0145	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-11-001/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-11-001/ctx/ctx0038		113	4	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-11-001/itrp/0035	'Through studies on various ontology-based product models and ontology-based applications, Kadiri and Kiritsis [29][[ refid=''bib0145'' ]] summarized 7 key roles of ontology: (1) trusted source of knowledge, (2) database, (3) knowledge base, (4) bridge for multiple domains, (5) mediator for interoperability, (6) contextual search enabler, and (7) Linked Data enabler.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0175"""" view=""""all"""">For practitioner engineers working on product modeling, ontology could be the concept that is least understood and accepted. Questions, such as what ontology is, what roles ontology plays, and whether ontology is needed, are often raised within scientific and engineering communities <ce:cross-ref id=""""crf0290"""" refid=""""bib0145"""">[29][[ refid=''''bib0145'''' ]]</ce:cross-ref>. Through studies on various ontology-based product models and ontology-based applications, Kadiri and Kiritsis <ce:cross-ref id=""""crf0295"""" refid=""""bib0145"""">[29][[ refid=''''bib0145'''' ]]</ce:cross-ref> summarized 7 key roles of ontology: (1) trusted source of knowledge, (2) database, (3) knowledge base, (4) bridge for multiple domains, (5) mediator for interoperability, (6) contextual search enabler, and (7) Linked Data enabler. For product modeling, since different product ontologies were implemented for the same scope, harmonization and normalization of ontologies should also be taken care of <ce:cross-ref id=""""crf0300"""" refid=""""bib0145"""">[29][[ refid=''''bib0145'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Background	R.F. Babiceanu, R. Seker, Big Data and virtualization for manufacturing Cyber-Physical Systems: a survey of the current status and future outlook , Comput. Ind. , vol. 81 (2016), pp.128-137	http://dx.doi.org/10.1016/j.compind.2016.12.001	background		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-12-001/br/bib0215	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-12-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-12-001/ctx/ctx0025		62	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2016-12-001/itrp/0014	'As a baseline, CPSs are related to concepts such as Internet of Things (IoT), Systems of Systems (SoS) and Big Data [43][[ refid=''bib0215'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0100"""" view=""""all"""">As a baseline, CPSs are related to concepts such as Internet of Things (IoT), Systems of Systems (SoS) and Big Data <ce:cross-ref id=""""crf0240"""" refid=""""bib0215"""">[43][[ refid=''''bib0215'''' ]]</ce:cross-ref>. Therefore, they are considered as “Open Systems”, since they can not only use cloud information (where computation can come from anywhere) <ce:cross-ref id=""""crf0245"""" refid=""""bib0220"""">[44][[ refid=''''bib0220'''' ]]</ce:cross-ref>, but also consider human users both in- and out-of-the-loop <ce:cross-ref id=""""crf0250"""" refid=""""bib0070"""">[14][[ refid=''''bib0070'''' ]]</ce:cross-ref>. CPSs are both structurally and functionally open. Structural openness means that they can include collaborative sub-systems of varying spatial and complexity scales in time and space. Functional openness implies that they can consist of units (computers, agent, components, network…) that may enter or leave the system at any time <ce:cross-refs id=""""crfs0030"""" refid=""""bib0070 bib0225"""">[14,46][[ refid=''''bib0070 bib0225'''' ]]</ce:cross-refs>. On the opposite, closed mechatronics systems are often characterized by their independence (“embedded”) and self-reliance, and rather consider humans outside the loop.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Concept overview	S. Mitchelmore, J. Rowley, Entrepreneurial competencies: a literature review and development agenda , Int. J. Entrep. Behav. Res. , vol. 16 (2010), pp.92-111	http://dx.doi.org/10.1016/j.compind.2017.05.001			http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-05-001/br/bib0110	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-05-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-05-001/ctx/ctx0020		74	4	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-05-001/itrp/0003	'Defining competencies is a challenging task and multiple definitions exist [22][[ refid=''bib0110'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0065"""" view=""""all"""">Defining competencies is a challenging task and multiple definitions exist <ce:cross-ref id=""""crf0110"""" refid=""""bib0110"""">[22][[ refid=''''bib0110'''' ]]</ce:cross-ref>. Generally, they can be considered as “the sum of our experiences and the knowledge, competencies, values and attitudes we have acquired during out lifetime” <ce:cross-ref id=""""crf0115"""" refid=""""bib0115"""">[23][[ refid=''''bib0115'''' ]]</ce:cross-ref>. Similarly, it is considered <ce:cross-ref id=""""crf0120"""" refid=""""bib0120"""">[24][[ refid=''''bib0120'''' ]]</ce:cross-ref> that competency is a “a set of behavior patterns that the incumbent needs to bring to a position in the order to perform its tasks and functions with competency”, and it is also pointed out that several individual competencies are needed to do so. However, as pointed out <ce:cross-ref id=""""crf0125"""" refid=""""bib0125"""">[25][[ refid=''''bib0125'''' ]]</ce:cross-ref>: “it should be remembered that competencies do not exist in isolation”. Although the precise definition of competency depends on the context <ce:cross-ref id=""""crf0130"""" refid=""""bib0125"""">[25][[ refid=''''bib0125'''' ]]</ce:cross-ref>, it can be considered that generally competencies are <ce:italic>”a combination of attributes such as knowledge, abilities, competencies and attitudes which enable an individual to perform a set of tasks to an appropriate standard”</ce:italic><ce:cross-ref id=""""crf0135"""" refid=""""bib0130"""">[26][[ refid=''''bib0130'''' ]]</ce:cross-ref>. As the OECD report <ce:cross-ref id=""""crf0140"""" refid=""""bib0135"""">[27][[ refid=''''bib0135'''' ]]</ce:cross-ref> points out, competency involves “the ability to meet complex demands, by drawing on and mobilizing psychosocial resources (including competencies and attitudes) in a particular context”. competencies can be learned and are considered traits of successful employees within an organization. Competencies can be considered from a wider viewpoint to include competencies, knowledge, behaviors etc. that are necessary to effectively complete a task.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Concept overview	G. Steptoe-Warren, D. Howat, I. Hume, Strategic thinking and decision making: literature review , J. Strateg. Manage. , vol. 4 (2011), pp.238	http://dx.doi.org/10.1016/j.compind.2017.05.001			http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-05-001/br/bib0205	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-05-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-05-001/ctx/ctx0035		74	4	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-05-001/itrp/0057	'It is pointed out [41][[ refid=''bib0205'' ]] that “managerial cognition, corporate values as well as individual values and beliefs can have an influence on strategic decision-making choices”.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0100"""" view=""""all"""">Strategic thinking is praised as a key competency that can lead to success. Strategy in today''''s competitive business landscape is moving away from the basic “strategic planning” to more of “strategic thinking” in order to remain competitive <ce:cross-ref id=""""crf0190"""" refid=""""bib0200"""">[40][[ refid=''''bib0200'''' ]]</ce:cross-ref>. It is pointed out <ce:cross-ref id=""""crf0195"""" refid=""""bib0205"""">[41][[ refid=''''bib0205'''' ]]</ce:cross-ref> that “managerial cognition, corporate values as well as individual values and beliefs can have an influence on strategic decision-making choices”. The availability of several MOOCs on strategic thinking, may assist the development of this competency as participants learn the theory, and via examples how to do practice it. In addition, MOOCs are promoting a results-driven culture, where in short time-frames new knowledge is put into test and assessed immediately. As such people also learn to work methodologically and focus on the important aspects that yield the best outcome.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Concept overview	S. Hoidn, K. Kärkkä inen, Promoting skills for innovation in higher education: A literature review on the effectiveness of problem-based learning and of teaching behaviours, Tech. rep. , None, Organisation for Economic Co-operation and Development (OECD), oECD Education Working Papers, No. 100, OECD Publishing (2014, January)	http://dx.doi.org/10.1016/j.compind.2017.05.001			http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-05-001/br/bib0240	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-05-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-05-001/ctx/ctx0044		74	4	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-05-001/itrp/0087	'Innovators and entrepreneurs require competency sets for innovation such as technical competencies, thinking and creativity competencies, as well as social and behavioral competencies [48][[ refid=''bib0240'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0130"""" view=""""all"""">Employee competencies constitute a key factor for innovation. Several competencies seem to have an effect on innovation <ce:cross-ref id=""""crf0230"""" refid=""""bib0235"""">[47][[ refid=''''bib0235'''' ]]</ce:cross-ref>: “Competencies such as alertness to new opportunities, ability to present products, ideas or reports, ability to mobilize the capacities of others, ability to come-up with new ideas and solutions, and ability to use computers and the Internet appear to have stronger marginal effects on the likelihood of innovating and, consequently, emerge as key competencies in explaining the propensity of individuals to become innovators in their working environments”. Innovators and entrepreneurs require competency sets for innovation such as technical competencies, thinking and creativity competencies, as well as social and behavioral competencies <ce:cross-ref id=""""crf0235"""" refid=""""bib0240"""">[48][[ refid=''''bib0240'''' ]]</ce:cross-ref>. In highly innovative economies competent labor, in combination with sector specific knowledge, form the engine for service innovation and quality manufacturing <ce:cross-ref id=""""crf0240"""" refid=""""bib0245"""">[49][[ refid=''''bib0245'''' ]]</ce:cross-ref>. The level of knowledge and type of competencies constitute key factors for matching supply and demand in the knowledge economy. From the investments in intangible assets, the competencies and qualifications of employees are seen as the biggest beneficiaries <ce:cross-ref id=""""crf0245"""" refid=""""bib0250"""">[50][[ refid=''''bib0250'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Introduction	K.H. Yang, J. Hu, N.A. White, A.I. King, C.C. Chou, P. Prasad, Development of numerical models for injury biomechanics research: a review of 50 years of publications in the Stapp Car Crash Conference , Stapp Car Crash J. , vol. 50 (2006), pp.429-490	http://dx.doi.org/10.1016/j.compind.2017.06.006	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-006/br/bib0035	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-006/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-006/ctx/ctx0006		46	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-006/itrp/0035	'Biomechanics is considered as a bridge discipline between medicine and mechanical engineering which enables the 3D representation and numerical simulation of biomechanical structures with specific constitutive laws [7][[ refid=''bib0035'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0025"""" view=""""all"""">Similar stakes in biomechanics still exist with such approaches in CAD application <ce:cross-ref id=""""crf0030"""" refid=""""bib0030"""">[6][[ refid=''''bib0030'''' ]]</ce:cross-ref>. Biomechanics is considered as a bridge discipline between medicine and mechanical engineering which enables the 3D representation and numerical simulation of biomechanical structures with specific constitutive laws <ce:cross-ref id=""""crf0035"""" refid=""""bib0035"""">[7][[ refid=''''bib0035'''' ]]</ce:cross-ref>. According to the same authors, some mathematical models of the human body have been proposed over the last decades <ce:cross-ref id=""""crf0040"""" refid=""""bib0035"""">[7][[ refid=''''bib0035'''' ]]</ce:cross-ref>. By considering the main geometric parameters and specific material properties of its components, such models aim at to be the most biofidelic as possible in order to predict the behaviour of related mechanical structures <ce:cross-ref id=""""crf0045"""" refid=""""bib0035"""">[7][[ refid=''''bib0035'''' ]]</ce:cross-ref>. Thus, the development of realistic biomechanical models goes through a particular attention to the shape, size and more generally the anthropometry of the geometry used to develop these models. Even if these models enable more or less to simulate the average population with a 50th percentile geometry, it becomes critical to develop robust and configurable models, including position, geometric and structural characteristics of a given population, in a parametric and central manner.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Related work	J.-M. Nurmilaakso, EDI, XML and e-business frameworks: a survey , Comput. Ind. , vol. 59 (2008), pp.370-379	http://dx.doi.org/10.1016/j.compind.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/br/bib0105	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/ctx/ctx0023		58	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/itrp/0002	'An analysis of the use of the ASC X12, EDIFACT and XML formats in 38 e-business frameworks is presented in [21][[ refid=''bib0105'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0085"""" view=""""all"""">An analysis of the use of the ASC X12, EDIFACT and XML formats in 38 e-business frameworks is presented in <ce:cross-ref id=""""crf0140"""" refid=""""bib0105"""">[21][[ refid=''''bib0105'''' ]]</ce:cross-ref>. The use of EDI-based or XML-based e-business frameworks in 7593 European companies is discussed. The authors conclude that EDI formats retained a strong position in cross-industry-document e-business frameworks, and the XML format is gaining importance in industry-specific e-business frameworks and dominates in cross-industry-process e-business frameworks. The adoption of e-business functions and migration from EDI-based to XML-based e-business frameworks in supply chain integration is explored in <ce:cross-ref id=""""crf0145"""" refid=""""bib0110"""">[22][[ refid=''''bib0110'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Related work	J.M. Nurmilaakso, P. Kotinurmi, A review of XML-based supply-chain integration , Prod. Plann. Control , vol. 15 (2004), pp.608-621	http://dx.doi.org/10.1016/j.compind.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/br/bib0040	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/ctx/ctx0018		58	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/itrp/0056	'A review of 15 XML-based supply chain integration e-business frameworks is available in [8][[ refid=''bib0040'' ]]: AEX, BMEcat, BPEL4WS, CIDX, CITE, eBIS-XML, eBuild-XML, IXRetail, OpenTrans, PDX, PIDX, PSL, STAR, TranXML, UBL.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0070"""" view=""""all"""">Enabling technologies for B2B interactions and frameworks are discussed in <ce:cross-ref id=""""crf0110"""" refid=""""bib0090"""">[18][[ refid=''''bib0090'''' ]]</ce:cross-ref>. The dimensions for evaluating the B2B interaction frameworks are: coupling among partners, heterogeneity, autonomy, external manageability, adaptability, security and scalability. A review of 15 XML-based supply chain integration e-business frameworks is available in <ce:cross-ref id=""""crf0115"""" refid=""""bib0040"""">[8][[ refid=''''bib0040'''' ]]</ce:cross-ref>: AEX, BMEcat, BPEL4WS, CIDX, CITE, eBIS-XML, eBuild-XML, IXRetail, OpenTrans, PDX, PIDX, PSL, STAR, TranXML, UBL. The authors emphasize the advantages of XML, show how the frameworks analyzed solve integration problems, emphasizing that their large number of versions cause interoperability challenges as complete transformations between frameworks are not always possible.</ce:para>""''"'	cites_as_review	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Introduction	R. Rezaei, T. Kian Chiew, S. Pack Lee, A review of e-business interoperability frameworks , J. Syst. Softw. , vol. 93 (2014), pp.199-216	http://dx.doi.org/10.1016/j.compind.2017.06.010	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/br/bib0050	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/ctx/ctx0011		58	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/itrp/0065	'Recent works, although aiming to review e-business interoperability frameworks [10][[ refid=''bib0050'' ]], did not actually tackle domain-specific interoperability frameworks.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0045"""" view=""""all"""">Most articles addressing interoperability in the context of e-business focus on e-business frameworks, e.g., <ce:cross-refs id=""""crfs0010"""" refid=""""bib0035 bib0040 bib0045 bib0010 bib0050 bib0015"""">[7–9,2,10,3][[ refid=''''bib0035 bib0040 bib0045 bib0010 bib0050 bib0015'''' ]]</ce:cross-refs> are descriptive in nature. In several cases the actual use in practice of the respective framework is not addressed (e.g., <ce:cross-ref id=""""crf0060"""" refid=""""bib0050"""">[10][[ refid=''''bib0050'''' ]]</ce:cross-ref>). The coverage of interoperability requirements is not analyzed. Domain-specific standardization initiatives receive little attention <ce:cross-ref id=""""crf0065"""" refid=""""bib0205"""">[41][[ refid=''''bib0205'''' ]]</ce:cross-ref>, although numerous advances were made. In order to attain seamless interoperability in today’s networked economy, when accurate real-time information exchange is crucial for successful businesses, and spans different organizations from different industries, it is important to understand the specificities of each domain specific approach. Recent works, although aiming to review e-business interoperability frameworks <ce:cross-ref id=""""crf0070"""" refid=""""bib0050"""">[10][[ refid=''''bib0050'''' ]]</ce:cross-ref>, did not actually tackle domain-specific interoperability frameworks. Other works focus on a specific case study <ce:cross-ref id=""""crf0075"""" refid=""""bib0055"""">[11][[ refid=''''bib0055'''' ]]</ce:cross-ref>, or implementations following a certain standard specifications, as in: <ce:cross-refs id=""""crfs0015"""" refid=""""bib0060 bib0065"""">[12,13][[ refid=''''bib0060 bib0065'''' ]]</ce:cross-refs>. An up-to-date review or analysis of current advances of domain-specific initiatives for seamless communication is not available, although highly relevant. This article addresses this gap.</ce:para>""''"'	cites_as_review	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Related work	A. Dogac, I. Cingil, A survey and comparison of business-to-business e-commerce frameworks , ACM SIGecom Exch. , vol. 2 (2001), pp.16-27	http://dx.doi.org/10.1016/j.compind.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/br/bib0080	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/ctx/ctx0015		58	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/itrp/0069	'A comparative analysis of the eCo framework, RosettaNet, BizTalk, cXML and MESChain is presented in [16][[ refid=''bib0080'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0065"""" view=""""all"""">A comparative analysis of five business-to-business frameworks (eCo, BizTalk, OBI, cXML, RosettaNet) concerning security, communication protocols, service discovery, repositories, message format, query mechanism, scalability and ontology aspects is presented in <ce:cross-ref id=""""crf0090"""" refid=""""bib0070"""">[14][[ refid=''''bib0070'''' ]]</ce:cross-ref>. A special focus, however, is on security issues related to enterprise business transactions over the Internet. An overview of BizTalk, cXML, eCo Framework, ICE (Information and Content Exchange), IOTP (Internet Open Trading Protocol), OAG (Open Applications Group), RosettaNet, xCBL, ebXML and ontology.org frameworks is available in <ce:cross-ref id=""""crf0095"""" refid=""""bib0075"""">[15][[ refid=''''bib0075'''' ]]</ce:cross-ref>. A comparative analysis of the eCo framework, RosettaNet, BizTalk, cXML and MESChain is presented in <ce:cross-ref id=""""crf0100"""" refid=""""bib0080"""">[16][[ refid=''''bib0080'''' ]]</ce:cross-ref>. The comparison criteria concern product taxonomy support, catalog support, service discovery, document conversion, automated business process support. The eCo, RosettaNet, BizTalk and e-Speak frameworks are analyzed in <ce:cross-ref id=""""crf0105"""" refid=""""bib0085"""">[17][[ refid=''''bib0085'''' ]]</ce:cross-ref>. The focus is on e-service components, and the criteria used for the comparison are: service discovery, service brokering, service negotiation, service mediation, service billing, service payment, service composition and service security.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Related work	Y. Zhao, K. Sandahl, XML-based frameworks for internet commerce , Enterprise Information System II, Springer Science+Business Media (2001)	http://dx.doi.org/10.1016/j.compind.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/br/bib0075	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/ctx/ctx0014		58	5	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-06-010/itrp/0070	'An overview of BizTalk, cXML, eCo Framework, ICE (Information and Content Exchange), IOTP (Internet Open Trading Protocol), OAG (Open Applications Group), RosettaNet, xCBL, ebXML and ontology.orgframeworks is available in [15][[ refid=''bib0075'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0065"""" view=""""all"""">A comparative analysis of five business-to-business frameworks (eCo, BizTalk, OBI, cXML, RosettaNet) concerning security, communication protocols, service discovery, repositories, message format, query mechanism, scalability and ontology aspects is presented in <ce:cross-ref id=""""crf0090"""" refid=""""bib0070"""">[14][[ refid=''''bib0070'''' ]]</ce:cross-ref>. A special focus, however, is on security issues related to enterprise business transactions over the Internet. An overview of BizTalk, cXML, eCo Framework, ICE (Information and Content Exchange), IOTP (Internet Open Trading Protocol), OAG (Open Applications Group), RosettaNet, xCBL, ebXML and ontology.org frameworks is available in <ce:cross-ref id=""""crf0095"""" refid=""""bib0075"""">[15][[ refid=''''bib0075'''' ]]</ce:cross-ref>. A comparative analysis of the eCo framework, RosettaNet, BizTalk, cXML and MESChain is presented in <ce:cross-ref id=""""crf0100"""" refid=""""bib0080"""">[16][[ refid=''''bib0080'''' ]]</ce:cross-ref>. The comparison criteria concern product taxonomy support, catalog support, service discovery, document conversion, automated business process support. The eCo, RosettaNet, BizTalk and e-Speak frameworks are analyzed in <ce:cross-ref id=""""crf0105"""" refid=""""bib0085"""">[17][[ refid=''''bib0085'''' ]]</ce:cross-ref>. The focus is on e-service components, and the criteria used for the comparison are: service discovery, service brokering, service negotiation, service mediation, service billing, service payment, service composition and service security.</ce:para>""''"'	cites_as_review	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Related works	A. Akram, D. Chohan, X.D. Wang, X. Yang, R. Allan, A Service Oriented Architecture for Portals Using Portlets , UK e-Science AHM 2005 (2005)	http://dx.doi.org/10.1016/j.compind.2017.08.005	related work		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-08-005/br/bib0115	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-08-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-08-005/ctx/ctx0022		50	7	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-08-005/itrp/0001	'In [23][[ refid=''bib0115'' ]], it is presented a survey of all the types of Service Oriented Architectures for portals using portlets.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0090"""" view=""""all"""">The architecture on which the portal is built is, of course, of primary importance since, for example, it has to allow for flexible integration of new services. For this reason we searched for possible solutions for the KBMS 2.0. Once the objectives to define an innovative portal are established, the architecture should be chosen with the purpose to best satisfy the requirements of the stakeholders. In <ce:cross-ref id=""""crf0140"""" refid=""""bib0115"""">[23][[ refid=''''bib0115'''' ]]</ce:cross-ref>, it is presented a survey of all the types of Service Oriented Architectures for portals using portlets.</ce:para>""''"'	cites_as_review	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Introduction	H. Lausen, Y. Ding, M. Stollberg, D. Fensel, R.L. Hernandez, S.-K. Han, Semantic web portals: state-of-the-art survey , J. Knowl. Manage. , vol. 9 (2005), pp.40-49 , http://dblp.uni-trier.de/db/journals/jkm/jkm9.html#LausenDSFHH05	http://dx.doi.org/10.1016/j.compind.2017.08.005	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-08-005/br/bib0105	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-08-005/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-08-005/ctx/ctx0009		50	7	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-08-005/itrp/0021	'Semantics are aimed at representing users in ad-hoc profiles to better exploit knowledge in the portal [21][[ refid=''bib0105'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0040"""" view=""""all"""">This paper presents a portal for companies with an improved knowledge management. For instance, knowledge portals interconnect individuals and provide logical links between user''''s roles and documents in the repository to unify networking <ce:cross-ref id=""""crf0035"""" refid=""""bib0125"""">[25][[ refid=''''bib0125'''' ]]</ce:cross-ref>. The portal described in this paper makes a further step with respect to the <ce:italic>standard</ce:italic> knowledge portals as it considers both features of personalization and semantics to interconnect users and knowledge. Personalization is aimed at modeling the user context by analyzing the user''''s knowledge (i.e., preferences, activities), and by defining processes that exploit such knowledge in order to tailor the search outcome to his/her information needs <ce:cross-refs id=""""crfs0010"""" refid=""""bib0130 bib0135 bib0140 bib0145"""">[26–29][[ refid=''''bib0130 bib0135 bib0140 bib0145'''' ]]</ce:cross-refs>. Semantics are aimed at representing users in ad-hoc profiles to better exploit knowledge in the portal <ce:cross-ref id=""""crf0040"""" refid=""""bib0105"""">[21][[ refid=''''bib0105'''' ]]</ce:cross-ref>. The definition of personalized methodologies has become easier, thanks to user profiles that store user''''s knowledge, i.e. preferences, interests, activities, and personal data. Ontologies have been more recently considered powerful and expressive means for representing knowledge of user profiles <ce:cross-refs id=""""crfs0015"""" refid=""""bib0150 bib0155"""">[30,31][[ refid=''''bib0150 bib0155'''' ]]</ce:cross-refs>. This paper presents how to define user profiles represented as an ontology in an innovative way by considering the Ontology Design Patterns (ODP) <ce:cross-ref id=""""crf0045"""" refid=""""bib0160"""">[32][[ refid=''''bib0160'''' ]]</ce:cross-ref>. ODP are defined as a <ce:italic>“reusable successful solution to a recurrent modeling problem”</ce:italic>, and they are aimed at reducing mistakes in ontologies, detecting uncovered requirements, improving qualities of produced ontologies, etc. <ce:cross-refs id=""""crfs0020"""" refid=""""bib0165 bib0170"""">[33,34][[ refid=''''bib0165 bib0170'''' ]]</ce:cross-refs>. In the literature, semantic portals adopt ontologies to define a logical structure of contents <ce:cross-refs id=""""crfs0025"""" refid=""""bib0175 bib0180 bib0125"""">[35,36,25][[ refid=''''bib0175 bib0180 bib0125'''' ]]</ce:cross-refs>; in our portal, we consider another approach since the ontology is used to define user''''s knowledge that can be applied to better connect users with documents.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Related works	H. Lausen, Y. Ding, M. Stollberg, D. Fensel, R.L. Hernandez, S.-K. Han, Semantic web portals: state-of-the-art survey , J. Knowl. Manage. , vol. 9 (2005), pp.40-49 , http://dblp.uni-trier.de/db/journals/jkm/jkm9.html#LausenDSFHH05	http://dx.doi.org/10.1016/j.compind.2017.08.005	related work		http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-08-005/br/bib0105	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-08-005/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-08-005/ctx/ctx0018		50	7	http://www.scar.disi.unibo.it/r/10-1016-j-compind-2017-08-005/itrp/0056	'In [21][[ refid=''bib0105'' ]] it is provided a survey of Semantic Web portals.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0075"""" view=""""all"""">We have taken inspiration from the Semantic Web portals that use ontologies to manage the knowledge in the portals in order to define an innovative model for a user profile. In <ce:cross-ref id=""""crf0115"""" refid=""""bib0105"""">[21][[ refid=''''bib0105'''' ]]</ce:cross-ref> it is provided a survey of Semantic Web portals. In detail, the following semantic portals are presented: Esperonto Portal, OntoWeb Portal, Empolis K42 Portal, Mondeca ITM Portal, SWWS Portal, Mindswap Portal, and OntoWebEdu. In these cases, domain ontologies are used to model the knowledge of the portals by mainly considering information about project partners, project members, organization/company, documents, and meetings. The ontologies are connected through several relationships. The common features of these portals are given by the use of ontologies as a browsing search engine, where an ontological taxonomy (or a hyperbolic tree) is used by users/members to retrieve search results linked to concepts and/or instances of the considered taxonomy (or hyperbolic tree). None of these portals can be considered as a complete Semantic Web portal for several reasons: different document types are not explicitly modeled within the ontologies, multi-language capabilities are not supported, there is a lack of collaboration features, a limited use of common Web technologies, an insufficient helpline and documentation, or a poor level of usability. In the present work, at variance with respect of the aforementioned projects we change the point of view by focusing on user ontologies in order to enhance the connection between the users and the documents. With the advent of the Web 2.0, social aspects have assumed a key role in the Semantic Web technologies with the intent to stimulate the communication and interaction among users. In a distributed enterprise environment, users have their own work space and common shared areas for cooperation. The portals previously described do not consider features to support and improve communication between community members. A portal has to guarantee, not only a satisfying solution for the standard Semantic Web features previously presented, but a mixture of advanced functionalities too. These advanced and innovative features are related to the use of ontologies for the following services: user cooperation, knowledge sharing, a network of users with common interests, etc. This integrates personalized functionalities to improve the effectiveness of the portal. Enriching the portal with personalized recommendations provides alternative paths to present data, and increments the possibilities for users to discover the contents they are interested in. In <ce:cross-ref id=""""crf0120"""" refid=""""bib0205"""">[41][[ refid=''''bib0205'''' ]]</ce:cross-ref> a conceptual model for extracting personalized recommendations based on user profiling, ontological domain models, and semantic reasoning is presented. The approach offers a high-level representation of the designed application based on a domain specific metamodel (i.e., the <ce:italic>Artist</ce:italic> ontology domain) for Web applications called WebML <ce:cross-ref id=""""crf0125"""" refid=""""bib0210"""">[42][[ refid=''''bib0210'''' ]]</ce:cross-ref>. The considered ontology-user profile models three knowledge aspects, that are: (1) user''''s data, (2) user explicit preferences on ontological objects, (3) user requests on ontological objects related to his/her navigation.</ce:para>""''"'	cites_as_review	AGA+ANG	50_classified_citesAsReview_semweb
extends	Related work	A. Armando, S.E. Ponta, Model checking of security-sensitive business processes , Formal aspects in security and trust, 6th international workshop, FAST09, Springer , vol. vol. 5983 (2010), pp.66-80	http://dx.doi.org/10.1016/j.cose.2013.10.002	related work		http://www.scar.disi.unibo.it/r/10-1016-j-cose-2013-10-002/br/bib3	http://www.scar.disi.unibo.it/r/10-1016-j-cose-2013-10-002/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-cose-2013-10-002/ctx/ctx0056		55	6	http://www.scar.disi.unibo.it/r/10-1016-j-cose-2013-10-002/itrp/0053	'The present paper extends Armando and Ponta (2010)[[ refid=''bib3'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p1350"""" view=""""all"""">The present paper extends <ce:cross-ref refid=""""bib3"""" id=""""crosref0665"""">Armando and Ponta (2010)[[ refid=''''bib3'''' ]]</ce:cross-ref>. A wider variety of business process features are now supported and the properties of the framework are formally stated and proved. In particular this extended work provides (<ce:italic>i</ce:italic>) support for human and automated tasks; (<ce:italic>ii</ce:italic>) support for data items as input and output to and from tasks; (<ce:italic>iii</ce:italic>) an overview of possible extensions to the framework to show its flexibility; (<ce:italic>iv</ce:italic>) a description of the reduction to SAT of the BMC problem; (<ce:italic>v</ce:italic>) an extended experimental analysis relying on finer grained properties; and (<ce:italic>vi</ce:italic>) formal results showing the correctness of the translation.</ce:para>""''"'	extends	ANG	
uses_method_in	The CAMNEP detection method	R.R. Yager, On ordered weighted averaging aggregation operators in multicriteria decisionmaking , Syst Man Cybern IEEE Transactions (1988)	http://dx.doi.org/10.1016/j.cose.2014.05.011	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cose-2014-05-011/br/bib52>	<http://www.scar.disi.unibo.it/r/10-1016-j-cose-2014-05-011/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-cose-2014-05-011/ctx/ctx0025>				http://www.scar.disi.unibo.it/r/10-1016-j-cose-2014-05-011/itrp/0010	'Each aggregator can use two different averaging operators: an order-weighted averaging (Yager, 1988[[ refid=''bib52'' ]]) or simple weighted averaging.'			FDY+AGA	infered_pred1
uses_method_in	Our suggested active learning based framework	C.C. Chang, C.J. Lin, LIBSVM: a library for support vector machines , ACM Trans Intell Syst Technol (TIST) , vol. 2 (2011), pp.27	http://dx.doi.org/10.1016/j.cose.2014.10.014			<http://www.scar.disi.unibo.it/r/10-1016-j-cose-2014-10-014/br/bib6>	<http://www.scar.disi.unibo.it/r/10-1016-j-cose-2014-10-014/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-cose-2014-10-014/ctx/ctx0055>				http://www.scar.disi.unibo.it/r/10-1016-j-cose-2014-10-014/itrp/0151	'In our implementation we will use Lib-SVM implementation (Chang and Lin, 2011[[ refid=''bib6'' ]]) which is fast and also supports multiclass classification.'			FDY+AGA	infered_pred1
cites_as_review	Related work	V. Chandola, A. Banerjee, V. Kumar, Anomaly detection: a survey , ACM Comput Surv , vol. 41 (2009), pp.None	http://dx.doi.org/10.1016/j.cose.2015.06.004	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-cose-2015-06-004/br/bib11>	<http://www.scar.disi.unibo.it/r/10-1016-j-cose-2015-06-004/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-cose-2015-06-004/ctx/ctx0042>				http://www.scar.disi.unibo.it/r/10-1016-j-cose-2015-06-004/itrp/0031	'Various techniques have been proposed to detect anomalies (Chandola et al., 2009[[ refid=''bib11'' ]]).'			FDY+AGA	infered_pred1
cites_as_review	Introduction	V. Chandola, A. Banerjee, V. Kumar, Anomaly detection: a survey , ACM Comput Surv , vol. 41 (2009), pp.None	http://dx.doi.org/10.1016/j.cose.2015.06.004	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-cose-2015-06-004/br/bib11>	<http://www.scar.disi.unibo.it/r/10-1016-j-cose-2015-06-004/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-cose-2015-06-004/ctx/ctx0004>				http://www.scar.disi.unibo.it/r/10-1016-j-cose-2015-06-004/itrp/0041	'Various techniques have been proposed to detect anomalies (see Chandola et al. (2009)[[ refid=''bib11'' ]] for a survey).'			FDY+AGA	infered_pred1
extends	Introduction	G. Bopche, B. Mehtre, Extending attack graph-based metrics for enterprise network security management , Proceedings of the 3rd international conference on advanced computing, networking and informatics, Springer India , vol. vol. 44 (2016), pp.315-325	http://dx.doi.org/10.1016/j.cose.2016.09.010	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-cose-2016-09-010/br/bib0035	http://www.scar.disi.unibo.it/r/10-1016-j-cose-2016-09-010/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-cose-2016-09-010/ctx/ctx0010		66	8	http://www.scar.disi.unibo.it/r/10-1016-j-cose-2016-09-010/itrp/0140	'This paper is an extension of our previous work (Bopche and Mehtre, 2016[[ refid=''bib0035'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0055"""" view=""""all"""">By observing shortcomings of the previously proposed metrics, we conclude that a change in the network attack surface should be measured with graph distance metrics. To bridge the gap, we explore classical graph distance measures based on the Maximum Common Subgraph (<ce:italic>MCS</ce:italic>) (<ce:cross-ref id=""""crf0065"""" refid=""""bib0040"""">Bunke and Shearer, 1998[[ refid=''''bib0040'''' ]]</ce:cross-ref>) and the Graph Edit Distance (<ce:italic>GED</ce:italic>) (<ce:cross-ref id=""""crf0070"""" refid=""""bib0220"""">Messmer and Bunke, 1998[[ refid=''''bib0220'''' ]]</ce:cross-ref>) to measure the distance between two successive attack graphs adjacent over the time. As shown in <ce:cross-ref id=""""crf0075"""" refid=""""f0010"""">Fig. 1</ce:cross-ref><ce:float-anchor refid=""""f0010""""/>, for a pair of attack graphs, i.e. <mml:math altimg=""""si3.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mo>〈</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mtext>​</mml:mtext><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>G</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>〉</mml:mo></mml:mrow></mml:math> generated for the same network over the sampling interval Δ<ce:italic>t</ce:italic>, the similarity (or distance) between these graphs naturally represents the similarity (or distance) between their respective attack surfaces. Such change measurement (in the network attack surface) is fundamental to the problem of intrusion prevention. This paper is an extension of our previous work (<ce:cross-ref id=""""crf0080"""" refid=""""bib0035"""">Bopche and Mehtre, 2016[[ refid=''''bib0035'''' ]]</ce:cross-ref>). In this paper, we have adopted classical graph distance measures based on the <ce:italic>MCS</ce:italic> and <ce:italic>GED</ce:italic> to our particular problem of monitoring the security of temporal networks. It is because of their inherent capability of handling random structured graphs, where each graph is having unconstrained and unique labels for both nodes and edges (<ce:cross-ref id=""""crf0085"""" refid=""""bib0335"""">Showbridge et al., 1999[[ refid=''''bib0335'''' ]]</ce:cross-ref>). The results obtained from <ce:italic>MCS</ce:italic> and <ce:italic>GED</ce:italic> based metrics assist security analysts in understanding the root causes (i.e. network/security events) responsible for the change in the network attack surface. In doing so, the analyst can gain better insight about the network attack surface and achieve a better understanding of their managed networks. Further, these metrics indicate the potential problems that are not so obvious even with the effective attack graph visualization.</ce:para>""''"'	extends	ANG	
cites_as_review	Countermeasures	V. Chandola, A. Banerjee, V. Kumar, Anomaly detection: a survey , ACM Comput Surv , vol. 41 (2009), pp.15	http://dx.doi.org/10.1016/j.cose.2017.04.006			<http://www.scar.disi.unibo.it/r/10-1016-j-cose-2017-04-006/br/bib0210>	<http://www.scar.disi.unibo.it/r/10-1016-j-cose-2017-04-006/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-cose-2017-04-006/ctx/ctx0098>				http://www.scar.disi.unibo.it/r/10-1016-j-cose-2017-04-006/itrp/0047	'Anomaly is a pattern in data that is not consistent with the schemes of normal behavior (Chandola et al., 2009[[ refid=''bib0210'' ]]).'			FDY+AGA	infered_pred1
uses_method_in	Using mdFoam	H.J.C. Berendsen, J.P.M. Postma, W.F. Gunsteren, A. DiNola, J.R. Haak, , J. Chem. Phys. , vol. 81 (1984), pp.3684-3690	http://dx.doi.org/10.1016/j.cpc.2017.09.029			<http://www.scar.disi.unibo.it/r/10-1016-j-cpc-2017-09-029/br/b38>	<http://www.scar.disi.unibo.it/r/10-1016-j-cpc-2017-09-029/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cpc-2017-09-029/ctx/ctx0020>				http://www.scar.disi.unibo.it/r/10-1016-j-cpc-2017-09-029/itrp/0003	'A Berendsen thermostat [38[[ refid=''b38'' ]]] is applied to the entire domain in order to set the temperature T=300 K.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Molecular dynamics with mdFoam	L. Verlet, , Phys. Rev. , vol. 159 (1967), pp.98-103	http://dx.doi.org/10.1016/j.cpc.2017.09.029			<http://www.scar.disi.unibo.it/r/10-1016-j-cpc-2017-09-029/br/b24>	<http://www.scar.disi.unibo.it/r/10-1016-j-cpc-2017-09-029/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-cpc-2017-09-029/ctx/ctx0009>				http://www.scar.disi.unibo.it/r/10-1016-j-cpc-2017-09-029/itrp/0016	'All MD simulations in this paper (as well as all previous publications using mdFoam+) use the well-known Velocity-Verlet [24[[ refid=''b24'' ]]] scheme, which is illustrated in Fig. 1 and can be described algorithmically for one MD time-step, t→t+Δt, as follows:'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Molecular dynamics with mdFoam	G.B. Macpherson, Niklas Nordin, Henry G. Weller, , Commun. Numer. Methods. Eng. , vol. 25 (2009), pp.263-273	http://dx.doi.org/10.1016/j.cpc.2017.09.029			<http://www.scar.disi.unibo.it/r/10-1016-j-cpc-2017-09-029/br/b25>	<http://www.scar.disi.unibo.it/r/10-1016-j-cpc-2017-09-029/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-cpc-2017-09-029/ctx/ctx0010>				http://www.scar.disi.unibo.it/r/10-1016-j-cpc-2017-09-029/itrp/0070	'Step 1 Estimate the velocity at the mid-step for all N molecules in the system: [[ formulaid=''id11_pos0'' ]] Step 2 Update the positions of all N molecules in the system using OpenFOAM’s inbuilt particle tracking algorithm [25[[ refid=''b25'' ]]], as discussed in Section 2.6, which handles motion of molecules across faces of the mesh (and also deals with boundaries).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method comparisons	Y. Hong, On computing the distribution function for the Poisson binomial distribution , Comput. Statist. Data Anal. , vol. 59 (2013), pp.41-51	http://dx.doi.org/10.1016/j.csda.2018.01.007	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/br/b21>	<http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/ctx/ctx0019>				http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/itrp/0041	'To compare the efficiency of the four methods, we again follow the setup of Hong (2013)[[ refid=''b21'' ]].'			FDY+AGA	infered_pred1
cites	Method comparisons	Y. Hong, On computing the distribution function for the Poisson binomial distribution , Comput. Statist. Data Anal. , vol. 59 (2013), pp.41-51	http://dx.doi.org/10.1016/j.csda.2018.01.007	methods		http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/br/b21	http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/ctx/ctx0018		26	5	http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/itrp/0042	'We report the original TAE values for the DFT-CF algorithm from Hong (2013)[[ refid=''b21'' ]] and denote them as DFT-CF(1), along with the TAE values computed on our own machine, which are denoted as DFT-CF(2).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p18"""">The results of the comparison are provided in <ce:cross-ref refid=""""tbl1"""" id=""""d1e4613"""">Table 1</ce:cross-ref>. We report the original TAE values for the DFT-CF algorithm from <ce:cross-ref refid=""""b21"""" id=""""d1e4616"""">Hong (2013)[[ refid=''''b21'''' ]]</ce:cross-ref> and denote them as DFT-CF(1), along with the TAE values computed on our own machine, which are denoted as DFT-CF(2). For DC-FFT we set <mml:math id=""""mml148"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si148.gif""""><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:math> for the cases when <mml:math id=""""mml149"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si149.gif""""><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>30</mml:mn></mml:math> and <mml:math id=""""mml150"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si150.gif""""><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>32</mml:mn></mml:math> for all others. We see that DC, DC-FFT, and DFT-CF are all accurate in their ability to calculate the correct distribution function, however, we note that DC is almost uniformly more accurate than DC-FFT and DFT-CF. This may be explained by propagated cancellation effects from floating point arithmetic when using Fourier transforms, which requires summing terms with different signs. In contrast, DC only requires summing positive terms, and is thus protected from these errors. Unsurprisingly, RNA is less accurate than the exact methods, but for large <mml:math id=""""mml151"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si2.gif""""><mml:mi>n</mml:mi></mml:math> is still capable of accurately calculating the distribution function. RNA also appears to have more difficulty estimating the distribution function when the success probabilities are far apart from each other, or when they are near 0 or near 1.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Method comparisons	Y. Hong, On computing the distribution function for the Poisson binomial distribution , Comput. Statist. Data Anal. , vol. 59 (2013), pp.41-51	http://dx.doi.org/10.1016/j.csda.2018.01.007	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/br/b21>	<http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/ctx/ctx0013>				http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/itrp/0043	'In order to evaluate the efficacy of the proposed approaches, we recreate the experiments conducted in Hong (2013)[[ refid=''b21'' ]], which first evaluate the accuracy, and then the speed of several algorithms for calculating the Poisson binomial distribution function.'			FDY+AGA	infered_pred1
uses_method_in	Method comparisons	Y. Hong, On computing the distribution function for the Poisson binomial distribution , Comput. Statist. Data Anal. , vol. 59 (2013), pp.41-51	http://dx.doi.org/10.1016/j.csda.2018.01.007	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/br/b21>	<http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/ctx/ctx0017>				http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/itrp/0047	'To give a ground truth distribution function for comparison, we first generate 3 independent Binomial(ni,pi) random variables, X1,X2, and X3, as is done in Hong (2013)[[ refid=''b21'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Method comparisons	M. Frigo, S.G. Johnson, The design and implementation of FFTW3 , Proc. IEEE , vol. 93 (2005), pp.216-231	http://dx.doi.org/10.1016/j.csda.2018.01.007	methods		http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/br/b17	http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/ctx/ctx0016		26	5	http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/itrp/0048	'For our Fourier transform implementation we use the Fastest Fourier Transform in the West (Frigo and Johnson, 2005)[[ refid=''b17'' ]], which is freely available as a library in C, and is easy to use.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p15"""">The DFT-CF method is written in C and then ported to R, so we similarly coded our approaches in C and then ported the code to R to carry out the experiments. For our Fourier transform implementation we use the Fastest Fourier Transform in the West <ce:cross-ref refid=""""b17"""" id=""""d1e4246"""">(Frigo and Johnson, 2005)[[ refid=''''b17'''' ]]</ce:cross-ref>, which is freely available as a library in C, and is easy to use. Aside from being widely used and a standard for FFT computation, it also easily allows for the utilization of specialized algorithms which can speed up the FFT computation — for example, exploiting the fact that our input sequences consist of only real numbers. The output sequence after applying FFT will thus be Hermitian symmetric, which means only half of the FFT result will need to be calculated.</ce:para>""''"'	cites	AGA	
cites	Method comparisons	Y. Hong, On computing the distribution function for the Poisson binomial distribution , Comput. Statist. Data Anal. , vol. 59 (2013), pp.41-51	http://dx.doi.org/10.1016/j.csda.2018.01.007	methods		http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/br/b21	http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/ctx/ctx0015		26	5	http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/itrp/0049	'See Hong (2013)[[ refid=''b21'' ]] for further discussion and details about the RNA method.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p14"""">In order to evaluate the efficacy of the proposed approaches, we recreate the experiments conducted in <ce:cross-ref refid=""""b21"""" id=""""d1e4227"""">Hong (2013)[[ refid=''''b21'''' ]]</ce:cross-ref>, which first evaluate the accuracy, and then the speed of several algorithms for calculating the Poisson binomial distribution function. Since the conclusion of <ce:cross-ref refid=""""b21"""" id=""""d1e4231"""">Hong (2013)[[ refid=''''b21'''' ]]</ce:cross-ref> is that the DFT-CF and refined normal approximation (RNA) are generally preferred to others, we will compare our proposed methods only to them. See <ce:cross-ref refid=""""b21"""" id=""""d1e4235"""">Hong (2013)[[ refid=''''b21'''' ]]</ce:cross-ref> for further discussion and details about the RNA method.</ce:para>""''"'	uses_method_in	AGA	
cites	Method comparisons	Y. Hong, On computing the distribution function for the Poisson binomial distribution , Comput. Statist. Data Anal. , vol. 59 (2013), pp.41-51	http://dx.doi.org/10.1016/j.csda.2018.01.007	methods		http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/br/b21	http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/ctx/ctx0014		26	5	http://www.scar.disi.unibo.it/r/10-1016-j-csda-2018-01-007/itrp/0050	'Since the conclusion of Hong (2013)[[ refid=''b21'' ]] is that the DFT-CF and refined normal approximation (RNA) are generally preferred to others, we will compare our proposed methods only to them.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p14"""">In order to evaluate the efficacy of the proposed approaches, we recreate the experiments conducted in <ce:cross-ref refid=""""b21"""" id=""""d1e4227"""">Hong (2013)[[ refid=''''b21'''' ]]</ce:cross-ref>, which first evaluate the accuracy, and then the speed of several algorithms for calculating the Poisson binomial distribution function. Since the conclusion of <ce:cross-ref refid=""""b21"""" id=""""d1e4231"""">Hong (2013)[[ refid=''''b21'''' ]]</ce:cross-ref> is that the DFT-CF and refined normal approximation (RNA) are generally preferred to others, we will compare our proposed methods only to them. See <ce:cross-ref refid=""""b21"""" id=""""d1e4235"""">Hong (2013)[[ refid=''''b21'''' ]]</ce:cross-ref> for further discussion and details about the RNA method.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Adaptive Cascade Deep Convolutional Neural Networks	A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet Classification With Deep Convolutional Neural Networks[C]//Advances in Neural Information Processing Systems , None (2012)	http://dx.doi.org/10.1016/j.csi.2015.06.004			<http://www.scar.disi.unibo.it/r/10-1016-j-csi-2015-06-004/br/bb0090>	<http://www.scar.disi.unibo.it/r/10-1016-j-csi-2015-06-004/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-csi-2015-06-004/ctx/ctx0022>				http://www.scar.disi.unibo.it/r/10-1016-j-csi-2015-06-004/itrp/0001	'Instead of the standard hyper-tangent function f(x)=tanh(x), Rectified Linear Units (ReLUs) [18][[ refid=''bb0090'' ]]f(x)=max(0,x) is applied to the filter responses to accelerate the training procedure.'			FDY+AGA	infered_pred1
uses_method_in	Experimental protocol	C.-C. Chang, C.-J. Lin, Libsvm: a library for support vector machines , ACM Trans. Intel. Syst. Technol. , vol. 2 (2011), pp.27	http://dx.doi.org/10.1016/j.csl.2015.12.001	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-csl-2015-12-001/br/bib0050>	<http://www.scar.disi.unibo.it/r/10-1016-j-csl-2015-12-001/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-csl-2015-12-001/ctx/ctx0048>				http://www.scar.disi.unibo.it/r/10-1016-j-csl-2015-12-001/itrp/0039	'A SVM classifier is learnt with the LIBSVM library (Chang and Lin, 2011[[ refid=''bib0050'' ]]) using the one-against-one method with a linear kernel.'			FDY+AGA	infered_pred1
uses_method_in	Visual attention to optimize a sequence of segmentation	L. Itti, C. Koch, E. Niebur, A model of saliency-based visual attention for rapid scene analysis , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 20 (1998), pp.1254-1259	http://dx.doi.org/10.1016/j.cviu.2011.09.004			<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2011-09-004/br/b0140>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2011-09-004/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2011-09-004/ctx/ctx0028>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2011-09-004/itrp/0013	'The full process is described in Ref. [28][[ refid=''b0140'' ]] and illustrated in Fig. 6 .'			FDY+AGA	infered_pred1
uses_data_from	Experiments and results	B. Leibe, B. Schiele, Analyzing appearance and contour based methods for object categorization, in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2003, pp. 409–415.	http://dx.doi.org/10.1016/j.cviu.2011.12.001	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2011-12-001/br/b0345>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2011-12-001/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2011-12-001/ctx/ctx0056>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2011-12-001/itrp/0129	'These classes have different number of images varying from 7 to 98 images each.•ETH-80 [69][[ refid=''b0345'' ]]: This database is available in the project COGVIS.'			FDY+AGA	infered_pred1
uses_method_in	Experimental results	A. Vedaldi, B. Fulkerson, VLFeat – an open and portable library of computer vision algorithms, in: ACM International Conference on Multimedia, 2010.	http://dx.doi.org/10.1016/j.cviu.2012.09.007	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2012-09-007/br/b0170>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2012-09-007/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2012-09-007/ctx/ctx0046>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2012-09-007/itrp/0018	'For all datasets, we have extracted SIFT descriptors [34][[ refid=''b0170'' ]] on a dense spatial grid, with the step-size corresponding to half of the patch-size, over 8 scales separated by a factor of 1.2, and the smallest patch-size set to 16 pixels.'			FDY+AGA	infered_pred1
uses_data_from	Experiments	D. Nister, H. Stewenius, Scalable recognition with a vocabulary tree , CVPR (2006)	http://dx.doi.org/10.1016/j.cviu.2013.03.008	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2013-03-008/br/b0015>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2013-03-008/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2013-03-008/ctx/ctx0062>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2013-03-008/itrp/0074	'Currently, ImageNet [3][[ refid=''b0015'' ]] contains more than 12million images and 17,624 categories.'			FDY+AGA	infered_pred1
uses_data_from	Experimental results	J. Xiao, J. Hays, K. Ehinger, A. Oliva, A. Torralba, Sun database: large-scale scene recognition from abbey to zoo, in: Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2010, pp. 3485–3492.	http://dx.doi.org/10.1016/j.cviu.2014.01.010	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2014-01-010/br/b0285>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2014-01-010/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2014-01-010/ctx/ctx0065>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2014-01-010/itrp/0040	'To verify if this is still true for large number of categories, we performed an experiment on the SUN (Scene Understanding) data set [57][[ refid=''b0285'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Cross-modal regularization	C.-C. Chang, C.-J. Lin, LIBSVM: a library for support vector machines , ACM Trans. Intell. Syst. Technol. , vol. 2 (2011), pp.271-2727	http://dx.doi.org/10.1016/j.cviu.2014.03.003			<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2014-03-003/br/b0420>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2014-03-003/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2014-03-003/ctx/ctx0045>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2014-03-003/itrp/0135	'Our SVM implementation is based on the LibSVM [84][[ refid=''b0420'' ]] package.'			FDY+AGA	infered_pred1
uses_method_in	Results of the ICPR 2012 HARL competition	I. Laptev, M. Marszalek, C. Schmid, B. Rozenfeld, Learning realistic human actions from movies, in: International Conference on Computer Vision and Pattern Recognition (CVPR), 2008, pp. 1–8.	http://dx.doi.org/10.1016/j.cviu.2014.06.014	results		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2014-06-014/br/b0285>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2014-06-014/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2014-06-014/ctx/ctx0035>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2014-06-014/itrp/0052	'Space–time interest points were extracted and HoG-HoF (histogram of gradients and histogram of motion flow) features were extracted from the local patches [57][[ refid=''b0285'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Experimental results	A. Vedaldi, B. Fulkerson, VLFeat: An Open and Portable Library of Computer Vision Algorithms, 2008. <	http://dx.doi.org/10.1016/j.cviu.2015.01.005	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-01-005/br/b0200>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-01-005/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-01-005/ctx/ctx0046>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-01-005/itrp/0016	'We use the function vl_phow provided by the vl_feat library [40][[ refid=''b0200'' ]] with default settings.'			FDY+AGA	infered_pred1
uses_method_in	Experimental results	A. Vedaldi, B. Fulkerson, VLFeat: An Open and Portable Library of Computer Vision Algorithms, 2008. <	http://dx.doi.org/10.1016/j.cviu.2015.01.005	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-01-005/br/b0200>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-01-005/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-01-005/ctx/ctx0066>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-01-005/itrp/0024	'In this experiment we use the VLFeat library [40][[ refid=''b0200'' ]] that includes multiple encoding methods such as BOW, LLC, Super Vectors and Fisher Vectors.'			FDY+AGA	infered_pred1
uses_method_in	Experimental evaluation	L. Itti, C. Koch, E. Niebur, A model of saliency based visual attention for rapid scene analysis , IEEE Trans. Pattern Anal. Mach. Intell. (PAMI) , vol. 20 (1998), pp.1254-1259	http://dx.doi.org/10.1016/j.cviu.2015.01.007	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-01-007/br/b0060>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-01-007/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-01-007/ctx/ctx0046>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-01-007/itrp/0021	'Furthermore, it presents similar computational delay with the classic method of Itti [12][[ refid=''b0060'' ]].'			FDY+AGA	infered_pred1
uses_data_from	Experiments	E. Mathias, H. James, A. Marc, How do humans sketch objects? , ACM TOG (Proc. SIGGRAPH) , vol. 31 (2012), pp.44:1-44:10	http://dx.doi.org/10.1016/j.cviu.2015.02.003	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-003/br/b0005>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-003/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-003/ctx/ctx0049>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-003/itrp/0054	'We evaluate our methods on the sketch dataset with the most categories to date proposed by Eitz et al. [1][[ refid=''b0005'' ]], which has 250 categories and 20,000 sketches (80 sketches per category).'			FDY+AGA	infered_pred1
uses_method_in	Experiments	A. Vedaldi, B. Fulkerson, VLFeat: an open and portable library of computer vision algorithms, 2008, <	http://dx.doi.org/10.1016/j.cviu.2015.02.003	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-003/br/b0195>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-003/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-003/ctx/ctx0053>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-003/itrp/0093	'HOG is computed using the VLFeat [39][[ refid=''b0195'' ]] implementation with each patch divided into 4×4 cells and the orientation is set to 4.'			FDY+AGA	infered_pred1
uses_data_from	Introduction	E. Mathias, H. James, A. Marc, How do humans sketch objects? , ACM TOG (Proc. SIGGRAPH) , vol. 31 (2012), pp.44:1-44:10	http://dx.doi.org/10.1016/j.cviu.2015.02.003	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-003/br/b0005>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-003/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-003/ctx/ctx0013>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-003/itrp/0097	'The dataset [1][[ refid=''b0005'' ]] we evaluate on has as many as 250 categories.'			FDY+AGA	infered_pred1
uses_method_in	Evaluation of key-segment model	C.-C. Chang, C.-J. Lin, LIBSVM: a library for support vector machines , ACM Trans. Intell. Syst. Technol. , vol. 2 (2011), pp.27:1-27:27	http://dx.doi.org/10.1016/j.cviu.2015.02.012	model	results	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-012/br/b0025>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-012/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-012/ctx/ctx0040>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-02-012/itrp/0020	'We use [5][[ refid=''b0025'' ]] to train the SVM classifier.'			FDY+AGA	infered_pred1
uses_method_in	Evaluation	C.C. Chang, C.J. Lin, LIBSVM: a library for support vector machines , ACM Trans. Intell. Syst. Technol. , vol. 2 (2011), pp.27:1-27:27	http://dx.doi.org/10.1016/j.cviu.2015.04.006	results		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-04-006/br/bib0006>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-04-006/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-04-006/ctx/ctx0030>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-04-006/itrp/0055	'SVM for both descriptors was implemented using one-vs.-all LIBSVM [6][[ refid=''bib0006'' ]] with an RBF kernel using chi-squared distance function (RBF-X2).'			FDY+AGA	infered_pred1
uses_method_in	Experiments	A. Krizhevsky, I. Sutskever, G.E. Hinton, ImageNet classification with deep convolutional neural networks , Proc. of NIPS, Lake Tahoe, NV, USA (2012)	http://dx.doi.org/10.1016/j.cviu.2015.05.009	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-05-009/br/bib0052>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-05-009/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-05-009/ctx/ctx0044>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-05-009/itrp/0083	'We compare also with a ConvNet-based classifier [52][[ refid=''bib0052'' ]], trained using ImageNet 2010 metadata.'			FDY+AGA	infered_pred1
uses_method_in	Experimental results	A. Vedaldi, B. Fulkerson, Vlfeat: an open and portable library of computer vision algorithms , Proceedings of the International Conference on Multimedia, ACM (2010)	http://dx.doi.org/10.1016/j.cviu.2015.05.010	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-05-010/br/bib0033>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-05-010/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-05-010/ctx/ctx0041>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-05-010/itrp/0021	'To further explore the capability of the proposed H3DF as a local pattern descriptor, we combine the H3DF with dense sampling as used in DenseSIFT [30][[ refid=''bib0033'' ]] with an evenly dense sampling grid at multiple scales (denseH3DF).'			FDY+AGA	infered_pred1
uses_method_in	AU intensity estimation and emotion clustering	C.-C. Chang, C.-J. Lin, Libsvm: A library for support vector machines , ACM Trans. Intell. Syst. Technol. , vol. 2 (2011), pp.1-27	http://dx.doi.org/10.1016/j.cviu.2015.07.007			<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-07-007/br/bib0060>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-07-007/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-07-007/ctx/ctx0075>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-07-007/itrp/0111	'We employ the Libsvm [60][[ refid=''bib0060'' ]] package integrated with OpenCV for SVR-based AU intensity estimation.'			FDY+AGA	infered_pred1
uses_method_in	Experimental results and analysis	C.-C. Chang, C.-J. Lin, Libsvm: a library for support vector machines , ACM Trans. Intell. Syst. Technol. , vol. 2 (2011), pp.27:1-27:27	http://dx.doi.org/10.1016/j.cviu.2015.11.018	results	discussion	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-11-018/br/bib0034>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-11-018/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-11-018/ctx/ctx0029>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2015-11-018/itrp/0013	'The LibSVM [34][[ refid=''bib0034'' ]] was used to learn the SVM classifiers.'			FDY+AGA	infered_pred1
uses_data_from	Experiments	J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, L. Fei-Fei, Imagenet: A large-scale hierarchical image database , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2009, IEEE (2009)	http://dx.doi.org/10.1016/j.cviu.2016.01.003	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-01-003/br/bib0063>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-01-003/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-01-003/ctx/ctx0034>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-01-003/itrp/0057	'Furthermore, we collected a set of random images by sampling 20,000 images from the ImageNet data set [63][[ refid=''bib0063'' ]] to evaluate our method on the task of self-taught image classification.'			FDY+AGA	infered_pred1
uses_method_in	Experiments	A.S. Razavian, H. Azizpour, J. Sullivan, S. Carlsson, Cnn features off-the-shelf: an astounding baseline for recognition , Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), IEEE (2014)	http://dx.doi.org/10.1016/j.cviu.2016.01.003	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-01-003/br/bib0067>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-01-003/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-01-003/ctx/ctx0036>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-01-003/itrp/0059	'In Section 5.3 we also investigate the use of features extracted from a CNN [67][[ refid=''bib0067'' ]] in combination with the previous ones.'			FDY+AGA	infered_pred1
uses_method_in	Experimental results	A.S. Razavian, H. Azizpour, J. Sullivan, S. Carlsson, CNN features off-the-shelf: an astounding baseline for recognition , Proceedings of Computer Vision and Pattern Recognition Workshops (2014)	http://dx.doi.org/10.1016/j.cviu.2016.01.012	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-01-012/br/bib0049>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-01-012/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-01-012/ctx/ctx0064>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-01-012/itrp/0130	'Following [49][[ refid=''bib0049'' ]], the output for the last convolutional layer has been taken as the image feature representation.'			FDY+AGA	infered_pred1
uses_method_in	Framework for multiple image group cosegmentation	R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, S. Süstrunk, Slic superpixels compared to state-of-the-art superpixel methods , IEEE Trans. Patt. Anal. Mach. Intell. , vol. 34 (2012), pp.2274-2282	http://dx.doi.org/10.1016/j.cviu.2016.02.004			<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-02-004/br/bib0032>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-02-004/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-02-004/ctx/ctx0012>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-02-004/itrp/0053	'To speed up the process, we compute the measurement in (8) based on superpixels obtained by the simple linear iterative clustering (SLIC) superpixel generation method [32][[ refid=''bib0032'' ]] (with the desired number of superpixels set as 300).'			FDY+AGA	infered_pred1
cites_as_review	Related work	Y. Bengio, A. Courville, P. Vincent, Representation learning: a review and new perspectives , IEEE Trans. PAMI , vol. 35 (2013), pp.1798-1828	http://dx.doi.org/10.1016/j.cviu.2016.02.011	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-02-011/br/bib0041>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-02-011/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-02-011/ctx/ctx0038>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-02-011/itrp/0095	'More generally, the main problem of learning “how to represent the data” is comprehensively presented in [41][[ refid=''bib0041'' ]], which also contains a review of several related approaches.'			FDY+AGA	infered_pred1
uses_method_in	Experimentation	A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks , NIPS (2012)	http://dx.doi.org/10.1016/j.cviu.2016.04.003	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-04-003/br/bib0016>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-04-003/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-04-003/ctx/ctx0049>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-04-003/itrp/0053	'For a video, we extract a 4096-dimensional representation using a pre-trained AlexNet (Krizhevsky et al., 2012[[ refid=''bib0016'' ]]).'			FDY+AGA	infered_pred1
uses_method_in	Experiments	Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, T. Darrell, Caffe: Convolutional architecture for fast feature embedding , Proceedings of the ACM International Conference on Multimedia, ACM (2014)	http://dx.doi.org/10.1016/j.cviu.2016.07.002	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-07-002/br/bib0018>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-07-002/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-07-002/ctx/ctx0036>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-07-002/itrp/0051	'We run our algorithm within the matCaffe (Caffe toolbox with the Matlab interface) framework (Jia et al., 2014[[ refid=''bib0018'' ]]).'			FDY+AGA	infered_pred1
cites_as_review	Recovering 3D human pose from a single image	Y. Bengio, A. Courville, P. Vincent, Representation learning: a review and new perspectives , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 35 (2013), pp.1798-1828	http://dx.doi.org/10.1016/j.cviu.2016.09.002			<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-09-002/br/bib0018>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-09-002/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-09-002/ctx/ctx0034>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-09-002/itrp/0058	'Deep-Learning Methods: Deep-learning methods are representation-learning approaches (Bengio et al., 2013[[ refid=''bib0018'' ]]) composed of multiple non-linear transformations.'			FDY+AGA	infered_pred1
uses_method_in	Experiments	C.D. Manning, M. Surdeanu, J. Bauer, J. Finkel, S.J. Bethard, D. McClosky, The Stanford CoreNLP natural language processing toolkit , ACL: System Demonstrations (2014)	http://dx.doi.org/10.1016/j.cviu.2016.10.001	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-10-001/br/bib0034>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-10-001/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-10-001/ctx/ctx0079>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-10-001/itrp/0194	'To extract these, the captions are processed using the Stanford CoreNLP toolkit Manning et al. (2014)[[ refid=''bib0034'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Pain event detection and locating	C.-C. Chang, C.-J. Lin, LIBSVM: a library for support vector machines , ACM Trans. Intell. Syst. Technol. , vol. 2 (2011), pp.1-27	http://dx.doi.org/10.1016/j.cviu.2016.11.003			<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-11-003/br/bib0043>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-11-003/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-11-003/ctx/ctx0033>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2016-11-003/itrp/0048	'The basis kernels can be linear kernels, radial basis function (RBF) kernels and polynomial kernels, etc. In our study, we use a linear kernel for each type of features and adopt the grid search with LIBSVM (Chang and Lin, 2011[[ refid=''bib0043'' ]]) to learn the kernel weights β1, β2 and coefficients α.'			FDY+AGA	infered_pred1
uses_method_in	Convnet architectures	A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks , Proceedings of Neural Information Processing Systems (2012)	http://dx.doi.org/10.1016/j.cviu.2017.01.009			<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-009/br/bib0033>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-009/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-009/ctx/ctx0037>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-009/itrp/0067	'In our experiments we choose Alex net (Krizhevsky et al., 2012[[ refid=''bib0033'' ]]) as a starting point and then try to increase network’s depth with a modified structure.'			FDY+AGA	infered_pred1
uses_method_in	Network architectures for models trained	K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition , 2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, Las Vegas, NV, USA, June 27–30, 2016 (2016)	http://dx.doi.org/10.1016/j.cviu.2017.01.010	model		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-010/br/bib0012>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-010/sec/appendix-a>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-010/ctx/ctx0037>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-010/itrp/0036	'We use zero-padding (referred to as Identity Projections by He et al. (2016)[[ refid=''bib0012'' ]]) to match the number of layers in order to perform element-wise addition when we have to connect layers with different number of output channels by a residual connection.'			FDY+AGA	infered_pred1
uses_method_in	Network architectures for models trained	K. He, X. Zhang, S. Ren, J. Sun, Delving deep into rectifiers: Surpassing human-level performance on imagenet classification , Proceedings of the IEEE International Conference on Computer Vision (2015)	http://dx.doi.org/10.1016/j.cviu.2017.01.010	model		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-010/br/bib0011>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-010/sec/appendix-a>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-010/ctx/ctx0039>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-010/itrp/0043	'We initialize all layers with the MSRA method for initialization as described by He et al. (2015)[[ refid=''bib0011'' ]].'			FDY+AGA	infered_pred1
cites_as_review	Introduction	Y. Bengio, A. Courville, P. Vincent, Representation learning: a review and new perspectives , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 35 (2013), pp.1798-1828	http://dx.doi.org/10.1016/j.cviu.2017.01.011	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-011/br/bib0013>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-011/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-011/ctx/ctx0007>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-01-011/itrp/0045	'Since the performance of machine learning and reasoning methods heavily relies on the design of data representation (Bengio et al., 2013[[ refid=''bib0013'' ]]), human representations are intensively investigated to address human-centered research problems (e.g., human detection, tracking, pose estimation, and action recognition).'			FDY+AGA	infered_pred1
uses_method_in	Results	Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., 2014. Caffe: convolutional architecture for fast feature embedding. arXiv preprint arXiv:	http://dx.doi.org/10.1016/j.cviu.2017.02.001	results		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-02-001/br/bib0024>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-02-001/sec/8>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-02-001/ctx/ctx0031>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-02-001/itrp/0059	'Because deep CNN-based features are extracted from the network, which is trained for recognition tasks, we can regard it as a feature that expresses discriminative information of an image, in our tests, we use the Caffe implementation (Jia et al., 2014[[ refid=''bib0024'' ]]).'			FDY+AGA	infered_pred1
uses_method_in	Results	A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks , Adv. Neural Inf. Process. Syst. (2012)	http://dx.doi.org/10.1016/j.cviu.2017.02.001	results		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-02-001/br/bib0027>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-02-001/sec/8>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-02-001/ctx/ctx0030>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-02-001/itrp/0060	'We extract features from the sixth layer of the network which has the same architecture as that proposed by Krizhevsky et al. (2012)[[ refid=''bib0027'' ]] and won ILSVRC2012.'			FDY+AGA	infered_pred1
uses_method_in	Method	K. He, X. Zhang, S. Ren, J. Sun, Delving deep into rectifiers: surpassing human-level performance on imagenet classification , CoRR , vol. abs/1502.01852 (2015), pp.None	http://dx.doi.org/10.1016/j.cviu.2017.04.002	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-04-002/br/bib0017>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-04-002/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-04-002/ctx/ctx0035>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-04-002/itrp/0051	'In our approach we made use of parametric rectified linear units (He et al., 2015[[ refid=''bib0017'' ]]) (PReLU) as our activation functions.'			FDY+AGA	infered_pred1
uses_method_in	Method	K. He, X. Zhang, S. Ren, J. Sun, Delving deep into rectifiers: surpassing human-level performance on imagenet classification , CoRR , vol. abs/1502.01852 (2015), pp.None	http://dx.doi.org/10.1016/j.cviu.2017.04.002	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-04-002/br/bib0017>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-04-002/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-04-002/ctx/ctx0036>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-04-002/itrp/0055	'In this context we initialise the network parameters using MSRA (He et al., 2015[[ refid=''bib0017'' ]]) as it is an appropriate choice when employing PReLU activation units.'			FDY+AGA	infered_pred1
uses_method_in	Camera calibration and vehicle tracking	A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks , Advances in Neural Information Processing Systems 25, Curran Associates, Inc. (2012)	http://dx.doi.org/10.1016/j.cviu.2017.05.015			<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-05-015/br/bib0024>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-05-015/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-05-015/ctx/ctx0040>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-05-015/itrp/0019	'We used a CNN (Krizhevsky et al., 2012[[ refid=''bib0024'' ]]) for the classification itself.'			FDY+AGA	infered_pred1
uses_method_in	Proposed approach	C.D. Manning, M. Surdeanu, J. Bauer, J. Finkel, S.J. Bethard, D. McClosky, The Stanford CoreNLP natural language processing toolkit , Association for Computational Linguistics System Demonstrations, ACL (2014)	http://dx.doi.org/10.1016/j.cviu.2017.05.017			<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-05-017/br/bib0025>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-05-017/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-05-017/ctx/ctx0056>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-05-017/itrp/0065	'For the head identification step, we rely on the implementation of Collin’s algorithm from Stanford CoreNLP (Manning et al., 2014[[ refid=''bib0025'' ]]).'			FDY+AGA	infered_pred1
uses_method_in	Algorithms for VQA	K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition , The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016)	http://dx.doi.org/10.1016/j.cviu.2017.06.005			<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-06-005/br/bib0019>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-06-005/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-06-005/ctx/ctx0056>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-06-005/itrp/0109	'During test, the labels are obtained by classifying each bounding box using ResNet (He et al., 2016[[ refid=''bib0019'' ]]).'			FDY+AGA	infered_pred1
uses_method_in	Learning a compact representation for SBIR	Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, T. Darrell, Caffe: Convolutional architecture for fast feature embedding , Proceedings of the 22nd ACM international conference on Multimedia, ACM (2014)	http://dx.doi.org/10.1016/j.cviu.2017.06.007			<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-06-007/br/bib0025>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-06-007/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-06-007/ctx/ctx0043>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-06-007/itrp/0025	'We train the CNN for 10,000 epochs using stochastic gradient descent (SGD) implemented in PyCaffe (Jia et al., 2014[[ refid=''bib0025'' ]]), step-decreasing the learning rate at epoch 6000, 8000 and 9000.'			FDY+AGA	infered_pred1
uses_data_from	Experiments	J. Xu, T. Mei, T. Yao, Y. Rui, Msr-vtt: a large video description dataset for bridging video and language , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2016)	http://dx.doi.org/10.1016/j.cviu.2017.06.012	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-06-012/br/bib0037>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-06-012/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-06-012/ctx/ctx0030>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-06-012/itrp/0046	'MSR-VTT (Xu et al., 2016[[ refid=''bib0037'' ]]).'			FDY+AGA	infered_pred1
uses_method_in	Experiments	L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, A.L. Yuille, Semantic image segmentation with deep convolutional nets and fully connected crfs , ICLR (2015)	http://dx.doi.org/10.1016/j.cviu.2017.09.001	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-09-001/br/bib0008>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-09-001/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-09-001/ctx/ctx0031>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-09-001/itrp/0030	'We also make small improvements over DeepLab-CRF (Chen et al., 2015[[ refid=''bib0008'' ]]) in the case of PASCAL-50S.'			FDY+AGA	infered_pred1
uses_method_in	Proposed algorithm	R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, S. Susstrunk, SLIC superpixels compared to state-of-the-art superpixel methods , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 34 (2012), pp.2274-2282	http://dx.doi.org/10.1016/j.cviu.2017.10.014			<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-10-014/br/bib0001>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-10-014/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-10-014/ctx/ctx0026>				http://www.scar.disi.unibo.it/r/10-1016-j-cviu-2017-10-014/itrp/0011	'We first utilize the simple linear iterative clustering (SLIC) algorithm (Achanta et al., 2012[[ refid=''bib0001'' ]]) to obtain superpixels on the haze image for our proposed dehazing method.'			FDY+AGA	infered_pred1
extends	UFOme: A comprehensive ontology mapping system	Giuseppe Pirr, Domenico Talia, Ufome: a user friendly ontology mapping environment, in: Proceedings of the Fourth Italian SWAP Workshop on Semantic Web Applications and Perspectives, CEUR-WS, 2007.	http://dx.doi.org/10.1016/j.datak.2009.12.002			http://www.scar.disi.unibo.it/r/10-1016-j-datak-2009-12-002/br/bib40	http://www.scar.disi.unibo.it/r/10-1016-j-datak-2009-12-002/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-datak-2009-12-002/ctx/ctx0062		65	6	http://www.scar.disi.unibo.it/r/10-1016-j-datak-2009-12-002/itrp/0056	'The work presented here is an extension of a preliminary version of UFOme described in [40][[ refid=''bib40'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""">The UFOme system has been implemented in Java. The work presented here is an extension of a preliminary version of UFOme described in <ce:cross-ref refid=""""bib40"""">[40][[ refid=''''bib40'''' ]]</ce:cross-ref>. In particular, the main improvements w.r.t this earlier version is the design and implementation of the strategy prediction module. Moreover, in this paper we provide an extensive evaluation of the system. </ce:para>""''"'	extends	ANG	
cites_as_review	Related work	R. Navigli, Word sense disambiguation: a survey, ACM Computing Surveys 41 (2) (2009).	http://dx.doi.org/10.1016/j.datak.2010.10.004	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2010-10-004/br/bb0230>	<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2010-10-004/sec/8>	<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2010-10-004/ctx/ctx0053>				http://www.scar.disi.unibo.it/r/10-1016-j-datak-2010-10-004/itrp/0056	'We opted to use WN because it is the most commonly used English lexical thesaurus for the task of WSD [46][[ refid=''bb0230'' ]]; however, our normalization method can be easily adapted to use other thesauri that provide a network of semantic relationships among meanings like WN does.'			FDY+AGA	infered_pred1
uses_method_in	Experimental results	C.-C. Chang, C.-J. Lin, LIBSVM: a library for support vector machines , ACM Transactions on Intelligent Systems and Technology , vol. 2 (2011), pp.27:1-27:27	http://dx.doi.org/10.1016/j.datak.2013.01.005	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-01-005/br/bb0155>	<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-01-005/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-01-005/ctx/ctx0042>				http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-01-005/itrp/0030	'For the sake of brevity, for LibSVM we just reported the values of the most significant tuned parameters, while we omit the ones that, after tuning, are set to their standard value reported in the referenced paper [31][[ refid=''bb0155'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Overview of methods	R. Yager, On ordered weighted averaging aggregation operators in multi-criteria decision making , IEEE Transactions on Systems, Man, and Cybernetics , vol. 18 (1988), pp.183-190	http://dx.doi.org/10.1016/j.datak.2013.01.007	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-01-007/br/bb0260>	<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-01-007/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-01-007/ctx/ctx0022>				http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-01-007/itrp/0001	'Euclidean Distance is used as the similarity function for these features and the weights of the distance function are determined by either a constant weighting (CW) of each feature or by dynamically adapting the weights using the Ordered Weighting Averaging (OWA) method [52][[ refid=''bb0260'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Similarity measurement techniques	R. Yager, On ordered weighted averaging aggregation operators in multi-criteria decision making , IEEE Transactions on Systems, Man, and Cybernetics , vol. 18 (1988), pp.183-190	http://dx.doi.org/10.1016/j.datak.2013.01.007			<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-01-007/br/bb0260>	<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-01-007/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-01-007/ctx/ctx0051>				http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-01-007/itrp/0078	'The Ordered Weighted Average (OWA) method [52][[ refid=''bb0260'' ]] allows dynamic weighting of the features by ordering the descriptor distance values.'			FDY+AGA	infered_pred1
cites_as_review	Introduction	R. Navigli, Word sense disambiguation: a survey , ACM Computing Surveys , vol. 41 (2009), pp.1-69	http://dx.doi.org/10.1016/j.datak.2013.07.004	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-07-004/br/bb0140>	<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-07-004/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-07-004/ctx/ctx0003>				http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-07-004/itrp/0034	'Disambiguation requires a knowledge source and a fundamental issue in disambiguation is the choice of the knowledge source; these have ranged from structured resources such as WordNet to unlabelled corpora [28][[ refid=''bb0140'' ]].'			FDY+AGA	infered_pred1
extends	Related work	C. Lim, S. Lu, A. Chebotko, F. Fotouhi, OPQL: a first OPM-level query language for scientific workflow provenance , Proc. of the IEEE International Conference on Services Computing (SCC) (2011)	http://dx.doi.org/10.1016/j.datak.2013.08.008	related work		http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-08-008/br/bb0115	http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-08-008/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-08-008/ctx/ctx0037		44	10	http://www.scar.disi.unibo.it/r/10-1016-j-datak-2013-08-008/itrp/0043	'This paper extends [23][[ refid=''bb0115'' ]] with the following additional contributions:1We introduce five new mapping functions i.e.,Ou^,Og^,Od^,Ot^,Oc^ for graph pattern Po in Section 3.2.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0550"""" view=""""all"""">Using <ce:italic>OPQL</ce:italic> together with OPMProv provides the following advantages for querying provenance over generic graph database language or other languages such as SQL or SPARQL: 1) <ce:italic>OPQL</ce:italic> is geared specifically towards provenance, featuring edges such as <ce:italic>WasGeneratedBy</ce:italic>, <ce:italic>WasDerivedFrom</ce:italic>, <ce:italic>WasTriggeredBy</ce:italic> and others, not available in other languages. Thus, <ce:italic>OPQL</ce:italic> offers conciseness and simplicity that neither generic languages nor SQL nor SPARQL can provide. For example, <ce:cross-ref refid=""""f0065"""" id=""""cf0595"""">Fig. 13</ce:cross-ref> presents the same query written in SQL, XQuery, SPARQL and <ce:italic>OPQL</ce:italic>. From the figure it is clear that <ce:italic>OPQL</ce:italic> is by far the easiest and the most natural of the four, 2) the fact that <ce:italic>OPQL</ce:italic> relies on the popular OPM provenance model minimizes the learning curve for the user. Indeed, as more and more scientists become familiar with OPM model, it is easier and more natural to use this knowledge to query provenance rather than to learn a new query language. 3) Unlike SQL, <ce:italic>OPQL</ce:italic> does not require the user to know the underlying storage schema. If the schema changes, the original <ce:italic>OPQL</ce:italic> query still produces the same result, whereas the SQL query needs be edited. 4) <ce:italic>OPQL</ce:italic> is technology-independent, and therefore can be integrated with any scientific workflow system. SQL on the other hand is only compatible with relational database technology which limits its use in workflow systems with non-relational storage. 5) OPMP<ce:small-caps>rov</ce:small-caps> reconstructs provenance graph from the results obtained from executing an SQL query. Without OPMP<ce:small-caps>rov</ce:small-caps> the user would be forced to translate returned row sets into graphs himself, which is tedious. In summary, OPQL together with OPMP<ce:small-caps>rov</ce:small-caps> free users from low-level details of provenance storage and querying a simple query language and intuitive results in the form of a graph. This paper provides <ce:italic>OPQL</ce:italic> to support the querying of scientific workflow provenance at the graph level, covering six types of graph patterns, a provenance graph algebra, <ce:italic>OPQL</ce:italic> syntax and semantics, implementation, and evaluation. This paper extends <ce:cross-ref refid=""""bb0115"""" id=""""cf0600"""">[23][[ refid=''''bb0115'''' ]]</ce:cross-ref> with the following additional contributions:<ce:list id=""""l0010""""><ce:list-item id=""""o0015""""><ce:label>1</ce:label><ce:para id=""""p0505"""" view=""""all"""">We introduce five new mapping functions <mml:math altimg=""""si50.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mfenced open=""""("""" close="""")""""><mml:mrow><mml:mi>i</mml:mi><mml:mo>.</mml:mo><mml:mi>e</mml:mi><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mover accent=""""true""""><mml:mi>u</mml:mi><mml:mo stretchy=""""true"""">^</mml:mo></mml:mover></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mover accent=""""true""""><mml:mi>g</mml:mi><mml:mo stretchy=""""true"""">^</mml:mo></mml:mover></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mover accent=""""true""""><mml:mi>d</mml:mi><mml:mo stretchy=""""true"""">^</mml:mo></mml:mover></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mover accent=""""true""""><mml:mi>t</mml:mi><mml:mo stretchy=""""true"""">^</mml:mo></mml:mover></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>O</mml:mi><mml:mover accent=""""true""""><mml:mi>c</mml:mi><mml:mo stretchy=""""true"""">^</mml:mo></mml:mover></mml:msub></mml:mrow></mml:mfenced></mml:math> for graph pattern <ce:italic>P<ce:inf loc=""""post"""">o</ce:inf></ce:italic> in <ce:cross-ref refid=""""s0025"""" id=""""cf0605"""">Section 3.2</ce:cross-ref>. These mapping functions enable users to retrieve causal dependencies between nodes using our mphOPQL language.</ce:para></ce:list-item><ce:list-item id=""""o0020""""><ce:label>2</ce:label><ce:para id=""""p0510"""" view=""""all"""">We propose an <ce:italic>OPQL</ce:italic> syntax that is required to formulate <ce:italic>OPQL</ce:italic> queries and a formal semantics for <ce:italic>OPQL</ce:italic> constructs, resulting in a new <ce:cross-ref refid=""""s0060"""" id=""""cf0610"""">Section 3.4</ce:cross-ref>. This provides a formal foundation for <ce:italic>OPQL</ce:italic>.</ce:para></ce:list-item><ce:list-item id=""""o0025""""><ce:label>3</ce:label><ce:para id=""""p0515"""" view=""""all"""">We present the architecture of our OPMP<ce:small-caps>rov</ce:small-caps> system in the context of the scientific workflow management system.</ce:para></ce:list-item><ce:list-item id=""""o0030""""><ce:label>4</ce:label><ce:para id=""""p0520"""" view=""""all"""">We present 13 queries out of 16 queries defined in the Third Provenance Challenge <ce:cross-ref refid=""""bb0045"""" id=""""cf0615"""">[9][[ refid=''''bb0045'''' ]]</ce:cross-ref> in <ce:italic>OPQL</ce:italic> to demonstrate the expressiveness of <ce:italic>OPQL</ce:italic> in <ce:cross-ref refid=""""s0075"""" id=""""cf0620"""">Section 3.5</ce:cross-ref>. These queries expressed in <ce:italic>OPQL</ce:italic> are executable in the OPMP<ce:small-caps>rov</ce:small-caps> system.</ce:para></ce:list-item><ce:list-item id=""""o0035""""><ce:label>5</ce:label><ce:para id=""""p0555"""" view=""""all"""">We implement the <ce:italic>OPQL</ce:italic> Web service to provide users with a provenance querying service for scientific workflows in <ce:cross-ref refid=""""s0080"""" id=""""cf0625"""">Section 4</ce:cross-ref>. In addition, we implement user-friendly GUIs, such as OPMP<ce:small-caps>ro</ce:small-caps>V<ce:small-caps>is</ce:small-caps><ce:italic><ce:sup loc=""""post"""">W</ce:sup></ce:italic> (web version) and OPMP<ce:small-caps>ro</ce:small-caps>V<ce:small-caps>is</ce:small-caps><ce:italic><ce:sup loc=""""post"""">D</ce:sup></ce:italic> (desktop version), to invoke the <ce:italic>OPQL</ce:italic> Web service. This expands applicability of <ce:italic>OPQL</ce:italic>.</ce:para></ce:list-item></ce:list></ce:para>""''"'	extends	ANG	
extends	Empirically uncovering ontological anti-patterns	G. Guizzardi, T.P. Sales, Detection, simulation and elimination of semantic anti-patterns in ontology-driven conceptual models , Proc. of 33rd International Conf. on Conceptual Modeling (ER 2014), Atlanta (2014)	http://dx.doi.org/10.1016/j.datak.2015.06.004			http://www.scar.disi.unibo.it/r/10-1016-j-datak-2015-06-004/br/bb0070	http://www.scar.disi.unibo.it/r/10-1016-j-datak-2015-06-004/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-datak-2015-06-004/ctx/ctx0049		76	7	http://www.scar.disi.unibo.it/r/10-1016-j-datak-2015-06-004/itrp/0043	'In the follow-up study reported here (which extends our initial report in [14][[ refid=''bb0070'' ]]), we manage to assemble a much larger benchmark of 54 OntoUML models.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0160"""" view=""""all"""">In this first empirical study, we manage to identify six initial ontological anti-patterns. Two of them were identified in three models. Another three were identified in six, seven and eight models respectively, and one anti-pattern that appeared in all the analyzed models. For more details, please refer to the preliminary report <ce:cross-ref refid=""""bb0085"""" id=""""cf0465"""">[17][[ refid=''''bb0085'''' ]]</ce:cross-ref>. This initial study gave us confidence that the adopted method could be used as a means for detecting these ontological anti-patterns. In the follow-up study reported here (which extends our initial report in <ce:cross-ref refid=""""bb0070"""" id=""""cf0470"""">[14][[ refid=''''bb0070'''' ]]</ce:cross-ref>), we manage to assemble a much larger benchmark of 54 OntoUML models. <ce:cross-ref refid=""""t0005"""" id=""""cf0475"""">Table 1</ce:cross-ref><ce:float-anchor refid=""""t0005""""/> provides a general description of all conceptual models in the repository, following the same classification adopted in the preliminary study<ce:cross-ref refid=""""fn0010"""" id=""""cf0480""""><ce:sup loc=""""post"""">2</ce:sup></ce:cross-ref><ce:footnote id=""""fn0010""""><ce:label>2</ce:label><ce:note-para id=""""np0025"""" view=""""all"""">The conceptual models in this table are publicly available at: <ce:inter-ref xlink:href=""""http://www.menthor.net/model-repository.html"""" id=""""ir0050"""" xlink:type=""""simple"""">http://www.menthor.net/model-repository.html</ce:inter-ref>. The few exceptions of missing models are due to non-disclosure agreements that prohibited their publication.</ce:note-para></ce:footnote>.</ce:para>""''"'	extends	ANG	
extends	Introduction	G. Mecca, G. Rull, D. Santoro, E. Teniente, Semantic-based mappings , ER (2013)	http://dx.doi.org/10.1016/j.datak.2015.07.003	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-datak-2015-07-003/br/bb0055	http://www.scar.disi.unibo.it/r/10-1016-j-datak-2015-07-003/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-datak-2015-07-003/ctx/ctx0007		39	8	http://www.scar.disi.unibo.it/r/10-1016-j-datak-2015-07-003/itrp/0026	'This paper extends our prior research [11][[ refid=''bb0055'' ]], where we first studied the problem of rewriting ontology-based mappings.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0075"""" view=""""all"""">This paper extends our prior research <ce:cross-ref refid=""""bb0055"""" id=""""cf0065"""">[11][[ refid=''''bb0055'''' ]]</ce:cross-ref>, where we first studied the problem of rewriting ontology-based mappings. We make several important advancements, as follows:<ce:list id=""""l0015""""><ce:list-item id=""""o0045""""><ce:label>(i)</ce:label><ce:para id=""""p0080"""" view=""""all"""">First, previous papers only discussed rewritings based on standard embedded dependencies for a rather limited form on negation. In this paper, we extend our algorithms to handle arbitrary non-recursive Datalog with negation using deds, thus considerably extending the reach of our rewriting algorithm.</ce:para></ce:list-item><ce:list-item id=""""o0050""""><ce:label>(ii)</ce:label><ce:para id=""""p0085"""" view=""""all"""">At the same time, we make the sufficient conditions under which the rewriting only contains embedded dependencies more precise, and extend the limited case discussed in previous papers.</ce:para></ce:list-item><ce:list-item id=""""o0055""""><ce:label>(iii)</ce:label><ce:para id=""""p0090"""" view=""""all"""">In addition, we present the first chase technique for deds, and a comprehensive experimental evaluation based on scenarios with and without deds. As we mentioned above, this is the first practical study of the scalability of the chase of high-complexity dependencies, an important problem in data exchange.</ce:para></ce:list-item><ce:list-item id=""""o0060""""><ce:label>(iv)</ce:label><ce:para id=""""p0095"""" view=""""all"""">Finally, we provide full proofs of all theorems (in <ce:cross-ref refid=""""s0110"""" id=""""cf0070"""">Appendix A</ce:cross-ref>).</ce:para></ce:list-item></ce:list></ce:para>""''"'	extends	ANG	
uses_method_in	The framework	C.D. Manning, M. Surdeanu, J. Bauer, J.R. Finkel, S. Bethard, & D. McClosky, The Stanford CoreNLP Natural Language Processing Toolkit.v in: Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, 55-60, 2014.	http://dx.doi.org/10.1016/j.datak.2017.06.006			<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2017-06-006/br/bib30>	<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2017-06-006/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-datak-2017-06-006/ctx/ctx0035>				http://www.scar.disi.unibo.it/r/10-1016-j-datak-2017-06-006/itrp/0030	'We use Stanford PTBTokenizer [30][[ refid=''bib30'' ]] in this work.'			FDY+AGA	infered_pred1
extends	Introduction	M. Bala, O. Boussaid, Z. Alimazighi, Big-ETL: Extracting-Transforming-Loading Approach for Big Data, in: Proceedings of the International Conference on Parallel and Distributed Processing Techniques and Applications (PDPTA), The Steering Committee of The World Congress in Computer Science, Computer Engineering and Applied Computing (WorldComp), 2015, p. 462.	http://dx.doi.org/10.1016/j.datak.2017.08.003	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-datak-2017-08-003/br/bib11	http://www.scar.disi.unibo.it/r/10-1016-j-datak-2017-08-003/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-datak-2017-08-003/ctx/ctx0007		44	7	http://www.scar.disi.unibo.it/r/10-1016-j-datak-2017-08-003/itrp/0040	'This paper extends our research work introduced by [11][[ refid=''bib11'' ]] that suggests a new fine-grained parallel/distributed ETL approach for Big Data, consisting of a set of MR-based ETL functionalities.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0040"""" view=""""all"""">This paper extends our research work introduced by <ce:cross-ref id=""""cr0115"""" refid=""""bib11"""">[11][[ refid=''''bib11'''' ]]</ce:cross-ref> that suggests a new fine-grained parallel/distributed ETL approach for Big Data, consisting of a set of MR-based ETL functionalities. We first present a fine-grained description of an ETL process in terms of its core functionalities and elementary functions; these are then parallelized/distributed according to the MR paradigm. Our approach allows thereby the parallelization/distribution of the ETL at three levels: notably “functionality” and “elementary function” levels as well as the “process” level. Our experimental results will reveal that our approach improves the ETL performance for handling Big Data. A number of approaches have been proposed by the DSS community in the ETL field <ce:cross-refs id=""""crs0015"""" refid=""""bib12 bib13 bib14 bib15 bib8 bib16 bib9 bib10"""">[12–15,8,16,9,10][[ refid=''''bib12 bib13 bib14 bib15 bib8 bib16 bib9 bib10'''' ]]</ce:cross-refs>. We propose a classification of the existing research studies based on the parallelization criteria. We have developed a prototype and conducted some experiments in order to validate our approach. The rest of this paper is structured as follows. <ce:cross-ref id=""""cr0120"""" refid=""""s0010"""">Section 2</ce:cross-ref> presents the fundamental concepts related to this research study. <ce:cross-ref id=""""cr0125"""" refid=""""s0015"""">Section 3</ce:cross-ref> presents a state-of-the-art in the ETL field followed by a classification of ETL approaches proposed in the literature according to the parallelization criteria. <ce:cross-ref id=""""cr0130"""" refid=""""s0030"""">Section 4</ce:cross-ref> describes our novel approach which is illustrated with ETL functionalities examples in <ce:cross-refs id=""""crs0020"""" refid=""""s0075 s0105"""">Sections 5 and 6</ce:cross-refs>. <ce:cross-ref id=""""cr0135"""" refid=""""s0120"""">Section 7</ce:cross-ref> describes our prototypical implementation and the conducted experiments. <ce:cross-ref id=""""cr0140"""" refid=""""s0145"""">Section 8</ce:cross-ref> concludes this work and presents some suggestions for future research.</ce:para>""''"'	extends	ANG	
uses_method_in	Experiments	C.-C. Chang, C.-J. Lin, LIBSVM: a library for support vector machines , ACM Trans Intell. Syst Technol , vol. 2 (2011), pp.1-27 , http://www.csie.ntu.edu.tw/∼cjlin/libsvm	http://dx.doi.org/10.1016/j.diin.2015.09.001	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-diin-2015-09-001/br/bib8>	<http://www.scar.disi.unibo.it/r/10-1016-j-diin-2015-09-001/sec/sec4>	<http://www.scar.disi.unibo.it/r/10-1016-j-diin-2015-09-001/ctx/ctx0035>				http://www.scar.disi.unibo.it/r/10-1016-j-diin-2015-09-001/itrp/0032	'Also for the character n-gram feature representation, the classification is performed by a Support Vector Machine (SVM) with a linear kernel (Chang and Lin, 2011[[ refid=''bib8'' ]]).'			FDY+AGA	infered_pred1
uses_method_in	Experiments	C.-C. Chang, C.-J. Lin, LIBSVM: a library for support vector machines , ACM Trans Intell. Syst Technol , vol. 2 (2011), pp.1-27 , http://www.csie.ntu.edu.tw/∼cjlin/libsvm	http://dx.doi.org/10.1016/j.diin.2015.09.001	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-diin-2015-09-001/br/bib8>	<http://www.scar.disi.unibo.it/r/10-1016-j-diin-2015-09-001/sec/sec4>	<http://www.scar.disi.unibo.it/r/10-1016-j-diin-2015-09-001/ctx/ctx0031>				http://www.scar.disi.unibo.it/r/10-1016-j-diin-2015-09-001/itrp/0037	'We used the LibSVM implementation (Chang and Lin, 2011[[ refid=''bib8'' ]]) for all experiments below.'			FDY+AGA	infered_pred1
uses_method_in	Experimental results	I. Laptev, M. Marszalek, C. Schmid, B. Rozenfeld, Learning realistic human actions from movies , The IEEE Conference on Computer Vision and Pattern Recognition (2008)	http://dx.doi.org/10.1016/j.dsp.2015.02.014	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-dsp-2015-02-014/br/br0530>	<http://www.scar.disi.unibo.it/r/10-1016-j-dsp-2015-02-014/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-dsp-2015-02-014/ctx/ctx0048>				http://www.scar.disi.unibo.it/r/10-1016-j-dsp-2015-02-014/itrp/0055	'HOG/HOF: The HOG/HOF descriptors were introduced in [53][[ refid=''br0530'' ]] and are similar in spirit to the well known SIFT descriptor.'			FDY+AGA	infered_pred1
uses_method_in	Experimental results	I. Laptev, M. Marszalek, C. Schmid, B. Rozenfeld, Learning realistic human actions from movies , The IEEE Conference on Computer Vision and Pattern Recognition (2008)	http://dx.doi.org/10.1016/j.dsp.2015.02.014	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-dsp-2015-02-014/br/br0530>	<http://www.scar.disi.unibo.it/r/10-1016-j-dsp-2015-02-014/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-dsp-2015-02-014/ctx/ctx0049>				http://www.scar.disi.unibo.it/r/10-1016-j-dsp-2015-02-014/itrp/0059	'In our evaluation we used the same grid parameters used in [53][[ refid=''br0530'' ]] as well as their online code.1'			FDY+AGA	infered_pred1
uses_method_in	Research methodology	G. Miner, Practical Text Mining and Statistical Analysis for Non-structured Text Data Applications , None, Academic Press (2012)	http://dx.doi.org/10.1016/j.dss.2018.01.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/br/bb0180	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/ctx/ctx0046		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/itrp/0015	'To be able to generate the term document matrix, we preprocess the reviews by means of tokenization, stop word filtering, stemming, n-gram generation and feature selection [36[[ refid=''bb0180'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0235"""" view=""""all"""">Finally, Configuration C uses a classical text mining approach, bag-of-words, that is based on the different words of the text and thus has a more comprehensive feature set. This model configuration is later used to compare the results for models involving sentiment analysis. To be able to generate the term document matrix, we preprocess the reviews by means of tokenization, stop word filtering, stemming, n-gram generation and feature selection [<ce:cross-ref id=""""cf0465"""" refid=""""bb0180"""">36[[ refid=''''bb0180'''' ]]</ce:cross-ref>].</ce:para>""''"'	cites_as_review	AGA	
uses_method_in	Research methodology	S.B. Kotsiantis, Supervised machine learning: a review of classification techniques , Informatica , vol. 31 (2007), pp.249-268	http://dx.doi.org/10.1016/j.dss.2018.01.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/br/bb0310	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/ctx/ctx0047		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/itrp/0016	'In this context, we concentrate on Naïve Bayes (NB) as a rather simple learning algorithm as well as Neural Network (NN) and Support Vector Machine (SVM) representing more complex learning algorithms [62[[ refid=''bb0310'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0240"""" view=""""all"""">We evaluate the performance of different machine learning techniques in predicting the recommendation decision. Towards that goal, we perform supervised learning and learn from pre-labeled examples, i.e. the online reviews and the indication of the reviewer expressing the airline recommendation. In this context, we concentrate on <ce:italic>Naïve Bayes</ce:italic> (<ce:italic>NB</ce:italic>) as a rather simple learning algorithm as well as <ce:italic>Neural Network</ce:italic> (<ce:italic>NN</ce:italic>) and <ce:italic>Support Vector Machine</ce:italic> (<ce:italic>SVM</ce:italic>) representing more complex learning algorithms [<ce:cross-ref id=""""cf0470"""" refid=""""bb0310"""">62[[ refid=''''bb0310'''' ]]</ce:cross-ref>].</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Research methodology	J. Han, M. Kamber, Data Mining: Concepts and Techniques , None, Elsevier; Morgan Kaufmann (2006)	http://dx.doi.org/10.1016/j.dss.2018.01.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/br/bb0260	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/ctx/ctx0040		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/itrp/0017	'To investigate the three research questions, focused on examining which service aspects are expressed in online reviews and whether a reviewer''s recommendation can be explained by sentiment on core and augmented service aspects expressed in the review (i.e., RQ1a/b), whether the review''s contents have predictive power to infer the recommendation (i.e., RQ2), and whether the type of business model impacts the explanation and prediction of service recommendations (i.e., RQ3), we adapt the structured knowledge discovery process proposed by Han and Kamber [52[[ refid=''bb0260'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0175"""" view=""""all"""">To investigate the three research questions, focused on examining which service aspects are expressed in online reviews and whether a reviewer''''s recommendation can be explained by sentiment on core and augmented service aspects expressed in the review (i.e., <ce:cross-ref refid=""""en0005"""" id=""""cf0315"""">RQ1a</ce:cross-ref>/<ce:cross-ref refid=""""en0010"""" id=""""cf0320"""">b</ce:cross-ref>), whether the review''''s contents have predictive power to infer the recommendation (i.e., <ce:cross-ref refid=""""en0015"""" id=""""cf0325"""">RQ2</ce:cross-ref>), and whether the type of business model impacts the explanation and prediction of service recommendations (i.e., <ce:cross-ref refid=""""en0020"""" id=""""cf0330"""">RQ3</ce:cross-ref>), we adapt the structured knowledge discovery process proposed by Han and Kamber [<ce:cross-ref id=""""cf0335"""" refid=""""bb0260"""">52[[ refid=''''bb0260'''' ]]</ce:cross-ref>].</ce:para>""''"'	cites_as_review	AGA	
uses_data_from	Research methodology	P.J. Stone, D.C. Dunphy, M.S. Smith, The General Inquirer: A Computer Approach to Content Analysis , None, MIT Press (1966)	http://dx.doi.org/10.1016/j.dss.2018.01.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/br/bb0275	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/ctx/ctx0042		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/itrp/0020	'In order to extract the sentiment expressed within a review, we leverage the Harvard General Inquirer lexicon that connects syntactic, semantic, and practical information to words (e.g., delay is tagged having a negative sentiment) [55[[ refid=''bb0275'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0200"""" view=""""all"""">In order to extract the sentiment expressed within a review, we leverage the Harvard General Inquirer lexicon that connects syntactic, semantic, and practical information to words (e.g., delay is tagged having a negative sentiment) [<ce:cross-ref id=""""cf0375"""" refid=""""bb0275"""">55[[ refid=''''bb0275'''' ]]</ce:cross-ref>]. We specifically take into account the word lists for positive (pos) and negative (neg) words that are used to determine the sentiment polarity expressed within the different reviews, as shown in Eq. <ce:cross-ref id=""""cf0380"""" refid=""""fo0005"""">(1)</ce:cross-ref> [<ce:cross-ref id=""""cf0385"""" refid=""""bb0280"""">56[[ refid=''''bb0280'''' ]]</ce:cross-ref>]. We summarize the occurrences of positive and negative words while taking negations into consideration (in case of a negation preceding the sentiment-bearing term, its orientation is reversed). As shown in Eq. <ce:cross-ref id=""""cf0390"""" refid=""""fo0005"""">(1)</ce:cross-ref>, sentiment polarity ranges from −1 (negative) to 1 (positive). Arguably, several terms in a review might indicate neutral sentiment. However, based on the AD theoretical model, we note that the diagnosticity, i.e., polarity of sentiment of a service-aspect, rather than a neutral stance, is likely to influence its recommendation by the reviewer.<ce:display><ce:formula id=""""fo0005""""><ce:label>(1)</ce:label><mml:math display=""""block"""" altimg=""""si1.gif"""" overflow=""""scroll""""><mml:mtext>Polarity</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>pos</mml:mi><mml:mo>−</mml:mo><mml:mi>neg</mml:mi></mml:mrow><mml:mrow><mml:mi>pos</mml:mi><mml:mo>+</mml:mo><mml:mi>neg</mml:mi></mml:mrow></mml:mfrac><mml:mspace width=""""2em""""/><mml:mfenced open=""""("""" close="""")""""><mml:mrow><mml:mtext>Range</mml:mtext><mml:mo>:</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mspace width=""""0.25em""""/><mml:mtext>to</mml:mtext><mml:mspace width=""""0.25em""""/><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:math></ce:formula></ce:display></ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Research methodology	'P.C. Tetlock, M. Saar-Tsechansky, S. Macskassy, More than words: quantifying language to measure firms'' fundamentals , The Journal of Finance , vol. 63 (2008), pp.1437-1467'	http://dx.doi.org/10.1016/j.dss.2018.01.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/br/bb0280	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/ctx/ctx0043		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/itrp/0021	'We specifically take into account the word lists for positive (pos) and negative (neg) words that are used to determine the sentiment polarity expressed within the different reviews, as shown in Eq. (1) [56[[ refid=''bb0280'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0200"""" view=""""all"""">In order to extract the sentiment expressed within a review, we leverage the Harvard General Inquirer lexicon that connects syntactic, semantic, and practical information to words (e.g., delay is tagged having a negative sentiment) [<ce:cross-ref id=""""cf0375"""" refid=""""bb0275"""">55[[ refid=''''bb0275'''' ]]</ce:cross-ref>]. We specifically take into account the word lists for positive (pos) and negative (neg) words that are used to determine the sentiment polarity expressed within the different reviews, as shown in Eq. <ce:cross-ref id=""""cf0380"""" refid=""""fo0005"""">(1)</ce:cross-ref> [<ce:cross-ref id=""""cf0385"""" refid=""""bb0280"""">56[[ refid=''''bb0280'''' ]]</ce:cross-ref>]. We summarize the occurrences of positive and negative words while taking negations into consideration (in case of a negation preceding the sentiment-bearing term, its orientation is reversed). As shown in Eq. <ce:cross-ref id=""""cf0390"""" refid=""""fo0005"""">(1)</ce:cross-ref>, sentiment polarity ranges from −1 (negative) to 1 (positive). Arguably, several terms in a review might indicate neutral sentiment. However, based on the AD theoretical model, we note that the diagnosticity, i.e., polarity of sentiment of a service-aspect, rather than a neutral stance, is likely to influence its recommendation by the reviewer.<ce:display><ce:formula id=""""fo0005""""><ce:label>(1)</ce:label><mml:math display=""""block"""" altimg=""""si1.gif"""" overflow=""""scroll""""><mml:mtext>Polarity</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>pos</mml:mi><mml:mo>−</mml:mo><mml:mi>neg</mml:mi></mml:mrow><mml:mrow><mml:mi>pos</mml:mi><mml:mo>+</mml:mo><mml:mi>neg</mml:mi></mml:mrow></mml:mfrac><mml:mspace width=""""2em""""/><mml:mfenced open=""""("""" close="""")""""><mml:mrow><mml:mtext>Range</mml:mtext><mml:mo>:</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mspace width=""""0.25em""""/><mml:mtext>to</mml:mtext><mml:mspace width=""""0.25em""""/><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:math></ce:formula></ce:display></ce:para>""''"'	cites_as_review	AGA	
cites	Research methodology	P. Langley, W. Iba, K. Thompson, An analysis of Bayesian classifiers , Proceedings of the Tenth National Conference on Artificial Intelligence, Seattle, WA (1992)	http://dx.doi.org/10.1016/j.dss.2018.01.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/br/bb0315	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/ctx/ctx0048		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/itrp/0035	'Although Naïve Bayes classifiers are rather simple and rely on potentially unrealistic assumptions, they have nevertheless been proven to generally perform well and in fact have the advantage of requiring low computational effort and thus being more time-efficient [63[[ refid=''bb0315'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0245"""" view=""""all""""><ce:italic>Naïve Bayes</ce:italic> represents a simple machine learning technology relying on the Bayes theorem. Classifiers built upon the Bayes theorem are assumed to be naïve as they assume the independence of the different input variables. In Naïve Bayes classifiers, instances are classified based on the joint probabilities of their input variables. Although Naïve Bayes classifiers are rather simple and rely on potentially unrealistic assumptions, they have nevertheless been proven to generally perform well and in fact have the advantage of requiring low computational effort and thus being more time-efficient [<ce:cross-ref id=""""cf0475"""" refid=""""bb0315"""">63[[ refid=''''bb0315'''' ]]</ce:cross-ref>].</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Research methodology	J. Han, M. Kamber, Data Mining: Concepts and Techniques , None, Elsevier; Morgan Kaufmann (2006)	http://dx.doi.org/10.1016/j.dss.2018.01.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/br/bb0260	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/ctx/ctx0049		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/itrp/0036	'The output neuron uses, as input, the weighted sum of outputs from neurons in the previous layer (or input variables in case of the initial input layer), and applies the activation function to the input [52[[ refid=''bb0260'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0250"""" view=""""all""""><ce:italic>Neural Networks</ce:italic> consist of a variety of (computational) neurons appearing in interconnected input, hidden, and output layers, and are intended to mimic the behavior of human neural networks. To achieve this behavior, weights are assigned to the connections between different neurons. Furthermore, each neuron has an activation function which is used to process the input of the neuron. The output neuron uses, as input, the weighted sum of outputs from neurons in the previous layer (or input variables in case of the initial input layer), and applies the activation function to the input [<ce:cross-ref id=""""cf0480"""" refid=""""bb0260"""">52[[ refid=''''bb0260'''' ]]</ce:cross-ref>]. When a neural network is trained, the weights of the different neurons are updated so that the overall neural network''''s output corresponds to the actual classification [<ce:cross-ref id=""""cf0485"""" refid=""""bb0320"""">64[[ refid=''''bb0320'''' ]]</ce:cross-ref>]. In this study, we apply a feed-forward neural network using backpropagation. As activation function, we use the most commonly adopted sigmoid function [<ce:cross-ref id=""""cf0490"""" refid=""""bb0325"""">65[[ refid=''''bb0325'''' ]]</ce:cross-ref>].</ce:para>""''"'	cites	AGA	
cites	Research methodology	R. Kohavi, A study of cross-validation and bootstrap for accuracy estimation and model selection , Proceedings of the International Joint Conference on Artificial Intelligence, Montreal, Quebec, Canada , vol. Vol. 14(2) (1995), pp.None	http://dx.doi.org/10.1016/j.dss.2018.01.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/br/bb0340	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/ctx/ctx0057		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/itrp/0055	'Furthermore, previous research has found that 10-fold stratified cross-validation performs best for evaluating models trained with real-world datasets such as the one in this study [68[[ refid=''bb0340'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0260"""" view=""""all"""">In order to evaluate the different predictive models, we perform stratified 10-fold cross-validation [<ce:cross-ref id=""""cf0515"""" refid=""""bb0340"""">68[[ refid=''''bb0340'''' ]]</ce:cross-ref>]. This evaluation procedure is advantageous as it avoids overfitting based on the notion that classifier training and classifier testing are performed on separate observations [<ce:cross-ref id=""""cf0520"""" refid=""""bb0345"""">69[[ refid=''''bb0345'''' ]]</ce:cross-ref>]. Furthermore, previous research has found that 10-fold stratified cross-validation performs best for evaluating models trained with real-world datasets such as the one in this study [<ce:cross-ref id=""""cf0525"""" refid=""""bb0340"""">68[[ refid=''''bb0340'''' ]]</ce:cross-ref>].</ce:para>""''"'	uses_data_from	AGA	
cites	Research methodology	T. Mitchell, Machine Learning , None, McGraw-Hill (1997)	http://dx.doi.org/10.1016/j.dss.2018.01.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/br/bb0345	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/ctx/ctx0056		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/itrp/0056	'This evaluation procedure is advantageous as it avoids overfitting based on the notion that classifier training and classifier testing are performed on separate observations [69[[ refid=''bb0345'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0260"""" view=""""all"""">In order to evaluate the different predictive models, we perform stratified 10-fold cross-validation [<ce:cross-ref id=""""cf0515"""" refid=""""bb0340"""">68[[ refid=''''bb0340'''' ]]</ce:cross-ref>]. This evaluation procedure is advantageous as it avoids overfitting based on the notion that classifier training and classifier testing are performed on separate observations [<ce:cross-ref id=""""cf0520"""" refid=""""bb0345"""">69[[ refid=''''bb0345'''' ]]</ce:cross-ref>]. Furthermore, previous research has found that 10-fold stratified cross-validation performs best for evaluating models trained with real-world datasets such as the one in this study [<ce:cross-ref id=""""cf0525"""" refid=""""bb0340"""">68[[ refid=''''bb0340'''' ]]</ce:cross-ref>].</ce:para>""''"'	uses_method_in	AGA	
cites	Research methodology	C.W. Hsu, C.C. Chang, C.J. Lin, A Practical Guide to Support Vector Classification , None, National Taiwan University (2003) , http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf	http://dx.doi.org/10.1016/j.dss.2018.01.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/br/bb0335	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/ctx/ctx0053		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/itrp/0063	'As shown by Hsu, Chang, and Lin [67[[ refid=''bb0335'' ]]], the Radial Basis Function (RBF) represents an appropriate kernel.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0255"""" view=""""all""""><ce:italic>Support Vector Machine</ce:italic> [<ce:cross-ref id=""""cf0495"""" refid=""""bb0330"""">66[[ refid=''''bb0330'''' ]]</ce:cross-ref>] represents another machine learning technique that is based upon the principle of finding the maximum margin hyperplane that maximizes the distances between instances of different classes [<ce:cross-ref id=""""cf0500"""" refid=""""bb0310"""">62[[ refid=''''bb0310'''' ]]</ce:cross-ref>]. As a linear separation of observations is not always possible, transformations are conducted by means of kernel functions that enable a separation of the observations according to their assigned classes. As shown by Hsu, Chang, and Lin [<ce:cross-ref id=""""cf0505"""" refid=""""bb0335"""">67[[ refid=''''bb0335'''' ]]</ce:cross-ref>], the Radial Basis Function (RBF) represents an appropriate kernel. We select the parameters of the kernel function by means of the grid-search heuristic proposed by [<ce:cross-ref id=""""cf0510"""" refid=""""bb0335"""">67[[ refid=''''bb0335'''' ]]</ce:cross-ref>].</ce:para>""''"'	cites	AGA	
uses_method_in	Research methodology	C.M. Fuller, D.P. Biros, R.L. Wilson, Decision support for determining veracity via linguistic-based cues , Wireless Healthcare , vol. 46 (2009), pp.695-703	http://dx.doi.org/10.1016/j.dss.2018.01.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/br/bb0325	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/ctx/ctx0051		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/itrp/0066	'As activation function, we use the most commonly adopted sigmoid function [65[[ refid=''bb0325'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0250"""" view=""""all""""><ce:italic>Neural Networks</ce:italic> consist of a variety of (computational) neurons appearing in interconnected input, hidden, and output layers, and are intended to mimic the behavior of human neural networks. To achieve this behavior, weights are assigned to the connections between different neurons. Furthermore, each neuron has an activation function which is used to process the input of the neuron. The output neuron uses, as input, the weighted sum of outputs from neurons in the previous layer (or input variables in case of the initial input layer), and applies the activation function to the input [<ce:cross-ref id=""""cf0480"""" refid=""""bb0260"""">52[[ refid=''''bb0260'''' ]]</ce:cross-ref>]. When a neural network is trained, the weights of the different neurons are updated so that the overall neural network''''s output corresponds to the actual classification [<ce:cross-ref id=""""cf0485"""" refid=""""bb0320"""">64[[ refid=''''bb0320'''' ]]</ce:cross-ref>]. In this study, we apply a feed-forward neural network using backpropagation. As activation function, we use the most commonly adopted sigmoid function [<ce:cross-ref id=""""cf0490"""" refid=""""bb0325"""">65[[ refid=''''bb0325'''' ]]</ce:cross-ref>].</ce:para>""''"'	cites	AGA	
uses_method_in	Research methodology	R. Nisbet, J.F. Elder, G. Miner, Handbook of Statistical Analysis and Data Mining Applications , None, Academic Press/Elsevier (2009)	http://dx.doi.org/10.1016/j.dss.2018.01.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/br/bb0320	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/ctx/ctx0050		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/itrp/0067	'When a neural network is trained, the weights of the different neurons are updated so that the overall neural network''s output corresponds to the actual classification [64[[ refid=''bb0320'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0250"""" view=""""all""""><ce:italic>Neural Networks</ce:italic> consist of a variety of (computational) neurons appearing in interconnected input, hidden, and output layers, and are intended to mimic the behavior of human neural networks. To achieve this behavior, weights are assigned to the connections between different neurons. Furthermore, each neuron has an activation function which is used to process the input of the neuron. The output neuron uses, as input, the weighted sum of outputs from neurons in the previous layer (or input variables in case of the initial input layer), and applies the activation function to the input [<ce:cross-ref id=""""cf0480"""" refid=""""bb0260"""">52[[ refid=''''bb0260'''' ]]</ce:cross-ref>]. When a neural network is trained, the weights of the different neurons are updated so that the overall neural network''''s output corresponds to the actual classification [<ce:cross-ref id=""""cf0485"""" refid=""""bb0320"""">64[[ refid=''''bb0320'''' ]]</ce:cross-ref>]. In this study, we apply a feed-forward neural network using backpropagation. As activation function, we use the most commonly adopted sigmoid function [<ce:cross-ref id=""""cf0490"""" refid=""""bb0325"""">65[[ refid=''''bb0325'''' ]]</ce:cross-ref>].</ce:para>""''"'	cites	AGA	
uses_method_in	Research methodology	T. Loughran, B. McDonald, When is a liability not a liability? Textual analysis, dictionaries, and 10-Ks , The Journal of Finance , vol. 66 (2011), pp.35-65	http://dx.doi.org/10.1016/j.dss.2018.01.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/br/bb0285	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/ctx/ctx0044		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/itrp/0080	'For identifying the service aspects expressed and for developing domain-specific word lists that can be applied for topic detection, we adapt the approach proposed by Loughran and McDonald [57[[ refid=''bb0285'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0210"""" view=""""all"""">For <ce:italic>identifying the service aspects expressed and for developing domain</ce:italic>-<ce:italic>specific word lists</ce:italic> that can be applied for topic detection, we adapt the approach proposed by Loughran and McDonald [<ce:cross-ref id=""""cf0395"""" refid=""""bb0285"""">57[[ refid=''''bb0285'''' ]]</ce:cross-ref>]. We analyze the different words which are contained in the whole corpus of online reviews. We manually analyze each word occurring in &gt;2.5% of the online reviews. On the one hand, we check whether it belongs to the main airline service aspects that represent evaluation categories available for rating flight experiences on <ce:inter-ref id=""""ir0015"""" xlink:href=""""http://airlinequality.com"""" xlink:type=""""simple"""">airlinequality.com</ce:inter-ref>, namely: <ce:italic>Seat Comfort</ce:italic>, <ce:italic>Cabin Staff Service</ce:italic>, <ce:italic>Inflight Entertainment</ce:italic>, <ce:italic>Food</ce:italic> &amp;<ce:italic>Beverages</ce:italic>, <ce:italic>Ground Service</ce:italic>, <ce:italic>Value For Money</ce:italic>, <ce:italic>and Wifi</ce:italic> &amp;<ce:italic>Connectivity</ce:italic> and map these to the core and augmented service categories, i.e. whether they relate to the core service (e.g. seat comfort) or whether they can be regarded as ancillary (e.g. food or entertainment, see <ce:cross-ref id=""""cf0400"""" refid=""""t0005"""">Table 1</ce:cross-ref><ce:float-anchor refid=""""t0005""""/>). On the other hand, we focus on the core and augmented service concept as well as past empirical studies (i.e. Aksoy, Atilgan, and Akinci [<ce:cross-ref id=""""cf0405"""" refid=""""bb0290"""">58[[ refid=''''bb0290'''' ]]</ce:cross-ref>], Anderson, Pearo, and Widener [<ce:cross-ref id=""""cf0410"""" refid=""""bb0295"""">59[[ refid=''''bb0295'''' ]]</ce:cross-ref>], Chen and Chang [<ce:cross-ref id=""""cf0415"""" refid=""""bb0300"""">60[[ refid=''''bb0300'''' ]]</ce:cross-ref>] and Gilbert and Wong [<ce:cross-ref id=""""cf0420"""" refid=""""bb0305"""">61[[ refid=''''bb0305'''' ]]</ce:cross-ref>]) to identify aspects beyond the categories available on <ce:inter-ref id=""""ir0020"""" xlink:href=""""http://airlinequality.com"""" xlink:type=""""simple"""">airlinequality.com</ce:inter-ref>. Following this procedure, we also identify <ce:italic>Punctuality</ce:italic>, <ce:italic>Safety</ce:italic>, <ce:italic>and Aircraft</ce:italic> as additional service aspects of interest. We recognize <ce:italic>Value for Money</ce:italic> as neither a core nor an augmented service aspect. <ce:cross-ref id=""""cf0425"""" refid=""""t0005"""">Table 1</ce:cross-ref> summarizes the resulting word lists.</ce:para>""''"'	cites	AGA	
uses_method_in	Research methodology	R. Kohavi, A study of cross-validation and bootstrap for accuracy estimation and model selection , Proceedings of the International Joint Conference on Artificial Intelligence, Montreal, Quebec, Canada , vol. Vol. 14(2) (1995), pp.None	http://dx.doi.org/10.1016/j.dss.2018.01.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/br/bb0340	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/ctx/ctx0055		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/itrp/0085	'In order to evaluate the different predictive models, we perform stratified 10-fold cross-validation [68[[ refid=''bb0340'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0260"""" view=""""all"""">In order to evaluate the different predictive models, we perform stratified 10-fold cross-validation [<ce:cross-ref id=""""cf0515"""" refid=""""bb0340"""">68[[ refid=''''bb0340'''' ]]</ce:cross-ref>]. This evaluation procedure is advantageous as it avoids overfitting based on the notion that classifier training and classifier testing are performed on separate observations [<ce:cross-ref id=""""cf0520"""" refid=""""bb0345"""">69[[ refid=''''bb0345'''' ]]</ce:cross-ref>]. Furthermore, previous research has found that 10-fold stratified cross-validation performs best for evaluating models trained with real-world datasets such as the one in this study [<ce:cross-ref id=""""cf0525"""" refid=""""bb0340"""">68[[ refid=''''bb0340'''' ]]</ce:cross-ref>].</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Research methodology	C.W. Hsu, C.C. Chang, C.J. Lin, A Practical Guide to Support Vector Classification , None, National Taiwan University (2003) , http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf	http://dx.doi.org/10.1016/j.dss.2018.01.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/br/bb0335	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/ctx/ctx0054		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-01-002/itrp/0086	'We select the parameters of the kernel function by means of the grid-search heuristic proposed by [67[[ refid=''bb0335'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0255"""" view=""""all""""><ce:italic>Support Vector Machine</ce:italic> [<ce:cross-ref id=""""cf0495"""" refid=""""bb0330"""">66[[ refid=''''bb0330'''' ]]</ce:cross-ref>] represents another machine learning technique that is based upon the principle of finding the maximum margin hyperplane that maximizes the distances between instances of different classes [<ce:cross-ref id=""""cf0500"""" refid=""""bb0310"""">62[[ refid=''''bb0310'''' ]]</ce:cross-ref>]. As a linear separation of observations is not always possible, transformations are conducted by means of kernel functions that enable a separation of the observations according to their assigned classes. As shown by Hsu, Chang, and Lin [<ce:cross-ref id=""""cf0505"""" refid=""""bb0335"""">67[[ refid=''''bb0335'''' ]]</ce:cross-ref>], the Radial Basis Function (RBF) represents an appropriate kernel. We select the parameters of the kernel function by means of the grid-search heuristic proposed by [<ce:cross-ref id=""""cf0510"""" refid=""""bb0335"""">67[[ refid=''''bb0335'''' ]]</ce:cross-ref>].</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experimental study	D.W. Aha, D. Kibler, M.K. Albert, Instance-based learning algorithms , Machine Learning , vol. 6 (1991), pp.37-66	http://dx.doi.org/10.1016/j.dss.2018.02.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/br/bb0215	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/ctx/ctx0035		42	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/itrp/0039	'For the CF component Weka was used to instantiate a k-nearest neighbors classifier, IBk [43[[ refid=''bb0215'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0250"""" view=""""all"""">For the CF component Weka was used to instantiate a k-nearest neighbors classifier, IBk [<ce:cross-ref id=""""cf0475"""" refid=""""bb0215"""">43[[ refid=''''bb0215'''' ]]</ce:cross-ref>]. We selected this because of its ability to identify the optimal value of K based on cross-validation. We used a brute force algorithm called LinearNNSearch to establish Euclidean distances between the neighbors. After several training iterations of various sizes (up to 1000 neighbors), we found that a value of 22 for nearest neighbors (K) was the optimal setting for this dataset.</ce:para>""''"'	cites	AGA	
uses_method_in	Experimental study	G. Adomavicius, R. Sankaranarayanan, S. Sen, A. Tuzhilin, Incorporating contextual information in recommender systems using a multidimensional approach , ACM Transactions on Information Systems , vol. 23 (2005), pp.103-145	http://dx.doi.org/10.1016/j.dss.2018.02.006	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/br/bb0105>	<http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/ctx/ctx0034>				http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/itrp/0040	'We use the commonly accepted metrics of recall, precision, and F-measure [21[[ refid=''bb0105'' ]]] to measure accuracy across all methods.'			FDY+AGA	infered_pred1
cites	Experimental study	G. Adomavicius, R. Sankaranarayanan, S. Sen, A. Tuzhilin, Incorporating contextual information in recommender systems using a multidimensional approach , ACM Transactions on Information Systems , vol. 23 (2005), pp.103-145	http://dx.doi.org/10.1016/j.dss.2018.02.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/br/bb0105	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/ctx/ctx0037		42	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/itrp/0041	'Following [21[[ refid=''bb0105'' ]]], the performance of CF and Cacheda et al. were contrasted with that of our method via the F-measure.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0265"""" view=""""all"""">We present the results of our experiments in <ce:cross-ref id=""""cf0490"""" refid=""""t0030"""">Table 6</ce:cross-ref><ce:float-anchor refid=""""t0030""""/>. Following [<ce:cross-ref id=""""cf0495"""" refid=""""bb0105"""">21[[ refid=''''bb0105'''' ]]</ce:cross-ref>], the performance of CF and Cacheda et al. were contrasted with that of our method via the F-measure. Although it is important to ensure that all items recommended are indeed favorable, it is also important to not incorrectly categorize favorable products as non-favorable. This is why the F-measure is better suited for recommendation systems, as it provides a harmonic mean of the precision and recall. We also performed a z-test for proportions [<ce:cross-ref id=""""cf0500"""" refid=""""bb0225"""">45[[ refid=''''bb0225'''' ]]</ce:cross-ref>] for precision and recall to identify where we significantly outperformed the other methods prior to comparing F-measures. Statistically significant differences for precision, recall, and F-measure were calculated and are highlighted with an asterisk symbol (*).</ce:para>""''"'	uses_method_in	AGA	
cites	Experimental study	A. Umyarov, A. Tuzhilin, Using external aggregate ratings for improving individual recommendations , ACM Transactions on the Web , vol. 5 (2011), pp.3	http://dx.doi.org/10.1016/j.dss.2018.02.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/br/bb0220	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/ctx/ctx0036		42	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/itrp/0042	'Using external aggregate ratings have been shown to improve recommendation systems, as long as the external source is statistically representative of the population (or individual) of interest [44[[ refid=''bb0220'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0255"""" view=""""all"""">We started by using the publicly available 10 million record dataset from <ce:inter-ref id=""""ir0015"""" xlink:href=""""http://MovieLens.org"""" xlink:type=""""simple"""">MovieLens.org</ce:inter-ref>. Although the dataset was rich in quantity of user ratings, it did not have any details about the ~10,000 movies, besides a title. We needed to tie in valid external aggregate ratings and descriptive data about each movie title from a high-volume website, such as <ce:inter-ref id=""""ir0020"""" xlink:href=""""http://IMDB.com"""" xlink:type=""""simple"""">IMDB.com</ce:inter-ref>. Using external aggregate ratings have been shown to improve recommendation systems, as long as the external source is statistically representative of the population (or individual) of interest [<ce:cross-ref id=""""cf0480"""" refid=""""bb0220"""">44[[ refid=''''bb0220'''' ]]</ce:cross-ref>]. For simplicity, we did not stratify the external rating data to generate sub population aggregate ratings based on some stereotyping of the individual (e.g., males only, age 18–25, etc.).</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experimental study	G. Adomavicius, R. Sankaranarayanan, S. Sen, A. Tuzhilin, Incorporating contextual information in recommender systems using a multidimensional approach , ACM Transactions on Information Systems , vol. 23 (2005), pp.103-145	http://dx.doi.org/10.1016/j.dss.2018.02.006	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/br/bb0105>	<http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/ctx/ctx0039>				http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/itrp/0048	'The absolute difference in F-measure is substantial if it is >0.05, and the difference in at least one of its components (i.e., precision or recall) is statistically significant (determined using the z-test for proportions at the significance level of 0.05, two-tailed, critical value of z=1.96) [21[[ refid=''bb0105'' ]]].'			FDY+AGA	infered_pred1
uses_method_in	Experimental study	S.K. Kachigan, Statistical Analysis: an Interdisciplinary Introduction to Univariate & Multivariate Methods , None, Radius Press (1986)	http://dx.doi.org/10.1016/j.dss.2018.02.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/br/bb0225	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/ctx/ctx0038		42	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-006/itrp/0049	'We also performed a z-test for proportions [45[[ refid=''bb0225'' ]]] for precision and recall to identify where we significantly outperformed the other methods prior to comparing F-measures.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0265"""" view=""""all"""">We present the results of our experiments in <ce:cross-ref id=""""cf0490"""" refid=""""t0030"""">Table 6</ce:cross-ref><ce:float-anchor refid=""""t0030""""/>. Following [<ce:cross-ref id=""""cf0495"""" refid=""""bb0105"""">21[[ refid=''''bb0105'''' ]]</ce:cross-ref>], the performance of CF and Cacheda et al. were contrasted with that of our method via the F-measure. Although it is important to ensure that all items recommended are indeed favorable, it is also important to not incorrectly categorize favorable products as non-favorable. This is why the F-measure is better suited for recommendation systems, as it provides a harmonic mean of the precision and recall. We also performed a z-test for proportions [<ce:cross-ref id=""""cf0500"""" refid=""""bb0225"""">45[[ refid=''''bb0225'''' ]]</ce:cross-ref>] for precision and recall to identify where we significantly outperformed the other methods prior to comparing F-measures. Statistically significant differences for precision, recall, and F-measure were calculated and are highlighted with an asterisk symbol (*).</ce:para>""''"'	uses_method_in	AGA	
cites	The computational methods	D.M. Blei, A.Y. Ng, M.I. Jordan, Latent Dirichlet allocation , The Journal of Machine Learning Research , vol. 3 (2003), pp.993-1022	http://dx.doi.org/10.1016/j.dss.2018.02.008	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/br/bb0250	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/ctx/ctx0047		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/itrp/0015	'This method introduces a latent topic variable and assumes that both the topic-word distribution and document-topic distribution are Dirichlet distributions [50[[ refid=''bb0250'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0140"""" view=""""all"""">The topic modeling method is a popular type of technology in the field of text mining. Representative topics can be extracted from massive textual data. LDA is one of the most effective topic modeling methods. This method introduces a latent topic variable and assumes that both the topic-word distribution and document-topic distribution are Dirichlet distributions [<ce:cross-ref id=""""cf0380"""" refid=""""bb0250"""">50[[ refid=''''bb0250'''' ]]</ce:cross-ref>]. Using an estimation method (e.g., Markov Chain Monte Carlo), the prior parameters of the distributions can be inferred [<ce:cross-ref id=""""cf0385"""" refid=""""bb0255"""">51[[ refid=''''bb0255'''' ]]</ce:cross-ref>]. Semantically related words are more likely to be grouped into the same topic according to their co-occurrences in different documents. In our study, we apply LDA to obtain a topic-level description of secondhand suit-dresses. Hence, we can obtain the topic-level completeness of the descriptions for each secondhand seller.</ce:para>""''"'	uses_method_in	AGA	
cites	The computational methods	T.L. Griffiths, M. Steyvers, Finding scientific topics , Proceedings of the National Academy of Sciences , vol. 101 (2004), pp.5228-5235	http://dx.doi.org/10.1016/j.dss.2018.02.008	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/br/bb0255	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/ctx/ctx0048		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/itrp/0037	'Using an estimation method (e.g., Markov Chain Monte Carlo), the prior parameters of the distributions can be inferred [51[[ refid=''bb0255'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0140"""" view=""""all"""">The topic modeling method is a popular type of technology in the field of text mining. Representative topics can be extracted from massive textual data. LDA is one of the most effective topic modeling methods. This method introduces a latent topic variable and assumes that both the topic-word distribution and document-topic distribution are Dirichlet distributions [<ce:cross-ref id=""""cf0380"""" refid=""""bb0250"""">50[[ refid=''''bb0250'''' ]]</ce:cross-ref>]. Using an estimation method (e.g., Markov Chain Monte Carlo), the prior parameters of the distributions can be inferred [<ce:cross-ref id=""""cf0385"""" refid=""""bb0255"""">51[[ refid=''''bb0255'''' ]]</ce:cross-ref>]. Semantically related words are more likely to be grouped into the same topic according to their co-occurrences in different documents. In our study, we apply LDA to obtain a topic-level description of secondhand suit-dresses. Hence, we can obtain the topic-level completeness of the descriptions for each secondhand seller.</ce:para>""''"'	uses_method_in	AGA	
cites	The computational methods	T. Wang, Y. Cai, H.F. Leung, R.Y. Lau, Q. Li, H. Min, Product topic extraction supervised with online domain knowledge , Knowledge-Based Systems , vol. 71 (2014), pp.86-100	http://dx.doi.org/10.1016/j.dss.2018.02.008	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/br/bb0260	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/ctx/ctx0049		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/itrp/0038	'However, LDA also has some demonstrated drawbacks [52[[ refid=''bb0260'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0145"""" view=""""all"""">However, LDA also has some demonstrated drawbacks [<ce:cross-ref id=""""cf0390"""" refid=""""bb0260"""">52[[ refid=''''bb0260'''' ]]</ce:cross-ref>]. One of the major weaknesses is that the topics can be very noisy, especially on short texts. As some topics contain many irrelevant words, it is a difficult task to map topic results into interpretable concepts. Furthermore, although LDA ensures the objectiveness of the results, some valuable topics could be missed due to the limitations of the original datasets. For example, if a topic were vital in the real-word domain but barely existed in all experimental documents, it would not be reflected in LDA results.</ce:para>""''"'	cites	AGA	
uses_method_in	The computational methods	K.P. Murphy, Machine Learning: A Probabilistic Perspective , None, MIT Press (2012)	http://dx.doi.org/10.1016/j.dss.2018.02.008	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/br/bb0285	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/ctx/ctx0053		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/itrp/0053	'A perplexity-based approach is applied to estimate the number of topics in all documents [57[[ refid=''bb0285'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0170"""" view=""""all"""">As a supplement to domain ontology, LDA is applied to extract topics from secondhand sellers'''' product descriptions. All product descriptions written by the same seller are gathered together as one document. A perplexity-based approach is applied to estimate the number of topics in all documents [<ce:cross-ref id=""""cf0425"""" refid=""""bb0285"""">57[[ refid=''''bb0285'''' ]]</ce:cross-ref>]. To guarantee the objectivity of the topic modeling results, the classical realization process of LDA is employed. The domain corpus of suit-dresses is then used to screen out the peculiar topics of secondhand suit-dresses from the LDA results. As the volume of suit-dress description data is much larger than that of secondhand suit-dresses, the topic is peculiar as long as it contains 10% words outside the corpus. The final topic-level description of secondhand suit-dresses combines both the concepts from ontology and the selected peculiar topics from the LDA results. The pseudo code of our ontology-based topic modeling method is illustrated in <ce:cross-ref id=""""cf0430"""" refid=""""en0005"""">Algorithm 1</ce:cross-ref>.<ce:enunciation id=""""en0005""""><ce:label>Algorithm 1</ce:label><ce:para id=""""p0175"""" view=""""all"""">Ontology-based topic model.</ce:para><ce:para id=""""p0180"""" view=""""all""""><ce:inline-figure baseline=""""0.0""""><ce:link locator=""""fx1"""" id=""""lk0015"""" xlink:type=""""simple"""" xlink:href=""""pii:S016792361830037X/fx1"""" xlink:role=""""http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4""""/><ce:alt-text role=""""short"""" id=""""al0050"""">Image 1</ce:alt-text></ce:inline-figure></ce:para></ce:enunciation></ce:para>""''"'	cites	AGA	
cites	The computational methods	R.Y. Chen, W. Xu, The determinants of online customer ratings: a combined domain ontology and topic text analytics approach , Electronic Commerce Research , vol. 17 (2017), pp.31-50	http://dx.doi.org/10.1016/j.dss.2018.02.008	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/br/bb0280	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/ctx/ctx0052		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/itrp/0054	'Chen and Xu [56[[ refid=''bb0280'' ]]] first considered combining the domain ontology and topic model results, which enabled them to obtain constant topics from the domain ontology and new topics from customer reviews.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0160"""" view=""""all"""">Both the topic modeling method and the domain ontology-based method are appropriate for identifying topic-level descriptions. However, as discussed in the previous section, they also have defects. Chen and Xu [<ce:cross-ref id=""""cf0420"""" refid=""""bb0280"""">56[[ refid=''''bb0280'''' ]]</ce:cross-ref>] first considered combining the domain ontology and topic model results, which enabled them to obtain constant topics from the domain ontology and new topics from customer reviews. In this study, we make two improvements to the ontology-based topic modeling method. First, we solve the problem of the difficulty of directly constructing a special domain ontology. Second, we introduce a domain corpus in advance; therefore, the combining process is more automatic and requires little manual intervention.</ce:para>""''"'	cites_as_review	AGA	
cites	The computational methods	T. Narock, L. Zhou, V. Yoon, V. Semantic, Similarity of ontology instances using polarity mining , Journal of the American Society for Information Science and Technology , vol. 64 (2013), pp.416-427	http://dx.doi.org/10.1016/j.dss.2018.02.008	methods		http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/br/bb0275	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/ctx/ctx0051		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-dss-2018-02-008/itrp/0055	'In ontology-based text analytics tasks, researchers often manually construct a domain ontology before the text mining process [55[[ refid=''bb0275'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0150"""" view=""""all"""">The concept of ontology originated in the field of philosophy and is now widely used in information systems studies [<ce:cross-ref id=""""cf0395"""" refid=""""bb0205"""">41[[ refid=''''bb0205'''' ]]</ce:cross-ref>,<ce:cross-ref id=""""cf0400"""" refid=""""bb0265"""">53[[ refid=''''bb0265'''' ]]</ce:cross-ref>,<ce:cross-ref id=""""cf0405"""" refid=""""bb0270"""">54[[ refid=''''bb0270'''' ]]</ce:cross-ref>]. Ontology is often constructed by a hierarchy of concepts with their relationships and some constraints. Due to its reusability, domain ontology is widely used to represent specific domain knowledge. In ontology-based text analytics tasks, researchers often manually construct a domain ontology before the text mining process [<ce:cross-ref id=""""cf0410"""" refid=""""bb0275"""">55[[ refid=''''bb0275'''' ]]</ce:cross-ref>]. A powerful reference is necessary to ensure the semantic relationships among different concepts. Otherwise, the constructed domain ontology would be ambiguous. Particularly in the e-commerce context, classical ontologies grow very large and quickly and become cumbersome to use. Hence, to construct a secondhand product ontology, we use fuzzy ontology, where similar words and words with similar meanings are combined in the same class. This can simplify the construction of the ontology.</ce:para>""''"'	cites	AGA	
cites	Conclusion	A.R. Abas, Using general regression with local tuning for learning mixture models from incomplete data sets , Egypt Inform J , vol. 11 (2010), pp.49-57	http://dx.doi.org/10.1016/j.eij.2011.08.001	conclusion		<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2011-08-001/br/b0170>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2011-08-001/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2011-08-001/ctx/ctx0015>				http://www.scar.disi.unibo.it/r/10-1016-j-eij-2011-08-001/itrp/0014	'Finally we may consider using general regression techniques, as an alternative approach to estimate the elasticity [34][[ refid=''b0170'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites_as_review	Introduction	Abdel Aziz H, Saleh M, El-Gayar N, El-Shishiny H. Dynamic pricing literature review. Technical report #3, Egyptian Data Mining and Computer Modeling Center of Excellence; Information Technology Industry Development Agency, Egypt; 2008.	http://dx.doi.org/10.1016/j.eij.2011.08.001	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2011-08-001/br/b0065>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2011-08-001/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2011-08-001/ctx/ctx0005>				http://www.scar.disi.unibo.it/r/10-1016-j-eij-2011-08-001/itrp/0034	'Based on a comprehensive literature review we conducted [13][[ refid=''b0065'' ]], we identified the following research gaps: 1.'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites_as_review	BCI applications	M.C. Domingo, An overview of the internet of things for people with disabilities , J Netw Comput Appl , vol. 35 (2012), pp.584-596	http://dx.doi.org/10.1016/j.eij.2015.06.002	motivation		<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/br/b0285>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/ctx/ctx0038>				http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/itrp/0050	'They are also expected to witness cooperation between Internet Of Things (IOT) and BCI technologies as stated in [57][[ refid=''b0285'' ]].'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites	Challenges and proposed solutions	S. Makeig, C. Kothe, T. Mullen, N. Bigdely-Shamlo, Z. Zhang, K. Kreutz-Delgado, Evolving signal processing for brain-computer interfaces , Proc IEEE , vol. 100 (2012), pp.1567-1584	http://dx.doi.org/10.1016/j.eij.2015.06.002			<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/br/b0700>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/ctx/ctx0126>				http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/itrp/0053	'Temporal based preprocessing can contribute in removing artifacts [140][[ refid=''b0700'' ]] from the signal using linear combination of the EOG-contaminated EEG signal and the EOG signal recorded using eye movement recording electrodes.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Signal acquisition	J.R. Wolpaw, C.B. Boulay, , Brain signals for brain-computer interfaces, Springer (2010)	http://dx.doi.org/10.1016/j.eij.2015.06.002			<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/br/b0510>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/ctx/ctx0083>				http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/itrp/0059	'It records the electrical activity of neurons at the embracing area [102][[ refid=''b0510'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	BCI applications	Bagchi S, Chattopadhyay M. An easy-to-adopt approach for regular and routine monitoring of the consciousness level of human brain of stayed alone sick person. In: Sensing Technology (ICST), 2012 Sixth International Conference on. IEEE; 2012. p. 698–703.	http://dx.doi.org/10.1016/j.eij.2015.06.002	motivation		<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/br/b0150>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/ctx/ctx0022>				http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/itrp/0069	'Consciousness level monitoring via brain waves has been expanded to include not only drivers but also stayed-alone sick people as suggested in [30][[ refid=''b0150'' ]].'		<http://purl.org/spar/cito/extends>		top100compsc
cites	BCI applications	Ko L-W, Lee H-C, Tsai S-F, Shih T-C, Chuang Y-T, Huang H-L, Ho S-Y, Lin C-T. Eeg-based motion sickness classification system with genetic feature selection. In: Computational Intelligence, Cognitive Algorithms, Mind, and Brain (CCMB), 2013 IEEE Symposium on. IEEE; 2013. p. 158–64.	http://dx.doi.org/10.1016/j.eij.2015.06.002	motivation		<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/br/b0145>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/ctx/ctx0021>				http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/itrp/0074	'In another study [29][[ refid=''b0145'' ]], a virtual reality-based motion-sickness platform has been designed with a 32-channel EEG system and a joystick which is used to report the motion sickness level (MSL) in real time experiments.'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites	Signal acquisition	L.F. Nicolas-Alonso, J. Gomez-Gil, Brain computer interfaces, a review , Sensors , vol. 12 (2012), pp.1211-1279	http://dx.doi.org/10.1016/j.eij.2015.06.002			<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/br/b0615>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/ctx/ctx0103>				http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/itrp/0090	'Table 1[123][[ refid=''b0615'' ]] gives a summary for brain acquisition methods along with their advantages and disadvantages.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	BCI electrical signals	C.N. Gupta, R. Palaniappan, R. Paramesran, Exploiting the p300 paradigm for cognitive biometrics , Int J Cognitive Biometrics , vol. 1 (2012), pp.26-38	http://dx.doi.org/10.1016/j.eij.2015.06.002			<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/br/b0625>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/ctx/ctx0106>				http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/itrp/0095	'EP components are labeled either exogenous or endogenous [125][[ refid=''b0625'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	BCI electrical signals	A. Maye, D. Zhang, Y. Wang, S. Gao, A.K. Engel, Multimodal brain-computer interfaces , Tsinghua Sci Technol , vol. 16 (2011), pp.133-139	http://dx.doi.org/10.1016/j.eij.2015.06.002			<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/br/b0635>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/ctx/ctx0108>				http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/itrp/0099	'Steady State Evoked Potentials (SSEP) [127][[ refid=''b0635'' ]] are evoked by a stimulus modulated at a fixed frequency and occur as an increase in EEG activity at the stimulation frequency.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	BCI applications	Y. Dong, Z. Hu, K. Uchimura, N. Murayama, Driver inattention monitoring system for intelligent vehicles: a review , Intell Transport Syst, IEEE Trans , vol. 12 (2011), pp.596-614	http://dx.doi.org/10.1016/j.eij.2015.06.002	motivation		<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/br/b0315>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/ctx/ctx0045>				http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/itrp/0123	'It has been found that distraction and fatigue are two main sources for driver’s inattention, which is considered as a strong cause for most traffic accidents [63][[ refid=''b0315'' ]].'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites_as_review	BCI applications	Khalifa W, Salem A, Roushdy M, Revett K. A survey of EEG based user authentication schemes. In: Informatics and Systems (INFOS), 2012 8th International Conference on. IEEE; 2012. p. BIO–55.	http://dx.doi.org/10.1016/j.eij.2015.06.002	motivation		<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/br/b0415>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/ctx/ctx0064>				http://www.scar.disi.unibo.it/r/10-1016-j-eij-2015-06-002/itrp/0156	'They have shown to be vulnerable to several drawbacks such as simple insecure password, shoulder surfing, theft crime, and cancelable biometrics [83][[ refid=''b0415'' ]].'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites	Application of the human microbiota	H. Lu, C. Zhang, G. Qian, X. Hu, H. Zhang, C. Chen, An analysis of microbiota-targeted therapies in patients with avian influenza virus subtype H7N9 infection , BMC Infect Dis , vol. 14 (2014), pp.359	http://dx.doi.org/10.1016/J.ENG.2017.01.008	motivation		<http://www.scar.disi.unibo.it/r/10-1016-j-eng-2017-01-008/br/bib164>	<http://www.scar.disi.unibo.it/r/10-1016-j-eng-2017-01-008/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-eng-2017-01-008/ctx/ctx0145>				http://www.scar.disi.unibo.it/r/10-1016-j-eng-2017-01-008/itrp/0188	'The administration of probiotics is reported to help restore the health of H7N9 patients more quickly [164][[ refid=''bib164'' ]].'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites	Application of the human microbiota	N. Iida, A. Dzutsev, C.A. Stewart, L. Smith, N. Bouladoux, R.A. Weingarten, Commensal bacteria control cancer response to therapy by modulating the tumor microenvironment , Science , vol. 342 (2013), pp.967-970	http://dx.doi.org/10.1016/J.ENG.2017.01.008	motivation		<http://www.scar.disi.unibo.it/r/10-1016-j-eng-2017-01-008/br/bib169>	<http://www.scar.disi.unibo.it/r/10-1016-j-eng-2017-01-008/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-eng-2017-01-008/ctx/ctx0149>				http://www.scar.disi.unibo.it/r/10-1016-j-eng-2017-01-008/itrp/0198	'Iida et al. [169][[ refid=''bib169'' ]] reported that optimal responses to cancer therapy require an intact commensal microbiota that mediates the therapy effects by modulating myeloid-derived cell functions in the tumor microenvironment.'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites	Application of the human microbiota	S. Viaud, F. Saccheri, G. Mignot, T. Yamazaki, R. Daillère, D. Hannani, The intestinal microbiota modulates the anticancer immune effects of cyclophosphamide , Science , vol. 342 (2013), pp.971-976	http://dx.doi.org/10.1016/J.ENG.2017.01.008	motivation		<http://www.scar.disi.unibo.it/r/10-1016-j-eng-2017-01-008/br/bib170>	<http://www.scar.disi.unibo.it/r/10-1016-j-eng-2017-01-008/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-eng-2017-01-008/ctx/ctx0150>				http://www.scar.disi.unibo.it/r/10-1016-j-eng-2017-01-008/itrp/0211	'Viaud et al. [170][[ refid=''bib170'' ]] reported that the gut microbiota helps to shape the anticancer immune response of cyclophosphamide.'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
uses_method_in	Analysis and results	R. Bartle, Hearts, clubs, diamonds, spades: players who suit MUDS,	http://dx.doi.org/10.1016/j.entcom.2018.06.002	results	discussion	<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/br/b0085>	<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/ctx/ctx0027>				http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/itrp/0006	'We used the ranking of the statements outlined in Section 4 in order to capture a respondents player type as outlined in Bartle’s classic work [17][[ refid=''b0085'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites_as_review	Introduction	Pew Research Center, Gaming and Gamers, 2015.	http://dx.doi.org/10.1016/j.entcom.2018.06.002	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/br/b0010>	<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/ctx/ctx0002>				http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/itrp/0022	'This is further underlined in a survey by the Pew Research Center [2][[ refid=''b0010'' ]] that found that 49% of adults in America have played a video game, and 10% of those surveyed would describe themselves as ‘gamers’.'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites	Discussion	E. Aries, Interaction patterns and themes of male, female, and mixed groups , Small Group Behav. , vol. 7 (1976), pp.7-18	http://dx.doi.org/10.1016/j.entcom.2018.06.002	discussion		<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/br/b0210>	<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/ctx/ctx0034>				http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/itrp/0031	'For female players the transition from Achiever to Socialiser occurs at a lower level of agreeableness, we hypothesise this is due to the increased tendency for social emphasis over tasked emphasis [42][[ refid=''b0210'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Analysis and results	A. Hirotugu, Likelihood of a model and information criteria , J. Econometrics , vol. 16 (1981), pp.3-14	http://dx.doi.org/10.1016/j.entcom.2018.06.002	discussion	results	<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/br/b0185>	<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/ctx/ctx0030>				http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/itrp/0036	'A linear regression model was created from all of the variables in the study and we followed a step-wise reduction process of removing the least significant term until all model coefficients are significant and there was no further reduction in the Akaike’s Information Criteria [37][[ refid=''b0185'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Analysis and results	J.D. Ivory, Still a man’s game: gender representation in online reviews of video games , Mass Commun. Soc. , vol. 9 (2006), pp.103-114	http://dx.doi.org/10.1016/j.entcom.2018.06.002	discussion	results	<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/br/b0200>	<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/ctx/ctx0032>				http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/itrp/0038	'It is worth noting that all of the characters are heroes (far from playing a ‘damsel in distress’ trope [40][[ refid=''b0200'' ]]) and although there are fewer female characters in the entire hero roster, 7 out of the 12 most popular characters were female.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Background	L.E. Nacke, C. Bateman, R.L. Mandryk, Brainhex: A neurobiological gamer typology survey , Entertain. Comput. , vol. 5 (2014), pp.55-62 ,	http://dx.doi.org/10.1016/j.entcom.2018.06.002	background		<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/br/b0095>	<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/ctx/ctx0014>				http://www.scar.disi.unibo.it/r/10-1016-j-entcom-2018-06-002/itrp/0053	'Brain Hex [19][[ refid=''b0095'' ]] was one of the first attempts at mapping personality types to gaming motivation archetypes, this created a larger number of gaming archetypes and identified some correlations with the Mayers-Briggs psychotypes to these resulting archetypes, this was done across a number of different games and gamers were asked to consider an abstract situation to consider their gaming archetype.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	YouReputation prototype and lessons learned	E. Portmann, The FORA framework—a fuzzy grassroots ontology for online reputation management , None, University of Fribourg, Department of Informatics (2012)	http://dx.doi.org/10.1016/j.fss.2014.06.004			http://www.scar.disi.unibo.it/r/10-1016-j-fss-2014-06-004/br/br0340	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2014-06-004/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2014-06-004/ctx/ctx0098		112	8	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2014-06-004/itrp/0026	'All conventional applications must expand their semantic functionalities towards YouReputation, and YouReputation, in turn, its user-friendliness and reliability towards the products on the market (see [34][[ refid=''br0340'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""pr0770"""" view=""""all"""">In summary, it can be stated that none of the applications on the market meet the requirements of communications operatives in full. All conventional applications must expand their semantic functionalities towards YouReputation, and YouReputation, in turn, its user-friendliness and reliability towards the products on the market (see <ce:cross-ref refid=""""br0340"""" id=""""crf1080"""">[34][[ refid=''''br0340'''' ]]</ce:cross-ref>).</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
extends	Acknowledgement	E. Portmann, A fuzzy grassroots ontology for improving social semantic Web search , Proceedings of 6th International Summer School on Aggregation Operators, Benevento (2011)	http://dx.doi.org/10.1016/j.fss.2014.06.004	acknowledgements		http://www.scar.disi.unibo.it/r/10-1016-j-fss-2014-06-004/br/br0330	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2014-06-004/sec/sec5	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2014-06-004/ctx/ctx0110		112	8	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2014-06-004/itrp/0099	'Upon the recommendation of the referees this article is a revised version of Portmann''s article [33][[ refid=''br0330'' ]] presented at the Sixth International Summer School on Aggregation Operators in Benevento, Italy.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""pr0830"""" view=""""all"""">Upon the recommendation of the referees this article is a revised version of Portmann''''s article <ce:cross-ref refid=""""br0330"""" id=""""crf1190"""">[33][[ refid=''''br0330'''' ]]</ce:cross-ref> presented at the Sixth International Summer School on Aggregation Operators in Benevento, Italy. That is why we are grateful to the referees for this honor. We also appreciate our colleagues of Mediamatics, the Fuzzy Marketing Methods, and the Berkeley Initiative in Soft Computing research centers who selflessly helped with word and deed when we sometimes could not see the wood through the trees. Thereby the <ce:grant-sponsor id=""""gsp0010"""" sponsor-id=""""http://dx.doi.org/10.13039/501100001711"""" xlink:type=""""simple"""" xlink:role=""""http://www.elsevier.com/xml/linking-roles/grant-sponsor"""">Swiss National Science Foundation</ce:grant-sponsor> supported this research under grant number <ce:grant-number refid=""""gsp0010"""">PBFRP2-138628</ce:grant-number>.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Introduction	H. Levesque, All I know: a study in autoepistemic logic , Artif. Intell. (1990)	http://dx.doi.org/10.1016/j.fss.2015.02.018	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-02-018/br/br0060	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-02-018/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-02-018/ctx/ctx0006		61	8	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-02-018/itrp/0032	'In [6][[ refid=''br0060'' ]], Levesque''s logic of only knowing is introduced as an extension of autoepistemic logic to enable the modeling of expressions of the form “φ is all that is believed”, i.e. there are no other relevant beliefs, but φ. To this end, the language is expanded with a second modal operator O. For every formula φ, Oφ reads “φ is all that is believed” or “only φ is believed”.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""pr0030"""" view=""""all"""">In <ce:cross-ref refid=""""br0060"""" id=""""crf0190"""">[6][[ refid=''''br0060'''' ]]</ce:cross-ref>, Levesque''''s logic of <ce:italic>only knowing</ce:italic> is introduced as an extension of autoepistemic logic to enable the modeling of expressions of the form “<ce:italic>φ</ce:italic> is all that is believed”, i.e. there are no other relevant beliefs, but <ce:italic>φ</ce:italic>. To this end, the language is expanded with a second modal operator O. For every formula <ce:italic>φ</ce:italic>, <mml:math altimg=""""si22.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""normal"""">O</mml:mi><mml:mi>φ</mml:mi></mml:math> reads “<ce:italic>φ</ce:italic> is <ce:italic>all</ce:italic> that is believed” or “<ce:italic>only φ</ce:italic> is believed”. In <ce:cross-ref refid=""""br0060"""" id=""""crf0200"""">[6][[ refid=''''br0060'''' ]]</ce:cross-ref> it is then shown that stable expansions correspond to a particular type of valid sentences in this logic. Finally, a sound and complete axiomatization based on classical K45 modal logic is provided by pointing out that <mml:math altimg=""""si23.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""normal"""">O</mml:mi><mml:mi>φ</mml:mi></mml:math> can be rewritten as <mml:math altimg=""""si24.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""normal"""">B</mml:mi><mml:mi>φ</mml:mi><mml:mo>∧</mml:mo><mml:mi mathvariant=""""normal"""">N</mml:mi><mml:mo>¬</mml:mo><mml:mi>φ</mml:mi></mml:math> where the modal operators N and B are both K45 operators. In particular, <mml:math altimg=""""si2.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""normal"""">B</mml:mi><mml:mi>φ</mml:mi></mml:math> corresponds to “<ce:italic>φ</ce:italic> is believed” and <mml:math altimg=""""si25.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""normal"""">N</mml:mi><mml:mo>¬</mml:mo><mml:mi>φ</mml:mi></mml:math> to “at most ¬<ce:italic>φ</ce:italic> is believed to be false”. Hence <mml:math altimg=""""si23.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""normal"""">O</mml:mi><mml:mi>φ</mml:mi></mml:math> corresponds to “at least and at most <ce:italic>φ</ce:italic> is believed”, i.e. “exactly <ce:italic>φ</ce:italic> is believed”.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Evaluative linguistic expressions	R. Itani, A relevance-based analysis of Lakoffian hedges: sort of, a typical and technically , MIT Work. Pap. Linguist. , vol. 7 (1973), pp.87-105	http://dx.doi.org/10.1016/j.fss.2015.08.022			http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-08-022/br/br0180	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-08-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-08-022/ctx/ctx0018		39	4	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-08-022/itrp/0058	'The hedge “a sort of” is thus a specific hedge that in some sense has widening effect, but when applied, the given expression does not include typical examples—hence absurdness of the latter example (cf. also [18][[ refid=''br0180'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""pr0200"""" view=""""all"""">The necessity to use hedges and the difference between widening and narrowing hedges has been discussed in <ce:cross-ref refid=""""br0270"""" id=""""crf0220"""">[27][[ refid=''''br0270'''' ]]</ce:cross-ref>. Namely, the formulation of concepts in everyday communication often requires the use of hedges. The concepts (e.g. “bird”) trigger prototypical images in people''''s minds. To be able to mark their less prototypical representatives, we can use widening hedge using which we are able to refer to a non-prototypical one. According to Lakoff <ce:cross-ref refid=""""br0230"""" id=""""crf0230"""">[23][[ refid=''''br0230'''' ]]</ce:cross-ref>, a sentence like “A penguin is sort of a bird” is acceptable, but “A raven is sort of a bird” is absurd. The hedge “a sort of” is thus a specific hedge that in some sense has widening effect, but when applied, the given expression does not include typical examples—hence absurdness of the latter example (cf. also <ce:cross-ref refid=""""br0180"""" id=""""crf0240"""">[18][[ refid=''''br0180'''' ]]</ce:cross-ref>).</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Evaluative linguistic expressions	, Hedging and Discourse: Approaches to the Analysis of a Pragmatic Phenomenon in Academic Texts, De Gruyter (1997)	http://dx.doi.org/10.1016/j.fss.2015.08.022			http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-08-022/br/br0270	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-08-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-08-022/ctx/ctx0016		39	4	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-08-022/itrp/0071	'The necessity to use hedges and the difference between widening and narrowing hedges has been discussed in [27][[ refid=''br0270'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""pr0200"""" view=""""all"""">The necessity to use hedges and the difference between widening and narrowing hedges has been discussed in <ce:cross-ref refid=""""br0270"""" id=""""crf0220"""">[27][[ refid=''''br0270'''' ]]</ce:cross-ref>. Namely, the formulation of concepts in everyday communication often requires the use of hedges. The concepts (e.g. “bird”) trigger prototypical images in people''''s minds. To be able to mark their less prototypical representatives, we can use widening hedge using which we are able to refer to a non-prototypical one. According to Lakoff <ce:cross-ref refid=""""br0230"""" id=""""crf0230"""">[23][[ refid=''''br0230'''' ]]</ce:cross-ref>, a sentence like “A penguin is sort of a bird” is acceptable, but “A raven is sort of a bird” is absurd. The hedge “a sort of” is thus a specific hedge that in some sense has widening effect, but when applied, the given expression does not include typical examples—hence absurdness of the latter example (cf. also <ce:cross-ref refid=""""br0180"""" id=""""crf0240"""">[18][[ refid=''''br0180'''' ]]</ce:cross-ref>).</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Introduction	F. Bobillo, U. Straccia, Generalized fuzzy rough description logics , Inf. Sci. , vol. 189 (2012), pp.43-62	http://dx.doi.org/10.1016/j.fss.2015.11.021	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-11-021/br/br0120	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-11-021/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-11-021/ctx/ctx0019		71	8	http://www.scar.disi.unibo.it/r/10-1016-j-fss-2015-11-021/itrp/0076	'A revised and extended version of their work is [12][[ refid=''br0120'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""pr0080"""" view=""""all"""">Another interesting approach is the one taken by Bobillo and Straccia in <ce:cross-ref refid=""""br0110"""" id=""""crf0270"""">[11][[ refid=''''br0110'''' ]]</ce:cross-ref>. The authors provide a simple solution to join two formalisms, fuzzy DLs and rough DLs, and define a fuzzy rough DL. This logic is more general than other related approaches, including tight and loose fuzzy rough approximations and being independent of the fuzzy logic operators considered. The key idea in rough set theory is the approximation of a vague concept by means of a pair of concepts, usually this approximation is based on an equivalence relation between elements of the domain. They extend this idea using fuzzy similarity relations instead of equivalence relations, giving raise to fuzzy rough sets. Bobillo and Straccia use a fixed set of similarities in order to introduce the semantics for the upper and lower approximation constructors. A revised and extended version of their work is <ce:cross-ref refid=""""br0120"""" id=""""crf0280"""">[12][[ refid=''''br0120'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
extends	Introduction	J.O. Fitó, M. Macías, J. Guitart, Toward business-driven risk management for cloud computing, in: Proceedings of the 6th International Conference on Network and Service Management (CNSM 2010), Niagara Falls, Canada, October 25–29, 2010, pp. 238–241.	http://dx.doi.org/10.1016/j.future.2012.05.008	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-future-2012-05-008/br/br000040	http://www.scar.disi.unibo.it/r/10-1016-j-future-2012-05-008/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-future-2012-05-008/ctx/ctx0006		34	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2012-05-008/itrp/0025	'This paper, which extends our previous work [8][[ refid=''br000040'' ]], contributes to the inclusion of the risk management discipline into the Cloud computing paradigm.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000025"""" view=""""all"""">This paper, which extends our previous work <ce:cross-ref refid=""""br000040"""">[8][[ refid=''''br000040'''' ]]</ce:cross-ref>, contributes to the inclusion of the risk management discipline into the Cloud computing paradigm.</ce:para>""''"'	extends	ANG	
extends	PSN: preprocessing a online social network	D.J. Watts, P.S. Dodds, M.E.J. Newman, Identity and search in social networks , Science , vol. 296 (2002), pp.1302-1305	http://dx.doi.org/10.1016/j.future.2012.06.010			http://www.scar.disi.unibo.it/r/10-1016-j-future-2012-06-010/br/br000115	http://www.scar.disi.unibo.it/r/10-1016-j-future-2012-06-010/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2012-06-010/ctx/ctx0029		40	6	http://www.scar.disi.unibo.it/r/10-1016-j-future-2012-06-010/itrp/0010	'This definition extends the one presented in [23][[ refid=''br000115'' ]], in which d(i,ij)=1 if i and nij belong to any common domain.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000290"""" view=""""all"""">Without loss of generality, we assume that user <mml:math altimg=""""si48.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>i</mml:mi></mml:math> has knowledge of the <ce:italic>active domain</ce:italic> of his neighbors, the <ce:italic>topic</ce:italic> and the <ce:italic>target</ce:italic>. We define three operators for computing the relations between user <mml:math altimg=""""si49.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>i</mml:mi></mml:math> and his neighbor <mml:math altimg=""""si50.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>. <ce:list id=""""l000025""""><ce:list-item id=""""li000055""""><ce:label>•</ce:label><ce:para id=""""p000295"""" view=""""all""""><ce:italic>Definition</ce:italic> 1: <mml:math altimg=""""si51.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mo>♢</mml:mo></mml:math><ce:italic>operator</ce:italic> counts the number of bits of “1” that have the same position in <mml:math altimg=""""si52.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math> and <mml:math altimg=""""si53.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>, i.e., the number of common domains between user <mml:math altimg=""""si54.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>i</mml:mi></mml:math> and his neighbor <mml:math altimg=""""si55.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>. For example, <mml:math altimg=""""si56.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mn>11100</mml:mn><mml:mo>♢</mml:mo><mml:mn>11011</mml:mn><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>11100</mml:mn><mml:mo>♢</mml:mo><mml:mn>00011</mml:mn><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math>.</ce:para></ce:list-item><ce:list-item id=""""li000060""""><ce:label>•</ce:label><ce:para id=""""p000300"""" view=""""all""""><ce:italic>Definition</ce:italic> 2: <mml:math altimg=""""si57.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mo>∘</mml:mo></mml:math><ce:italic>operator</ce:italic> counts the number of bits of “1” in <mml:math altimg=""""si58.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>, i.e., the number of domains where user <mml:math altimg=""""si59.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>i</mml:mi></mml:math> is involved. For example, <mml:math altimg=""""si60.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mo>∘</mml:mo><mml:mn>11100</mml:mn><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:math>.</ce:para></ce:list-item><ce:list-item id=""""li000065""""><ce:label>•</ce:label><ce:para id=""""p000305"""" view=""""all""""><ce:italic>Definition</ce:italic> 3: the <ce:italic>social distance</ce:italic> from <mml:math altimg=""""si61.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>i</mml:mi></mml:math> to his neighbor <mml:math altimg=""""si62.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math> is <mml:math altimg=""""si63.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>∘</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>♢</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:math>. This definition extends the one presented in <ce:cross-ref refid=""""br000115"""">[23][[ refid=''''br000115'''' ]]</ce:cross-ref>, in which <mml:math altimg=""""si64.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math> if <mml:math altimg=""""si65.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>i</mml:mi></mml:math> and <mml:math altimg=""""si66.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math> belong to any common domain. In our work, <mml:math altimg=""""si67.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math> only if <mml:math altimg=""""si68.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>⊆</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>. The basic intuition is that: if there is one domain where <mml:math altimg=""""si69.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math> is involved but user <mml:math altimg=""""si70.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>i</mml:mi></mml:math> is not, user <mml:math altimg=""""si71.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>i</mml:mi></mml:math> will not know <mml:math altimg=""""si72.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math>’s behavior in that domain, and consequently cannot give a proper opinion of him when considering that domain. The concept here is similar to the social difference, which we usually use in real life.</ce:para></ce:list-item></ce:list></ce:para>""''"'	extends	ANG	
extends	Introduction	P. Chen, B. Plale, M.S. Aktas, Temporal representation for scientific data provenance , The 8th Int’l IEEE Conference on e-Science, IEEE Computer Society (2012)	http://dx.doi.org/10.1016/j.future.2013.09.032	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-future-2013-09-032/br/br000040	http://www.scar.disi.unibo.it/r/10-1016-j-future-2013-09-032/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-future-2013-09-032/ctx/ctx0007		61	9	http://www.scar.disi.unibo.it/r/10-1016-j-future-2013-09-032/itrp/0029	'This study extends the work published in [8][[ refid=''br000040'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000055"""" view=""""all"""">The goal of the study described here is to evaluate our proposed temporal provenance representation for data mining kinds of tasks. This study extends the work published in <ce:cross-ref id=""""cf000105"""" refid=""""br000040"""">[8][[ refid=''''br000040'''' ]]</ce:cross-ref>. While the earlier work proposes Logical Clock-P and carries out a preliminary evaluation to show that useful data mining can be carried out against the temporal representation, the contributions of this paper are a full evaluation of the data mining potential of the Logical Clock-P representation. We carry out an empirical study to understand which clustering algorithm works the best with the proposed temporal representation. We discuss the implications of the temporal representation by illustrating the use of the representation for detecting the cause of execution failures. We evaluate the performance and the scalability of proposed method. Evaluation is carried out against a large 10 GB database of provenance traces generated from six real-life workflows <ce:cross-ref id=""""cf000110"""" refid=""""br000045"""">[9][[ refid=''''br000045'''' ]]</ce:cross-ref>, and a real life provenance dataset <ce:cross-ref id=""""cf000115"""" refid=""""br000050"""">[10][[ refid=''''br000050'''' ]]</ce:cross-ref> captured from a ground processing pipeline of the NASA AMSR-E satellite-bound instrument.</ce:para>""''"'	extends	ANG	
extends	Introduction	J. García-Galán, O.F. Rana, P. Trinidad, A. Ruiz-Cortés, Migrating to the cloud: a software product line based analysis, in: 3rd International Conference on Cloud Computing and Services Science, CLOSER, 2013, pp. 416–426.	http://dx.doi.org/10.1016/j.future.2015.03.006	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-03-006/br/br000040	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-03-006/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-03-006/ctx/ctx0006		64	10	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-03-006/itrp/0030	'This paper extends our previous work [8][[ refid=''br000040'' ]] in several ways.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000055"""" view=""""all"""">This paper extends our previous work <ce:cross-ref id=""""cf000060"""" refid=""""br000040"""">[8][[ refid=''''br000040'''' ]]</ce:cross-ref> in several ways. In particular, we provide (i) an explicit description of the configuration problem, (ii) a modelling methodology to describe the configuration space of an IaaS as a FM, (iii) a verification of the configuration space represented by the FM by means of analysis operations and (iv) an evaluation of the expressiveness, accuracy and performance of our approach.</ce:para>""''"'	extends	ANG	
cites	Applications	S. Bitam, A. Mellouk, ITS-Cloud: Cloud computing for Intelligent transportation system , Global Communications Conference (GLOBECOM), 2012 IEEE, IEEE (2012)	http://dx.doi.org/10.1016/j.future.2015.09.021	motivation		http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-09-021/br/br000360	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-09-021/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-09-021/ctx/ctx0089		177	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-09-021/itrp/0085	'These platforms aim at providing real-time, cheap, secure, and on-demand services to customers, through different types of Clouds, which also include temporary vehicular Clouds (i.e. formed by the vehicles representing the Cloud datacenters [72][[ refid=''br000360'' ]]) designed to expand the conventional Clouds in order to increase on-demand the whole Cloud computing, processing, and storage capabilities, by using under-utilized facilities of vehicles.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000255"""" view=""""all"""">The literature proposes several examples of multi-layered, Cloud-based vehicular data platforms that merge Cloud computing and IoT technologies to tackle the main current challenges <ce:cross-ref id=""""cf000580"""" refid=""""br000185"""">[37][[ refid=''''br000185'''' ]]</ce:cross-ref>. These platforms aim at providing real-time, cheap, secure, and on-demand services to customers, through different types of Clouds, which also include temporary vehicular Clouds (i.e. formed by the vehicles representing the Cloud datacenters <ce:cross-ref id=""""cf000585"""" refid=""""br000360"""">[72][[ refid=''''br000360'''' ]]</ce:cross-ref>) designed to expand the conventional Clouds in order to increase on-demand the whole Cloud computing, processing, and storage capabilities, by using under-utilized facilities of vehicles.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_extends_semweb
extends	Introduction	L. Boratto, S. Carta, Modeling the preferences of a group of users detected by clustering: A group recommendation case-study , Proceedings of the 4th International Conference on Web Intelligence, Mining and Semantics, WIMS14, WIMS’14, ACM (2014)	http://dx.doi.org/10.1016/j.future.2015.10.007	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-007/br/br000095	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-007/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-007/ctx/ctx0011		37	4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-007/itrp/0045	'This paper extends the work presented in [19][[ refid=''br000095'' ]] in the following ways: (i) a deeper contextualization of the group modeling problem with the state of the art is given, (ii) a novel motivation to the group modeling problem in our context is presented, (iii) an answer to a set of research questions that arise when dealing with the problem is given.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000140"""" view=""""all"""">This paper extends the work presented in <ce:cross-ref id=""""cf000060"""" refid=""""br000095"""">[19][[ refid=''''br000095'''' ]]</ce:cross-ref> in the following ways: (i) a deeper contextualization of the group modeling problem with the state of the art is given, (ii) a novel motivation to the group modeling problem in our context is presented, (iii) an answer to a set of research questions that arise when dealing with the problem is given.</ce:para>""''"'	extends	AGA+ANG	tba_50_classified_extends_semweb
cites	Introduction	R.N. Calheiros, R. Ranjan, A. Beloglazov, C.A.F. De Rose, R. Buyya, C loudSim: a toolkit for modeling and simulation of cloud computing environments and evaluation of resource provisioning algorithms , Softw. - Pract. Exp. , vol. 41 (2011), pp.23-50	http://dx.doi.org/10.1016/j.future.2015.10.023	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-023/br/br000060	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-023/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-023/ctx/ctx0008		49	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-023/itrp/0021	'CEPSim extends CloudSim [12][[ refid=''br000060'' ]] using a query model based on Directed Acyclic Graphs (DAGs) and introduces a simulation algorithm based on a novel abstraction called event sets.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000055"""" view=""""all""""><ce:italic>CEPSim</ce:italic> extends <ce:italic>CloudSim</ce:italic> <ce:cross-ref id=""""cf000070"""" refid=""""br000060"""">[12][[ refid=''''br000060'''' ]]</ce:cross-ref> using a query model based on Directed Acyclic Graphs (DAGs) and introduces a simulation algorithm based on a novel abstraction called <ce:italic>event sets</ce:italic>. <ce:italic>CEPSim</ce:italic> can be used to model different types of clouds, including public, private, hybrid, and multi-cloud environments, and to simulate execution of user-defined queries on them. In addition, it can also be customized with various operator placement and scheduling strategies. These features enable architects and researchers to analyse the scalability and performance of cloud-based CEP and SP systems and to compare easily the effects of different query processing strategies.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
extends	Introduction	W.A. Higashino, M.A.M. Capretz, L.F. Bittencourt, CEPSim: A Simulator for Cloud-Based Complex Event Processing , 2015 IEEE International Congress on Big Data, IEEE (2015)	http://dx.doi.org/10.1016/j.future.2015.10.023	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-023/br/br000075	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-023/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-023/ctx/ctx0009		49	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-023/itrp/0022	'This article significantly extends the authors’ previous work [15][[ refid=''br000075'' ]] by improving the discussion about CEPSim’s goals and assumptions, by introducing the event set concept, by presenting detailed descriptions of all simulation algorithms and a thorough evaluation of CEPSim.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000060"""" view=""""all"""">This article significantly extends the authors’ previous work <ce:cross-ref id=""""cf000075"""" refid=""""br000075"""">[15][[ refid=''''br000075'''' ]]</ce:cross-ref> by improving the discussion about <ce:italic>CEPSim</ce:italic>’s goals and assumptions, by introducing the event set concept, by presenting detailed descriptions of all simulation algorithms and a thorough evaluation of <ce:italic>CEPSim</ce:italic>. New experiments include comparing <ce:italic>CEPSim</ce:italic> with a real SP system in multiple scenarios, assessment of its performance, and a detailed analysis of the available simulation parameters.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Related work	S.K. Garg, R. Buyya, N etworkCloudSim: Modelling Parallel Applications in Cloud Simulations , 2011 Fourth IEEE International Conference on Utility and Cloud Computing, IEEE (2011)	http://dx.doi.org/10.1016/j.future.2015.10.023	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-023/br/br000045	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-023/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-023/ctx/ctx0031		49	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-10-023/itrp/0058	'Garg and Buyya [9][[ refid=''br000045'' ]] created NetworkCloudSim, which extends CloudSim with a three-tier network model and an application model that can represent communicating processes.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000160"""" view=""""all"""">Because of its limitations, <ce:italic>CloudSim</ce:italic> has originated many extensions in the literature <ce:cross-refs id=""""cs000030"""" refid=""""br000045 br000170 br000175"""">[9,34,35][[ refid=''''br000045 br000170 br000175'''' ]]</ce:cross-refs>. Garg and Buyya <ce:cross-ref id=""""cf000245"""" refid=""""br000045"""">[9][[ refid=''''br000045'''' ]]</ce:cross-ref> created <ce:italic>NetworkCloudSim</ce:italic>, which extends <ce:italic>CloudSim</ce:italic> with a three-tier network model and an application model that can represent communicating processes. Guérout et al. <ce:cross-ref id=""""cf000250"""" refid=""""br000170"""">[34][[ refid=''''br000170'''' ]]</ce:cross-ref>, on the other hand, focused on implementing the DVFS model on <ce:italic>CloudSim</ce:italic>. Finally, Grozev and Buyya <ce:cross-ref id=""""cf000255"""" refid=""""br000175"""">[35][[ refid=''''br000175'''' ]]</ce:cross-ref> presented a model for three-tier Web applications and incorporated it into <ce:italic>CloudSim</ce:italic>. These extensions are orthogonal to those presented in this paper because they do not focus on CEP.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
extends	Fuzzy user-oriented Cloud service selection system: Cloud-FuSeR	H. Dong, F.K. Hussain, E. Chang, A context-aware semantic similarity model for ontology environments , Concurr. Comput.: Pract. Exper. , vol. 23 (2011), pp.505-524	http://dx.doi.org/10.1016/j.future.2015.11.025			http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-11-025/br/br000230	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-11-025/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-11-025/ctx/ctx0050		78	5	http://www.scar.disi.unibo.it/r/10-1016-j-future-2015-11-025/itrp/0082	'This section describes a fuzzy lightweight semantic model (F-lightweight in abbreviation) which is an extension of our previous work: a context-aware lightweight similarity model (C-lightweight in abbreviation) [46][[ refid=''br000230'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000275"""" view=""""all"""">This section describes a fuzzy lightweight semantic model (F-lightweight in abbreviation) which is an extension of our previous work: a context-aware lightweight similarity model (C-lightweight in abbreviation) <ce:cross-ref id=""""cf000255"""" refid=""""br000230"""">[46][[ refid=''''br000230'''' ]]</ce:cross-ref>. The C-lightweight model deals with similarity matching with precise information, combining the ontology structure and the context of ontology concepts and relationships. For further details on the lightweight semantic model, readers can refer to <ce:cross-ref id=""""cf000260"""" refid=""""br000230"""">[46][[ refid=''''br000230'''' ]]</ce:cross-ref>. The F-lightweight model improves the C-lightweight model by integrating the fuzzy pseudo-concepts and fuzzy relationships.</ce:para>""''"'	extends	AGA+ANG	tba_50_classified_extends_semweb
extends	Introduction	J. Cała, Y. Xu, E.A. Wijaya, P. Missier, From scripted HPC-based NGS pipelines to workflows on the cloud , 2014 14th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, IEEE (2014)	http://dx.doi.org/10.1016/j.future.2016.01.001	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-001/br/br000065	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-001/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-001/ctx/ctx0009		33	5	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-001/itrp/0016	'This paper extends our preliminary workshop publication [13][[ refid=''br000065'' ]] which reported on initial progress on the Cloud-e-Genome project, a collaboration between the School of Computing Science and Institute of Genetic Medicine at Newcastle University.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000090"""" view=""""all"""">This paper extends our preliminary workshop publication <ce:cross-ref id=""""cf000125"""" refid=""""br000065"""">[13][[ refid=''''br000065'''' ]]</ce:cross-ref> which reported on initial progress on the Cloud-e-Genome project, a collaboration between the School of Computing Science and Institute of Genetic Medicine at Newcastle University. This extended version offers the following new contributions:</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Introduction	C. Curino, E.P. Jones, R.A. Popa, N. Malviya, E. Wu, S. Madden, N. Zeldovich, Relational cloud: A database-as-a-service for the cloud, in: Proceedings of the 5th Biennial Conference on Innovative Data Systems Research, CIDR, Asilomar, California, January 9–12, 2011.	http://dx.doi.org/10.1016/j.future.2016.01.003	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-003/br/br000010	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-003/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-003/ctx/ctx0002		181	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-003/itrp/0012	'Although, the concept of cloud computing is mainly popular in three flavors—(1) Infrastructure-as-a-Service (IaaS), (2) Platform-as-a-Service (PaaS) and (3) Software-as-a-Service (SaaS), but in this data science age, should be equally expandable to Database-as-a-Service (DBaaS) [2][[ refid=''br000010'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000035"""" view=""""all"""">Today, the cloud computing also has emerged as one of the major shifts in recent information and communication age that promises an affordable and robust computational architecture for large-scale and even for overly complex enterprise applications. It is a powerful and revolutionary paradigm that offers service-oriented computing and abstracts the software-equipped hardware infrastructure from the clients or users. Although, the concept of cloud computing is mainly popular in three flavors—(1) Infrastructure-as-a-Service (IaaS), (2) Platform-as-a-Service (PaaS) and (3) Software-as-a-Service (SaaS), but in this data science age, should be equally expandable to Database-as-a-Service (DBaaS) <ce:cross-ref id=""""cf000035"""" refid=""""br000010"""">[2][[ refid=''''br000010'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_extends_semweb
cites	Secure polynomial evaluation	P. Paillier, Public-key cryptosystems based on composite degree residuosity classes, in: EUROCRYPT, 1999, pp. 223–238.	http://dx.doi.org/10.1016/j.future.2016.01.008	results		http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-008/br/br000160	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-008/sec/appendix-b	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-008/ctx/ctx0032		34	5	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-008/itrp/0046	'An alternative approach is to replace the somewhat homomorphic encryption scheme with an additively homomorphic encryption scheme, e.g. Paillier [32][[ refid=''br000160'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000970"""" view=""""all"""">An alternative approach is to replace the somewhat homomorphic encryption scheme with an additively homomorphic encryption scheme, e.g. Paillier <ce:cross-ref id=""""cf000425"""" refid=""""br000160"""">[32][[ refid=''''br000160'''' ]]</ce:cross-ref>. In this case the client would send the powers <mml:math altimg=""""si978.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:math> encrypted, and the server would evaluate <mml:math altimg=""""si545.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>c</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math> homomorphically in encrypted form (under <mml:math altimg=""""si37.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math>’s public key). This solution requires the transmission of <mml:math altimg=""""si10.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>n</mml:mi></mml:math> field elements from the client to the server and one field element from the server to the client.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
extends	Introduction	G. Ateniese, Ö. Dagdelen, I. Damgård, D. Venturi, Entangled encodings and data entanglement, in: Proceedings of the Third International Workshop on Security in Cloud Computing, SCC@ASIACCS, 2015, pp. 3–12.	http://dx.doi.org/10.1016/j.future.2016.01.008	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-008/br/br000105	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-008/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-008/ctx/ctx0014		34	5	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-008/itrp/0063	'A preliminary version of this paper appeared as [21][[ refid=''br000105'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000165"""" view=""""all""""><ce:italic>Publication note</ce:italic>. A preliminary version of this paper appeared as <ce:cross-ref id=""""cf000160"""" refid=""""br000105"""">[21][[ refid=''''br000105'''' ]]</ce:cross-ref>. This is the full version of that paper, containing additional material–in particular all details about modeling and securely realizing data entanglement in the UC framework–and significantly revised proofs.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
extends	Time ontology	R. Wannous, J. Malki, A. Bouju, C. Vincent, Time integration in semantic trajectories using an ontological modelling approach , New Trends in Databases and Information Systems, Springer , vol. vol. 185 (2013), pp.187-198	http://dx.doi.org/10.1016/j.future.2016.01.012			http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-012/br/br000010	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-012/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-012/ctx/ctx0017		22	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-01-012/itrp/0026	'This mapping is detailed in our previous work [2][[ refid=''br000010'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000095"""" view=""""all"""">The seal trajectory ontology includes concepts that can be considered as temporal. For example, the concept <ce:monospace>Sequence</ce:monospace> is a temporal interval. To integrate temporal concepts and relationships in the seal trajectory ontology, we choose a mapping approach between our ontology and the OWL-Time<ce:cross-ref id=""""cf000180"""" refid=""""fn000010""""><ce:sup loc=""""post"""">2</ce:sup></ce:cross-ref> ontology <ce:cross-ref id=""""cf000185"""" refid=""""br000025"""">[5][[ refid=''''br000025'''' ]]</ce:cross-ref> developed by the World Wide Web Consortium (W3C). This mapping is detailed in our previous work <ce:cross-ref id=""""cf000190"""" refid=""""br000010"""">[2][[ refid=''''br000010'''' ]]</ce:cross-ref>. An extract of the declarative part of this ontology is shown in <ce:cross-ref id=""""cf000195"""" refid=""""f000020"""">Fig. 4</ce:cross-ref><ce:float-anchor refid=""""f000020""""/> described in detail in <ce:cross-ref id=""""cf000200"""" refid=""""br000025"""">[5][[ refid=''''br000025'''' ]]</ce:cross-ref>. We are mainly interested in the <ce:monospace>ProperInterval</ce:monospace> concept and its two properties <ce:monospace>hasBeginning</ce:monospace> and <ce:monospace>hasEnd</ce:monospace>.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Challenges	V. Pendyala, S. Shim, C. Bussler, The web that extends beyond the world , Computer , vol. 48 (2015), pp.18-25	http://dx.doi.org/10.1016/j.future.2016.10.026			http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-10-026/br/br000430	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-10-026/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-10-026/ctx/ctx0074		75	3	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-10-026/itrp/0087	'With the help of IoT, the Internet is expanding at an unprecedented scale connecting people all over the globe and even outside the globe (e.g. Interplanetary Web [86][[ refid=''br000430'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000405"""" view=""""all"""">With the help of IoT, the Internet is expanding at an unprecedented scale connecting people all over the globe and even outside the globe (e.g. Interplanetary Web <ce:cross-ref id=""""cf000525"""" refid=""""br000430"""">[86][[ refid=''''br000430'''' ]]</ce:cross-ref>). Internet connectivity has become an integral part of our daily life, especially the Millennial generation. IoT pushes the Internet connectivity to a new level that people are connected no matter they like it or not. The Executive Chairman of Google, Eric Schmidt, predicted that the Internet will disappear since nobody will notice the existence of the connection in the IoT world. Recent research is focusing on Internet of People based on IoT technologies since this is a new challenge for humans to interact with so many Things at the same time. Miranda et al. <ce:cross-ref id=""""cf000530"""" refid=""""br000435"""">[87][[ refid=''''br000435'''' ]]</ce:cross-ref> realised the importance of humans with technologies and proposed a reference architecture for IoT developers and researchers to consider the relationship between humans and IoT systems. The ultimate goal of the Internet of People may come from a transition of the disappearing of computers (or pervasive computing) to the disappearing of Internet to the disappearing of interface and finally Humans and Things are seamlessly connected in a natural way.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Related work	D.F. Barbieri, D. Braga, S. Ceri, M. Grossniklaus, An execution environment for C-SPARQL queries, in: EDBT, 2010.	http://dx.doi.org/10.1016/j.future.2016.10.030	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-10-030/br/br000060	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-10-030/sec/9	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-10-030/ctx/ctx0047		55	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2016-10-030/itrp/0021	'Specifically, C-SPARQL [12][[ refid=''br000060'' ]] extends the SPARQL language with window and aggregation clauses to support RDF stream processing.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000815"""" view=""""all"""">One approach to addressing data variety in streams is the utilization of schema mappings <ce:cross-ref id=""""cf000605"""" refid=""""br000190"""">[38][[ refid=''''br000190'''' ]]</ce:cross-ref>. However, defining one-to-one structural mappings is unsustainable for multi-disciplinary domains with fast changing information spaces, like emerging IoT application in general and Smart Grids in particular. Others have used semantics to manage diverse data in CEP <ce:cross-refs id=""""cs000060"""" refid=""""br000060 br000065 br000195"""">[12,13,39][[ refid=''''br000060 br000065 br000195'''' ]]</ce:cross-refs>. Specifically, C-SPARQL <ce:cross-ref id=""""cf000610"""" refid=""""br000060"""">[12][[ refid=''''br000060'''' ]]</ce:cross-ref> extends the SPARQL language with window and aggregation clauses to support RDF stream processing. However, while it allows time based RDF data filtering and aggregation, it misses a few other basic CEP operators and patterns such as negation and length window. ETALIS <ce:cross-ref id=""""cf000615"""" refid=""""br000065"""">[13][[ refid=''''br000065'''' ]]</ce:cross-ref> is a rule-based deductive system that acts as a unified execution engine for temporal pattern matching and semantic reasoning. It implements two <ce:italic>separate</ce:italic> languages for pattern detection and semantic reasoning: ETALIS Language for Events (ELE), and EP-SPARQL for stream reasoning. Both are transformed to Prolog rules and executed by a Prolog inference engine. Rather than adopting a bespoke solution that departs from traditional CEP systems, our <mml:math altimg=""""si1.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>χ</mml:mi></mml:math>-CEP query model integrates the native and well-understood CEP with semantic knowledge constructs. In practice, this allows our framework to process semantic-enriched CEP queries using existing CEP tools that scale and the proposed optimizations improving performance for semantic processing.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
extends	Introduction	G. Gonzalez-Granadillo, E. Alvarez, A. Motzek, M. Merialdo, J. Garcia-Alfaro, H. Debar, Towards an automated and dynamic risk management response system , 21st Nordic Conference on Secure IT Systems NordSec (2016)	http://dx.doi.org/10.1016/j.future.2017.05.043	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-05-043/br/b6	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-05-043/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-05-043/ctx/ctx0003		39	6	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-05-043/itrp/0030	'This article extends previous work [6][[ refid=''b6'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""d1e1322"""">This article extends previous work <ce:cross-ref refid=""""b6"""" id=""""d1e1324"""">[6][[ refid=''''b6'''' ]]</ce:cross-ref>. The original work has been significantly extended by an in-depth description of the complete system, and, most importantly, a complete extension towards an automated incident handling of multiple threat scenarios. Moreover, we evaluate proactive and reactive behaviors of the system in one consistent use case involving real world experts on real world data.</ce:para>""''"'	extends	ANG	
uses_method_in	Empirical study	L.F. Costa, F.A. Rodrigues, G. Travieso, P.R.V. Boas, Characterization of complex networks: A survey of measurements , Adv. Phys. , vol. 56 (2007), pp.167-242	http://dx.doi.org/10.1016/j.future.2017.09.039			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/br/b24	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/ctx/ctx0023		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/itrp/0003	'The definition of these parameters can be found in [24[[ refid=''b24'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p54"""">In <ce:cross-ref refid=""""tbl1"""" id=""""d1e5866"""">Table 1</ce:cross-ref>, we provide an overview of the size characteristics of these software systems, measured in KLOC (thousand lines of code), and some detailed statistical properties of the WCCNs constructed from the source code of some directories of them, measured in <mml:math id=""""mml404"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si4.gif""""><mml:mrow><mml:mo>|</mml:mo><mml:mi>N</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:math> (number of nodes), <mml:math id=""""mml405"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si5.gif""""><mml:mrow><mml:mo>|</mml:mo><mml:mi>E</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:math> (number of edges), <mml:math id=""""mml406"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si6.gif""""><mml:mrow><mml:mo>〈</mml:mo><mml:mi>k</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:math> (average degree of network nodes), <mml:math id=""""mml407"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si7.gif""""><mml:mi>d</mml:mi></mml:math> (diameter), <mml:math id=""""mml408"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si8.gif""""><mml:mi>C</mml:mi></mml:math> (clustering coefficient), and <mml:math id=""""mml409"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si9.gif""""><mml:mi>l</mml:mi></mml:math> (average path length). The definition of these parameters can be found in [<ce:cross-ref refid=""""b24"""" id=""""d1e5919"""">24[[ refid=''''b24'''' ]]</ce:cross-ref>]. It should be noted that KLOC is the practical lines of code, excluding the comment lines and blank lines. When calculating <mml:math id=""""mml410"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si6.gif""""><mml:mrow><mml:mo>〈</mml:mo><mml:mi>k</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:math>, <mml:math id=""""mml411"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si7.gif""""><mml:mi>d</mml:mi></mml:math>, <mml:math id=""""mml412"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si8.gif""""><mml:mi>C</mml:mi></mml:math> and <mml:math id=""""mml413"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si9.gif""""><mml:mi>l</mml:mi></mml:math>, we ignore the isolated nodes in WCCNs. We also provide the <mml:math id=""""mml414"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si11.gif""""><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math>, the <mml:math id=""""mml415"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si9.gif""""><mml:mi>l</mml:mi></mml:math> of the corresponding random network, which can be approximately calculated through <mml:math id=""""mml416"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si416.gif""""><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mi>N</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:math>/<mml:math id=""""mml417"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si417.gif""""><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>〈</mml:mo><mml:mi>k</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:math>, and <mml:math id=""""mml418"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si10.gif""""><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math> through <mml:math id=""""mml419"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si6.gif""""><mml:mrow><mml:mo>〈</mml:mo><mml:mi>k</mml:mi><mml:mo>〉</mml:mo></mml:mrow></mml:math>/<mml:math id=""""mml420"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si4.gif""""><mml:mrow><mml:mo>|</mml:mo><mml:mi>N</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:math>.</ce:para>""''"'		ANG	
uses_method_in	Method	A. Garas, F. Schweitzer, S. Havlin, A k-shell decomposition method for weighted networks , New J. Phys. , vol. 14 (2012), pp.083030	http://dx.doi.org/10.1016/j.future.2017.09.039	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/br/b17>	<http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/ctx/ctx0020>				http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/itrp/0004	'The weighted degree of node i, kwi, is defined as [17[[ refid=''b17'' ]]] [[ formulaid=''id13_pos0'' ]] where ki is the degree of node i and ∑j=1kiwij is the sum over all the edge weight of node i. Integers α and β are the user-defined weights, showing the preferences of the user.'			FDY+AGA	infered_pred1
uses_method_in	Method	A. Garas, F. Schweitzer, S. Havlin, A k-shell decomposition method for weighted networks , New J. Phys. , vol. 14 (2012), pp.083030	http://dx.doi.org/10.1016/j.future.2017.09.039	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/br/b17>	<http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/ctx/ctx0021>				http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/itrp/0005	'Here we only discuss the case where α = β = 1 following the line of thought given in [17[[ refid=''b17'' ]]], treating the edge weights and the node degree equally.'			FDY+AGA	infered_pred1
cites	Empirical study	H.C. Gall, M. Lanza, Software evolution: Analysis and visualization, in: Proceedings of the 28th International Conference on Software Engineering, ICSE’06, Shanghai, China, 2006, pp. 1055–1056.	http://dx.doi.org/10.1016/j.future.2017.09.039			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/br/b26	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/ctx/ctx0027		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/itrp/0008	'Gaining higher level evolution information about software has been regarded as a key to deal with software complexity and deterioration [26[[ refid=''b26'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p70"""">As we all know, the original design of a specific software system is rarely prepared for every new requirement appearing over its life cycle. Software has to evolve to accommodate them. Gaining higher level evolution information about software has been regarded as a key to deal with software complexity and deterioration [<ce:cross-ref refid=""""b26"""" id=""""d1e7166"""">26[[ refid=''''b26'''' ]]</ce:cross-ref>]. However, it is still a difficult task to analyze the structural evolution of software because of a lack of suitable methods to describe evolution quantitatively [<ce:cross-ref refid=""""b12"""" id=""""d1e7169"""">12[[ refid=''''b12'''' ]]</ce:cross-ref>]. The weighted <mml:math id=""""mml487"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si247.gif""""><mml:mi>k</mml:mi></mml:math>-core structure can also reflect the change in the software structure. So, in this section, we examine the evolution of <mml:math id=""""mml488"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si12.gif""""><mml:msubsup><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>W</mml:mi></mml:mrow></mml:msubsup></mml:math> of the 16 subject software system over their consecutive versions.</ce:para>""''"'		ANG	
uses_method_in	Empirical study	W.F. Pan, B. Jiang, Y.Y. Xu, Refactoring packages of object-oriented software using genetic algorithm based community detection technique , Int. J. Comput. Appl. Technol. , vol. 48 (2013), pp.185-194	http://dx.doi.org/10.1016/j.future.2017.09.039			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/br/b25	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/ctx/ctx0024		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-09-039/itrp/0009	'The WCCNs for all the subject systems are all automatically built and analyzed by our own developed tool SNAP [25[[ refid=''b25'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p57"""">For a specific piece of software, we extract structural information, build WCCNs and finally use <mml:math id=""""mml427"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si1.gif""""><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mtext>-</mml:mtext><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math> to obtain the <mml:math id=""""mml428"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si247.gif""""><mml:mi>k</mml:mi></mml:math>-core structure of the software. The WCCNs for all the subject systems are all automatically built and analyzed by our own developed tool SNAP [<ce:cross-ref refid=""""b25"""" id=""""d1e6145"""">25[[ refid=''''b25'''' ]]</ce:cross-ref>]. For illustration purpose, <ce:cross-refs refid=""""fig3 fig3a fig3b fig3c fig3d"""" id=""""d1e6152"""">Figs. 3(a)–3(d)</ce:cross-refs> respectively show the WCCNs built from four subject systems. Enlarging the corresponding WCCNs can give you the details such as the name of the class each node denotes, the edge between every pair of classes if exists, and the weight on the edge. The positions of the nodes and edges of WCCNs are all calculated using the original circular algorithm in Cytoscape.<ce:cross-ref refid=""""fn1"""" id=""""d1e6155""""><ce:sup loc=""""post"""">1</ce:sup></ce:cross-ref><ce:footnote id=""""fn1""""><ce:label>1</ce:label><ce:note-para view=""""all"""" id=""""d1e6162""""><ce:hsp sp=""""0.16667""""/>Cytoscape. Available at: <ce:inter-ref id=""""interref1"""" xlink:href=""""http://www.cytoscape.org/"""" xlink:type=""""simple"""">http://www.cytoscape.org/</ce:inter-ref>.</ce:note-para></ce:footnote></ce:para>""''"'		ANG	
cites	The stories told by exhibits	P. Marti, F. Gabrielli, F. Pucci, Situated interaction in art , Pers. Ubiquitous Comput. , vol. 5 (2001), pp.71-74	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b28	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0022		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0001	'In addition, in the experimental cases where the visiting style was matched to appropriate content, the users demonstrated increased interest by requesting more information about the exhibits explicitly [28[[ refid=''b28'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p23"""">The need to go beyond a single narration has been recognized in recent years and there have been certain attempts to present multiple views to visitors. For example, in the “PEACH” project mobile devices were also used. This particular project is worth mentioning due to its special design, using cinematic techniques in order to create a feeling of personalized TV. The documentary-like content also adapted to the interests of the user [<ce:cross-ref refid=""""b25"""" id=""""d1e787"""">25[[ refid=''''b25'''' ]]</ce:cross-ref>]. Another known systems is “HIPS” (Hyper-Interaction within Physical Space), a hypermedia system supporting mobile presentation of museum and historical information. Tourists and museum visitors were equipped with a hand-held device which provides electronic tours. Tourists’ positions were detected and auditory information was personalized and context depended [<ce:cross-ref refid=""""b26"""" id=""""d1e790"""">26[[ refid=''''b26'''' ]]</ce:cross-ref>]. The main principle of the application was that information is context depended and thus, it should be presented in different ways [<ce:cross-ref refid=""""b9"""" id=""""d1e793"""">9[[ refid=''''b9'''' ]]</ce:cross-ref>]. The environment became an interface and the visitor’s movements became a form of input to the system. The system could spot a novice visitor from her movements and support her during the visit. HIPS assumed that different visiting styles need different durations for the presentations and the empirical data support this hypothesis [<ce:cross-ref refid=""""b27"""" id=""""d1e796"""">27[[ refid=''''b27'''' ]]</ce:cross-ref>]. HIPS was using infrared emitters to connect to the users devices (PDAs) [<ce:cross-ref refid=""""b28"""" id=""""d1e799"""">28[[ refid=''''b28'''' ]]</ce:cross-ref>]. Finally, user testing and evaluation showed that all users liked the idea of receiving information related to their movement. In addition, in the experimental cases where the visiting style was matched to appropriate content, the users demonstrated increased interest by requesting more information about the exhibits explicitly [<ce:cross-ref refid=""""b28"""" id=""""d1e803"""">28[[ refid=''''b28'''' ]]</ce:cross-ref>].</ce:para>""''"'		ANG	
cites	The stories told by exhibits	S. Bampatzia, O.G. Bravo-Quezada, A. Antoniou, M. Lopez Nores, M. Wallace, G. Lepouras, C. Vasilakis, The use of semantics in the CrossCult H2020 project, in: 2nd International KEYSTONE Conference, IKC 2016, Cluj-Napoca Romania, 8-9 September, 2016.	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b29	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0023		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0002	'The ultimate goal is to calculate the degrees of separation between objects and people, targeting to the maximization of the impact that can exist through the interactions of people and cultural heritage objects; the approach presented in [29[[ refid=''b29'' ]]] is one possible way to do this.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p25"""">In this paper, we propose an ad-hoc network that includes objects and people. This network will be able to interact uniquely with each person according to parameters that may include among others the enriched content history of an object. The ultimate goal is to calculate the degrees of separation between objects and people, targeting to the maximization of the impact that can exist through the interactions of people and cultural heritage objects; the approach presented in [<ce:cross-ref refid=""""b29"""" id=""""d1e813"""">29[[ refid=''''b29'''' ]]</ce:cross-ref>] is one possible way to do this.</ce:para>""''"'		ANG	
cites	The stories told by exhibits	F. Gabrielli, P. Marti, L. Petroni, 1999 The environment as interface. Proceedings of the i3 Annual Conference: Community of the Future. October 20-22, Siena, pp. 44-47.	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b27	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0020		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0003	'HIPS assumed that different visiting styles need different durations for the presentations and the empirical data support this hypothesis [27[[ refid=''b27'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p23"""">The need to go beyond a single narration has been recognized in recent years and there have been certain attempts to present multiple views to visitors. For example, in the “PEACH” project mobile devices were also used. This particular project is worth mentioning due to its special design, using cinematic techniques in order to create a feeling of personalized TV. The documentary-like content also adapted to the interests of the user [<ce:cross-ref refid=""""b25"""" id=""""d1e787"""">25[[ refid=''''b25'''' ]]</ce:cross-ref>]. Another known systems is “HIPS” (Hyper-Interaction within Physical Space), a hypermedia system supporting mobile presentation of museum and historical information. Tourists and museum visitors were equipped with a hand-held device which provides electronic tours. Tourists’ positions were detected and auditory information was personalized and context depended [<ce:cross-ref refid=""""b26"""" id=""""d1e790"""">26[[ refid=''''b26'''' ]]</ce:cross-ref>]. The main principle of the application was that information is context depended and thus, it should be presented in different ways [<ce:cross-ref refid=""""b9"""" id=""""d1e793"""">9[[ refid=''''b9'''' ]]</ce:cross-ref>]. The environment became an interface and the visitor’s movements became a form of input to the system. The system could spot a novice visitor from her movements and support her during the visit. HIPS assumed that different visiting styles need different durations for the presentations and the empirical data support this hypothesis [<ce:cross-ref refid=""""b27"""" id=""""d1e796"""">27[[ refid=''''b27'''' ]]</ce:cross-ref>]. HIPS was using infrared emitters to connect to the users devices (PDAs) [<ce:cross-ref refid=""""b28"""" id=""""d1e799"""">28[[ refid=''''b28'''' ]]</ce:cross-ref>]. Finally, user testing and evaluation showed that all users liked the idea of receiving information related to their movement. In addition, in the experimental cases where the visiting style was matched to appropriate content, the users demonstrated increased interest by requesting more information about the exhibits explicitly [<ce:cross-ref refid=""""b28"""" id=""""d1e803"""">28[[ refid=''''b28'''' ]]</ce:cross-ref>].</ce:para>""''"'		ANG	
cites	The stories told by exhibits	P. Marti, F. Gabrielli, F. Pucci, Situated interaction in art , Pers. Ubiquitous Comput. , vol. 5 (2001), pp.71-74	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b28	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0021		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0004	'HIPS was using infrared emitters to connect to the users devices (PDAs) [28[[ refid=''b28'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p23"""">The need to go beyond a single narration has been recognized in recent years and there have been certain attempts to present multiple views to visitors. For example, in the “PEACH” project mobile devices were also used. This particular project is worth mentioning due to its special design, using cinematic techniques in order to create a feeling of personalized TV. The documentary-like content also adapted to the interests of the user [<ce:cross-ref refid=""""b25"""" id=""""d1e787"""">25[[ refid=''''b25'''' ]]</ce:cross-ref>]. Another known systems is “HIPS” (Hyper-Interaction within Physical Space), a hypermedia system supporting mobile presentation of museum and historical information. Tourists and museum visitors were equipped with a hand-held device which provides electronic tours. Tourists’ positions were detected and auditory information was personalized and context depended [<ce:cross-ref refid=""""b26"""" id=""""d1e790"""">26[[ refid=''''b26'''' ]]</ce:cross-ref>]. The main principle of the application was that information is context depended and thus, it should be presented in different ways [<ce:cross-ref refid=""""b9"""" id=""""d1e793"""">9[[ refid=''''b9'''' ]]</ce:cross-ref>]. The environment became an interface and the visitor’s movements became a form of input to the system. The system could spot a novice visitor from her movements and support her during the visit. HIPS assumed that different visiting styles need different durations for the presentations and the empirical data support this hypothesis [<ce:cross-ref refid=""""b27"""" id=""""d1e796"""">27[[ refid=''''b27'''' ]]</ce:cross-ref>]. HIPS was using infrared emitters to connect to the users devices (PDAs) [<ce:cross-ref refid=""""b28"""" id=""""d1e799"""">28[[ refid=''''b28'''' ]]</ce:cross-ref>]. Finally, user testing and evaluation showed that all users liked the idea of receiving information related to their movement. In addition, in the experimental cases where the visiting style was matched to appropriate content, the users demonstrated increased interest by requesting more information about the exhibits explicitly [<ce:cross-ref refid=""""b28"""" id=""""d1e803"""">28[[ refid=''''b28'''' ]]</ce:cross-ref>].</ce:para>""''"'		ANG	
cites	The smart exhibit	RFID Journal, How much information can an RFID tag store? 2017,	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b32	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0026		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0005	'Typically, an RFID tag can accommodate up to 2 KBytes of data [32[[ refid=''b32'' ]]], so the amount of this information is essentially limited and external storage services are required to store additional data for the exhibit, including extended semantic data, multimedia files, enhanced descriptions, histories and so forth.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p32""""><ce:italic>Basic implementation</ce:italic>. Same as the elementary implementation, but the RFID chip also has the exhibits’ basic information, such as title and creator, as well as a brief description including key semantic properties. Typically, an RFID tag can accommodate up to 2 KBytes of data [<ce:cross-ref refid=""""b32"""" id=""""d1e857"""">32[[ refid=''''b32'''' ]]</ce:cross-ref>], so the amount of this information is essentially limited and external storage services are required to store additional data for the exhibit, including extended semantic data, multimedia files, enhanced descriptions, histories and so forth. These storage services will be provided by the museum’s server.</ce:para>""''"'		ANG	
cites	The smart exhibit	Toshiba, FLASHAIR	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b33	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0027		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0006	'This can be implemented for example by having FlashAir cards [33[[ refid=''b33'' ]]] installed on them, which may provide from 8 to 32 GB of storage space, plus wireless LAN communication capabilities.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p35""""><ce:italic>Memory-rich implementation</ce:italic>. In this option, exhibits have large storage capabilities and the means to communicate with high data rates with their environments. This can be implemented for example by having <ce:italic>FlashAir</ce:italic> cards [<ce:cross-ref refid=""""b33"""" id=""""d1e877"""">33[[ refid=''''b33'''' ]]</ce:cross-ref>] installed on them, which may provide from 8 to 32 GB of storage space, plus wireless LAN communication capabilities. Now all the information related to each exhibit is stored on it, allowing for full mobility and automatic joining of other exhibitions in other museums. Formulation of exhibitions and personalized information presentation is again driven by the museum server, since exhibits only offer content, not processing capabilities. The museum-hosted server may store additional data on the exhibit’s memory, such as the exhibitions it has participated in or information regarding the profile of the visitors that have viewed it, thus the exhibit’s level of self-awareness can be progressively elevated. Exhibit geolocation can be fostered by standardized WiFi triangulation or WiFi fingerprinting methods [<ce:cross-refs refid=""""b34 b35"""" id=""""d1e880"""">34,35[[ refid=''''b34 b35'''' ]]</ce:cross-refs>]; alternatively RFID tags can be also attached to exhibits to implement geolocation through an RFID reader antenna grid. Exhibit geolocation is further discussed in Subsection <ce:cross-ref refid=""""sec3.2"""" id=""""d1e883"""">3.2</ce:cross-ref>.</ce:para>""''"'		ANG	
cites	The smart exhibit	S.L. Ting, S.K. Kwok, A.H.C. Tsang, G.T.S. Ho, The study on using passive RFID tags for indoor positioning , Int. J. Eng. Bus. Manag. , vol. 3 (2011), pp.None	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b30	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0024		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0007	'The RFID tag is sensed by RFID readers hosted in the exhibition rooms, which notify a museum-hosted server regarding the locations of the exhibits [30[[ refid=''b30'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p28""""><ce:float-anchor refid=""""fig3""""/><ce:italic>Elementary implementation</ce:italic>. Exhibits carry an RFID tag providing only a single identification number. The RFID tag is sensed by RFID readers hosted in the exhibition rooms, which notify a museum-hosted server regarding the locations of the exhibits [<ce:cross-ref refid=""""b30"""" id=""""d1e835"""">30[[ refid=''''b30'''' ]]</ce:cross-ref>]. The museum-hosted server maintains a repository containing all the information (descriptions, semantic information and RFID identifications) for the exhibits that it accommodates, therefore having obtained the exhibit location information from the RFID readers, it can run logic for exhibit presentation and dynamic exhibition formulation. Visitors receive the exhibition and exhibit information by connecting to the server through standard Internet connectivity, typically supported through WiFi access points installed by the museum. Visitor requests to the server may contain visitor profile information, which the server can exploit to perform personalization. Practically, any technology that supports geolocation and the provision of a unique identifier for each exhibit, such as ibeacons [<ce:cross-ref refid=""""b31"""" id=""""d1e838"""">31[[ refid=''''b31'''' ]]</ce:cross-ref>], can be used; in the rest of this paper we will limit our discussion to the RFID technology since our main focus is to describe the architectural approaches, rather than fully explore all available technological options.</ce:para>""''"'		ANG	
cites	Introduction	Karp Ivan, Lavine Steven, , Exhibiting Cultures: The Poetics and Politics of Museum Display, Smithsonian Institution Press (1991)	http://dx.doi.org/10.1016/j.future.2017.10.038	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0002		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0027	'Out of the abundance of items that they possess, museums select only a handful to put on display [2[[ refid=''b2'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p6"""">Museum exhibitions are far more than mere groups of exhibits, randomly selected and placed in a room. Quite the contrary, an exhibition tells a story [<ce:cross-ref refid=""""b1"""" id=""""d1e576"""">1[[ refid=''''b1'''' ]]</ce:cross-ref>]. Out of the abundance of items that they possess, museums select only a handful to put on display [<ce:cross-ref refid=""""b2"""" id=""""d1e579"""">2[[ refid=''''b2'''' ]]</ce:cross-ref>]. And to do this they employ curators, individuals who combine high expertise in the content’s area (e.g. archeology, art, culture, folklore, etc.), good museological skills, understanding of educational methods and a creative temperament. It should come as no surprise that curators are typically highly trained [<ce:cross-ref refid=""""b3"""" id=""""d1e582"""">3[[ refid=''''b3'''' ]]</ce:cross-ref>] or that curation makes up for a major part of a museum’s budget [<ce:cross-ref refid=""""b4"""" id=""""d1e585"""">4[[ refid=''''b4'''' ]]</ce:cross-ref>].</ce:para>""''"'		ANG	
cites	Introduction	Mette Houlberg Rung, Thoughts about an exhibition - using materiality and sensuousness as a narrative device, 2016,	http://dx.doi.org/10.1016/j.future.2017.10.038	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b5	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0004		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0030	'In theory, the result of the meticulous work of the curator is a story that is told in a space [5[[ refid=''b5'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p7"""">In theory, the result of the meticulous work of the curator is a story that is told in a space [<ce:cross-ref refid=""""b5"""" id=""""d1e590"""">5[[ refid=''''b5'''' ]]</ce:cross-ref>]. In practice, curators view the items in the exhibition, identify the implied links among then and see the story they are meant to tell. For most visitors, they are mere sets of exhibits, accompanied by some information such as the name of the creator or the year in which they were created [<ce:cross-ref refid=""""b6"""" id=""""d1e593"""">6[[ refid=''''b6'''' ]]</ce:cross-ref>]. This is why a museum experience is rarely complete if not combined with the use of a print, audio or human guide, who can reveal the hidden story. But even so, the aforementioned conventional way of setting up exhibitions marks a huge missed opportunity. Each individual exhibit in a museum has many stories to tell: for example Goya’s monumental work “The 3rd of May 1808 in Madrid” (<ce:cross-ref refid=""""fig1"""" id=""""d1e596"""">Fig. 1</ce:cross-ref>) [<ce:cross-ref refid=""""b7"""" id=""""d1e599"""">7[[ refid=''''b7'''' ]]</ce:cross-ref>] can tell us about Spanish resistance to Napoleon’s armies; about the horror of war; about how different people face death; about the history of Madrid; about the artist’s personal style or the trends of the artistic period; and so forth. And when individual exhibits are combined, the number of stories they can tell is merely countless, however out of these stories only one is typically selected and highlighted in each exhibition. Works such as PEACH [<ce:cross-ref refid=""""b8"""" id=""""d1e602"""">8[[ refid=''''b8'''' ]]</ce:cross-ref>], HyperAudio and HIPS [<ce:cross-ref refid=""""b9"""" id=""""d1e606"""">9[[ refid=''''b9'''' ]]</ce:cross-ref>] take into account the museum content – typically stored in some knowledge base – and the current context to create context-aware museum guides, where the stories told are automatically synthesized through narration generation algorithms, which consider the museum knowledge base content. The generated stories can be further refined or filtered to match the user interests, the visitor model, the interaction history or any other context parameter. However, even in these works, when exhibits are introduced, removed or moved in new locations, the knowledge base hosting the content on which creation of personalized experiences relies must be done manually, introducing a laborious piece of work. Moreover, museum curators may register in the knowledge base only a fraction of an exhibit’s semantic content (e.g. the part that is highly related to the current exhibition), missing thus opportunities for discovering and presenting non-trivial and unexpected relationships between exhibits.</ce:para>""''"'		ANG	
cites	Introduction	, Museums and the Public Understanding of Science, The Science Museum (1992)	http://dx.doi.org/10.1016/j.future.2017.10.038	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b6	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0005		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0031	'For most visitors, they are mere sets of exhibits, accompanied by some information such as the name of the creator or the year in which they were created [6[[ refid=''b6'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p7"""">In theory, the result of the meticulous work of the curator is a story that is told in a space [<ce:cross-ref refid=""""b5"""" id=""""d1e590"""">5[[ refid=''''b5'''' ]]</ce:cross-ref>]. In practice, curators view the items in the exhibition, identify the implied links among then and see the story they are meant to tell. For most visitors, they are mere sets of exhibits, accompanied by some information such as the name of the creator or the year in which they were created [<ce:cross-ref refid=""""b6"""" id=""""d1e593"""">6[[ refid=''''b6'''' ]]</ce:cross-ref>]. This is why a museum experience is rarely complete if not combined with the use of a print, audio or human guide, who can reveal the hidden story. But even so, the aforementioned conventional way of setting up exhibitions marks a huge missed opportunity. Each individual exhibit in a museum has many stories to tell: for example Goya’s monumental work “The 3rd of May 1808 in Madrid” (<ce:cross-ref refid=""""fig1"""" id=""""d1e596"""">Fig. 1</ce:cross-ref>) [<ce:cross-ref refid=""""b7"""" id=""""d1e599"""">7[[ refid=''''b7'''' ]]</ce:cross-ref>] can tell us about Spanish resistance to Napoleon’s armies; about the horror of war; about how different people face death; about the history of Madrid; about the artist’s personal style or the trends of the artistic period; and so forth. And when individual exhibits are combined, the number of stories they can tell is merely countless, however out of these stories only one is typically selected and highlighted in each exhibition. Works such as PEACH [<ce:cross-ref refid=""""b8"""" id=""""d1e602"""">8[[ refid=''''b8'''' ]]</ce:cross-ref>], HyperAudio and HIPS [<ce:cross-ref refid=""""b9"""" id=""""d1e606"""">9[[ refid=''''b9'''' ]]</ce:cross-ref>] take into account the museum content – typically stored in some knowledge base – and the current context to create context-aware museum guides, where the stories told are automatically synthesized through narration generation algorithms, which consider the museum knowledge base content. The generated stories can be further refined or filtered to match the user interests, the visitor model, the interaction history or any other context parameter. However, even in these works, when exhibits are introduced, removed or moved in new locations, the knowledge base hosting the content on which creation of personalized experiences relies must be done manually, introducing a laborious piece of work. Moreover, museum curators may register in the knowledge base only a fraction of an exhibit’s semantic content (e.g. the part that is highly related to the current exhibition), missing thus opportunities for discovering and presenting non-trivial and unexpected relationships between exhibits.</ce:para>""''"'		ANG	
cites	Introduction	P. Lima, , The Third of May (2012)	http://dx.doi.org/10.1016/j.future.2017.10.038	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0006		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0032	'Each individual exhibit in a museum has many stories to tell: for example Goya’s monumental work “The 3rd of May 1808 in Madrid” (Fig. 1) [7[[ refid=''b7'' ]]] can tell us about Spanish resistance to Napoleon’s armies; about the horror of war; about how different people face death; about the history of Madrid; about the artist’s personal style or the trends of the artistic period; and so forth.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p7"""">In theory, the result of the meticulous work of the curator is a story that is told in a space [<ce:cross-ref refid=""""b5"""" id=""""d1e590"""">5[[ refid=''''b5'''' ]]</ce:cross-ref>]. In practice, curators view the items in the exhibition, identify the implied links among then and see the story they are meant to tell. For most visitors, they are mere sets of exhibits, accompanied by some information such as the name of the creator or the year in which they were created [<ce:cross-ref refid=""""b6"""" id=""""d1e593"""">6[[ refid=''''b6'''' ]]</ce:cross-ref>]. This is why a museum experience is rarely complete if not combined with the use of a print, audio or human guide, who can reveal the hidden story. But even so, the aforementioned conventional way of setting up exhibitions marks a huge missed opportunity. Each individual exhibit in a museum has many stories to tell: for example Goya’s monumental work “The 3rd of May 1808 in Madrid” (<ce:cross-ref refid=""""fig1"""" id=""""d1e596"""">Fig. 1</ce:cross-ref>) [<ce:cross-ref refid=""""b7"""" id=""""d1e599"""">7[[ refid=''''b7'''' ]]</ce:cross-ref>] can tell us about Spanish resistance to Napoleon’s armies; about the horror of war; about how different people face death; about the history of Madrid; about the artist’s personal style or the trends of the artistic period; and so forth. And when individual exhibits are combined, the number of stories they can tell is merely countless, however out of these stories only one is typically selected and highlighted in each exhibition. Works such as PEACH [<ce:cross-ref refid=""""b8"""" id=""""d1e602"""">8[[ refid=''''b8'''' ]]</ce:cross-ref>], HyperAudio and HIPS [<ce:cross-ref refid=""""b9"""" id=""""d1e606"""">9[[ refid=''''b9'''' ]]</ce:cross-ref>] take into account the museum content – typically stored in some knowledge base – and the current context to create context-aware museum guides, where the stories told are automatically synthesized through narration generation algorithms, which consider the museum knowledge base content. The generated stories can be further refined or filtered to match the user interests, the visitor model, the interaction history or any other context parameter. However, even in these works, when exhibits are introduced, removed or moved in new locations, the knowledge base hosting the content on which creation of personalized experiences relies must be done manually, introducing a laborious piece of work. Moreover, museum curators may register in the knowledge base only a fraction of an exhibit’s semantic content (e.g. the part that is highly related to the current exhibition), missing thus opportunities for discovering and presenting non-trivial and unexpected relationships between exhibits.</ce:para>""''"'		ANG	
cites	Related work	L. Findlater, J. McGrenere, A comparison of static, adaptive, and adaptable menus , Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI ’04, ACM (2004)	http://dx.doi.org/10.1016/j.future.2017.10.038	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b63	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0061		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0035	'But personalization is not only viewed as important by experts, since museum visitors also report the need to have personalized experiences [63[[ refid=''b63'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p114"""">Finally, personalization is another important aspect for cultural heritage applications known to increase visitor engagement and the overall quality of the cultural experience [<ce:cross-refs refid=""""b46 b60"""" id=""""d1e1508"""">46,60[[ refid=''''b46 b60'''' ]]</ce:cross-refs>]. When it comes to the IoT, personalization is recognized as a critical element for the success of systems and applications [<ce:cross-ref refid=""""b61"""" id=""""d1e1511"""">61[[ refid=''''b61'''' ]]</ce:cross-ref>]. Since more and more people recognize the importance of personalization in cultural heritage, due to its potential to address the needs of a very diverse audience, there are many works that attempt to apply personalization in spaces of cultural heritage [<ce:cross-ref refid=""""b45"""" id=""""d1e1514"""">45[[ refid=''''b45'''' ]]</ce:cross-ref>]. Ardissono et al. [<ce:cross-ref refid=""""b62"""" id=""""d1e1517"""">62[[ refid=''''b62'''' ]]</ce:cross-ref>] provide a detailed survey of the field of personalized applications in cultural heritage. But personalization is not only viewed as important by experts, since museum visitors also report the need to have personalized experiences [<ce:cross-ref refid=""""b63"""" id=""""d1e1520"""">63[[ refid=''''b63'''' ]]</ce:cross-ref>]. Personalization for cultural heritage is coupled with the needs for mobility in personalized space sensitive devices [<ce:cross-ref refid=""""b64"""" id=""""d1e1524"""">64[[ refid=''''b64'''' ]]</ce:cross-ref>] as well as needs for presence in social media, like Youtube and Pinetest [<ce:cross-ref refid=""""b65"""" id=""""d1e1527"""">65[[ refid=''''b65'''' ]]</ce:cross-ref>], Facebook [<ce:cross-ref refid=""""b66"""" id=""""d1e1530"""">66[[ refid=''''b66'''' ]]</ce:cross-ref>], Twitter [<ce:cross-ref refid=""""b67"""" id=""""d1e1533"""">67[[ refid=''''b67'''' ]]</ce:cross-ref>], and Instagram [<ce:cross-ref refid=""""b68"""" id=""""d1e1536"""">68[[ refid=''''b68'''' ]]</ce:cross-ref>].</ce:para>""''"'		ANG	
cites	Related work	F. Amato, A. Chianese, V. Moscato, A. Picariello, G. Sperli, Snops: a smart environment for cultural heritage applications , 12th ACM International Workshop on Web Information and Data Management, ACM , vol. 4 (2012), pp.9-56	http://dx.doi.org/10.1016/j.future.2017.10.038	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b50	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0048		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0036	'For example, the SNOPS project provided multilevel information in a smart-city environment, where visitors could exploit object features in regards to specific contexts [50[[ refid=''b50'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p111"""">The developing area of research on the IoT has attracted significant research interest over the last years. The landscape of IoT is getting thoroughly analyzed, meaning that communication technologies, discovery functionalities and mechanisms are studied in detail [<ce:cross-ref refid=""""b49"""" id=""""d1e1460"""">49[[ refid=''''b49'''' ]]</ce:cross-ref>]. In addition, the IoT is further studied within the scopes of cultural heritage. For example, the SNOPS project provided multilevel information in a smart-city environment, where visitors could exploit object features in regards to specific contexts [<ce:cross-ref refid=""""b50"""" id=""""d1e1463"""">50[[ refid=''''b50'''' ]]</ce:cross-ref>]. The approach presented in [<ce:cross-ref refid=""""b51"""" id=""""d1e1466"""">51[[ refid=''''b51'''' ]]</ce:cross-ref>] and [<ce:cross-ref refid=""""b52"""" id=""""d1e1469"""">52[[ refid=''''b52'''' ]]</ce:cross-ref>] defines the idea of the single smart space concept and its capabilities, representing a new way of conceiving smart spaces within the cultural heritage domain. This work introduces a form of “smart exhibits” which can carry along multimedia files and communicate with each other in a master/slave fashion (a <ce:italic>server</ce:italic> smart exhibit may retrieve multimedia files from <ce:italic>client</ce:italic> exhibits), but it does not address the aspect of using semantics to accommodate self-organizing exhibitions and no personalization potential is described. Furthermore, indoor cultural activities have been also studied within the framework of the IoT and significant factors that affect the museum visits have been identified, like the visit context [<ce:cross-ref refid=""""b53"""" id=""""d1e1479"""">53[[ refid=''''b53'''' ]]</ce:cross-ref>]. Another example of museum IoT system is the iPhone App, “Take me I’m yours”. The project explores ways that objects can talk to the visitors and require actions [<ce:cross-ref refid=""""b54"""" id=""""d1e1482"""">54[[ refid=''''b54'''' ]]</ce:cross-ref>].</ce:para>""''"'		ANG	
cites	Related work	A. Antoniou, A. Katifori, M. Roussou, M. Vayanou, M. Karvounis, M. Kyriakidi, L. Pujol-Tost, Capturing the visitor profile for a personalized mobile museum experience: An indirect approach, in: UMAP (Extended Proceedings), 2016.	http://dx.doi.org/10.1016/j.future.2017.10.038	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b45	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0059		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0039	'Since more and more people recognize the importance of personalization in cultural heritage, due to its potential to address the needs of a very diverse audience, there are many works that attempt to apply personalization in spaces of cultural heritage [45[[ refid=''b45'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p114"""">Finally, personalization is another important aspect for cultural heritage applications known to increase visitor engagement and the overall quality of the cultural experience [<ce:cross-refs refid=""""b46 b60"""" id=""""d1e1508"""">46,60[[ refid=''''b46 b60'''' ]]</ce:cross-refs>]. When it comes to the IoT, personalization is recognized as a critical element for the success of systems and applications [<ce:cross-ref refid=""""b61"""" id=""""d1e1511"""">61[[ refid=''''b61'''' ]]</ce:cross-ref>]. Since more and more people recognize the importance of personalization in cultural heritage, due to its potential to address the needs of a very diverse audience, there are many works that attempt to apply personalization in spaces of cultural heritage [<ce:cross-ref refid=""""b45"""" id=""""d1e1514"""">45[[ refid=''''b45'''' ]]</ce:cross-ref>]. Ardissono et al. [<ce:cross-ref refid=""""b62"""" id=""""d1e1517"""">62[[ refid=''''b62'''' ]]</ce:cross-ref>] provide a detailed survey of the field of personalized applications in cultural heritage. But personalization is not only viewed as important by experts, since museum visitors also report the need to have personalized experiences [<ce:cross-ref refid=""""b63"""" id=""""d1e1520"""">63[[ refid=''''b63'''' ]]</ce:cross-ref>]. Personalization for cultural heritage is coupled with the needs for mobility in personalized space sensitive devices [<ce:cross-ref refid=""""b64"""" id=""""d1e1524"""">64[[ refid=''''b64'''' ]]</ce:cross-ref>] as well as needs for presence in social media, like Youtube and Pinetest [<ce:cross-ref refid=""""b65"""" id=""""d1e1527"""">65[[ refid=''''b65'''' ]]</ce:cross-ref>], Facebook [<ce:cross-ref refid=""""b66"""" id=""""d1e1530"""">66[[ refid=''''b66'''' ]]</ce:cross-ref>], Twitter [<ce:cross-ref refid=""""b67"""" id=""""d1e1533"""">67[[ refid=''''b67'''' ]]</ce:cross-ref>], and Instagram [<ce:cross-ref refid=""""b68"""" id=""""d1e1536"""">68[[ refid=''''b68'''' ]]</ce:cross-ref>].</ce:para>""''"'		ANG	
cites_as_review	Related work	L. Ardissono, T. Kuflik, D. Petrelli, Personalization in cultural heritage: the road travelled and the one ahead , User Model. User-Adapted Interact. , vol. 22 (2012), pp.73-99	http://dx.doi.org/10.1016/j.future.2017.10.038	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b62	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0060		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0040	'Ardissono et al. [62[[ refid=''b62'' ]]] provide a detailed survey of the field of personalized applications in cultural heritage.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p114"""">Finally, personalization is another important aspect for cultural heritage applications known to increase visitor engagement and the overall quality of the cultural experience [<ce:cross-refs refid=""""b46 b60"""" id=""""d1e1508"""">46,60[[ refid=''''b46 b60'''' ]]</ce:cross-refs>]. When it comes to the IoT, personalization is recognized as a critical element for the success of systems and applications [<ce:cross-ref refid=""""b61"""" id=""""d1e1511"""">61[[ refid=''''b61'''' ]]</ce:cross-ref>]. Since more and more people recognize the importance of personalization in cultural heritage, due to its potential to address the needs of a very diverse audience, there are many works that attempt to apply personalization in spaces of cultural heritage [<ce:cross-ref refid=""""b45"""" id=""""d1e1514"""">45[[ refid=''''b45'''' ]]</ce:cross-ref>]. Ardissono et al. [<ce:cross-ref refid=""""b62"""" id=""""d1e1517"""">62[[ refid=''''b62'''' ]]</ce:cross-ref>] provide a detailed survey of the field of personalized applications in cultural heritage. But personalization is not only viewed as important by experts, since museum visitors also report the need to have personalized experiences [<ce:cross-ref refid=""""b63"""" id=""""d1e1520"""">63[[ refid=''''b63'''' ]]</ce:cross-ref>]. Personalization for cultural heritage is coupled with the needs for mobility in personalized space sensitive devices [<ce:cross-ref refid=""""b64"""" id=""""d1e1524"""">64[[ refid=''''b64'''' ]]</ce:cross-ref>] as well as needs for presence in social media, like Youtube and Pinetest [<ce:cross-ref refid=""""b65"""" id=""""d1e1527"""">65[[ refid=''''b65'''' ]]</ce:cross-ref>], Facebook [<ce:cross-ref refid=""""b66"""" id=""""d1e1530"""">66[[ refid=''''b66'''' ]]</ce:cross-ref>], Twitter [<ce:cross-ref refid=""""b67"""" id=""""d1e1533"""">67[[ refid=''''b67'''' ]]</ce:cross-ref>], and Instagram [<ce:cross-ref refid=""""b68"""" id=""""d1e1536"""">68[[ refid=''''b68'''' ]]</ce:cross-ref>].</ce:para>""''"'		ANG	
cites	Related work	O. Etzion, F. Forunier, On the personalization of event-based systems , Proceedings of the 1st ACM International Workshop on Human Centered Event Understanding from Multimedia, HuEvent ’14, ACM (2014)	http://dx.doi.org/10.1016/j.future.2017.10.038	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b61	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0058		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0041	'When it comes to the IoT, personalization is recognized as a critical element for the success of systems and applications [61[[ refid=''b61'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p114"""">Finally, personalization is another important aspect for cultural heritage applications known to increase visitor engagement and the overall quality of the cultural experience [<ce:cross-refs refid=""""b46 b60"""" id=""""d1e1508"""">46,60[[ refid=''''b46 b60'''' ]]</ce:cross-refs>]. When it comes to the IoT, personalization is recognized as a critical element for the success of systems and applications [<ce:cross-ref refid=""""b61"""" id=""""d1e1511"""">61[[ refid=''''b61'''' ]]</ce:cross-ref>]. Since more and more people recognize the importance of personalization in cultural heritage, due to its potential to address the needs of a very diverse audience, there are many works that attempt to apply personalization in spaces of cultural heritage [<ce:cross-ref refid=""""b45"""" id=""""d1e1514"""">45[[ refid=''''b45'''' ]]</ce:cross-ref>]. Ardissono et al. [<ce:cross-ref refid=""""b62"""" id=""""d1e1517"""">62[[ refid=''''b62'''' ]]</ce:cross-ref>] provide a detailed survey of the field of personalized applications in cultural heritage. But personalization is not only viewed as important by experts, since museum visitors also report the need to have personalized experiences [<ce:cross-ref refid=""""b63"""" id=""""d1e1520"""">63[[ refid=''''b63'''' ]]</ce:cross-ref>]. Personalization for cultural heritage is coupled with the needs for mobility in personalized space sensitive devices [<ce:cross-ref refid=""""b64"""" id=""""d1e1524"""">64[[ refid=''''b64'''' ]]</ce:cross-ref>] as well as needs for presence in social media, like Youtube and Pinetest [<ce:cross-ref refid=""""b65"""" id=""""d1e1527"""">65[[ refid=''''b65'''' ]]</ce:cross-ref>], Facebook [<ce:cross-ref refid=""""b66"""" id=""""d1e1530"""">66[[ refid=''''b66'''' ]]</ce:cross-ref>], Twitter [<ce:cross-ref refid=""""b67"""" id=""""d1e1533"""">67[[ refid=''''b67'''' ]]</ce:cross-ref>], and Instagram [<ce:cross-ref refid=""""b68"""" id=""""d1e1536"""">68[[ refid=''''b68'''' ]]</ce:cross-ref>].</ce:para>""''"'		ANG	
cites	The smart exhibit	N.K. Kwan, Method and system for answering online certificate status protocol (OCSP) requests without certificate revocation lists (CRL), Patent US 6970862 B2, available at	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b41	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0035		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0042	'Therefore, content requesters can query the venue server regarding the acceptability of the content they received, similarly to the logic of web browsers, which query OCSP servers [41[[ refid=''b41'' ]]] to verify that certificates they receive have not been revoked.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p52"""">In the case of the agent-based implementation option, again malicious parties can try to imitate an exhibit, and join the exhibit network, providing arbitrary content. Similarly to the case of the memory-rich implementation option, a special venue-operated trusted wireless network can be used as a first measure to separate legitimate exhibits (to which the SSID and the network key of the trusted wireless network will be known) from malicious parties and visitors. Furthermore, public key cryptography can also be used to mitigate security risks: each legitimate exhibit has available a private key/digital certificate pair, where the digital certificate is digitally signed by the exhibit owner, and uses this certificate to secure its communications with content requesters. Content requesters (which may be the venue server, another exhibit in the same venue, or even a client application in a visitor’s device) can then verify whether the exhibit uses an acceptable digital certificate, by verifying the signature path on the exhibit’s digital certificate. While the venue server can maintain a list of exhibit owners whose signatures on digital certificates are accepted, maintaining such lists in all content requesters (other exhibits and client applications) is impractical, due to the need to frequently update them as exhibits or visitors move from one venue to another. To foster the content validation procedure, the venue server can make available a service that checks the acceptability of presented digital certificates, based on the known list of exhibit owners whose signatures on digital certificates are accepted. Therefore, content requesters can query the venue server regarding the acceptability of the content they received, similarly to the logic of web browsers, which query OCSP servers [<ce:cross-ref refid=""""b41"""" id=""""d1e1042"""">41[[ refid=''''b41'''' ]]</ce:cross-ref>] to verify that certificates they receive have not been revoked.</ce:para>""''"'		ANG	
cites	The smart exhibit	FlashAir Config, Network mode	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b40	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0034		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0043	'As a first measure, the wireless LAN access point that is embedded in the FlashAir cards may be set to Station Mode, in which case the FlashAir becomes a Wireless LAN client [40[[ refid=''b40'' ]]], and the APPSSID and APPNETWORKKEY parameters (corresponding to a WLAN’s Service Set Identifier (SSID) and network key) can be set to point to a venue-operated trusted wireless network.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p50"""">In the memory-rich implementation option, visitors are presented with information and media files provided by the exhibits, so a malicious party may try to emulate an exhibit, and thus inject content into the exhibitions. The security issues can be addressed by exploiting the security features that are built-in the <ce:italic>FlashAir</ce:italic> cards. As a first measure, the wireless LAN access point that is embedded in the <ce:italic>FlashAir</ce:italic> cards may be set to Station Mode, in which case the <ce:italic>FlashAir</ce:italic> becomes a Wireless LAN client [<ce:cross-ref refid=""""b40"""" id=""""d1e1022"""">40[[ refid=''''b40'''' ]]</ce:cross-ref>], and the <ce:monospace>APPSSID</ce:monospace> and <ce:monospace>APPNETWORKKEY</ce:monospace> parameters (corresponding to a WLAN’s Service Set Identifier (SSID) and network key) can be set to point to a venue-operated trusted wireless network. Under this scheme, the venue server that extracts content to weave exhibitions can be set to query only devices that are connected to the particular wireless network, excluding effectively “impostor” devices, since the <ce:monospace>APPNETWORKKEY</ce:monospace> will not be known to malicious parties. Visitor devices will connect to a different WLAN’s Service Set Identifier (SSID), and requests for content will be routed to the respective devices in the venue-operated trusted wireless network through standard network routing configurations.</ce:para>""''"'		ANG	
cites	The exhiSTORY system architecture	S. Bampatzia, O.G. Bravo-Quezada, A. Antoniou, M. Lopez Nores, M. Wallace, G. Lepouras, C. Vasilakis, The use of semantics in the CrossCult H2020 project, in: 2nd International KEYSTONE Conference, IKC 2016, Cluj-Napoca Romania, 8-9 September, 2016.	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b29	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0037		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0044	'This internal procedure is out of the scope of the current work and is presented thoroughly in [29[[ refid=''b29'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p78"""">The operation of the story finder module is based on the “x degrees of semantic separation” described in Section <ce:cross-ref refid=""""sec2"""" id=""""d1e1230"""">2</ce:cross-ref>. It examines the individual context of each one of the exhibits and then locates meaningful links among them in the exhibition’s semantics. This internal procedure is out of the scope of the current work and is presented thoroughly in [<ce:cross-ref refid=""""b29"""" id=""""d1e1233"""">29[[ refid=''''b29'''' ]]</ce:cross-ref>]. Emphasis is on non-trivial links, i.e. links that connect a large number of the exhibits. Each one of these links is a story that can be told. The museum’s context from the knowledge base is queried for topics links that should be ignored, in order to avoid discussing topics that the museum’s management has identified as unfit for presentation.</ce:para>""''"'		ANG	
cites	The smart exhibit	U. Hatthasin, K. Vibhatavanij, D. Worasawate, One base station approach for indoor geolocation system using RFID , Proceedings of Asia-Pacific Microwave Conference (2007)	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b36	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0031		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0047	'Therefore, exhibits that remain still can be used as reference tags, and by applying a weighted-center of gravity technique, one reader antenna can be proved sufficient for an area of 12 m by 10 m, providing a level of accuracy of about 1.07 m [36[[ refid=''b36'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p47"""">According to Ting et al. [<ce:cross-ref refid=""""b30"""" id=""""d1e979"""">30[[ refid=''''b30'''' ]]</ce:cross-ref>], RFID tags can be used to geolocate objects, exploiting the signal strength captured by appropriately placed RFID reader antennas. This work asserts that the detection of passive RFID tags provides excellent precision when the distance between the reader antenna and the tag is up to 3 m, and exceeds 75% for distances up to 4.5 m, hence setting up a 2 m <mml:math id=""""mml7"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si7.gif""""><mml:mo>×</mml:mo></mml:math> 2 m rectangular grid of reader antennas will provide adequate precision for geolocating the exhibits. The number of required reader antennas can be however significantly reduced, by exploiting the fact that when venue exhibitions are restructured, a number of exhibits within the exhibitions is not moved. Therefore, exhibits that remain still can be used as reference tags, and by applying a weighted-center of gravity technique, one reader antenna can be proved sufficient for an area of 12 m by 10 m, providing a level of accuracy of about 1.07 m [<ce:cross-ref refid=""""b36"""" id=""""d1e987"""">36[[ refid=''''b36'''' ]]</ce:cross-ref>]. This setup is adequate for the positioning the exhibits within the generated narratives (the visitor can be directed to elements of the narrative at exhibition room level or exhibition room area level). These approaches apply to the elementary and the basic implementation for smart exhibits. Note that instead of polling for non-moved exhibits to identify reference tags, extra RFID tags can be positioned in the venue to play this role, i.e. provide reference points for geolocating exhibits.</ce:para>""''"'		ANG	
cites	The smart exhibit	S.L. Ting, S.K. Kwok, A.H.C. Tsang, G.T.S. Ho, The study on using passive RFID tags for indoor positioning , Int. J. Eng. Bus. Manag. , vol. 3 (2011), pp.None	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b30	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0030		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0048	'According to Ting et al. [30[[ refid=''b30'' ]]], RFID tags can be used to geolocate objects, exploiting the signal strength captured by appropriately placed RFID reader antennas.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p47"""">According to Ting et al. [<ce:cross-ref refid=""""b30"""" id=""""d1e979"""">30[[ refid=''''b30'''' ]]</ce:cross-ref>], RFID tags can be used to geolocate objects, exploiting the signal strength captured by appropriately placed RFID reader antennas. This work asserts that the detection of passive RFID tags provides excellent precision when the distance between the reader antenna and the tag is up to 3 m, and exceeds 75% for distances up to 4.5 m, hence setting up a 2 m <mml:math id=""""mml7"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si7.gif""""><mml:mo>×</mml:mo></mml:math> 2 m rectangular grid of reader antennas will provide adequate precision for geolocating the exhibits. The number of required reader antennas can be however significantly reduced, by exploiting the fact that when venue exhibitions are restructured, a number of exhibits within the exhibitions is not moved. Therefore, exhibits that remain still can be used as reference tags, and by applying a weighted-center of gravity technique, one reader antenna can be proved sufficient for an area of 12 m by 10 m, providing a level of accuracy of about 1.07 m [<ce:cross-ref refid=""""b36"""" id=""""d1e987"""">36[[ refid=''''b36'''' ]]</ce:cross-ref>]. This setup is adequate for the positioning the exhibits within the generated narratives (the visitor can be directed to elements of the narrative at exhibition room level or exhibition room area level). These approaches apply to the elementary and the basic implementation for smart exhibits. Note that instead of polling for non-moved exhibits to identify reference tags, extra RFID tags can be positioned in the venue to play this role, i.e. provide reference points for geolocating exhibits.</ce:para>""''"'		ANG	
cites	The stories told by exhibits	V. Viswanathan, I. Krishnamurthi, Finding relevant semantic association paths through user-specific intermediate entities , Hum. Centric Comput. Inf. Sci. , vol. 2 (2012), pp.None	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b14	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0011		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0073	'In this notion, we suggest that given any pair of items we can find meaningful links between them with a reasonably small number of steps that go through facts related not only to history or art, but also to popular culture and any available information about the target user’s memories and interests; experiments reported in [14[[ refid=''b14'' ]]] provide evidence that user-specific intermediate entities can be used as elements of the path linking two nodes in a semantic network, and we plan to further explore this issue through experiments specifically targeted to the aforementioned aspects (popular culture, user’s memories and interests).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p18"""">For example, regarding the presentation of its own information, it is now possible for the exhibit “The 3rd of May 1808 in Madrid” to present to us all the information that could not be displayed in its small accompanying label. However, the full potential of the exhiSTORY system stems from the fact that having access to the full context and semantic information of the exhibits opens up great opportunities, which could be focused on looking for connections between them. Google<ce:cross-ref refid=""""fn1"""" id=""""d1e727""""><ce:sup loc=""""post"""">1</ce:sup></ce:cross-ref><ce:footnote id=""""fn1""""><ce:label>1</ce:label><ce:note-para view=""""all"""" id=""""d1e734"""">Google Inc. - <ce:inter-ref id=""""interref1"""" xlink:href=""""http://google.com"""" xlink:type=""""simple"""">http://google.com</ce:inter-ref>.</ce:note-para></ce:footnote>has experimented with the notion of x degrees of separation of items in museum collections based on their visual similarity [<ce:cross-ref refid=""""b13"""" id=""""d1e740"""">13[[ refid=''''b13'''' ]]</ce:cross-ref>], but we find the <ce:bold>semantic</ce:bold> notion of x degrees of separation far more stimulating. In this notion, we suggest that given any pair of items we can find meaningful links between them with a reasonably small number of steps that go through facts related not only to history or art, but also to popular culture and any available information about the target user’s memories and interests; experiments reported in [<ce:cross-ref refid=""""b14"""" id=""""d1e746"""">14[[ refid=''''b14'''' ]]</ce:cross-ref>] provide evidence that user-specific intermediate entities can be used as elements of the path linking two nodes in a semantic network, and we plan to further explore this issue through experiments specifically targeted to the aforementioned aspects (popular culture, user’s memories and interests).</ce:para>""''"'		ANG	
cites	The stories told by exhibits	M. Klingemann, S. Doury, X degrees of separation: the hidden paths through culture , Google Arts Cult. Exp. (2016)	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b13	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0010		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0074	'Google11Google Inc. - http://google.com.has experimented with the notion of x degrees of separation of items in museum collections based on their visual similarity [13[[ refid=''b13'' ]]], but we find the semantic notion of x degrees of separation far more stimulating.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p18"""">For example, regarding the presentation of its own information, it is now possible for the exhibit “The 3rd of May 1808 in Madrid” to present to us all the information that could not be displayed in its small accompanying label. However, the full potential of the exhiSTORY system stems from the fact that having access to the full context and semantic information of the exhibits opens up great opportunities, which could be focused on looking for connections between them. Google<ce:cross-ref refid=""""fn1"""" id=""""d1e727""""><ce:sup loc=""""post"""">1</ce:sup></ce:cross-ref><ce:footnote id=""""fn1""""><ce:label>1</ce:label><ce:note-para view=""""all"""" id=""""d1e734"""">Google Inc. - <ce:inter-ref id=""""interref1"""" xlink:href=""""http://google.com"""" xlink:type=""""simple"""">http://google.com</ce:inter-ref>.</ce:note-para></ce:footnote>has experimented with the notion of x degrees of separation of items in museum collections based on their visual similarity [<ce:cross-ref refid=""""b13"""" id=""""d1e740"""">13[[ refid=''''b13'''' ]]</ce:cross-ref>], but we find the <ce:bold>semantic</ce:bold> notion of x degrees of separation far more stimulating. In this notion, we suggest that given any pair of items we can find meaningful links between them with a reasonably small number of steps that go through facts related not only to history or art, but also to popular culture and any available information about the target user’s memories and interests; experiments reported in [<ce:cross-ref refid=""""b14"""" id=""""d1e746"""">14[[ refid=''''b14'''' ]]</ce:cross-ref>] provide evidence that user-specific intermediate entities can be used as elements of the path linking two nodes in a semantic network, and we plan to further explore this issue through experiments specifically targeted to the aforementioned aspects (popular culture, user’s memories and interests).</ce:para>""''"'		ANG	
cites	The stories told by exhibits	C. Rocchi, O. Stock, M. Zancanaro, M. Kruppa, A. Kruger, The museum visit: generating seamless personalized presentations on multiple devices , Proceedings of the 9th International Conference on Intelligent User Interfaces, Funchal, Madeira, Portugal, January 2004, IUI ’04, ACM (2004)	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b25	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0017		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0075	'The documentary-like content also adapted to the interests of the user [25[[ refid=''b25'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p23"""">The need to go beyond a single narration has been recognized in recent years and there have been certain attempts to present multiple views to visitors. For example, in the “PEACH” project mobile devices were also used. This particular project is worth mentioning due to its special design, using cinematic techniques in order to create a feeling of personalized TV. The documentary-like content also adapted to the interests of the user [<ce:cross-ref refid=""""b25"""" id=""""d1e787"""">25[[ refid=''''b25'''' ]]</ce:cross-ref>]. Another known systems is “HIPS” (Hyper-Interaction within Physical Space), a hypermedia system supporting mobile presentation of museum and historical information. Tourists and museum visitors were equipped with a hand-held device which provides electronic tours. Tourists’ positions were detected and auditory information was personalized and context depended [<ce:cross-ref refid=""""b26"""" id=""""d1e790"""">26[[ refid=''''b26'''' ]]</ce:cross-ref>]. The main principle of the application was that information is context depended and thus, it should be presented in different ways [<ce:cross-ref refid=""""b9"""" id=""""d1e793"""">9[[ refid=''''b9'''' ]]</ce:cross-ref>]. The environment became an interface and the visitor’s movements became a form of input to the system. The system could spot a novice visitor from her movements and support her during the visit. HIPS assumed that different visiting styles need different durations for the presentations and the empirical data support this hypothesis [<ce:cross-ref refid=""""b27"""" id=""""d1e796"""">27[[ refid=''''b27'''' ]]</ce:cross-ref>]. HIPS was using infrared emitters to connect to the users devices (PDAs) [<ce:cross-ref refid=""""b28"""" id=""""d1e799"""">28[[ refid=''''b28'''' ]]</ce:cross-ref>]. Finally, user testing and evaluation showed that all users liked the idea of receiving information related to their movement. In addition, in the experimental cases where the visiting style was matched to appropriate content, the users demonstrated increased interest by requesting more information about the exhibits explicitly [<ce:cross-ref refid=""""b28"""" id=""""d1e803"""">28[[ refid=''''b28'''' ]]</ce:cross-ref>].</ce:para>""''"'		ANG	
cites	The stories told by exhibits	C. Callaway, E. Not, A. Novello, C. Rocchi, O. Stock, M. Zancanaro, Automatic cinematography and multilingual NLG for generating video documentaries , Artif. Intell. , vol. 165 (2005), pp.57-89	http://dx.doi.org/10.1016/j.future.2017.10.038			http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b19	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0014		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0081	'Additionally, semantic information can be exploited to automatically generate documentaries as described in [19[[ refid=''b19'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p19"""">Once the semantic links that connect the items in a room have been found, each item can adjust the way it presents itself in order to form a part of an overall story that can be told, having also the potential for formulation of multiple stories, which are available to visitors to select among, according to their preferences and personality. This way a much richer experience is offered to the visitor; one that goes far beyond the basic level of information visitors usually receive. For example, if the painting “The 3rd of May 1808 in Madrid” is found in the same room with the painting “Napoleon Crossing the Alps” by Jacques-Louis David [<ce:cross-ref refid=""""b15"""" id=""""d1e751"""">15[[ refid=''''b15'''' ]]</ce:cross-ref>], these paintings could together tell a story about the Napoleonic wars, while if the same painting was found in the same room with Guernica by Picasso [<ce:cross-ref refid=""""b16"""" id=""""d1e754"""">16[[ refid=''''b16'''' ]]</ce:cross-ref>], these paintings could tell a story about the horrors of war, as well as a story about Spanish painters. The semantic information can be used also to reveal more unexpected connections, leveraging serendipity and stimulating curiosity: for example, the central figure in “The 3rd of May 1808 in Madrid” has his hands stretched out, a body position commonly found in depictions of martyrdom, such as the Crucifix (c.f. [<ce:cross-ref refid=""""b17"""" id=""""d1e757"""">17[[ refid=''''b17'''' ]]</ce:cross-ref>]) or the Martyrdom of St Philip [<ce:cross-ref refid=""""b18"""" id=""""d1e760"""">18[[ refid=''''b18'''' ]]</ce:cross-ref>]. Additionally, semantic information can be exploited to automatically generate documentaries as described in [<ce:cross-ref refid=""""b19"""" id=""""d1e763"""">19[[ refid=''''b19'''' ]]</ce:cross-ref>].</ce:para>""''"'		ANG	
cites	Related work	F. McDermott, L. Maye, G. Avram, Co-designing a collaborative platform with cultural heritage professionals, in: Proceedings of iHCI 2014, 1-2 September 2014, Dublin, 2014, pp. 18–26.	http://dx.doi.org/10.1016/j.future.2017.10.038	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b69	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0063		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0085	'Particularly “smart exhibit” has been used before in the literature to refer to exhibits that are handled by a system in a smart way [69[[ refid=''b69'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p115"""">Some of the terms used in the works mentioned above are used again in this paper. Their meaning is different, though, as they are redefined in a broader way. Particularly “smart exhibit” has been used before in the literature to refer to exhibits that are handled by a system in a smart way [<ce:cross-ref refid=""""b69"""" id=""""d1e1541"""">69[[ refid=''''b69'''' ]]</ce:cross-ref>]. Herein we use it to indicate exhibits are not merely passive artifacts but rather active members of the smart environment, a meaning that we feel is closer to what “smart” has come to mean in computing.</ce:para>""''"'		ANG	
cites	Related work	A. Hudson-Smith, S. Gray, C. Ross, R. Barthel, M.de. Jode, C. Warwick, M. Terras, Experiments with the internet of things in museum space: QRator , Proceedings of the 2012 ACM Conference on Ubiquitous Computing, UbiComp ’12, ACM (2012)	http://dx.doi.org/10.1016/j.future.2017.10.038	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/br/b58	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/ctx/ctx0055		63	7	http://www.scar.disi.unibo.it/r/10-1016-j-future-2017-10-038/itrp/0086	'Internet linked interactive museum item labels were used to construct narratives and increase visitor engagement [58[[ refid=''b58'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p112"""">Mobility is an important aspect of cultural heritage visits, since visitors usually move around the cultural space [<ce:cross-ref refid=""""b55"""" id=""""d1e1487"""">55[[ refid=''''b55'''' ]]</ce:cross-ref>]. IoT research is coupled with mobile devices as a way to assist people in their everyday lives. Current research is focusing on unique ways to interact with appliances in the surrounding environment with the user’s mobile devices [<ce:cross-ref refid=""""b56"""" id=""""d1e1490"""">56[[ refid=''''b56'''' ]]</ce:cross-ref>]. Particularly in regards to assisting people’s everyday life, IoT and mobile applications can be viewed within the framework of smart cities which can assist people in discovering resources and exploiting technology infrastructure [<ce:cross-ref refid=""""b57"""" id=""""d1e1493"""">57[[ refid=''''b57'''' ]]</ce:cross-ref>]. One of the most known and award wining works regarding IoT, mobility and cultural heritage was the QRator project applied at the UCL Grant museum of Zoology. Internet linked interactive museum item labels were used to construct narratives and increase visitor engagement [<ce:cross-ref refid=""""b58"""" id=""""d1e1496"""">58[[ refid=''''b58'''' ]]</ce:cross-ref>].</ce:para>""''"'		ANG	
cites	Related works	S.Y. Yerima, S. Sezer, G. McWilliams, I. Muttik, A new android malware detection approach using bayesian classification , 2013 IEEE 27th International Conference on Advanced Information Networking and Applications, IEEE (2013)	http://dx.doi.org/10.1016/j.future.2018.02.001	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/br/b29	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/ctx/ctx0025		46	4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/itrp/0010	'A recent work developed feature detectors to match and extract various static features such as API calls, Linux system commands, and manifest’s permissions [29[[ refid=''b29'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p23"""">A recent work developed feature detectors to match and extract various static features such as API calls, Linux system commands, and manifest’s permissions [<ce:cross-ref refid=""""b29"""" id=""""d1e2719"""">29[[ refid=''''b29'''' ]]</ce:cross-ref>]. Authors used Boolean mapping function (<mml:math id=""""mml22"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si22.gif""""><mml:mn>1</mml:mn></mml:math> if a feature is present <mml:math id=""""mml23"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si23.gif""""><mml:mn>0</mml:mn></mml:math> otherwise) to create a dataset and used Bayesian classification. With <mml:math id=""""mml24"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si24.gif""""><mml:mn>1600</mml:mn></mml:math> samples, the aforementioned method was able to achieve an accuracy of about <mml:math id=""""mml25"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si25.gif""""><mml:mn>92</mml:mn><mml:mtext>%</mml:mtext></mml:math> and AUC of <mml:math id=""""mml26"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si26.gif""""><mml:mn>97</mml:mn><mml:mtext>%</mml:mtext></mml:math>. Similarly, another work used permission with API calls and the combination of these two as the feature set and trained SVM, J48 and Bagging machine learning based method then built different classifiers and achieved best results with permission and API call combined feature set [<ce:cross-ref refid=""""b30"""" id=""""d1e2752"""">30[[ refid=''''b30'''' ]]</ce:cross-ref>]. MAMA [<ce:cross-ref refid=""""b17"""" id=""""d1e2755"""">17[[ refid=''''b17'''' ]]</ce:cross-ref>] had presented an analysis of Manifest file for Android malware detection and created three sets of features by extracting values from different elements of the manifest file. These three feature sets were used to train four machine learning algorithms (KNN, Decision Tree, Bayesian tree, and SVM) with different algorithmic configuration. On <ce:italic>permissions and features combined</ce:italic> feature set with Random forest (100 trees) authors achieved an accuracy of <mml:math id=""""mml27"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si27.gif""""><mml:mn>94</mml:mn><mml:mo>.</mml:mo><mml:mn>83</mml:mn><mml:mtext>%</mml:mtext></mml:math>, which is about <mml:math id=""""mml28"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si28.gif""""><mml:mn>10</mml:mn><mml:mtext>%</mml:mtext></mml:math> better than two other feature set which are <ce:italic>permissions</ce:italic> and <ce:italic>feature-only</ce:italic> [<ce:cross-ref refid=""""b17"""" id=""""d1e2786"""">17[[ refid=''''b17'''' ]]</ce:cross-ref>]. PUMA [<ce:cross-ref refid=""""b8"""" id=""""d1e2790"""">8[[ refid=''''b8'''' ]]</ce:cross-ref>], is an Android malware detector which uses <ce:italic>permission</ce:italic> and <ce:italic>uses-feature</ce:italic> of an application as feature set to train machine learning algorithms. Authors have achieved an accuracy of <mml:math id=""""mml29"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si29.gif""""><mml:mn>87</mml:mn><mml:mtext>%</mml:mtext></mml:math> and 0.19 FPR with Random Forest (100 trees). An Android malware classification framework to manage big app market was proposed, which used 11 different types of static features and ensemble of various learners [<ce:cross-ref refid=""""b19"""" id=""""d1e2806"""">19[[ refid=''''b19'''' ]]</ce:cross-ref>]. Authors achieved the best accuracy of <mml:math id=""""mml30"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si10.gif""""><mml:mn>99</mml:mn><mml:mo>.</mml:mo><mml:mn>39</mml:mn><mml:mtext>%</mml:mtext></mml:math> for malapps detection whereas <mml:math id=""""mml31"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si11.gif""""><mml:mn>82</mml:mn><mml:mo>.</mml:mo><mml:mn>93</mml:mn><mml:mtext>%</mml:mtext></mml:math> accuracy for benign apps detection. In a recent work, permissions and source code analysis based feature set were used to classify apps into malicious and benign using machine learning [<ce:cross-ref refid=""""b27"""" id=""""d1e2832"""">27[[ refid=''''b27'''' ]]</ce:cross-ref>]. With permission-based feature set and ensemble learning best result i.e. F-score <mml:math id=""""mml32"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si32.gif""""><mml:mn>89</mml:mn><mml:mo>.</mml:mo><mml:mn>4</mml:mn><mml:mtext>%</mml:mtext></mml:math> were achieved. PIndroid [<ce:cross-ref refid=""""b28"""" id=""""d1e2846"""">28[[ refid=''''b28'''' ]]</ce:cross-ref>], used permissions and intents to train ensemble learner and achieved <mml:math id=""""mml33"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si33.gif""""><mml:mn>99</mml:mn><mml:mo>.</mml:mo><mml:mn>8</mml:mn><mml:mtext>%</mml:mtext></mml:math> accuracy.</ce:para>""''"'		ANG	
cites	Related works	B. Sanz, I. Santos, C. Laorden, X. Ugarte-Pedrero, P.G. Bringas, G. Álvarez, Puma: Permission usage to detect malware in android , International Joint Conference CISIS12-ICEUTÉ 12-SOCÓ 12 Special Sessions, Springer (2013)	http://dx.doi.org/10.1016/j.future.2018.02.001	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/br/b8	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/ctx/ctx0029		46	4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/itrp/0012	'PUMA [8[[ refid=''b8'' ]]], is an Android malware detector which uses permission and uses-feature of an application as feature set to train machine learning algorithms.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p23"""">A recent work developed feature detectors to match and extract various static features such as API calls, Linux system commands, and manifest’s permissions [<ce:cross-ref refid=""""b29"""" id=""""d1e2719"""">29[[ refid=''''b29'''' ]]</ce:cross-ref>]. Authors used Boolean mapping function (<mml:math id=""""mml22"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si22.gif""""><mml:mn>1</mml:mn></mml:math> if a feature is present <mml:math id=""""mml23"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si23.gif""""><mml:mn>0</mml:mn></mml:math> otherwise) to create a dataset and used Bayesian classification. With <mml:math id=""""mml24"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si24.gif""""><mml:mn>1600</mml:mn></mml:math> samples, the aforementioned method was able to achieve an accuracy of about <mml:math id=""""mml25"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si25.gif""""><mml:mn>92</mml:mn><mml:mtext>%</mml:mtext></mml:math> and AUC of <mml:math id=""""mml26"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si26.gif""""><mml:mn>97</mml:mn><mml:mtext>%</mml:mtext></mml:math>. Similarly, another work used permission with API calls and the combination of these two as the feature set and trained SVM, J48 and Bagging machine learning based method then built different classifiers and achieved best results with permission and API call combined feature set [<ce:cross-ref refid=""""b30"""" id=""""d1e2752"""">30[[ refid=''''b30'''' ]]</ce:cross-ref>]. MAMA [<ce:cross-ref refid=""""b17"""" id=""""d1e2755"""">17[[ refid=''''b17'''' ]]</ce:cross-ref>] had presented an analysis of Manifest file for Android malware detection and created three sets of features by extracting values from different elements of the manifest file. These three feature sets were used to train four machine learning algorithms (KNN, Decision Tree, Bayesian tree, and SVM) with different algorithmic configuration. On <ce:italic>permissions and features combined</ce:italic> feature set with Random forest (100 trees) authors achieved an accuracy of <mml:math id=""""mml27"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si27.gif""""><mml:mn>94</mml:mn><mml:mo>.</mml:mo><mml:mn>83</mml:mn><mml:mtext>%</mml:mtext></mml:math>, which is about <mml:math id=""""mml28"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si28.gif""""><mml:mn>10</mml:mn><mml:mtext>%</mml:mtext></mml:math> better than two other feature set which are <ce:italic>permissions</ce:italic> and <ce:italic>feature-only</ce:italic> [<ce:cross-ref refid=""""b17"""" id=""""d1e2786"""">17[[ refid=''''b17'''' ]]</ce:cross-ref>]. PUMA [<ce:cross-ref refid=""""b8"""" id=""""d1e2790"""">8[[ refid=''''b8'''' ]]</ce:cross-ref>], is an Android malware detector which uses <ce:italic>permission</ce:italic> and <ce:italic>uses-feature</ce:italic> of an application as feature set to train machine learning algorithms. Authors have achieved an accuracy of <mml:math id=""""mml29"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si29.gif""""><mml:mn>87</mml:mn><mml:mtext>%</mml:mtext></mml:math> and 0.19 FPR with Random Forest (100 trees). An Android malware classification framework to manage big app market was proposed, which used 11 different types of static features and ensemble of various learners [<ce:cross-ref refid=""""b19"""" id=""""d1e2806"""">19[[ refid=''''b19'''' ]]</ce:cross-ref>]. Authors achieved the best accuracy of <mml:math id=""""mml30"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si10.gif""""><mml:mn>99</mml:mn><mml:mo>.</mml:mo><mml:mn>39</mml:mn><mml:mtext>%</mml:mtext></mml:math> for malapps detection whereas <mml:math id=""""mml31"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si11.gif""""><mml:mn>82</mml:mn><mml:mo>.</mml:mo><mml:mn>93</mml:mn><mml:mtext>%</mml:mtext></mml:math> accuracy for benign apps detection. In a recent work, permissions and source code analysis based feature set were used to classify apps into malicious and benign using machine learning [<ce:cross-ref refid=""""b27"""" id=""""d1e2832"""">27[[ refid=''''b27'''' ]]</ce:cross-ref>]. With permission-based feature set and ensemble learning best result i.e. F-score <mml:math id=""""mml32"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si32.gif""""><mml:mn>89</mml:mn><mml:mo>.</mml:mo><mml:mn>4</mml:mn><mml:mtext>%</mml:mtext></mml:math> were achieved. PIndroid [<ce:cross-ref refid=""""b28"""" id=""""d1e2846"""">28[[ refid=''''b28'''' ]]</ce:cross-ref>], used permissions and intents to train ensemble learner and achieved <mml:math id=""""mml33"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si33.gif""""><mml:mn>99</mml:mn><mml:mo>.</mml:mo><mml:mn>8</mml:mn><mml:mtext>%</mml:mtext></mml:math> accuracy.</ce:para>""''"'		ANG	
cites	Introduction	S.-H. Seo, A. Gupta, A.M. Sallam, E. Bertino, K. Yim, Detecting mobile malware threats to homeland security through static analysis , J. Netw. Comput. Appl. , vol. 38 (2014), pp.43-53	http://dx.doi.org/10.1016/j.future.2018.02.001	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/br/b21	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/ctx/ctx0008		46	4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/itrp/0013	'DroidAnalyzer is a static analysis tool which identifies potential vulnerabilities of Android apps and the presence of root exploits [21[[ refid=''b21'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p10"""">Many tools are being built to do an effective forensic analysis in recent times. Triaging for Detecting the suspicious application on a mobile device is one of the critical tasks of forensic analysis. DroidAnalyzer is a static analysis tool which identifies potential vulnerabilities of Android apps and the presence of root exploits [<ce:cross-ref refid=""""b21"""" id=""""d1e2454"""">21[[ refid=''''b21'''' ]]</ce:cross-ref>]. Currently, most of the tools use signature-based anti-virus (AV) engines to detect Android malware, which has two following limitations: (a) signature-based antivirus engines are limited to the signature database and represent a reactive security measure; (b) most of AV-engines are built for desktop applications and are extended for mobile devices so they lack in harnessing mobile-specific feature during the detecting process. In this paper, the aforementioned challenges are considered and a new forensic tool termed <ce:italic>FAMOUS</ce:italic> (<ce:bold>F</ce:bold> orensic <ce:bold>A</ce:bold> nalysis of <ce:bold>MO</ce:bold> bile devices <ce:bold>U</ce:bold> sing <ce:bold>S</ce:bold> coring of application permissions) incorporating machine-learning based classifier has been developed. The application’s permissions have been used to build a feature set to train various machine learning algorithms. Previous studies [<ce:cross-refs refid=""""b17 b8 b13"""" id=""""d1e2476"""">17,8,13[[ refid=''''b17 b8 b13'''' ]]</ce:cross-refs>] have represented permissions as the Boolean feature, in which required permissions were represented as 1 and rest were assigned 0. In this work, a permission scoring system based on statistical analysis of benign and malware permissions has been devised. A feature set is built based on the <ce:italic>score</ce:italic> given to each permission.</ce:para>""''"'		ANG	
uses_method_in	Experiments	F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, E. Duchesnay, Scikit-learn: Machine learning in Python , J. Mach. Learn. Res. , vol. 12 (2011), pp.2825-2830	http://dx.doi.org/10.1016/j.future.2018.02.001	methods		http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/br/b45	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/ctx/ctx0046		46	4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/itrp/0017	'Scikit-learn [45[[ refid=''b45'' ]]], a Python library was used for the purpose of machine learning algorithms training and testing.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p53"""">Each class sample was stored separately and was given as input to permission extractor component (Section <ce:cross-ref refid=""""sec3.2.1"""" id=""""d1e4526"""">3.2.1</ce:cross-ref>). MD5 hashes and SHA hashes along with package names were used to identify samples uniquely. Scikit-learn [<ce:cross-ref refid=""""b45"""" id=""""d1e4529"""">45[[ refid=''''b45'''' ]]</ce:cross-ref>], a Python library was used for the purpose of machine learning algorithms training and testing. All the statistical calculation and graph plotting was also done using various Python-based modules. To implement <ce:italic>FAMOUS</ce:italic> as the forensic tool, along with other modules <ce:italic>wxPython</ce:italic> module was used for developing Graphical User Interface (GUI). <ce:display><ce:formula id=""""fd6""""><ce:label>(6)</ce:label><mml:math id=""""mml142"""" display=""""block"""" overflow=""""scroll"""" altimg=""""si142.gif""""><mml:mi>C</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>M</mml:mi><mml:mo>|</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfenced open=""""{"""" close=""""""""><mml:mrow><mml:mtable align=""""axis"""" class=""""array""""><mml:mtr><mml:mtd columnalign=""""left""""><mml:mi>M</mml:mi><mml:mo>,</mml:mo></mml:mtd><mml:mtd columnalign=""""left""""><mml:mi>I</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∨</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∨</mml:mo><mml:mo>…</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign=""""left""""><mml:mi>B</mml:mi><mml:mo>,</mml:mo></mml:mtd><mml:mtd columnalign=""""left""""><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>I</mml:mi><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>!</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∧</mml:mo><mml:mo>!</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∧</mml:mo><mml:mo>…</mml:mo><mml:mo>!</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mfenced></mml:math></ce:formula></ce:display></ce:para>""''"'		ANG	
uses_method_in	Experiments	V. VirusTotal, Virustotal - free online virus, malware and url scanner, 2004. URL	http://dx.doi.org/10.1016/j.future.2018.02.001	methods		http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/br/b43	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/ctx/ctx0041		46	4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/itrp/0019	'All third party applications were verified with VirusTotal [43[[ refid=''b43'' ]]] and we found out that 46 (7%) applications are detected as malware by minimum one antivirus engine.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p48"""">For the purpose of experiment-I, we amalgamated two datasets. In first dataset (dataset-1), we have a total of 11,371 Android applications for the experiment, where dataset have samples from both classes i.e. <mml:math id=""""mml126"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si75.gif""""><mml:mn>5553</mml:mn></mml:math> malware and <mml:math id=""""mml127"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si81.gif""""><mml:mn>5818</mml:mn></mml:math> benign. For this dataset, malware samples were adopted from <ce:italic>DREBIN</ce:italic> project [<ce:cross-ref refid=""""b16"""" id=""""d1e4309"""">16[[ refid=''''b16'''' ]]</ce:cross-ref>] and benign samples were downloaded from <ce:italic>PlayDrone</ce:italic> archive [<ce:cross-ref refid=""""b40"""" id=""""d1e4316"""">40[[ refid=''''b40'''' ]]</ce:cross-ref>]. Second dataset (dataset-2), has total <mml:math id=""""mml128"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si128.gif""""><mml:mn>4317</mml:mn></mml:math> samples, Malware samples were gathered from multiple online public archives such as <ce:italic>Contagio dump</ce:italic> [<ce:cross-ref refid=""""b38"""" id=""""d1e4327"""">38[[ refid=''''b38'''' ]]</ce:cross-ref>], <ce:italic>AndroMalShare</ce:italic> [<ce:cross-ref refid=""""b41"""" id=""""d1e4334"""">41[[ refid=''''b41'''' ]]</ce:cross-ref>] and <ce:italic>Andrototal</ce:italic> [<ce:cross-ref refid=""""b42"""" id=""""d1e4340"""">42[[ refid=''''b42'''' ]]</ce:cross-ref>]. For benign samples we used <ce:italic>PlayDrone</ce:italic> collection [<ce:cross-ref refid=""""b40"""" id=""""d1e4346"""">40[[ refid=''''b40'''' ]]</ce:cross-ref>] which has a sorted list of Google Play apks based on download count. We downloaded top <mml:math id=""""mml129"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si129.gif""""><mml:mn>999</mml:mn></mml:math> and bottom <mml:math id=""""mml130"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si130.gif""""><mml:mn>979</mml:mn></mml:math> application from sorted list by pipelining Linux’s <ce:italic>head</ce:italic> and <ce:italic>tail</ce:italic> output to <ce:italic>grep</ce:italic> and <ce:italic>wget</ce:italic> respectively. Along with this we also collected <mml:math id=""""mml131"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si131.gif""""><mml:mn>755</mml:mn></mml:math> samples from different third-party app stores and a torrent collection<ce:cross-ref refid=""""fn7"""" id=""""d1e4378""""><ce:sup loc=""""post"""">7</ce:sup></ce:cross-ref><ce:footnote id=""""fn7""""><ce:label>7</ce:label><ce:note-para view=""""all"""" id=""""d1e4385""""><ce:inter-ref id=""""interref8"""" xlink:role=""""http://www.elsevier.com/xml/linking-roles/text/html"""" xlink:href=""""https://kat.cr/1380-paid-android-apps-and-games-apk-t5344319.html"""" xlink:type=""""simple"""">https://kat.cr/1380-paid-android-apps-and-games-apk-t5344319.html</ce:inter-ref>.</ce:note-para></ce:footnote>of <mml:math id=""""mml132"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si132.gif""""><mml:mn>1380</mml:mn></mml:math> Google Play’s paid apps and games. <ce:cross-ref refid=""""tbl4"""" id=""""d1e4396"""">Table 4</ce:cross-ref> illustrates the source and various categories of benign samples. All third party applications were verified with VirusTotal [<ce:cross-ref refid=""""b43"""" id=""""d1e4399"""">43[[ refid=''''b43'''' ]]</ce:cross-ref>] and we found out that <mml:math id=""""mml133"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si133.gif""""><mml:mn>46</mml:mn></mml:math> (<mml:math id=""""mml134"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si134.gif""""><mml:mn>7</mml:mn><mml:mtext>%</mml:mtext></mml:math>) applications are detected as malware by minimum one antivirus engine. We have used the MD5 hash to get the scan report and hence <mml:math id=""""mml135"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si135.gif""""><mml:mn>130</mml:mn></mml:math> applications do not have scanned result which was eliminated along with malicious applications from our dataset and we ended up with a total of <mml:math id=""""mml136"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si136.gif""""><mml:mn>587</mml:mn></mml:math> third-party applications in the benign dataset. Likewise, all the samples in both datasets were scanned with VirusTotal [<ce:cross-ref refid=""""b43"""" id=""""d1e4425"""">43[[ refid=''''b43'''' ]]</ce:cross-ref>] and the proper class label was given accordingly. Duplicate samples in dataset would skew the accuracy of the experiment, hence we removed duplicate samples by using MD5 hash and package name and only keep the unique samples in each dataset and each category. Dataset-1 was used for scoring, feature set generation and training whereas dataset-2 was only used for testing. It was made sure that samples present in dataset-2 are not available in dataset-1 and hence it is not used for score calculation. This separation represents the real-world scenario where new apps appear with new permission patterns.</ce:para>""''"'		ANG	
cites_as_review	Related works	F. Tchakounté, Permission-based malware detection mechanisms on android: Analysis and perspectives , J. Comput. Sci. , vol. 1 (2014), pp.None	http://dx.doi.org/10.1016/j.future.2018.02.001	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/br/b39	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/ctx/ctx0036		46	4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/itrp/0050	'A summarized report on permission-based Android Malware detection techniques has presented in [39[[ refid=''b39'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p24"""">Apk Evaluator [<ce:cross-ref refid=""""b32"""" id=""""d1e2863"""">32[[ refid=''''b32'''' ]]</ce:cross-ref>] is a permission-based classification system for the Android application. In training phase, it uses static analysis techniques to build a permissions-based signature database which is used to characterize profile for Android applications in the evaluation phase. Apk Evaluator [<ce:cross-ref refid=""""b32"""" id=""""d1e2866"""">32[[ refid=''''b32'''' ]]</ce:cross-ref>] is trained, analyzed and tested with <mml:math id=""""mml34"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si34.gif""""><mml:mn>1853</mml:mn></mml:math> benign samples collected from Google’s Play Store and <mml:math id=""""mml35"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si35.gif""""><mml:mn>6909</mml:mn></mml:math> malicious applications which were collected from different sources [<ce:cross-refs refid=""""b16 b1 b38"""" id=""""d1e2880"""">16,1,38[[ refid=''''b16 b1 b38'''' ]]</ce:cross-refs>]. With experimental results, authors have claimed approximately <mml:math id=""""mml36"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si36.gif""""><mml:mn>88</mml:mn><mml:mtext>%</mml:mtext></mml:math> accuracy with a 0.925 specificity. MAETROID [<ce:cross-ref refid=""""b33"""" id=""""d1e2890"""">33[[ refid=''''b33'''' ]]</ce:cross-ref>] uses the set of requested permissions and a set of metadata retrieved from the marketplace to analyze an app and provides the app’s risk level. A summarized report on permission-based Android Malware detection techniques has presented in [<ce:cross-ref refid=""""b39"""" id=""""d1e2893"""">39[[ refid=''''b39'''' ]]</ce:cross-ref>]. In the same work, the author has discussed various limitations of previous works and pointed out many issues with earlier techniques such as many of these works focused only on <ce:italic>the most requested</ce:italic> permission instead of considering every permission potentially risky, availability of malware samples, failure of machine learning techniques against mimicry and poisoning attacks, unable to work against obfuscation strategies and computation overhead and inefficiency of the solution due to more number of features extraction from the manifest.</ce:para>""''"'		ANG	
cites	Related works	N. Milosevic, A. Dehghantanha, K.-K.R. Choo, Machine learning aided Android malware classification , Comput. Electr. Eng. (2017)	http://dx.doi.org/10.1016/j.future.2018.02.001	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/br/b27	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/ctx/ctx0031		46	4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/itrp/0051	'In a recent work, permissions and source code analysis based feature set were used to classify apps into malicious and benign using machine learning [27[[ refid=''b27'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p23"""">A recent work developed feature detectors to match and extract various static features such as API calls, Linux system commands, and manifest’s permissions [<ce:cross-ref refid=""""b29"""" id=""""d1e2719"""">29[[ refid=''''b29'''' ]]</ce:cross-ref>]. Authors used Boolean mapping function (<mml:math id=""""mml22"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si22.gif""""><mml:mn>1</mml:mn></mml:math> if a feature is present <mml:math id=""""mml23"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si23.gif""""><mml:mn>0</mml:mn></mml:math> otherwise) to create a dataset and used Bayesian classification. With <mml:math id=""""mml24"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si24.gif""""><mml:mn>1600</mml:mn></mml:math> samples, the aforementioned method was able to achieve an accuracy of about <mml:math id=""""mml25"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si25.gif""""><mml:mn>92</mml:mn><mml:mtext>%</mml:mtext></mml:math> and AUC of <mml:math id=""""mml26"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si26.gif""""><mml:mn>97</mml:mn><mml:mtext>%</mml:mtext></mml:math>. Similarly, another work used permission with API calls and the combination of these two as the feature set and trained SVM, J48 and Bagging machine learning based method then built different classifiers and achieved best results with permission and API call combined feature set [<ce:cross-ref refid=""""b30"""" id=""""d1e2752"""">30[[ refid=''''b30'''' ]]</ce:cross-ref>]. MAMA [<ce:cross-ref refid=""""b17"""" id=""""d1e2755"""">17[[ refid=''''b17'''' ]]</ce:cross-ref>] had presented an analysis of Manifest file for Android malware detection and created three sets of features by extracting values from different elements of the manifest file. These three feature sets were used to train four machine learning algorithms (KNN, Decision Tree, Bayesian tree, and SVM) with different algorithmic configuration. On <ce:italic>permissions and features combined</ce:italic> feature set with Random forest (100 trees) authors achieved an accuracy of <mml:math id=""""mml27"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si27.gif""""><mml:mn>94</mml:mn><mml:mo>.</mml:mo><mml:mn>83</mml:mn><mml:mtext>%</mml:mtext></mml:math>, which is about <mml:math id=""""mml28"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si28.gif""""><mml:mn>10</mml:mn><mml:mtext>%</mml:mtext></mml:math> better than two other feature set which are <ce:italic>permissions</ce:italic> and <ce:italic>feature-only</ce:italic> [<ce:cross-ref refid=""""b17"""" id=""""d1e2786"""">17[[ refid=''''b17'''' ]]</ce:cross-ref>]. PUMA [<ce:cross-ref refid=""""b8"""" id=""""d1e2790"""">8[[ refid=''''b8'''' ]]</ce:cross-ref>], is an Android malware detector which uses <ce:italic>permission</ce:italic> and <ce:italic>uses-feature</ce:italic> of an application as feature set to train machine learning algorithms. Authors have achieved an accuracy of <mml:math id=""""mml29"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si29.gif""""><mml:mn>87</mml:mn><mml:mtext>%</mml:mtext></mml:math> and 0.19 FPR with Random Forest (100 trees). An Android malware classification framework to manage big app market was proposed, which used 11 different types of static features and ensemble of various learners [<ce:cross-ref refid=""""b19"""" id=""""d1e2806"""">19[[ refid=''''b19'''' ]]</ce:cross-ref>]. Authors achieved the best accuracy of <mml:math id=""""mml30"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si10.gif""""><mml:mn>99</mml:mn><mml:mo>.</mml:mo><mml:mn>39</mml:mn><mml:mtext>%</mml:mtext></mml:math> for malapps detection whereas <mml:math id=""""mml31"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si11.gif""""><mml:mn>82</mml:mn><mml:mo>.</mml:mo><mml:mn>93</mml:mn><mml:mtext>%</mml:mtext></mml:math> accuracy for benign apps detection. In a recent work, permissions and source code analysis based feature set were used to classify apps into malicious and benign using machine learning [<ce:cross-ref refid=""""b27"""" id=""""d1e2832"""">27[[ refid=''''b27'''' ]]</ce:cross-ref>]. With permission-based feature set and ensemble learning best result i.e. F-score <mml:math id=""""mml32"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si32.gif""""><mml:mn>89</mml:mn><mml:mo>.</mml:mo><mml:mn>4</mml:mn><mml:mtext>%</mml:mtext></mml:math> were achieved. PIndroid [<ce:cross-ref refid=""""b28"""" id=""""d1e2846"""">28[[ refid=''''b28'''' ]]</ce:cross-ref>], used permissions and intents to train ensemble learner and achieved <mml:math id=""""mml33"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si33.gif""""><mml:mn>99</mml:mn><mml:mo>.</mml:mo><mml:mn>8</mml:mn><mml:mtext>%</mml:mtext></mml:math> accuracy.</ce:para>""''"'		ANG	
cites	Related works	W. Wang, Y. Li, X. Wang, J. Liu, X. Zhang, Detecting android malicious apps and categorizing benign apps with ensemble of classifiers , Future Gener. Comput. Syst. (2017)	http://dx.doi.org/10.1016/j.future.2018.02.001	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/br/b19	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/ctx/ctx0030		46	4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/itrp/0052	'An Android malware classification framework to manage big app market was proposed, which used 11 different types of static features and ensemble of various learners [19[[ refid=''b19'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p23"""">A recent work developed feature detectors to match and extract various static features such as API calls, Linux system commands, and manifest’s permissions [<ce:cross-ref refid=""""b29"""" id=""""d1e2719"""">29[[ refid=''''b29'''' ]]</ce:cross-ref>]. Authors used Boolean mapping function (<mml:math id=""""mml22"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si22.gif""""><mml:mn>1</mml:mn></mml:math> if a feature is present <mml:math id=""""mml23"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si23.gif""""><mml:mn>0</mml:mn></mml:math> otherwise) to create a dataset and used Bayesian classification. With <mml:math id=""""mml24"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si24.gif""""><mml:mn>1600</mml:mn></mml:math> samples, the aforementioned method was able to achieve an accuracy of about <mml:math id=""""mml25"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si25.gif""""><mml:mn>92</mml:mn><mml:mtext>%</mml:mtext></mml:math> and AUC of <mml:math id=""""mml26"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si26.gif""""><mml:mn>97</mml:mn><mml:mtext>%</mml:mtext></mml:math>. Similarly, another work used permission with API calls and the combination of these two as the feature set and trained SVM, J48 and Bagging machine learning based method then built different classifiers and achieved best results with permission and API call combined feature set [<ce:cross-ref refid=""""b30"""" id=""""d1e2752"""">30[[ refid=''''b30'''' ]]</ce:cross-ref>]. MAMA [<ce:cross-ref refid=""""b17"""" id=""""d1e2755"""">17[[ refid=''''b17'''' ]]</ce:cross-ref>] had presented an analysis of Manifest file for Android malware detection and created three sets of features by extracting values from different elements of the manifest file. These three feature sets were used to train four machine learning algorithms (KNN, Decision Tree, Bayesian tree, and SVM) with different algorithmic configuration. On <ce:italic>permissions and features combined</ce:italic> feature set with Random forest (100 trees) authors achieved an accuracy of <mml:math id=""""mml27"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si27.gif""""><mml:mn>94</mml:mn><mml:mo>.</mml:mo><mml:mn>83</mml:mn><mml:mtext>%</mml:mtext></mml:math>, which is about <mml:math id=""""mml28"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si28.gif""""><mml:mn>10</mml:mn><mml:mtext>%</mml:mtext></mml:math> better than two other feature set which are <ce:italic>permissions</ce:italic> and <ce:italic>feature-only</ce:italic> [<ce:cross-ref refid=""""b17"""" id=""""d1e2786"""">17[[ refid=''''b17'''' ]]</ce:cross-ref>]. PUMA [<ce:cross-ref refid=""""b8"""" id=""""d1e2790"""">8[[ refid=''''b8'''' ]]</ce:cross-ref>], is an Android malware detector which uses <ce:italic>permission</ce:italic> and <ce:italic>uses-feature</ce:italic> of an application as feature set to train machine learning algorithms. Authors have achieved an accuracy of <mml:math id=""""mml29"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si29.gif""""><mml:mn>87</mml:mn><mml:mtext>%</mml:mtext></mml:math> and 0.19 FPR with Random Forest (100 trees). An Android malware classification framework to manage big app market was proposed, which used 11 different types of static features and ensemble of various learners [<ce:cross-ref refid=""""b19"""" id=""""d1e2806"""">19[[ refid=''''b19'''' ]]</ce:cross-ref>]. Authors achieved the best accuracy of <mml:math id=""""mml30"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si10.gif""""><mml:mn>99</mml:mn><mml:mo>.</mml:mo><mml:mn>39</mml:mn><mml:mtext>%</mml:mtext></mml:math> for malapps detection whereas <mml:math id=""""mml31"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si11.gif""""><mml:mn>82</mml:mn><mml:mo>.</mml:mo><mml:mn>93</mml:mn><mml:mtext>%</mml:mtext></mml:math> accuracy for benign apps detection. In a recent work, permissions and source code analysis based feature set were used to classify apps into malicious and benign using machine learning [<ce:cross-ref refid=""""b27"""" id=""""d1e2832"""">27[[ refid=''''b27'''' ]]</ce:cross-ref>]. With permission-based feature set and ensemble learning best result i.e. F-score <mml:math id=""""mml32"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si32.gif""""><mml:mn>89</mml:mn><mml:mo>.</mml:mo><mml:mn>4</mml:mn><mml:mtext>%</mml:mtext></mml:math> were achieved. PIndroid [<ce:cross-ref refid=""""b28"""" id=""""d1e2846"""">28[[ refid=''''b28'''' ]]</ce:cross-ref>], used permissions and intents to train ensemble learner and achieved <mml:math id=""""mml33"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si33.gif""""><mml:mn>99</mml:mn><mml:mo>.</mml:mo><mml:mn>8</mml:mn><mml:mtext>%</mml:mtext></mml:math> accuracy.</ce:para>""''"'		ANG	
cites	Related works	K.A. Talha, D.I. Alper, C. Aydin, Apk auditor: Permission-based android malware detection system , Digit. Investig. , vol. 13 (2015), pp.1-14	http://dx.doi.org/10.1016/j.future.2018.02.001	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/br/b32	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/ctx/ctx0033		46	4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/itrp/0053	'Apk Evaluator [32[[ refid=''b32'' ]]] is a permission-based classification system for the Android application.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p24"""">Apk Evaluator [<ce:cross-ref refid=""""b32"""" id=""""d1e2863"""">32[[ refid=''''b32'''' ]]</ce:cross-ref>] is a permission-based classification system for the Android application. In training phase, it uses static analysis techniques to build a permissions-based signature database which is used to characterize profile for Android applications in the evaluation phase. Apk Evaluator [<ce:cross-ref refid=""""b32"""" id=""""d1e2866"""">32[[ refid=''''b32'''' ]]</ce:cross-ref>] is trained, analyzed and tested with <mml:math id=""""mml34"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si34.gif""""><mml:mn>1853</mml:mn></mml:math> benign samples collected from Google’s Play Store and <mml:math id=""""mml35"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si35.gif""""><mml:mn>6909</mml:mn></mml:math> malicious applications which were collected from different sources [<ce:cross-refs refid=""""b16 b1 b38"""" id=""""d1e2880"""">16,1,38[[ refid=''''b16 b1 b38'''' ]]</ce:cross-refs>]. With experimental results, authors have claimed approximately <mml:math id=""""mml36"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si36.gif""""><mml:mn>88</mml:mn><mml:mtext>%</mml:mtext></mml:math> accuracy with a 0.925 specificity. MAETROID [<ce:cross-ref refid=""""b33"""" id=""""d1e2890"""">33[[ refid=''''b33'''' ]]</ce:cross-ref>] uses the set of requested permissions and a set of metadata retrieved from the marketplace to analyze an app and provides the app’s risk level. A summarized report on permission-based Android Malware detection techniques has presented in [<ce:cross-ref refid=""""b39"""" id=""""d1e2893"""">39[[ refid=''''b39'''' ]]</ce:cross-ref>]. In the same work, the author has discussed various limitations of previous works and pointed out many issues with earlier techniques such as many of these works focused only on <ce:italic>the most requested</ce:italic> permission instead of considering every permission potentially risky, availability of malware samples, failure of machine learning techniques against mimicry and poisoning attacks, unable to work against obfuscation strategies and computation overhead and inefficiency of the solution due to more number of features extraction from the manifest.</ce:para>""''"'		ANG	
cites	Related works	F. Idrees, M. Rajarajan, M. Conti, T.M. Chen, Y. Rahulamathavan, Pindroid: A novel android malware detection system using ensemble learning methods , Comput. Secur. , vol. 68 (2017), pp.36-46	http://dx.doi.org/10.1016/j.future.2018.02.001	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/br/b28	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/ctx/ctx0032		46	4	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-02-001/itrp/0054	'PIndroid [28[[ refid=''b28'' ]]], used permissions and intents to train ensemble learner and achieved 99.8% accuracy.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p23"""">A recent work developed feature detectors to match and extract various static features such as API calls, Linux system commands, and manifest’s permissions [<ce:cross-ref refid=""""b29"""" id=""""d1e2719"""">29[[ refid=''''b29'''' ]]</ce:cross-ref>]. Authors used Boolean mapping function (<mml:math id=""""mml22"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si22.gif""""><mml:mn>1</mml:mn></mml:math> if a feature is present <mml:math id=""""mml23"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si23.gif""""><mml:mn>0</mml:mn></mml:math> otherwise) to create a dataset and used Bayesian classification. With <mml:math id=""""mml24"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si24.gif""""><mml:mn>1600</mml:mn></mml:math> samples, the aforementioned method was able to achieve an accuracy of about <mml:math id=""""mml25"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si25.gif""""><mml:mn>92</mml:mn><mml:mtext>%</mml:mtext></mml:math> and AUC of <mml:math id=""""mml26"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si26.gif""""><mml:mn>97</mml:mn><mml:mtext>%</mml:mtext></mml:math>. Similarly, another work used permission with API calls and the combination of these two as the feature set and trained SVM, J48 and Bagging machine learning based method then built different classifiers and achieved best results with permission and API call combined feature set [<ce:cross-ref refid=""""b30"""" id=""""d1e2752"""">30[[ refid=''''b30'''' ]]</ce:cross-ref>]. MAMA [<ce:cross-ref refid=""""b17"""" id=""""d1e2755"""">17[[ refid=''''b17'''' ]]</ce:cross-ref>] had presented an analysis of Manifest file for Android malware detection and created three sets of features by extracting values from different elements of the manifest file. These three feature sets were used to train four machine learning algorithms (KNN, Decision Tree, Bayesian tree, and SVM) with different algorithmic configuration. On <ce:italic>permissions and features combined</ce:italic> feature set with Random forest (100 trees) authors achieved an accuracy of <mml:math id=""""mml27"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si27.gif""""><mml:mn>94</mml:mn><mml:mo>.</mml:mo><mml:mn>83</mml:mn><mml:mtext>%</mml:mtext></mml:math>, which is about <mml:math id=""""mml28"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si28.gif""""><mml:mn>10</mml:mn><mml:mtext>%</mml:mtext></mml:math> better than two other feature set which are <ce:italic>permissions</ce:italic> and <ce:italic>feature-only</ce:italic> [<ce:cross-ref refid=""""b17"""" id=""""d1e2786"""">17[[ refid=''''b17'''' ]]</ce:cross-ref>]. PUMA [<ce:cross-ref refid=""""b8"""" id=""""d1e2790"""">8[[ refid=''''b8'''' ]]</ce:cross-ref>], is an Android malware detector which uses <ce:italic>permission</ce:italic> and <ce:italic>uses-feature</ce:italic> of an application as feature set to train machine learning algorithms. Authors have achieved an accuracy of <mml:math id=""""mml29"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si29.gif""""><mml:mn>87</mml:mn><mml:mtext>%</mml:mtext></mml:math> and 0.19 FPR with Random Forest (100 trees). An Android malware classification framework to manage big app market was proposed, which used 11 different types of static features and ensemble of various learners [<ce:cross-ref refid=""""b19"""" id=""""d1e2806"""">19[[ refid=''''b19'''' ]]</ce:cross-ref>]. Authors achieved the best accuracy of <mml:math id=""""mml30"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si10.gif""""><mml:mn>99</mml:mn><mml:mo>.</mml:mo><mml:mn>39</mml:mn><mml:mtext>%</mml:mtext></mml:math> for malapps detection whereas <mml:math id=""""mml31"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si11.gif""""><mml:mn>82</mml:mn><mml:mo>.</mml:mo><mml:mn>93</mml:mn><mml:mtext>%</mml:mtext></mml:math> accuracy for benign apps detection. In a recent work, permissions and source code analysis based feature set were used to classify apps into malicious and benign using machine learning [<ce:cross-ref refid=""""b27"""" id=""""d1e2832"""">27[[ refid=''''b27'''' ]]</ce:cross-ref>]. With permission-based feature set and ensemble learning best result i.e. F-score <mml:math id=""""mml32"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si32.gif""""><mml:mn>89</mml:mn><mml:mo>.</mml:mo><mml:mn>4</mml:mn><mml:mtext>%</mml:mtext></mml:math> were achieved. PIndroid [<ce:cross-ref refid=""""b28"""" id=""""d1e2846"""">28[[ refid=''''b28'''' ]]</ce:cross-ref>], used permissions and intents to train ensemble learner and achieved <mml:math id=""""mml33"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si33.gif""""><mml:mn>99</mml:mn><mml:mo>.</mml:mo><mml:mn>8</mml:mn><mml:mtext>%</mml:mtext></mml:math> accuracy.</ce:para>""''"'		ANG	
cites	The P-Spec language	S. Scheinberg, Note on the Boolean properties of context free languages , Inf. Control , vol. 3 (1960), pp.372-375	http://dx.doi.org/10.1016/j.future.2018.03.013			http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/br/b17	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/ctx/ctx0011		18	6	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/itrp/0001	'P-Spec is a formal policy specification language with context-free grammar [17[[ refid=''b17'' ]]], which can be utilized to formally describe the heterogeneous service’s privacy policies or consumer’s privacy preferences precisely.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p9"""">P-Spec is a formal policy specification language with context-free grammar [<ce:cross-ref refid=""""b17"""" id=""""d1e6413"""">17[[ refid=''''b17'''' ]]</ce:cross-ref>], which can be utilized to formally describe the heterogeneous service’s privacy policies or consumer’s privacy preferences precisely. We first propose P-Spec language in reference [<ce:cross-ref refid=""""b18"""" id=""""d1e6425"""">18[[ refid=''''b18'''' ]]</ce:cross-ref>], and further improve it in this paper. In this section, we will introduce P-Spec policy specification language, and give its precise grammar and semantics definitions.</ce:para>""''"'		ANG	
cites	Related works	C. Ke, Z. Huang, M. Tang, Supporting negotiation mechanism privacy authority method in cloud computing , Knowl. Based Syst. , vol. 51 (2013), pp.48-59	http://dx.doi.org/10.1016/j.future.2018.03.013	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/br/b16	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/ctx/ctx0010		18	6	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/itrp/0002	'Changbo Ke and Zhiqiu Huang [16[[ refid=''b16'' ]]] utilized description logic to model privacy preferences and privacy policies, and identified the policy inconsistency conflicts between privacy preferences and privacy policies with the method of ontology rules reasoning algorithm, i.e., tableau algorithm.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p8"""">Owing to XML-based privacy policies, such as P3P [<ce:cross-ref refid=""""b10"""" id=""""d1e6384"""">10[[ refid=''''b10'''' ]]</ce:cross-ref>], XACML [<ce:cross-ref refid=""""b11"""" id=""""d1e6387"""">11[[ refid=''''b11'''' ]]</ce:cross-ref>] and EPAL [<ce:cross-ref refid=""""b12"""" id=""""d1e6390"""">12[[ refid=''''b12'''' ]]</ce:cross-ref>] et al., will easily cause the problems related with semantic inconsistency and semantic ambiguity during policy matching. Accordingly, nearly all latest policy matching approaches are based on the unified matching models based on some exclusive policy languages. Trabelsi [<ce:cross-ref refid=""""b13"""" id=""""d1e6393"""">13[[ refid=''''b13'''' ]]</ce:cross-ref>] proposed a policy matching approach based on Bloom Filters model to select the privacy-aware service for a given service consumer. They transmit XML privacy policies into Bloom Filters policy model, then execute policy matching based on these models. Although having been implemented, the approach only applies to those simple privacy policies. Elisa [<ce:cross-ref refid=""""b14"""" id=""""d1e6396"""">14[[ refid=''''b14'''' ]]</ce:cross-ref>] proposed a service selection approach with ranking mechanism to seek out a privacy-aware service composition from service repository. Firstly they define the privacy preferences and privacy policies into the fine-grained tabular-based privacy models. Then transform the tabular-based privacy models into AND/OR Tree models. Though traversing the AND/OR Tree, they can select out a group of candidate services, and further utilize ranking mechanism to select out an optimal service composition. Elisa’s approach can provide us some wonderful inspirations, such as sensitivity and delegation depth, but it is heavily rely on AND/OR Tree model which is exactly of semi-formalization tool. When the modeling object is some Massive data sets, thus it is nearly impossible to construct AND/OR Tree model in computer. Kagal [<ce:cross-ref refid=""""b15"""" id=""""d1e6400"""">15[[ refid=''''b15'''' ]]</ce:cross-ref>] proposed a semantic-based privacy policy matching framework and a semantic-based privacy policy language which can be utilized to describe privacy policies. But unfortunately, they only introduce the top-level framework of their approach, not giving the details of implementation. Changbo Ke and Zhiqiu Huang [<ce:cross-ref refid=""""b16"""" id=""""d1e6403"""">16[[ refid=''''b16'''' ]]</ce:cross-ref>] utilized description logic to model privacy preferences and privacy policies, and identified the policy inconsistency conflicts between privacy preferences and privacy policies with the method of ontology rules reasoning algorithm, i.e., tableau algorithm. The description logic-based language has good semantic expressiveness and can be utilized to describe different kind of semantic-complex privacy policies. However, the ontology rules reasoning algorithm of this approach is heavily rely on a third-party tool which is very hard to be deployed in real cloud platform. Hence, we think the feasibility of the approach need to be evaluated further.</ce:para>""''"'		ANG	
uses_method_in	Implementation and evaluation	K. Seamons, M. Winslett, T. Yu, B. Smith, E. Child, et al., Requirements for Policy Languages for Trust Negotiation, POLICY2002, 2002.	http://dx.doi.org/10.1016/j.future.2018.03.013	methods		http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/br/b6	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/ctx/ctx0017		18	6	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/itrp/0003	'Among them, the 8 requirements covering well-defined semantics, monotonicity, credential combination, constraints on attribute value, inter-credential constraints, credential chains, local credential variables and compliance checker modes are proposed by K. Seamons [6[[ refid=''b6'' ]]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p81"""">In this section, we compare our P-Spec policy specification language with other four policy languages including of PROTUNE [<ce:cross-ref refid=""""b5"""" id=""""d1e12958"""">5[[ refid=''''b5'''' ]]</ce:cross-ref>], KeyNote [<ce:cross-ref refid=""""b20"""" id=""""d1e12961"""">20[[ refid=''''b20'''' ]]</ce:cross-ref>], TPL [<ce:cross-ref refid=""""b21"""" id=""""d1e12964"""">21[[ refid=''''b21'''' ]]</ce:cross-ref>] and X-Sec [<ce:cross-ref refid=""""b22"""" id=""""d1e12967"""">22[[ refid=''''b22'''' ]]</ce:cross-ref>] by means of 11 policy language requirements. Among them, the 8 requirements covering well-defined semantics, monotonicity, credential combination, constraints on attribute value, inter-credential constraints, credential chains, local credential variables and compliance checker modes are proposed by K. Seamons [<ce:cross-ref refid=""""b6"""" id=""""d1e12979"""">6[[ refid=''''b6'''' ]]</ce:cross-ref>]. In addition, we increase 3 new requirements covering the syntax classification, policy sensitivity and policy depth. The comprehensive comparison of these five policy languages is shown in <ce:cross-ref refid=""""tbl8"""" id=""""d1e12982"""">Table 8</ce:cross-ref>.</ce:para>""''"'		ANG	
cites	Related works	E. Costante, F. Paci, N. Zannone, Privacy-aware web service composition and ranking , Int. J. Web Serv. Res. , vol. 10 (2013), pp.1-23	http://dx.doi.org/10.1016/j.future.2018.03.013	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/br/b14	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/ctx/ctx0008		18	6	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/itrp/0008	'Elisa [14[[ refid=''b14'' ]]] proposed a service selection approach with ranking mechanism to seek out a privacy-aware service composition from service repository.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p8"""">Owing to XML-based privacy policies, such as P3P [<ce:cross-ref refid=""""b10"""" id=""""d1e6384"""">10[[ refid=''''b10'''' ]]</ce:cross-ref>], XACML [<ce:cross-ref refid=""""b11"""" id=""""d1e6387"""">11[[ refid=''''b11'''' ]]</ce:cross-ref>] and EPAL [<ce:cross-ref refid=""""b12"""" id=""""d1e6390"""">12[[ refid=''''b12'''' ]]</ce:cross-ref>] et al., will easily cause the problems related with semantic inconsistency and semantic ambiguity during policy matching. Accordingly, nearly all latest policy matching approaches are based on the unified matching models based on some exclusive policy languages. Trabelsi [<ce:cross-ref refid=""""b13"""" id=""""d1e6393"""">13[[ refid=''''b13'''' ]]</ce:cross-ref>] proposed a policy matching approach based on Bloom Filters model to select the privacy-aware service for a given service consumer. They transmit XML privacy policies into Bloom Filters policy model, then execute policy matching based on these models. Although having been implemented, the approach only applies to those simple privacy policies. Elisa [<ce:cross-ref refid=""""b14"""" id=""""d1e6396"""">14[[ refid=''''b14'''' ]]</ce:cross-ref>] proposed a service selection approach with ranking mechanism to seek out a privacy-aware service composition from service repository. Firstly they define the privacy preferences and privacy policies into the fine-grained tabular-based privacy models. Then transform the tabular-based privacy models into AND/OR Tree models. Though traversing the AND/OR Tree, they can select out a group of candidate services, and further utilize ranking mechanism to select out an optimal service composition. Elisa’s approach can provide us some wonderful inspirations, such as sensitivity and delegation depth, but it is heavily rely on AND/OR Tree model which is exactly of semi-formalization tool. When the modeling object is some Massive data sets, thus it is nearly impossible to construct AND/OR Tree model in computer. Kagal [<ce:cross-ref refid=""""b15"""" id=""""d1e6400"""">15[[ refid=''''b15'''' ]]</ce:cross-ref>] proposed a semantic-based privacy policy matching framework and a semantic-based privacy policy language which can be utilized to describe privacy policies. But unfortunately, they only introduce the top-level framework of their approach, not giving the details of implementation. Changbo Ke and Zhiqiu Huang [<ce:cross-ref refid=""""b16"""" id=""""d1e6403"""">16[[ refid=''''b16'''' ]]</ce:cross-ref>] utilized description logic to model privacy preferences and privacy policies, and identified the policy inconsistency conflicts between privacy preferences and privacy policies with the method of ontology rules reasoning algorithm, i.e., tableau algorithm. The description logic-based language has good semantic expressiveness and can be utilized to describe different kind of semantic-complex privacy policies. However, the ontology rules reasoning algorithm of this approach is heavily rely on a third-party tool which is very hard to be deployed in real cloud platform. Hence, we think the feasibility of the approach need to be evaluated further.</ce:para>""''"'		ANG	
cites	Related works	L. Kagal, J. Pato, Preserving privacy based on semantic policy tools , Secur. Privacy IEEE , vol. 8 (2010), pp.25-30	http://dx.doi.org/10.1016/j.future.2018.03.013	related work		http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/br/b15	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/ctx/ctx0009		18	6	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/itrp/0009	'Kagal [15[[ refid=''b15'' ]]] proposed a semantic-based privacy policy matching framework and a semantic-based privacy policy language which can be utilized to describe privacy policies.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p8"""">Owing to XML-based privacy policies, such as P3P [<ce:cross-ref refid=""""b10"""" id=""""d1e6384"""">10[[ refid=''''b10'''' ]]</ce:cross-ref>], XACML [<ce:cross-ref refid=""""b11"""" id=""""d1e6387"""">11[[ refid=''''b11'''' ]]</ce:cross-ref>] and EPAL [<ce:cross-ref refid=""""b12"""" id=""""d1e6390"""">12[[ refid=''''b12'''' ]]</ce:cross-ref>] et al., will easily cause the problems related with semantic inconsistency and semantic ambiguity during policy matching. Accordingly, nearly all latest policy matching approaches are based on the unified matching models based on some exclusive policy languages. Trabelsi [<ce:cross-ref refid=""""b13"""" id=""""d1e6393"""">13[[ refid=''''b13'''' ]]</ce:cross-ref>] proposed a policy matching approach based on Bloom Filters model to select the privacy-aware service for a given service consumer. They transmit XML privacy policies into Bloom Filters policy model, then execute policy matching based on these models. Although having been implemented, the approach only applies to those simple privacy policies. Elisa [<ce:cross-ref refid=""""b14"""" id=""""d1e6396"""">14[[ refid=''''b14'''' ]]</ce:cross-ref>] proposed a service selection approach with ranking mechanism to seek out a privacy-aware service composition from service repository. Firstly they define the privacy preferences and privacy policies into the fine-grained tabular-based privacy models. Then transform the tabular-based privacy models into AND/OR Tree models. Though traversing the AND/OR Tree, they can select out a group of candidate services, and further utilize ranking mechanism to select out an optimal service composition. Elisa’s approach can provide us some wonderful inspirations, such as sensitivity and delegation depth, but it is heavily rely on AND/OR Tree model which is exactly of semi-formalization tool. When the modeling object is some Massive data sets, thus it is nearly impossible to construct AND/OR Tree model in computer. Kagal [<ce:cross-ref refid=""""b15"""" id=""""d1e6400"""">15[[ refid=''''b15'''' ]]</ce:cross-ref>] proposed a semantic-based privacy policy matching framework and a semantic-based privacy policy language which can be utilized to describe privacy policies. But unfortunately, they only introduce the top-level framework of their approach, not giving the details of implementation. Changbo Ke and Zhiqiu Huang [<ce:cross-ref refid=""""b16"""" id=""""d1e6403"""">16[[ refid=''''b16'''' ]]</ce:cross-ref>] utilized description logic to model privacy preferences and privacy policies, and identified the policy inconsistency conflicts between privacy preferences and privacy policies with the method of ontology rules reasoning algorithm, i.e., tableau algorithm. The description logic-based language has good semantic expressiveness and can be utilized to describe different kind of semantic-complex privacy policies. However, the ontology rules reasoning algorithm of this approach is heavily rely on a third-party tool which is very hard to be deployed in real cloud platform. Hence, we think the feasibility of the approach need to be evaluated further.</ce:para>""''"'		ANG	
cites	The P-Spec language	C. Chang, H.J. Keisler, Model Theory , None, North-Holland (1990)	http://dx.doi.org/10.1016/j.future.2018.03.013			http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/br/b19	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/ctx/ctx0013		18	6	http://www.scar.disi.unibo.it/r/10-1016-j-future-2018-03-013/itrp/0016	'In further, according to the Ref. [19[[ refid=''b19'' ]]], the model of formal language can be defined as an interpretation under a specific universe of A for the formal language.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p19"""">In further, according to the Ref. [<ce:cross-ref refid=""""b19"""" id=""""d1e7450"""">19[[ refid=''''b19'''' ]]</ce:cross-ref>], the model of formal language can be defined as an interpretation under a specific universe of <mml:math id=""""mml191"""" display=""""inline"""" overflow=""""scroll"""" altimg=""""si191.gif""""><mml:mi mathvariant=""""script"""">A</mml:mi></mml:math> for the formal language. Hence, we have the following definitions.</ce:para>""''"'		ANG	
cites	Technical differences	D. Rohde, J. Schwarz, Narrowband Internet of Things, Aug., 2016. Available:	http://dx.doi.org/10.1016/j.icte.2017.03.004			<http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/br/b6>	<http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/ctx/ctx0009>				http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/itrp/0008	'is defined as follows [6][[ refid=''b6'' ]] : [[ formulaid=''id6_pos0'' ]] where MDL∕UL=offset of NB-IoT channel number to downlink/uplink, FDL∕UL_low=downlink/uplink operating band, NDL∕UL=downlink/uplink E-UTRA absolute radio frequency channel number (EARFCN), NoffDL∕UL=Minimum range of NDL∕UL for downlink/uplink.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Technical differences	Semtech, AN 120022, LoRa Modulation Basics, May, 2015. Available:	http://dx.doi.org/10.1016/j.icte.2017.03.004			<http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/br/b5>	<http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/ctx/ctx0007>				http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/itrp/0015	'The relationship between the required data bit rate with the chirp rate and symbol rate in the LoRa modulation technique [5][[ refid=''b5'' ]] is defined as follows:'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Comparison in terms of IoT factors	3GPP TR 36.824 V11.0.0 3rd Generation Partnership Project, Technical Specification Group Radio Access Network, Evolved Universal Terrestrial Radio Access (E-UTRA), LTE coverage enhancements (Release 11), June, 2016	http://dx.doi.org/10.1016/j.icte.2017.03.004			<http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/br/b12>	<http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/ctx/ctx0019>				http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/itrp/0016	'The maximum coupling loss (MCL) is the limit value of the coupling loss at which the service can be delivered, and therefore it defines the range of the service [12][[ refid=''b12'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Technical differences	LoRa Alliance, LoRaWAN Specification, July, 2016	http://dx.doi.org/10.1016/j.icte.2017.03.004			<http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/br/b9>	<http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/ctx/ctx0012>				http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-004/itrp/0019	'All end-devices start and join the network as end-devices of Class A and can then decide to switch to Class B [9][[ refid=''b9'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Agreements on NextGen functions	NGMN Alliance, 5G White paper, V.1.0 (Feb. 2015).	http://dx.doi.org/10.1016/j.icte.2017.03.007			<http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-007/br/br000045>	<http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-007/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-007/ctx/ctx0011>				http://www.scar.disi.unibo.it/r/10-1016-j-icte-2017-03-007/itrp/0001	'Concept: The network slicing concept proposed by Next Generation Mobile Networks (NGMN) Alliance consists of three layers as depicted in Fig. 5, namely, (1) service instance layer, (2) network slice instance layer, and (3) resource layer [9][[ refid=''br000045'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
extends	Computing top-	I.F. Ilyas, W.G. Aref, A.K. Elmagarmid, Supporting top-k join queries in relational databases , VLDB J. , vol. 13 (2004), pp.207-221	http://dx.doi.org/10.1016/j.ijar.2017.11.008			http://www.scar.disi.unibo.it/r/10-1016-j-ijar-2017-11-008/br/br0080	http://www.scar.disi.unibo.it/r/10-1016-j-ijar-2017-11-008/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ijar-2017-11-008/ctx/ctx0019		62	7	http://www.scar.disi.unibo.it/r/10-1016-j-ijar-2017-11-008/itrp/0061	'Our approach extends the RankJoin operator in [8][[ refid=''br0080'' ]] to work with UNCQs.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""pr0560"""" view=""""all"""">Our approach extends the RankJoin operator in <ce:cross-ref refid=""""br0080"""" id=""""crf0420"""">[8][[ refid=''''br0080'''' ]]</ce:cross-ref> to work with UNCQs. The original RankJoin operator takes as input an integer <ce:italic>k</ce:italic>, a positive conjunctive query, a monotonic ranking function <ce:italic>f</ce:italic>, and <ce:italic>m</ce:italic> relations (where each tuple in each relation is accompanied by a score), and it yields the top-<ce:italic>k</ce:italic> joined tuples over the <ce:italic>m</ce:italic> relations, in descending order of their combined scores (computed using <ce:italic>f</ce:italic>). Specifically, it assumes that each of the <ce:italic>m</ce:italic> input relations is sorted by tuple-score in descending order, and tuples from the <ce:italic>m</ce:italic> relations are scanned and joined until <ce:italic>k</ce:italic> joined tuples are found such that the lowest among their scores is greater than or equal to a certain threshold.</ce:para>""''"'	extends	ANG	
extends	Discussion and conclusions	T.A. Pempek, Y.A. Yermolayeva, S. Calvert, College students’ social networking experiences on Facebook , J. Appl. Dev. Psychol. , vol. 30 (2009), pp.227-238	http://dx.doi.org/10.1016/j.im.2014.05.004	conclusion	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-im-2014-05-004/br/bib0320	http://www.scar.disi.unibo.it/r/10-1016-j-im-2014-05-004/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-im-2014-05-004/ctx/ctx0079		83	6	http://www.scar.disi.unibo.it/r/10-1016-j-im-2014-05-004/itrp/0016	'The study thus extends the work of researchers such as Pempek et al. [64][[ refid=''bib0320'' ]] by demonstrating that the effect of social gratifications on problematic SNS use is fully mediated by the presence of arousal in the online experience.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0170"""" view=""""all"""">The theoretical implications are fourfold. First, the present study supports the integration of U&amp;G and flow theories to explain SNS use and reinforces the speculation regarding an immediate theoretical correspondence between online flow and the U&amp;G gratification constructs <ce:cross-ref id=""""crf0595"""" refid=""""bib0385"""">[77][[ refid=''''bib0385'''' ]]</ce:cross-ref>. The empirical results indicate that SNS users build associations between their social gratifications and experiential states. Thus, the manner in which SNS users experience the usage process is as important as the gratification of their social needs; together, these factors determine consumers’ intentions to make further visits to an SNS website and their problematic use behavior. Second, this study shows that it is possible for both social gratifications and arousal to have a direct effect on problematic SNS use if both effects are examined independently of one another. Nonetheless, as the mediating effects reveal, the effect of social gratifications on problematic SNS use becomes insignificant when both the effects of social gratifications and arousal are considered simultaneously; hence, these results suggest that researchers should apply an integrative approach to explain problematic SNS use. The study thus extends the work of researchers such as Pempek et al. <ce:cross-ref id=""""crf0600"""" refid=""""bib0320"""">[64][[ refid=''''bib0320'''' ]]</ce:cross-ref> by demonstrating that the effect of social gratifications on problematic SNS use is fully mediated by the presence of arousal in the online experience.</ce:para>""''"'	extends	ANG	
extends	Related work	B. Celikkale, A. Erdem, E. Erdem, Visual attention-driven spatial pooling for image memorability , Computer Vision and Pattern Recognition Workshops (CVPRW), 2013 IEEE Computer Society Conference on, IEEE (2013)	http://dx.doi.org/10.1016/j.imavis.2015.07.001	related work		http://www.scar.disi.unibo.it/r/10-1016-j-imavis-2015-07-001/br/bb0140	http://www.scar.disi.unibo.it/r/10-1016-j-imavis-2015-07-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-imavis-2015-07-001/ctx/ctx0034		76	6	http://www.scar.disi.unibo.it/r/10-1016-j-imavis-2015-07-001/itrp/0088	'This article expands upon our previous workshop publication [28][[ refid=''bb0140'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0065"""" view=""""all"""">To our knowledge, no previous work attempted to improve image memorability prediction based on an attention-guided feature selection mechanism. This article expands upon our previous workshop publication <ce:cross-ref refid=""""bb0140"""" id=""""cf0345"""">[28][[ refid=''''bb0140'''' ]]</ce:cross-ref>. In this version, we add an entirely new set of experiments on the MIT Memorability dataset, and perform a more thorough experimental analysis to validate that selecting features from the salient image regions via our proposed attention-driven pooling strategy can indeed make more accurate predictions of memorability scores. In addition, we study a group of semantic features related to meta-level object categories <ce:cross-ref refid=""""bb0100"""" id=""""cf0350"""">[20][[ refid=''''bb0100'''' ]]</ce:cross-ref>, scene attributes <ce:cross-ref refid=""""bb0105"""" id=""""cf0355"""">[21][[ refid=''''bb0105'''' ]]</ce:cross-ref>, and invoked feelings <ce:cross-ref refid=""""bb0110"""" id=""""cf0360"""">[22][[ refid=''''bb0110'''' ]]</ce:cross-ref> that can automatically extracted from images (<ce:cross-ref refid=""""s0040"""" id=""""cf0365"""">Section 4</ce:cross-ref>), and analyze their roles in predicting memorability of images. Thus, we provide additional discussion of the results and related work, and include new quantitative comparisons of our combined framework against the state-of-the-art.</ce:para>""''"'	extends	ANG	
cites	Introduction	F.G. Mohammadi, M.S. Abadeh, Image steganalysis using a bee colony based feature selection algorithm , Eng. Appl. Artif. Intell. , vol. 31 (2014), pp.35-43	http://dx.doi.org/10.1016/j.imavis.2017.09.004	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-imavis-2017-09-004/br/bb0030	http://www.scar.disi.unibo.it/r/10-1016-j-imavis-2017-09-004/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-imavis-2017-09-004/ctx/ctx0005		246	6	http://www.scar.disi.unibo.it/r/10-1016-j-imavis-2017-09-004/itrp/0027	'FE extracts multiple features from the original data to generate a dataset [6][[ refid=''bb0030'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0025"""" view=""""all"""">Two key steps in data pre-processing are feature extraction (FE) and feature selection (FS). FS techniques are a subset of the general field of FE <ce:cross-ref id=""""cf0480"""" refid=""""bb0030"""">[6][[ refid=''''bb0030'''' ]]</ce:cross-ref>. FE extracts multiple features from the original data to generate a dataset <ce:cross-ref id=""""cf0485"""" refid=""""bb0030"""">[6][[ refid=''''bb0030'''' ]]</ce:cross-ref>. Contrarily, FS selects a subset of original features to construct model <ce:cross-ref id=""""cf0490"""" refid=""""bb0035"""">[7][[ refid=''''bb0035'''' ]]</ce:cross-ref>. According to Cantú-Paz et al. <ce:cross-ref id=""""cf0495"""" refid=""""bb0040"""">[8][[ refid=''''bb0040'''' ]]</ce:cross-ref>, identifying related features provides insights into underlying phenomenon. On the other hand, discarding irrelevant features improves the accuracy of data classifications. FE and FS are integral and mutually influential. In the work of Mohammadi and Abadeh <ce:cross-ref id=""""cf0500"""" refid=""""bb0030"""">[6][[ refid=''''bb0030'''' ]]</ce:cross-ref>, FE extracts images with hidden message through image steganalysis, and FS was adopted to determine appropriate features from the extracted images.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
extends	Introduction	J. Stadnik, M. Ganzha, M. Paprzycki, Are many heads better than one—on combining information from multiple internet sources , Intelligent Distributed Computing, Systems and Applications, Springer (2008)	http://dx.doi.org/10.1016/j.ins.2010.01.010	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2010-01-010/br/bib34	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2010-01-010/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2010-01-010/ctx/ctx0004		41	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2010-01-010/itrp/0031	'Work presented here extends initial results presented in [34][[ refid=''bib34'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""">We proceed as follows. In the next section, we outline most important existing results that are pertinent to our work. Next, introduce the three approaches to information combining. We follow with experimental results and their analysis. Work presented here extends initial results presented in <ce:cross-ref refid=""""bib34"""">[34][[ refid=''''bib34'''' ]]</ce:cross-ref>. </ce:para>""''"'	extends	ANG	
extends	Introduction	Y. Shi, M. Larson, A. Hanjalic, List-wise learning to rank with matrix factorization for collaborative filtering , Proceedings of the Fourth ACM Conference on Recommender Systems, RecSys ’10, ACM (2010)	http://dx.doi.org/10.1016/j.ins.2012.12.002	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2012-12-002/br/b0135	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2012-12-002/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2012-12-002/ctx/ctx0008		41	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2012-12-002/itrp/0017	'The approach presented in this paper builds on and expands the basic finding of the effectiveness of list-wise learning-to-rank, demonstrated in [27][[ refid=''b0135'' ]], where we first introduced ListRank, a ranking-oriented matrix factorization approach.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0025"""" view=""""all"""">The approach presented in this paper builds on and expands the basic finding of the effectiveness of list-wise learning-to-rank, demonstrated in <ce:cross-ref refid=""""b0135"""">[27][[ refid=''''b0135'''' ]]</ce:cross-ref>, where we first introduced ListRank, a ranking-oriented matrix factorization approach. The expansions that are presented here extend along two dimensions. First, we combine the advantages of ranking-oriented and rating-oriented recommendation by combining ListRank with a rating-oriented component, resulting in URM, a new recommendation model. Second, we conduct experimental evaluations on multiple datasets of various scales to validate the usefulness of the proposed URM approach, and demonstrate its specific contributions to the state of the art.</ce:para>""''"'	extends	ANG	
extends	Introduction	K. Li et al., Human-centered attention models for video summarization, in: Proc. 12th Int. Conf. on Multimodal Interfaces and 7th Workshop on Machine Learning for Multimodal Interaction, ICMI-MLMI’10, Beijing, China, 2010.	http://dx.doi.org/10.1016/j.ins.2013.12.039	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2013-12-039/br/b0145	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2013-12-039/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2013-12-039/ctx/ctx0009		82	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2013-12-039/itrp/0026	'This paper significantly extends our earlier work [29][[ refid=''b0145'' ]] and makes the following two major contributions.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0030"""" view=""""all"""">This paper significantly extends our earlier work <ce:cross-ref refid=""""b0145"""" id=""""c0090"""">[29][[ refid=''''b0145'''' ]]</ce:cross-ref> and makes the following two major contributions. (1) We propose a novel experimental paradigm to measure the brain’s comprehension of video stimuli quantitatively and then infer attention engagement by using fMRI techniques. The computation of PFS over the functional brain networks, where each node denotes the temporal fMRI signals from an ROI, indicates the attention engagement. It naturally results in the benchmark attention curve by using a small number of video stimuli. (2) In comparison with our earlier work in <ce:cross-ref refid=""""b0145"""" id=""""c0095"""">[29][[ refid=''''b0145'''' ]]</ce:cross-ref>, this paper re-designs and implements a computational framework for the optimization of bottom-up visual attention models under the guidance of fMRI-derived benchmark attention curves, as illustrated in <ce:cross-ref refid=""""f0005"""" id=""""c0100"""">Fig. 1</ce:cross-ref>. This new framework not only bridges the brain imaging field and low-level visual content analysis, but also lowers the cost of fMRI scanning. This framework enables the optimization and integration of low-level visual attention cues into better fMRI-driven visual attention models that correlate well with the human brain’s attention engagement.</ce:para>""''"'	extends	ANG	
cites	Big Data tools: techniques and technologies	Hui Li, Geoffrey Fox, Judy Qiu, Performance model for parallel matrix multiplication with dryad: dataflow graph runtime, in: 2012 Second International Conference on Cloud and Green Computing, 2012, pp. 675–683.	http://dx.doi.org/10.1016/j.ins.2014.01.015	data		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0505	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0096		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0030	'Dryad provides a large number of functionality, including generating the job graph, scheduling the processes on the available machines, handling transient failures in the cluster, collecting performance metrics, visualizing the job, invoking user-defined policies and dynamically updating the job graph in response to these policy decisions, without awareness of the semantics of the vertices [101][[ refid=''b0505'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0280"""" view=""""all"""">Dryad provides a large number of functionality, including generating the job graph, scheduling the processes on the available machines, handling transient failures in the cluster, collecting performance metrics, visualizing the job, invoking user-defined policies and dynamically updating the job graph in response to these policy decisions, without awareness of the semantics of the vertices <ce:cross-ref id=""""c0375"""" refid=""""b0505"""">[101][[ refid=''''b0505'''' ]]</ce:cross-ref>. <ce:cross-ref id=""""c0760"""" refid=""""f0045"""">Fig. 9</ce:cross-ref><ce:float-anchor refid=""""f0045""""/> schematically shows the implementation schema of Dryad. There is a centralized job manager to supervise every Dryad job. It uses a small set of cluster services to control the execution of the vertices on the cluster.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Big Data tools: techniques and technologies	Hui Li, Geoffrey Fox, Judy Qiu, Performance model for parallel matrix multiplication with dryad: dataflow graph runtime, in: 2012 Second International Conference on Cloud and Green Computing, 2012, pp. 675–683.	http://dx.doi.org/10.1016/j.ins.2014.01.015	data		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0505	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0094		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0032	'It bases on dataflow graph processing [101][[ refid=''b0505'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0275"""" view=""""all"""">Dryad <ce:cross-ref id=""""c0360"""" refid=""""b0375"""">[75][[ refid=''''b0375'''' ]]</ce:cross-ref> is another popular programming models for implementing parallel and distributed programs that can scale up capability of processing from a very small cluster to a large cluster. It bases on dataflow graph processing <ce:cross-ref id=""""c0365"""" refid=""""b0505"""">[101][[ refid=''''b0505'''' ]]</ce:cross-ref>. The infrastructure for running Dryad consists of a cluster of computing nodes, and a programmer use the resources of a computer cluster to running their programs in a distributed way. Indeed, Dryad programmers can use thousands of machines, each of them with multiple processors or cores. One bonus is that programmers does not need to know anything about concurrent programming. A Dryad application runs a computational directed graph which is composed of computational <ce:italic>vertices</ce:italic> and communication <ce:italic>channels</ce:italic>. The computation is structured as illustrated in <ce:cross-ref id=""""c0755"""" refid=""""f0040"""">Fig. 8</ce:cross-ref><ce:float-anchor refid=""""f0040""""/>: graph vertices represent the programs, while graph edges denote the channels. A Dryad programmer writes several sequential programs and connects them using one-way channels <ce:cross-ref id=""""c0370"""" refid=""""b0380"""">[76][[ refid=''''b0380'''' ]]</ce:cross-ref>. A Dryad job is to generator a graph, and it has capability to synthesize any directed acyclic graph. These generated graphs can also be updated after execution, in order to deal with the unexpected events in the computation.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Big Data tools: techniques and technologies	Grant Ingersoll, Introducing apache mahout: scalable, commercial-friendly machine learning for building intelligent applications , IBM Corporation (2009)	http://dx.doi.org/10.1016/j.ins.2014.01.015	data		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0370	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0098		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0035	'The Apache Mahout [74][[ refid=''b0370'' ]] aims to provide scalable and commercial machine learning techniques for large-scale and intelligent data analysis applications.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0290"""" view=""""all"""">The Apache Mahout <ce:cross-ref id=""""c0390"""" refid=""""b0370"""">[74][[ refid=''''b0370'''' ]]</ce:cross-ref> aims to provide scalable and commercial machine learning techniques for large-scale and intelligent data analysis applications. Many renowned big companies, such as Google, Amazon, Yahoo!, IBM, Twitter and Facebook, have implemented scalable machine learning algorithms in their projects. Many of their projects involve with Big Data problems and Apache Mahout provides a tool to alleviate the big challenges.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Big Data opportunities and challenges	Vamsee Kasavajhala, Solid state drive vs. hard disk drive price and performance study , Dell PowerVault Tech. Mark. (2012)	http://dx.doi.org/10.1016/j.ins.2014.01.015	data		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0435	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0031		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0043	'In the past decades, the persistent data were stored by using hard disk drives (HDDs) [87][[ refid=''b0435'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0110"""" view=""""all"""">Big Data has changed the way we capture and store data <ce:cross-ref id=""""r0040"""" refid=""""b0665"""">[133][[ refid=''''b0665'''' ]]</ce:cross-ref>, including data storage device, data storage architecture, data access mechanism. As we require more storage mediums and higher I/O speed to meet the challenges, there is no doubt that we need great innovations. Firstly, the accessibility of Big Data is on the top priority of the knowledge discovery process. Big Data should be accessed easily and promptly for further analysis, fully or partially break the restraint: CPU-heavy but I/O-poor. In addition, the under-developing storage technologies, such as solid-state drive (SSD) <ce:cross-ref id=""""c0135"""" refid=""""b0365"""">[73][[ refid=''''b0365'''' ]]</ce:cross-ref> and phase-change memory (PCM) <ce:cross-ref id=""""c0140"""" refid=""""b0720"""">[144][[ refid=''''b0720'''' ]]</ce:cross-ref>, may help us alleviate the difficulties, but they are far from enough. One significant shift is also underway, that is the transformative change of the traditional I/O subsystems. In the past decades, the persistent data were stored by using hard disk drives (HDDs) <ce:cross-ref id=""""c0145"""" refid=""""b0435"""">[87][[ refid=''''b0435'''' ]]</ce:cross-ref>. As we known, HDDs had much slower random I/O performance than sequential I/O performance, and data processing engines formatted their data and designed their query processing methods to work around this limitation. But, HDDs are increasingly being replaced by SSDs today, and other technologies such as PCM are also around the corner <ce:cross-ref id=""""r0045"""" refid=""""b0040"""">[8][[ refid=''''b0040'''' ]]</ce:cross-ref>. These current storage technologies cannot possess the same high performance for both the sequential and random I/O simultaneously, which requires us to rethink how to design storage subsystems for Big Data processing systems.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Big Data opportunities and challenges	David Leong, A new revolution in enterprise storage architecture , IEEE Potentials , vol. 28 (2009), pp.32-33	http://dx.doi.org/10.1016/j.ins.2014.01.015	data		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0495	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0033		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0046	'Direct-attached storage (DAS), network-attached storage (NAS), and storage area network (SAN) are the enterprise storage architectures that were commonly used [99][[ refid=''b0495'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0115"""" view=""""all"""">Direct-attached storage (DAS), network-attached storage (NAS), and storage area network (SAN) are the enterprise storage architectures that were commonly used <ce:cross-ref id=""""c0150"""" refid=""""b0495"""">[99][[ refid=''''b0495'''' ]]</ce:cross-ref>. However, all these existing storage architectures have severe drawbacks and limitations when it comes to large-scale distributed systems. Aggressive concurrency and per server throughput are the essential requirements for the applications on highly scalable computing clusters, and today’s storage systems lack the both. Optimizing data access is a popular way to improve the performance of data-intensive computing <ce:cross-refs id=""""r0050"""" refid=""""b0390 b0385 b0395"""">[78,77,79][[ refid=''''b0390 b0385 b0395'''' ]]</ce:cross-refs>, these techniques include data replication, migration, distribution, and access parallelism. In <ce:cross-ref id=""""c0155"""" refid=""""b0095"""">[19][[ refid=''''b0095'''' ]]</ce:cross-ref>, the performance, reliability and scalability in data-access platforms were discussed. Data-access platforms, such as CASTOR, dCache, GPFS and Scalla/Xrootd, are employed to demonstrate the large scale validation and performance measurement. Data storage and search schemes also lead to high overhead and latency <ce:cross-ref id=""""c0160"""" refid=""""b0810"""">[162][[ refid=''''b0810'''' ]]</ce:cross-ref>, distributed data-centric storage is a good approach in large-scale wireless sensor networks (WSNs). Shen, Zhao and Li proposed a distributed spatial–temporal similarity data storage scheme to provide efficient spatial–temporal and similarity data searching service in WSNs. The collective behavior of individuals that cooperate in a swarm provide approach to achieve self-organization in distributed systems <ce:cross-refs id=""""r0055"""" refid=""""b0620 b0920"""">[124,184][[ refid=''''b0620 b0920'''' ]]</ce:cross-refs>.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Big Data tools: techniques and technologies	Geoffrey E. Hinton, Ruslan Salakhutdinov, Reducing the dimensionality of data with neural networks , Science , vol. 313 (2006), pp.504-507	http://dx.doi.org/10.1016/j.ins.2014.01.015	data		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0350	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0087		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0094	'Recently, a generative deep networks, called autoencoder [70][[ refid=''b0350'' ]], perform very well as non-linear dimensionality reduction.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0240"""" view=""""all"""">Many researchers regard the curse of dimensionality as one aspect of Big Data problems. Indeed, Big Data should not be constricted in data volume, but all take the high-dimension characteristic of data into consideration. In fact, processing high-dimensional data is already a tough task in current scientific research. The state-of-the-art techniques for handling high-dimensional data intuitively fall into dimension reduction. Namely, we try to map the high-dimensional data space into lower dimensional space with less loss of information as possible. There are a large number of methods to reduce dimension <ce:cross-refs id=""""r0195"""" refid=""""b0735 b0545 b0280"""">[147,109,56][[ refid=''''b0735 b0545 b0280'''' ]]</ce:cross-refs>. Linear mapping methods, such as principal component analysis (PCA) and factor analysis, are popular linear dimension reduction techniques. Non-linear techniques include kernel PCA, manifold learning techniques such as Isomap, locally linear embedding (LLE), Hessian LLE, Laplacian eigenmaps, and LTSA <ce:cross-ref id=""""c0335"""" refid=""""b0490"""">[98][[ refid=''''b0490'''' ]]</ce:cross-ref>. Recently, a generative deep networks, called autoencoder <ce:cross-ref id=""""c0340"""" refid=""""b0350"""">[70][[ refid=''''b0350'''' ]]</ce:cross-ref>, perform very well as non-linear dimensionality reduction. Random projection in dimensionality reduction also have been well-developed <ce:cross-ref id=""""r0200"""" refid=""""b0125"""">[25][[ refid=''''b0125'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Big Data tools: techniques and technologies	Ella Bingham, Heikki Mannila, Random projection in dimensionality reduction: applications to image and text data , Knowledge Discovery and Data Mining, ACM Press (2001)	http://dx.doi.org/10.1016/j.ins.2014.01.015	data		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0125	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0088		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0095	'Random projection in dimensionality reduction also have been well-developed [25][[ refid=''b0125'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0240"""" view=""""all"""">Many researchers regard the curse of dimensionality as one aspect of Big Data problems. Indeed, Big Data should not be constricted in data volume, but all take the high-dimension characteristic of data into consideration. In fact, processing high-dimensional data is already a tough task in current scientific research. The state-of-the-art techniques for handling high-dimensional data intuitively fall into dimension reduction. Namely, we try to map the high-dimensional data space into lower dimensional space with less loss of information as possible. There are a large number of methods to reduce dimension <ce:cross-refs id=""""r0195"""" refid=""""b0735 b0545 b0280"""">[147,109,56][[ refid=''''b0735 b0545 b0280'''' ]]</ce:cross-refs>. Linear mapping methods, such as principal component analysis (PCA) and factor analysis, are popular linear dimension reduction techniques. Non-linear techniques include kernel PCA, manifold learning techniques such as Isomap, locally linear embedding (LLE), Hessian LLE, Laplacian eigenmaps, and LTSA <ce:cross-ref id=""""c0335"""" refid=""""b0490"""">[98][[ refid=''''b0490'''' ]]</ce:cross-ref>. Recently, a generative deep networks, called autoencoder <ce:cross-ref id=""""c0340"""" refid=""""b0350"""">[70][[ refid=''''b0350'''' ]]</ce:cross-ref>, perform very well as non-linear dimensionality reduction. Random projection in dimensionality reduction also have been well-developed <ce:cross-ref id=""""r0200"""" refid=""""b0125"""">[25][[ refid=''''b0125'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Big Data tools: techniques and technologies	Pentaho Business Analytics, 2012. <	http://dx.doi.org/10.1016/j.ins.2014.01.015	data		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0020	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0101		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0108	'Pentaho [4][[ refid=''b0020'' ]] is another software platform for Big Data.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0310"""" view=""""all"""">Pentaho <ce:cross-ref id=""""c0400"""" refid=""""b0020"""">[4][[ refid=''''b0020'''' ]]</ce:cross-ref> is another software platform for Big Data. It also generate reports from both structured and unstructured large volume of data. Pentaho plays as a business analytic platform for Big Data to provide professional services for businessmen with facile access, integration, visualization and exploration of data. Therefore, Pentaho can enable business users to make data-driven decisions that have a positive effect on the performance of their organization. The techniques embedded in it have several properties, including good security, scalability, and accessibility. Similar with JasperSoft, there is a chain between Pentaho’s tool and many of the most popular NoSQL databases, such as MongoDB <ce:cross-ref id=""""c0405"""" refid=""""b0725"""">[145][[ refid=''''b0725'''' ]]</ce:cross-ref> and Cassandra <ce:cross-ref id=""""r0225"""" refid=""""b0180"""">[36][[ refid=''''b0180'''' ]]</ce:cross-ref>. Once the connection to databases is established, users can drill up and drill down the columns into different information granules.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Big Data tools: techniques and technologies	Karmasphere Studio and Analyst, 2012. <	http://dx.doi.org/10.1016/j.ins.2014.01.015	data		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0015	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0105		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0113	'Karmasphere [3][[ refid=''b0015'' ]] is another Hadoop-based Big Data platform for business data analysis.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0340"""" view=""""all"""">Karmasphere <ce:cross-ref id=""""c0420"""" refid=""""b0015"""">[3][[ refid=''''b0015'''' ]]</ce:cross-ref> is another Hadoop-based Big Data platform for business data analysis. It provides a new approach for self-service access and analytics to Big Data in a fast, efficient and collaborative way. Karmasphere is natively designed for Hadoop platform, it provides users an integrated and user-friendly workspace for processing their Big Data applications and presenting the workflows. From the point of its performance, it has capability to discovery business insight from huge amounts of data, including data ingestion, iterative analysis, visualization and reporting. Karmasphere Studio is a set of plug-ins built on top of Eclipse. In this well-designed integrated development environment, users can easily write and implement their Hadoop jobs on the platform.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites_as_review	Big Data opportunities and challenges	Jing Han, Haihong E, Guan Le, Jian Du, Survey on nosql database, in: 2011 6th International Conference on Pervasive Computing and Applications (ICPCA), 2011, pp. 363–366.	http://dx.doi.org/10.1016/j.ins.2014.01.015	data		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0300	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0042		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0168	'Therefore, NoSQL systems are very flexible for data modeling, and easy to update application developments and deployments [60][[ refid=''b0300'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0135"""" view=""""all"""">To store and manage unstructured data or non-relational data, NoSQL employs a number of specific approaches. Firstly, data storage and management are separated into two independent parts. This is contrary to relational databases which try to meet the concerns in the two sides simultaneously. This design gives NoSQL databases systems a lot of advantages. In the storage part which is also called key-value storage, NoSQL focuses on the scalability of data storage with high-performance. In the management part, NoSQL provides low-level access mechanism in which data management tasks can be implemented in the application layer rather than having data management logic spread across in SQL or DB-specific stored procedure languages <ce:cross-ref id=""""c0175"""" refid=""""b0185"""">[37][[ refid=''''b0185'''' ]]</ce:cross-ref>. Therefore, NoSQL systems are very flexible for data modeling, and easy to update application developments and deployments <ce:cross-ref id=""""c0180"""" refid=""""b0300"""">[60][[ refid=''''b0300'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Underlying technologies and future researches	Josh Bongard, Biologically inspired computing , Computer , vol. 42 (2009), pp.95-98	http://dx.doi.org/10.1016/j.ins.2014.01.015			http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0130	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0145		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0204	'Biologically inspired Computing[26][[ refid=''b0130'' ]] maybe provides tools to solve Big Data problems from hardware design to software design.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0575"""" view=""""all""""><ce:italic>Computational intelligence</ce:italic>, which is inspired by nature, is a set of computational methodologies and approaches to address complex real-world problems. We have reason to believe that computational systems can also be illuminated by biological systems. <ce:italic>Biologically inspired Computing</ce:italic><ce:cross-ref id=""""c0595"""" refid=""""b0130"""">[26][[ refid=''''b0130'''' ]]</ce:cross-ref> maybe provides tools to solve Big Data problems from hardware design to software design. In analogy to nature, bio-inspired hardware systems can be classified as three axes, phylogeny, ontogeny, and epigenesis <ce:cross-ref id=""""c0600"""" refid=""""b0855"""">[171][[ refid=''''b0855'''' ]]</ce:cross-ref>. In <ce:cross-ref id=""""c0605"""" refid=""""b0960"""">[192][[ refid=''''b0960'''' ]]</ce:cross-ref>, authors give a review an emerging engineering discipline to program cell behaviors by embedding synthetic gene networks that perform computation, communications, and signal processing. Wang and Sun <ce:cross-ref id=""""c0610"""" refid=""""b0940"""">[188][[ refid=''''b0940'''' ]]</ce:cross-ref> proposed a bio-inspired cost minimization mechanism for data-intensive service provision. It utilizes bio-inspired mechanisms to search and find the optimal data service solution considering cost of data management and service maintenance. Tadashi <ce:cross-ref id=""""r0270"""" refid=""""b0625"""">[125][[ refid=''''b0625'''' ]]</ce:cross-ref> gave a review for biological communication (molecular communication) inspired by the cell and cell-to-cell communication. The data transformation and the communication between different computing units in Big Data systems maybe borrow some useful ideas from cells. In <ce:cross-ref id=""""c0615"""" refid=""""b0700"""">[140][[ refid=''''b0700'''' ]]</ce:cross-ref> two hardware processing architecture for modeling large networks of leaky-integrate-and-fire neurons, that integrate bio-inspired neural processing models into real-world control environments. Sergio <ce:cross-ref id=""""c0620"""" refid=""""b0080"""">[16][[ refid=''''b0080'''' ]]</ce:cross-ref> demonstrated self-synchronization mechanism, which borrowed from biological systems, as the basic tool for achieving globally optimal distributed decisions in a wireless sensor network.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Underlying technologies and future researches	Moshe Sipper, Eduardo Sanchez, Daniel Mange, Marco Tomassini, Andrés Pérez-Uribe, André Stauffer, A phylogenetic, ontogenetic, and epigenetic view of bio-inspired hardware systems , IEEE Trans. Evol. Comput. , vol. 1 (1997), pp.83-97	http://dx.doi.org/10.1016/j.ins.2014.01.015			http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0855	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0146		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0207	'In analogy to nature, bio-inspired hardware systems can be classified as three axes, phylogeny, ontogeny, and epigenesis [171][[ refid=''b0855'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0575"""" view=""""all""""><ce:italic>Computational intelligence</ce:italic>, which is inspired by nature, is a set of computational methodologies and approaches to address complex real-world problems. We have reason to believe that computational systems can also be illuminated by biological systems. <ce:italic>Biologically inspired Computing</ce:italic><ce:cross-ref id=""""c0595"""" refid=""""b0130"""">[26][[ refid=''''b0130'''' ]]</ce:cross-ref> maybe provides tools to solve Big Data problems from hardware design to software design. In analogy to nature, bio-inspired hardware systems can be classified as three axes, phylogeny, ontogeny, and epigenesis <ce:cross-ref id=""""c0600"""" refid=""""b0855"""">[171][[ refid=''''b0855'''' ]]</ce:cross-ref>. In <ce:cross-ref id=""""c0605"""" refid=""""b0960"""">[192][[ refid=''''b0960'''' ]]</ce:cross-ref>, authors give a review an emerging engineering discipline to program cell behaviors by embedding synthetic gene networks that perform computation, communications, and signal processing. Wang and Sun <ce:cross-ref id=""""c0610"""" refid=""""b0940"""">[188][[ refid=''''b0940'''' ]]</ce:cross-ref> proposed a bio-inspired cost minimization mechanism for data-intensive service provision. It utilizes bio-inspired mechanisms to search and find the optimal data service solution considering cost of data management and service maintenance. Tadashi <ce:cross-ref id=""""r0270"""" refid=""""b0625"""">[125][[ refid=''''b0625'''' ]]</ce:cross-ref> gave a review for biological communication (molecular communication) inspired by the cell and cell-to-cell communication. The data transformation and the communication between different computing units in Big Data systems maybe borrow some useful ideas from cells. In <ce:cross-ref id=""""c0615"""" refid=""""b0700"""">[140][[ refid=''''b0700'''' ]]</ce:cross-ref> two hardware processing architecture for modeling large networks of leaky-integrate-and-fire neurons, that integrate bio-inspired neural processing models into real-world control environments. Sergio <ce:cross-ref id=""""c0620"""" refid=""""b0080"""">[16][[ refid=''''b0080'''' ]]</ce:cross-ref> demonstrated self-synchronization mechanism, which borrowed from biological systems, as the basic tool for achieving globally optimal distributed decisions in a wireless sensor network.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Underlying technologies and future researches	Steve Loughran, Jose Alcaraz Calero, Andrew Farrell, Johannes Kirschnick, Julio Guijarro, Dynamic cloud deployment of a mapreduce architecture , IEEE Internet Comput. , vol. 16 (2012), pp.40-50	http://dx.doi.org/10.1016/j.ins.2014.01.015			http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0540	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0140		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0209	'Usually, we need to combine the distributed MapReduce and cloud computing to get an effective answer for providing petabyte-scale computing [108][[ refid=''b0540'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0555"""" view=""""all"""">Cloud computing is a highly feasible technology and attract a large number of researchers to develop it and try to apply to Big Data problems. Usually, we need to combine the distributed MapReduce and cloud computing to get an effective answer for providing petabyte-scale computing <ce:cross-ref id=""""c0570"""" refid=""""b0540"""">[108][[ refid=''''b0540'''' ]]</ce:cross-ref>. CloudView <ce:cross-ref id=""""c0575"""" refid=""""b0075"""">[15][[ refid=''''b0075'''' ]]</ce:cross-ref> is a framework for storage, processing and analysis of massive machine maintenance data in a cloud computing environment, which is formulated using the Map/Reduce model and reaches real-time response. In <ce:cross-ref id=""""c0580"""" refid=""""b0420"""">[84][[ refid=''''b0420'''' ]]</ce:cross-ref>, the authors extended Map/Reduce’s filtering aggregation programming model in cloud environment and boosts the performance of complex analysis queries.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Underlying technologies and future researches	Lijuan Wang, Jun Shen, Towards bio-inspired cost minimisation for data-intensive service provision, in: 2012 IEEE First International Conference on Services Economics (SE), 2012, pp. 16–23.	http://dx.doi.org/10.1016/j.ins.2014.01.015			http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0940	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0148		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0213	'Wang and Sun [188][[ refid=''b0940'' ]] proposed a bio-inspired cost minimization mechanism for data-intensive service provision.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0575"""" view=""""all""""><ce:italic>Computational intelligence</ce:italic>, which is inspired by nature, is a set of computational methodologies and approaches to address complex real-world problems. We have reason to believe that computational systems can also be illuminated by biological systems. <ce:italic>Biologically inspired Computing</ce:italic><ce:cross-ref id=""""c0595"""" refid=""""b0130"""">[26][[ refid=''''b0130'''' ]]</ce:cross-ref> maybe provides tools to solve Big Data problems from hardware design to software design. In analogy to nature, bio-inspired hardware systems can be classified as three axes, phylogeny, ontogeny, and epigenesis <ce:cross-ref id=""""c0600"""" refid=""""b0855"""">[171][[ refid=''''b0855'''' ]]</ce:cross-ref>. In <ce:cross-ref id=""""c0605"""" refid=""""b0960"""">[192][[ refid=''''b0960'''' ]]</ce:cross-ref>, authors give a review an emerging engineering discipline to program cell behaviors by embedding synthetic gene networks that perform computation, communications, and signal processing. Wang and Sun <ce:cross-ref id=""""c0610"""" refid=""""b0940"""">[188][[ refid=''''b0940'''' ]]</ce:cross-ref> proposed a bio-inspired cost minimization mechanism for data-intensive service provision. It utilizes bio-inspired mechanisms to search and find the optimal data service solution considering cost of data management and service maintenance. Tadashi <ce:cross-ref id=""""r0270"""" refid=""""b0625"""">[125][[ refid=''''b0625'''' ]]</ce:cross-ref> gave a review for biological communication (molecular communication) inspired by the cell and cell-to-cell communication. The data transformation and the communication between different computing units in Big Data systems maybe borrow some useful ideas from cells. In <ce:cross-ref id=""""c0615"""" refid=""""b0700"""">[140][[ refid=''''b0700'''' ]]</ce:cross-ref> two hardware processing architecture for modeling large networks of leaky-integrate-and-fire neurons, that integrate bio-inspired neural processing models into real-world control environments. Sergio <ce:cross-ref id=""""c0620"""" refid=""""b0080"""">[16][[ refid=''''b0080'''' ]]</ce:cross-ref> demonstrated self-synchronization mechanism, which borrowed from biological systems, as the basic tool for achieving globally optimal distributed decisions in a wireless sensor network.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Big Data tools: techniques and technologies	Sanjay Ranka, Sartaj Sahni, Clustering on a hypercube multicomputer , IEEE Trans. Parallel Distrib. Syst. , vol. 2 (1991), pp.532-536	http://dx.doi.org/10.1016/j.ins.2014.01.015	data		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0750	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0066		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0220	'Clustering Big Data is also developing to distributed and parallel implementation [150][[ refid=''b0750'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0210"""" view=""""all""""><ce:bold>Data mining</ce:bold> is a set of techniques to extract valuable information (patterns) from data, including clustering analysis, classification, regression and association rule learning. It involves the methods from machine learning and statistics. Big Data mining is more challenging compared with traditional data mining algorithms. Taking clustering as an example, a natural way of clustering Big Data is to extend existing methods (such as hierarchical clustering, K-Mean, and Fuzzy C-Mean) so that they can cope with the huge workloads <ce:cross-refs id=""""r0110"""" refid=""""b1025 b0195 b0120"""">[205,39,24][[ refid=''''b1025 b0195 b0120'''' ]]</ce:cross-refs>. Most extensions usually rely on analyzing a certain amount of samples of Big Data, and vary in how the sample-based results are used to derive a partition for the overall data. This kind of clustering algorithms <ce:cross-ref id=""""c0260"""" refid=""""b0450"""">[90][[ refid=''''b0450'''' ]]</ce:cross-ref> include CLARA (Clustering LARge Applications) algorithm, CLARANS (Clustering Large Applications based upon RANdomized Search), BIRCH (Balanced Iterative Reducing using Cluster Hierarchies) algorithm, and so on. Genetic algorithms are also applied to clustering as optimization criterion to reflect the goodness. Clustering Big Data is also developing to distributed and parallel implementation <ce:cross-ref id=""""c0265"""" refid=""""b0750"""">[150][[ refid=''''b0750'''' ]]</ce:cross-ref>. Taking discriminant analysis as another example, researchers try to develop effective algorithm for large-scale discriminant analysis <ce:cross-refs id=""""r0115"""" refid=""""b0165 b0825"""">[33,165][[ refid=''''b0165 b0825'''' ]]</ce:cross-refs>. The emphasis is on the reduction of computational complexity. Taking bioinformatics as another example, it becomes increasingly data-driven that leads to paradigm change from traditional single-gene biology to the approaches that combine integrative database analysis and data mining <ce:cross-ref id=""""c0270"""" refid=""""b0115"""">[23][[ refid=''''b0115'''' ]]</ce:cross-ref>. This new paradigm enables the synthesis of large-scale portraits of genome function.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Underlying technologies and future researches	Stuart P. Lloyd, Least squares quantization in pcm , IEEE Trans. Inf. Theory , vol. 28 (1982), pp.129-137	http://dx.doi.org/10.1016/j.ins.2014.01.015			http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/br/b0535	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/ctx/ctx0153		161	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2014-01-015/itrp/0235	'In essence, quantum computing [107][[ refid=''b0535'' ]] is to harness and exploit the powerful laws of quantum mechanics to process information.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0595"""" view=""""all"""">In essence, quantum computing <ce:cross-ref id=""""c0630"""" refid=""""b0535"""">[107][[ refid=''''b0535'''' ]]</ce:cross-ref> is to harness and exploit the powerful laws of quantum mechanics to process information. In a traditional computer, information is presented by long strings of bits which encode either a zero or a one. Differently, A quantum computer uses quantum bits or qubits. The difference between qubit and bit is that, a qubit is a quantum system that encodes the zero and the one into two distinguishable quantum states. Because qubits behave quantumly, we can capitalize on the phenomena of “superposition” and “entanglement” <ce:cross-ref id=""""c0635"""" refid=""""b0010"""">[2][[ refid=''''b0010'''' ]]</ce:cross-ref>. For example, 100 qubits in quantum systems require <mml:math altimg=""""si7.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msup><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>100</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math> complex values to be stored in classical computer systems. Nielsen and Chuang pointed out that “Trying to store all these complex numbers would not be possible on any conceivable classical computer” <ce:cross-ref id=""""r0275"""" refid=""""b0645"""">[129][[ refid=''''b0645'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Cloud security challenges	K. Hashizume, D.G. Rosado, E. Fernndez-Medina, E.B. Fernandez, An analysis of security issues for cloud computing , J. Internet Services Appl. , vol. 4 (2013), pp.1-13	http://dx.doi.org/10.1016/j.ins.2015.01.025			http://www.scar.disi.unibo.it/r/10-1016-j-ins-2015-01-025/br/b0195	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2015-01-025/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2015-01-025/ctx/ctx0090		212	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2015-01-025/itrp/0026	'Moreover, if the data backup process is outsourced to a third party by the CSP, risks boundary is also broadened [39][[ refid=''b0195'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0205"""" view=""""all"""">Besides the data at rest, the data being processed also comes across security risks <ce:cross-ref id=""""c0400"""" refid=""""b0495"""">[99][[ refid=''''b0495'''' ]]</ce:cross-ref>. Due to virtualization physical resources are shared among multiple tenants. This eventually may allow malicious users (sharing computing resources) to launch attacks on the data of other users while in processing phase <ce:cross-refs id=""""r0050"""" refid=""""b0195 b0325"""">[39,65][[ refid=''''b0195 b0325'''' ]]</ce:cross-refs>. Moreover, if the data backup process is outsourced to a third party by the CSP, risks boundary is also broadened <ce:cross-ref id=""""c0405"""" refid=""""b0195"""">[39][[ refid=''''b0195'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_extends_semweb
extends	Introduction	M. Zimmermann, E. Ntoutsi, M. Spiliopoulou, Extracting opinionated (sub)features from a stream of product reviews , Proceedings of the 16th International Conference on Discovery Science, Springer (2013)	http://dx.doi.org/10.1016/j.ins.2015.06.050	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2015-06-050/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2015-06-050/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2015-06-050/ctx/ctx0005		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2015-06-050/itrp/0028	'From the earlier version [1][[ refid=''bib0001'' ]], we have taken over the related work discussion (Section 2); we have expanded the related work though w.r.t. to our extension.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0004"""" view=""""all"""">From the earlier version <ce:cross-ref id=""""crf0010"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>, we have taken over the related work discussion (<ce:cross-ref id=""""crf0011"""" refid=""""sec0002"""">Section 2</ce:cross-ref>); we have expanded the related work though w.r.t. to our extension. Furthermore, we took over the first three parts of <ce:cross-ref id=""""crf0012"""" refid=""""sec0007"""">Section 3</ce:cross-ref>, where we introduce our definitions and present the earlier <ce:sans-serif>T-SentiStream</ce:sans-serif> before extending it in <ce:cross-ref id=""""crf0013"""" refid=""""sec0011"""">Section 3.4</ce:cross-ref> with a cluster merging component for better adaptation to the drifting stream. The experimental <ce:cross-ref id=""""crf0014"""" refid=""""sec0012"""">Section 4</ce:cross-ref> is completely rewritten: (i) we run extensive experiments on <ce:sans-serif>T-SentiStream</ce:sans-serif> and we compare it with the <ce:sans-serif>T-SentiStream*</ce:sans-serif> extension; (ii) for the evaluation, we use the criteria introduced in <ce:cross-ref id=""""crf0015"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>, and we introduce further criteria to quantify the behavior of the algorithms; (iii) we vary the values of several parameters and observe their impact on the performance of <ce:sans-serif>T-SentiStream</ce:sans-serif> and <ce:sans-serif>T-SentiStream*</ce:sans-serif>; (iv) next to the originally used dataset, we consider one further, larger dataset. The last concluding section is also rewritten.</ce:para>""''"'	extends	ANG	
extends	Introduction	I. García-Magariño, I. Plaza, FTS-SOCI: an agent-based framework for simulating teaching strategies with evolutions of sociograms , Simul. Model. Pract. Theory , vol. 57 (2015), pp.161-178	http://dx.doi.org/10.1016/j.ins.2016.01.063	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-01-063/br/bib0020	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-01-063/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-01-063/ctx/ctx0016		52	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-01-063/itrp/0057	'The current work extends our previous work about the FTS-SOCI tool [20][[ refid=''bib0020'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">The current work extends our previous work about the FTS-SOCI tool <ce:cross-ref id=""""crf0026"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>. The most relevant improvements are (a) the clustering process for obtaining the student types in the training phase, (b) the classification of students according to their psychological features, and (c) the enhancement of experiments, based on 38 real sociograms instead of two, and considering four sociometrics instead of two.</ce:para>""''"'	extends	ANG	
extends	Introduction	T.T. Truyen, D.Q. Phung, S. Venkatesh, Preference networks: Probabilistic models for recommendation systems , The 6th Australasian Data Mining Conference (AusDM), ACS , vol. vol. 70 (2007), pp.195-202	http://dx.doi.org/10.1016/j.ins.2016.06.027	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-06-027/br/bib0031	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-06-027/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-06-027/ctx/ctx0006		36	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-06-027/itrp/0034	'To summary, this paper extends our previous work on Preference Networks [31][[ refid=''bib0031'' ]] with the following contributions:•A novel use of ℓ1-regularized Markov random fields for structure learning in the context of collaborative filtering.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">To summary, this paper extends our previous work on Preference Networks <ce:cross-ref id=""""crf0024"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> with the following contributions:<ce:list id=""""celist0002""""><ce:list-item id=""""celistitem0001""""><ce:label>•</ce:label><ce:para id=""""para0007"""" view=""""all"""">A novel use of ℓ<ce:inf loc=""""post"""">1</ce:inf>-regularized Markov random fields for structure learning in the context of collaborative filtering. This is novel compared to other use of MRFs for collaborative filtering, where the networks must be specified by hand.</ce:para></ce:list-item><ce:list-item id=""""celistitem0002""""><ce:label>•</ce:label><ce:para id=""""para0008"""" view=""""all"""">The networks studied here are 3–4 orders of magnitude larger than those used in previous work of structure learning for MRFs. To reduce the computational complexity, we proposes to use top <ce:italic>m</ce:italic> popular users and items to build the connections in the network. We will show that this simple strategy works well with little loss in accuracy.</ce:para></ce:list-item><ce:list-item id=""""celistitem0003""""><ce:label>•</ce:label><ce:para id=""""para0009"""" view=""""all"""">A byproduct of our structure learning framework are item-item and user-user graphs, which are useful for visualization and further analysis.</ce:para></ce:list-item><ce:list-item id=""""celistitem0004""""><ce:label>•</ce:label><ce:para id=""""para0010"""" view=""""all"""">A comprehensive evaluation of ℓ<ce:inf loc=""""post"""">1</ce:inf>-regularized MRFs on two large-scale applications: movie recommendation, and online dating. The datasets are much larger than the one tested in <ce:cross-ref id=""""crf0025"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>: the movie dataset used here is 100 times larger, and the online dating is 170 times larger. Compared to the most recent work based on MRF <ce:cross-ref id=""""crf0026"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>, our movie dataset is 3.6 times larger, and our online dating set is 6.2 times larger.</ce:para></ce:list-item></ce:list></ce:para>""''"'	extends	ANG	
extends	Conclusion	T.T. Truyen, D.Q. Phung, S. Venkatesh, Preference networks: Probabilistic models for recommendation systems , The 6th Australasian Data Mining Conference (AusDM), ACS , vol. vol. 70 (2007), pp.195-202	http://dx.doi.org/10.1016/j.ins.2016.06.027	conclusion		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-06-027/br/bib0031	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-06-027/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-06-027/ctx/ctx0032		36	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-06-027/itrp/0042	'This paper extends our previous work of Preference Networks [31][[ refid=''bib0031'' ]] for collaborative filtering.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0077"""" view=""""all"""">This paper extends our previous work of Preference Networks <ce:cross-ref id=""""crf0119"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> for collaborative filtering. Unlike prior work where MRF structures must be specified by hand, this work jointly discovers item-item and user-user networks from data in a principled manner. We adapt ℓ<ce:inf loc=""""post"""">1</ce:inf>-regularized Markov random fields <ce:cross-ref id=""""crf0120"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> for large-scale structure learning, where the density of these networks can be easily controlled by a hyper-parameter. In our work on collaborative filtering, the MRFs are several order of magnitude larger than those previously studied in <ce:cross-ref id=""""crf0121"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. To cope with very large networks, we propose a simple method to reduce the complexity by several orders of magnitude through selecting a small neighborhood size with little loss of accuracy.</ce:para>""''"'	extends	ANG	
extends	Introduction	M.R. Bouadjenek, H. Hacid, M. Bouzeghoub, A. Vakali, Using Social Annotations to Enhance Document Representation for Personalized Search , Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval, ACM (2013)	http://dx.doi.org/10.1016/j.ins.2016.07.046	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-07-046/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-07-046/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-07-046/ctx/ctx0003		39	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-07-046/itrp/0031	'Our approach in this work is an extension of the basic one proposed in [10][[ refid=''bib0010'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">Our approach in this work is an extension of the basic one proposed in <ce:cross-ref id=""""crf0027"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. We rely on users’ annotations as a source of social information, which are associated to documents in bookmarking systems. As illustrated in <ce:cross-ref id=""""crf0001a"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref><ce:float-anchor refid=""""fig0001""""/>, the textual content of a document is shared between users under a common representation, i.e., all terms in a document are identically shared and presented to users as in the classic Vector Space Model (VSM), while the annotations given by a user to this document express his/her personal understanding of its content. Thus, these annotations express a personal representation of this document to this user. For example, as illustrated in <ce:cross-ref id=""""crf0001b"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref>, the red annotations given by <ce:italic>Bob</ce:italic> to the document express his personal representation/view of this document. On the other hand, the green annotations constitute the personal representation of this document to Alice since she has used them to describe the document’s content. In this paper, our main objective is to answer the following question: <ce:italic>How to formalize a personal representation of a document in a social collaborative setting, and how to use this representation in document search to, hopefully, improve the search quality?</ce:italic></ce:para>""''"'	extends	ANG	
extends	The RBMs and related works	N. Phan, D. Dou, H. Wang, D. Kil, B. Piniewski, Ontology-based deep learning for human behavior prediction in health social networks , ACM BCB’15 (2015)	http://dx.doi.org/10.1016/j.ins.2016.08.038	related work		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-08-038/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-08-038/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-08-038/ctx/ctx0018		40	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-08-038/itrp/0044	'This paper is an extension of our conference paper published in ACM BCB 2015 [23][[ refid=''bib0023'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0021"""" view=""""all"""">This paper is an extension of our conference paper published in ACM BCB 2015 <ce:cross-ref id=""""crf0040"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. The major extensions we have engaged are: (1) We have improved our previous ORBM model, not only so that it more accurately predicts human behavior, but also, so that it can generate explanations for each predicted behavior. We introduce a new temporal-smoothing social influence function to better capture the evolving of social influence over time. We further incorporate physical activity-based social influence into our function. We also introduce a new algorithm to quantitatively estimate the effects and roles of human behavior determinants in predicted behaviors. (2) An extensive experiment has been conducted on both real-world and synthetic health social networks to validate the effectiveness of our model, the roles of human behavior determinants, and the quality of generated explanations.</ce:para>""''"'	extends	ANG	
extends	Introduction	R. Dupre, V. Argyriou, D. Greenhill, G. Tzimiropoulos, A 3D scene analysis framework and descriptors for risk evaluation , International Conference on 3D Vision (3DV), IEEE (2015)	http://dx.doi.org/10.1016/j.ins.2016.08.075	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-08-075/br/bib0017	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-08-075/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-08-075/ctx/ctx0004		46	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2016-08-075/itrp/0030	'This work is an extension of the paper [17][[ refid=''bib0017'' ]] and introduces the following contributions.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0004"""" view=""""all"""">This work is an extension of the paper <ce:cross-ref id=""""crf0022"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> and introduces the following contributions. A) the novel robust kernel for 3D descriptors in comparison to the work in <ce:cross-ref id=""""crf0023"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>, B) an advanced boosting mechanism that supports complex data for supervised learning, C) a novel shape descriptor based on Newtonian Physics and D) an enriched version on the 3DRS data set. In more details; the robust kernel for 3D descriptors is suggested, which can reduce the effects that outliers have in the supervised learning mechanisms. Secondly, Complex and Hyper-Complex variants of Adaboost <ce:cross-ref id=""""crf0024"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> are presented, which provide an increase in computational efficiency. Thirdly, the Physics Behaviour Feature (PBF) descriptor is introduced utilising the physical properties of an object to identify hazardous objects. This is achieved through the application of Newtonian Physics and the estimation of an object’s angular velocity after the application of a force. Our final contribution is the enriched version of the 3D Risk Scenes (3DRS) dataset with additional objects, meta-data and risk scenes to create a more challenging and complete dataset for 3D scene risk analysis.</ce:para>""''"'	extends	ANG	
cites_as_review	Introduction	D. Lahat, T. Adali, C. Jutten, Multimodal data fusion: an overview of methods, challenges, and prospects , Proc. IEEE , vol. 103 (2015), pp.1449-1477	http://dx.doi.org/10.1016/j.ins.2017.08.004	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-004/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-004/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-004/ctx/ctx0004		57	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-004/itrp/0038	'Each descriptor can be regarded as an independent acquisition framework, termed as a modality [18][[ refid=''bib0018'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0001"""" view=""""all"""">Multi-modal fusion aims to combine information related to the same object acquired from different types of detectors, multiple sources or various conditions <ce:cross-refs id=""""crfs0001"""" refid=""""bib0003 bib0004 bib0018"""">[3,4,18][[ refid=''''bib0003 bib0004 bib0018'''' ]]</ce:cross-refs>. This task has attracted more and more research interests due to the widespread use in real-world applications, such as visual object classification <ce:cross-refs id=""""crfs0002"""" refid=""""bib0029 bib0030"""">[29,30][[ refid=''''bib0029 bib0030'''' ]]</ce:cross-refs>, tactile object recognition <ce:cross-ref id=""""crf0007"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>, robotics <ce:cross-refs id=""""crfs0003"""" refid=""""bib0027 bib0042"""">[27,42][[ refid=''''bib0027 bib0042'''' ]]</ce:cross-refs> and medical informatics <ce:cross-refs id=""""crfs0004"""" refid=""""bib0046 bib0047"""">[46,47][[ refid=''''bib0046 bib0047'''' ]]</ce:cross-refs>. In particular, Liu et al. <ce:cross-ref id=""""crf0008"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> originally developed a visual-tactile fusion framework for object recognition to enhance the performance significantly which indeed provided an effective strategy for multi-modal fusion. Inspired by this method, we focus on the application of multi-modal fusion to visual object classification since image/video object contains heterogeneous features acquired from different visual descriptors essentially. Each descriptor can be regarded as an independent acquisition framework, termed as a modality <ce:cross-ref id=""""crf0009"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. It is highly expected to take at least two features of image/video into account, each of which contains not only relevant information to the other features but also specific details that are different and irrelevant. This corresponds to the two significant principles ensuring the success of multiple feature learning: <ce:italic>consensus</ce:italic> and <ce:italic>complementary</ce:italic><ce:cross-ref id=""""crf0010"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref>. The goal of <ce:italic>consensus</ce:italic> principle is to maximize the agreement of multiple views in classification. Under <ce:italic>complementary</ce:italic> principle, classifiers with respect to each view will exchange complementary information with each other and thus learn from each other during the training process.</ce:para>""''"'	cites	ANG	
cites_as_review	Proposed method	Y. Bengio, A. Courville, P. Vincent, Representation learning: a review and new perspectives , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 35 (2013), pp.1798-1828	http://dx.doi.org/10.1016/j.ins.2017.08.026	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-026/br/bib0003>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-026/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-026/ctx/ctx0035>				http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-026/itrp/0042	'The semantic content of an image is characterized by its high-level representation learned from the entire image using, for instance, a CNN [3][[ refid=''bib0003'' ]].'			FDY+AGA	infered_pred1
cites_as_review	Related works	Y. Bengio, A. Courville, P. Vincent, Representation learning: a review and new perspectives , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 35 (2013), pp.1798-1828	http://dx.doi.org/10.1016/j.ins.2017.08.026	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-026/br/bib0003>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-026/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-026/ctx/ctx0032>				http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-026/itrp/0049	'Apart from CNN, auto-encoder is another commonly used algorithm for unsupervised representation learning [3][[ refid=''bib0003'' ]].'			FDY+AGA	infered_pred1
uses_data_from	Experiments	W. Jiang, D. Lee, S. Hu, Large-scale longitudinal analysis of SOAP-based and RESTful web services , Proceedings of the International Conference on Web Services (IWCS’2012), Hawaii, USA (2012)	http://dx.doi.org/10.1016/j.ins.2017.08.065	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/br/bib0013	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/ctx/ctx0027		32	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/itrp/0009	'We conducted our experiments using the QOS_WSDL dataset [13][[ refid=''bib0013'' ]], which includes measurements of quality attributes’ values for more than 1548 real world Web services.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0075"""" view=""""all"""">We conducted our experiments using the QOS_WSDL dataset <ce:cross-ref id=""""crf0049"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>, which includes measurements of quality attributes’ values for more than 1548 real world Web services. The evaluations are repeated during 38 different weeks for the following attributes: maximum response time, minimum response time, average response time, throughput (number of invocations for a given period of time), successability (number of successful invocations with respect to the total number of invocations), response size (the average size of response messages), and invoking times (number of invocations).</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experiments	M. Charrad, N. Ghazzali, V. Boiteau, A. Niknafs, NbClust: an R package for determining the relevant number of clusters in a dataset , J. Stat. Softw. , vol. 61 (2014), pp.1-36	http://dx.doi.org/10.1016/j.ins.2017.08.065	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/ctx/ctx0028		32	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/itrp/0012	'In this step, we use NbClust package written in R [10][[ refid=''bib0010'' ]] to find the best number of clusters.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0078"""" view=""""all"""">Next, the best number of clusters has to be defined. As mentioned before, three experiments are conducted to find the best number of clusters in our dataset. In this step, we use <ce:bold>NbClust</ce:bold> package written in R <ce:cross-ref id=""""crf0051"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref> to find the best number of clusters. The first method we use is the elbow method. It is a visual technique that starts with number of clusters <ce:italic>K</ce:italic>=2. It keeps increasing <ce:italic>K</ce:italic> in each step by 1 and calculating the clusters and the cost that comes with the training. The cost is defined as the total within cluster sum of squares, which is the sum of squared distances of each object to its cluster centroid. At some value of <ce:italic>K</ce:italic>, the cost drops dramatically and after that it reaches a plateau. This is the <ce:italic>K</ce:italic> value that represents the best number of clusters <ce:cross-ref id=""""crf0052"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>. <ce:cross-ref id=""""crf0053"""" refid=""""fig0002"""">Fig. 2</ce:cross-ref><ce:float-anchor refid=""""fig0002""""/> shows that the best number of clusters is 3 using the elbow method. It is worth to note that the best number of clusters is 3 and not 4 since the variation of the cost between 2–3 and 3–4 is not huge. Accordingly, 3 is selected instead of 4. It is the bend (knee) that indicates the point to be selected. The number of clusters 2 is not selected since still there is no prior variation (we have only one variation: 1–2). The second conducted experiment uses the silhouette method as shown in <ce:cross-ref id=""""crf0054"""" refid=""""fig0003"""">Fig. 3</ce:cross-ref><ce:float-anchor refid=""""fig0003""""/>. Again, the best number of clusters is 3.</ce:para>""''"'	cites	AGA	
cites	Experiments	P. Bholowalia, A. Kumar, A clustering technique based on elbow method and k-means in WSN , Int. J. Comput. Appl. , vol. 105 (2014), pp.17-24	http://dx.doi.org/10.1016/j.ins.2017.08.065	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/br/bib0007	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/ctx/ctx0029		32	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/itrp/0013	'This is the K value that represents the best number of clusters [7][[ refid=''bib0007'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0078"""" view=""""all"""">Next, the best number of clusters has to be defined. As mentioned before, three experiments are conducted to find the best number of clusters in our dataset. In this step, we use <ce:bold>NbClust</ce:bold> package written in R <ce:cross-ref id=""""crf0051"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref> to find the best number of clusters. The first method we use is the elbow method. It is a visual technique that starts with number of clusters <ce:italic>K</ce:italic>=2. It keeps increasing <ce:italic>K</ce:italic> in each step by 1 and calculating the clusters and the cost that comes with the training. The cost is defined as the total within cluster sum of squares, which is the sum of squared distances of each object to its cluster centroid. At some value of <ce:italic>K</ce:italic>, the cost drops dramatically and after that it reaches a plateau. This is the <ce:italic>K</ce:italic> value that represents the best number of clusters <ce:cross-ref id=""""crf0052"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>. <ce:cross-ref id=""""crf0053"""" refid=""""fig0002"""">Fig. 2</ce:cross-ref><ce:float-anchor refid=""""fig0002""""/> shows that the best number of clusters is 3 using the elbow method. It is worth to note that the best number of clusters is 3 and not 4 since the variation of the cost between 2–3 and 3–4 is not huge. Accordingly, 3 is selected instead of 4. It is the bend (knee) that indicates the point to be selected. The number of clusters 2 is not selected since still there is no prior variation (we have only one variation: 1–2). The second conducted experiment uses the silhouette method as shown in <ce:cross-ref id=""""crf0054"""" refid=""""fig0003"""">Fig. 3</ce:cross-ref><ce:float-anchor refid=""""fig0003""""/>. Again, the best number of clusters is 3.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments	G. Brock, V. Pihur, S. Datta, S. Datta, clValid: an R package for cluster validation , J. Stat. Softw. , vol. 25 (2008), pp.1-22	http://dx.doi.org/10.1016/j.ins.2017.08.065	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/br/bib0008	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/ctx/ctx0031		32	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/itrp/0028	'The experiments in this step are conducted by using the R package clValid [8][[ refid=''bib0008'' ]], which compares different clustering algorithms for the sake of identifying the best clustering algorithm.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0082"""" view=""""all"""">The next step in the clustering process is to find the best clustering algorithm. The experiments in this step are conducted by using the R package <ce:bold>clValid</ce:bold> <ce:cross-ref id=""""crf0058"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>, which compares different clustering algorithms for the sake of identifying the best clustering algorithm. clValid selected hierarchical clustering as shown in <ce:cross-ref id=""""crf0059"""" refid=""""tbl0002"""">Table 2</ce:cross-ref><ce:float-anchor refid=""""tbl0002""""/>. Therefore, in this work we apply hierarchical clustering with number of clusters equal to 3.</ce:para>""''"'	uses_method_in	AGA	
cites	Experiments	R. Tibshirani, G. Walther, T. Hastie, Estimating the number of clusters in a dataset via the gap statistic , J. R. Stat. Soc.: Ser. B , vol. 63 (2001), pp.411-423	http://dx.doi.org/10.1016/j.ins.2017.08.065	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/br/bib0028	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/ctx/ctx0030		32	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/itrp/0029	'The gap statistics was proposed by Tibshirani et al. [28][[ refid=''bib0028'' ]] to estimate the number of clusters in clustering analysis.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0079"""" view=""""all"""">The last conducted experiment to find the best number of clusters is performed using the gap statistics. The gap statistics was proposed by Tibshirani et al. <ce:cross-ref id=""""crf0055"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> to estimate the number of clusters in clustering analysis. Its idea is based on comparing the change in within-cluster dispersion with the increase of the number of clusters as expected under a reference distribution. The reference dataset is generated using Monte Carlo simulations of the sampling process. <ce:bold>NbClust</ce:bold> package implements the gap statistics with other indices to find the best number of clusters. It provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods. The output of applying the 30 indices with our dataset is depicted in <ce:cross-ref id=""""crf0056"""" refid=""""tbl0001"""">Table 1</ce:cross-ref><ce:float-anchor refid=""""tbl0001""""/>. As shown, the majority of indices indicates that the best number of clusters is 3. Moreover, <ce:cross-ref id=""""crf0057"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref><ce:float-anchor refid=""""fig0004""""/> shows the graphical representation of the output. Thus, a number of three clusters was suggested and confirmed by the three experiments.</ce:para>""''"'	cites	AGA	
cites	Experiments	A. Alshatri, Z. Tari, A. Alamri, I. Khalil, A. Zomaya, S. Foufou, A. Bouras, A survey of clustering algorithms for big data: taxonomy and empirical analysis , IEEE Trans. Emerg. Top. Comput. , vol. 2 (2014), pp.267-279	http://dx.doi.org/10.1016/j.ins.2017.08.065	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/br/bib0003	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/ctx/ctx0032		32	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/itrp/0030	'In [3][[ refid=''bib0003'' ]], the authors concluded that no clustering algorithm performs well in all the evaluation criteria.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0085"""" view=""""all"""">From the tables, we can see that the single-linkage with Pearson correlation distance enjoy good results in terms of DB, RS, RMSSTD, and SE. For the complete linkage algorithm, the Euclidean distance performs better in most of validation tests whereas for Ward’s algorithm the Euclidean performs better in terms of RS, RMSSTD and S measures. It can be concluded that the Euclidean distance performs well on the average. In <ce:cross-ref id=""""crf0064"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>, the authors concluded that no clustering algorithm performs well in all the evaluation criteria. Hence, we can conclude that the single linkage hierarchical clustering algorithm with the Euclidean distance measure performs well for our dataset. It is worth to note that Dynamic Time Warping is not a suitable distance measure to be used in our approach since we are clustering services based on their Haar coefficients rather than the time series itself. Dynamic Time Warping is known to be very convenient for clustering time series data.</ce:para>""''"'	uses_method_in	AGA	
cites_as_review	Unsupervised clustering in the Haar transform space	A. Alshatri, Z. Tari, A. Alamri, I. Khalil, A. Zomaya, S. Foufou, A. Bouras, A survey of clustering algorithms for big data: taxonomy and empirical analysis , IEEE Trans. Emerg. Top. Comput. , vol. 2 (2014), pp.267-279	http://dx.doi.org/10.1016/j.ins.2017.08.065			<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/br/bib0003>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/ctx/ctx0012>				http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-08-065/itrp/0036	'Hierarchical and partitioning are the main clustering techniques [3][[ refid=''bib0003'' ]].'			FDY+AGA	infered_pred1
cites	Experiments	P. Resnick, N. Iacovou, M. Suchak, P. Bergstrom, J. Riedl, GroupLens: an open architecture for collaborative filtering of netnews , Proceedings of the 1994 ACM Conference on Computer Supported Cooperative Work, ACM (1994)	http://dx.doi.org/10.1016/j.ins.2017.09.001	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/br/bib0038	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/ctx/ctx0099		117	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/itrp/0043	'UCF denotes the traditional CF approach proposed by Resnick et al. [38],[[ refid=''bib0038'' ]] which uses the similarity between users to predict missing ratings.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0100"""" view=""""all""""><ce:bold>UCF</ce:bold> denotes the traditional CF approach proposed by Resnick et al. <ce:cross-ref id=""""crf0248"""" refid=""""bib0038"""">[38],[[ refid=''''bib0038'''' ]]</ce:cross-ref> which uses the similarity between users to predict missing ratings. UCF measures the similarity between users using the Pearson correlation coefficient <ce:cross-ref id=""""crf0249"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Experiments	B. Sarwar, G. Karypis, J. Konstan, J. Riedl, Item-based collaborative filtering recommendation algorithms , Proceedings of the 10th International Conference on World Wide Web, ACM (2001)	http://dx.doi.org/10.1016/j.ins.2017.09.001	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/ctx/ctx0101		117	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/itrp/0102	'ICF denotes the traditional item-based CF approach proposed by Sarwar et al. [39][[ refid=''bib0039'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0101"""" view=""""all""""><ce:bold>ICF</ce:bold> denotes the traditional item-based CF approach proposed by Sarwar et al. <ce:cross-ref id=""""crf0250"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>. This approach uses the adjusted cosine similarity as the similarity measure.</ce:para>""''"'	cites	AGA	
cites	Experiments	J.S. Breese, D. Heckerman, C. Kadie, Empirical analysis of predictive algorithms for collaborative filtering , Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence, Morgan Kaufmann Publishers Inc (1998)	http://dx.doi.org/10.1016/j.ins.2017.09.001	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/br/bib0008	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/ctx/ctx0100		117	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/itrp/0103	'UCF measures the similarity between users using the Pearson correlation coefficient [8][[ refid=''bib0008'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0100"""" view=""""all""""><ce:bold>UCF</ce:bold> denotes the traditional CF approach proposed by Resnick et al. <ce:cross-ref id=""""crf0248"""" refid=""""bib0038"""">[38],[[ refid=''''bib0038'''' ]]</ce:cross-ref> which uses the similarity between users to predict missing ratings. UCF measures the similarity between users using the Pearson correlation coefficient <ce:cross-ref id=""""crf0249"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Experiments	B.K. Patra, R. Launonen, V. Ollikainen, S. Nandi, A new similarity measure using Bhattacharyya coefficient for collaborative filtering in sparse data , Knowl.-Based Syst. , vol. 82 (2015), pp.163-177	http://dx.doi.org/10.1016/j.ins.2017.09.001	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/br/bib0036	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/ctx/ctx0103		117	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/itrp/0104	'BCCF denotes the CF approach presented in [36][[ refid=''bib0036'' ]] which uses a novel similarity measure based on the Bhattacharyya Coefficient.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0103"""" view=""""all""""><ce:bold>BCCF</ce:bold> denotes the CF approach presented in <ce:cross-ref id=""""crf0252"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref> which uses a novel similarity measure based on the Bhattacharyya Coefficient. The proposed similarity measure utilizes all ratings made by a pair of users.</ce:para>""''"'	cites	AGA	
cites	Experiments	J. Bobadilla, F. Ortega, A. Hernando, J. Bernal, A collaborative filtering approach to mitigate the new user cold start problem , Knowl.-Based Syst. , vol. 26 (2012), pp.225-238	http://dx.doi.org/10.1016/j.ins.2017.09.001	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/br/bib0007	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/ctx/ctx0102		117	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/itrp/0105	'MJDCF stands for the approach proposed by Bobadilla et al. [7][[ refid=''bib0007'' ]] to mitigate the new user cold-start problem.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0102"""" view=""""all""""><ce:bold>MJDCF</ce:bold> stands for the approach proposed by Bobadilla et al. <ce:cross-ref id=""""crf0251"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> to mitigate the new user cold-start problem. This approach uses a new similarity measure, called Mean-Jaccard-Differences (MJD), to calculate the similarity between users. MJD combines the numerical information of ratings and the distribution of ratings.</ce:para>""''"'	cites	AGA	
cites	Experiments	H. Liu, Z. Hu, A. Mian, H. Tian, X. Zhu, A new user similarity model to improve the accuracy of collaborative filtering , Knowl.-Based Syst. , vol. 56 (2014), pp.156-166	http://dx.doi.org/10.1016/j.ins.2017.09.001	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/ctx/ctx0105		117	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/itrp/0106	'EUCF is the entropy-based UCF approach proposed by Kaleli [27][[ refid=''bib0027'' ]] to improve neighborhood formation in UCF.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0105"""" view=""""all""""><ce:bold>EUCF</ce:bold> is the entropy-based UCF approach proposed by Kaleli <ce:cross-ref id=""""crf0254"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> to improve neighborhood formation in UCF. In this approach, the neighborhood formation process is considered as an optimization problem which aims to minimize the entropy difference between users while maximizing the similarity between them.</ce:para>""''"'	cites	AGA	
cites	Experiments	A. Mnih, R.R. Salakhutdinov, Probabilistic matrix factorization , Adv. Neural Inf. Process. Syst. , vol. 20 (2008), pp.1257-1264	http://dx.doi.org/10.1016/j.ins.2017.09.001	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/br/bib0029	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/ctx/ctx0104		117	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/itrp/0107	'MFCF is a model-based CF approach which uses a basic MF model [29][[ refid=''bib0029'' ]] to predict unknown ratings.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0104"""" view=""""all""""><ce:bold>MFCF</ce:bold> is a model-based CF approach which uses a basic MF model <ce:cross-ref id=""""crf0253"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> to predict unknown ratings. MFCF only uses the user-item rating matrix to learn the latent features of users and items.</ce:para>""''"'	cites	AGA	
cites	Experiments	Q. Shambour, J. Lu, An effective recommender system by unifying user and item trust information for B2B applications , J. Comput. Syst. Sci , vol. 81 (2015), pp.1110-1126	http://dx.doi.org/10.1016/j.ins.2017.09.001	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/br/bib0042	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/ctx/ctx0107		117	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/itrp/0108	'HUIT, proposed by Shambour and Lu [42][[ refid=''bib0042'' ]], is a hybrid of the user-based and item-based trust recommendation approaches.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0107"""" view=""""all""""><ce:bold>HUIT</ce:bold>, proposed by Shambour and Lu <ce:cross-ref id=""""crf0256"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>, is a hybrid of the user-based and item-based trust recommendation approaches. This approach fuses the implicit trust information of users and items within the CF framework.</ce:para>""''"'	cites	AGA	
cites	Experiments	C. Kaleli, An entropy-based neighbor selection approach for collaborative filtering , Knowl.-Based Syst. , vol. 56 (2014), pp.273-280	http://dx.doi.org/10.1016/j.ins.2017.09.001	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/br/bib0021	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/ctx/ctx0106		117	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/itrp/0109	'EICF is the entropy-based ICF approach [21][[ refid=''bib0021'' ]] which solves the optimization problem of selecting the best neighbors of a target item based on the similarity and entropy difference between the target item and other items.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0106"""" view=""""all""""><ce:bold>EICF</ce:bold> is the entropy-based ICF approach <ce:cross-ref id=""""crf0255"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> which solves the optimization problem of selecting the best neighbors of a target item based on the similarity and entropy difference between the target item and other items.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments	J.S. Breese, D. Heckerman, C. Kadie, Empirical analysis of predictive algorithms for collaborative filtering , Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence, Morgan Kaufmann Publishers Inc (1998)	http://dx.doi.org/10.1016/j.ins.2017.09.001	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/br/bib0008	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/ctx/ctx0108		117	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-001/itrp/0111	'"''""For each test user, based on the """"Given − n"""" experimental protocol [8][[ refid=''''bib0008'''' ]], n ratings are randomly chosen as the training ratings and the remaining ratings are used as the test ratings.""''"'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0113"""" view=""""all"""">In our experiments, we use 5-fold cross-validation to evaluate the performance of each approach over multiple runs. That is, the set of users in a data set is randomly split into 5 disjoint subsets of approximately equal size (called folds). In each evaluation run, 1 subset (almost 20% of users) is used as the test set and the other 4 subsets (almost 80% of users) as the training set. For each test user, based on the """"Given <ce:italic>− n</ce:italic>"""" experimental protocol <ce:cross-ref id=""""crf0265"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>, <ce:italic>n</ce:italic> ratings are randomly chosen as the training ratings and the remaining ratings are used as the test ratings. The test ratings are treated as unseen ratings that the system would attempt to predict. This procedure is repeated 5 times until each fold is tested once. The results of all the evaluation runs are then averaged to obtain the overall performance.</ce:para>""''"'	uses_method_in	AGA	
cites_as_review	Related works	F. Laurer, G. Bloch, Incorporating prior knowledge in support vector machines for classification: a review , Neurocomputing , vol. 71 (2009), pp.1578-1594	http://dx.doi.org/10.1016/j.ins.2017.09.023	related work		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-023/br/bib0016	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-023/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-023/ctx/ctx0012		42	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-09-023/itrp/0053	'Some scientists directly incorporated relation rules into the learning mechanism [16][[ refid=''bib0016'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">Some scientists directly incorporated relation rules into the learning mechanism <ce:cross-ref id=""""crf0035"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>. Fung et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref> proposed incorporating prior knowledge into a linear SVM classifier in the form of convex constraints in the input space. Based on the method, many new algorithms have been developed in recent years. Maclin et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> refined the incorrect knowledge and incorporated correct prior knowledge into an SVM. Diligenti et al. <ce:cross-ref id=""""crf0167"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> proposed a general framework to convert first-order logic (FOL) clauses to constraints on real-valued functions by T-norms and incorporate the constraints into a semi-supervised multitask learning scheme. Gori et al. <ce:cross-ref id=""""crf0038"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> introduced equivalent constraints, a constraint checking problem, support constraints, and a constraint induction mechanism in semi-supervised learning problems. Gori et al. <ce:cross-ref id=""""crf0039"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref> also proposed a general scheme for constraint verification using kernel machines and applied the framework of learning to infer new constraints from old constraints based on kernel-based representations. Maggini et al. <ce:cross-ref id=""""crf0040"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> introduced a selection criterion based on a Gauss function in the penalty function to reduce the constraint effect on some points that yield an exception. However, these proposed methods attempt to incorporate prior knowledge into SVMs for classification.</ce:para>""''"'	cites	ANG	
cites	Material and methods	A. Borji, L. Itti, State-of-the-art in visual attention modeling , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 35 (2013), pp.185-207	http://dx.doi.org/10.1016/j.ins.2017.10.011	methods	materials	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/br/bib0006	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/ctx/ctx0034		38	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/itrp/0034	'According to the object-based attention theory [6][[ refid=''bib0006'' ]], human visual processing starts with the segmentation of an image into connected regions, which are also termed as proto-objects or pre-attentive objects.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0041"""" view=""""all"""">According to the object-based attention theory <ce:cross-ref id=""""crf0065"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>, human visual processing starts with the segmentation of an image into connected regions, which are also termed as proto-objects or <ce:italic>pre-attentive objects</ce:italic>. Each proto-object is then assigned an importance value, which is called its saliency score. Then the attention or focus reaches the most salient proto-object in the scene or image. In the present scenario, after generating the saliency map (consisting of the saliency value of each voxel), the most salient (or main) 3D proto-object is extracted by segmentation using an adaptive threshold (<ce:cross-ref id=""""crf0066"""" refid=""""fig0007"""">Fig. 7</ce:cross-ref><ce:float-anchor refid=""""fig0007""""/>) selected as the mean of the local gray scale distribution.</ce:para>""''"'	cites	FDY	
uses_method_in	Experimental results	B. Menze, The multimodal brain tumor image segmentation benchmark (BRATS) , IEEE Trans. Med. Imaging , vol. 34 (2014), pp.1993-2024	http://dx.doi.org/10.1016/j.ins.2017.10.011	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/br/bib0028	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/ctx/ctx0037		38	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/itrp/0035	'Table 2 provides a comparative study of five other state-of-the-art segmentation algorithms developed for brain tumor segmentation, along with SGC and AGC, as applied on the BRATS database [28][[ refid=''bib0028'' ]] and measuring accuracy in terms of DICE as well as average time of computation (in min) as evaluated on CPU-based and cluster architectures.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0072"""" view=""""all""""><ce:cross-ref id=""""crf0094"""" refid=""""tbl0002"""">Table 2</ce:cross-ref><ce:float-anchor refid=""""tbl0002""""/> provides a comparative study of five other state-of-the-art segmentation algorithms developed for brain tumor segmentation, along with SGC and AGC, as applied on the BRATS database <ce:cross-ref id=""""crf0095"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> and measuring accuracy in terms of <ce:italic>DICE</ce:italic> as well as average time of computation (in min) as evaluated on CPU-based and cluster architectures. It is observed that AGC performs the best on both counts. It is also to be noted that all supervised algorithms consume additional training and preprocessing time.<ce:list id=""""celist0001s""""><ce:list-item id=""""celistitem0001s""""><ce:label><ce:bold>(ii)</ce:bold></ce:label><ce:para id=""""para0073"""" view=""""all""""><ce:bold>Reliability and Robustness</ce:bold></ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_data_from	FDY	
uses_method_in	Experimental results	B. Menze, The multimodal brain tumor image segmentation benchmark (BRATS) , IEEE Trans. Med. Imaging , vol. 34 (2014), pp.1993-2024	http://dx.doi.org/10.1016/j.ins.2017.10.011	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/br/bib0028	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/ctx/ctx0036		38	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/itrp/0036	'Ground truth generation protocol for the BRATS database uses the FLAIR and T2 MR sequences for the process [28][[ refid=''bib0028'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0065"""" view=""""all"""">Three independent observers, having adequate knowledge in semi-automatic segmentation and blinded to each other, were required to individually segment the whole tumor region(s) for this purpose. Ground truth generation protocol for the BRATS database uses the <ce:italic>FLAIR</ce:italic> and <ce:italic>T</ce:italic>2 MR sequences for the process <ce:cross-ref id=""""crf0081"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. In order to maintain parity we employed only these two sequences during segmentation by SGC and AGC. While in SGC each observer manually selects a seed ROI randomly from the corresponding ground truth image, in case of AGC a label map is automatically generated from the saliency map.</ce:para>""''"'	uses_data_from	FDY	
uses_method_in	Material and methods	A.K. Jain, Fundamentals of Digital Image Processing , None, Prentice-Hall, Englewood Cliffs , vol. 3 (1989), pp.None	http://dx.doi.org/10.1016/j.ins.2017.10.011	methods	materials	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/br/bib0021	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/ctx/ctx0030		38	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/itrp/0039	'Here ΔE76=∥Vi−Vj∥, with ‖.‖ expressing the L2-norm [21][[ refid=''bib0021'' ]] and Vi=Li*,ai*,bi*,Vj=Lj*,aj*,bj*.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0025"""" view=""""all"""">Since our saliency detection algorithm depends on the center-surround difference of a region with its neighbors, based on the pixel color values, a perceptually uniform color space that decorrelates luminance from chrominance information becomes desirable. Therefore we choose to transform the RGB space to the International Commission on Illumination (CIE)-recommended <mml:math altimg=""""si1.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>C</mml:mi><mml:mi>I</mml:mi><mml:mi>E</mml:mi><mml:mspace width=""""0.16em""""/><mml:mo>−</mml:mo><mml:mspace width=""""0.16em""""/><mml:msup><mml:mi>L</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:msup><mml:mi>a</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:msup><mml:mi>b</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math> domain, with the Euclidean distance <ce:italic>ΔE</ce:italic><ce:inf loc=""""post"""">76</ce:inf> representing the color difference. Here <mml:math altimg=""""si2.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mstyle mathvariant=""""normal""""><mml:mi>Δ</mml:mi></mml:mstyle><mml:msub><mml:mi>E</mml:mi><mml:mn>76</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∥</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> with ‖.‖ expressing the <ce:italic>L</ce:italic><ce:inf loc=""""post"""">2</ce:inf>-norm <ce:cross-ref id=""""crf0038"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> and <mml:math altimg=""""si3.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>b</mml:mi><mml:mi>i</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math><mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:mrow></mml:math>. Converting an <ce:italic>RGB</ce:italic> image to <ce:italic>L</ce:italic>*<ce:italic>a</ce:italic>*<ce:italic>b</ce:italic>* results in the separation of luminosity (layer <ce:italic>L</ce:italic>*) and chromaticity (layer <ce:italic>a</ce:italic>*, which indicates the position of the color along the red-green axis, and layer <ce:italic>b</ce:italic>*, which represents the position of the color along the blue-yellow axis). <ce:cross-ref id=""""crf0039"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref><ce:float-anchor refid=""""fig0001""""/> shows sample MRI sequences and <ce:cross-ref id=""""crf0040"""" refid=""""fig0002"""">Fig. 2</ce:cross-ref><ce:float-anchor refid=""""fig0002""""/> illustrates the corresponding <ce:italic>L</ce:italic>*<ce:italic>a</ce:italic>*<ce:italic>b</ce:italic>* converted MR images.</ce:para>""''"'	cites	FDY	
cites	Material and methods	E. Erdem, A. Erdem, Visual saliency estimation by nonlinearly integrating features using region covariances , J. Vis. , vol. 13 (2013), pp.11	http://dx.doi.org/10.1016/j.ins.2017.10.011	methods	materials	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/br/bib0011	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/ctx/ctx0033		38	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/itrp/0040	'Thus our algorithm is simultaneously employed over multiple scales, analogous to [11][[ refid=''bib0011'' ]], for capturing the salient region(s) in the MR image at different levels of resolution.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0036"""" view=""""all"""">Re-scaling is performed to bring back the saliency maps to the original image size (<ce:italic>M</ce:italic> × <ce:italic>N</ce:italic>) using Bilinear interpolation <ce:cross-ref id=""""crf0046"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>. Let <mml:math altimg=""""si18.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msup><mml:mover accent=""""true""""><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msup></mml:math> denote the interpolated image at its original size, as generated from the saliency map <ce:italic>S<ce:sup loc=""""post"""">k</ce:sup></ce:italic> at scale <ce:italic>k</ce:italic>. Since the properties of a region depend on the pixels within it, saliency prediction is governed by both its size and scale. Thus our algorithm is simultaneously employed over multiple scales, analogous to <ce:cross-ref id=""""crf0047"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>, for capturing the salient region(s) in the <ce:italic>MR</ce:italic> image at different levels of resolution. Those region(s) consistently highlighted over different resolutions are deemed to be the ones most likely to be salient. Therefore we superimpose these saliency maps, corresponding to the different scales, for computing the final map. For example, the integrated map over the four scales (of <ce:cross-ref id=""""crf0048"""" refid=""""fig0003"""">Fig. 3</ce:cross-ref>) contains all important information and is depicted in <ce:cross-ref id=""""crf0049"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref><ce:float-anchor refid=""""fig0004""""/>(a). The final saliency map is now computed as<ce:display><ce:formula id=""""eq0003""""><ce:label>(3)</ce:label><mml:math altimg=""""si19.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd columnalign=""""right""""><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mn>16</mml:mn><mml:mo>,</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:munder><mml:msup><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>×</mml:mo><mml:msup><mml:mover accent=""""true""""><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where <ce:italic>r<ce:sup loc=""""post"""">k</ce:sup></ce:italic> is the weight corresponding to the saliency map at size <ce:italic>k</ce:italic>. In the present study we have chosen <ce:italic>r<ce:sup loc=""""post"""">k</ce:sup></ce:italic> = 1/4, ∀ <ce:italic>k</ce:italic>. Finally a 25 × 25 mean filter is applied to smoothen the saliency map <ce:italic>S</ce:italic>, in order to help focus on the core region within the actual ROI in the resized image. This is depicted in <ce:cross-ref id=""""crf0050"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref>(b), and acts as the reference map for subsequent segmentation.</ce:para>""''"'	uses_method_in	FDY	
uses_method_in	Material and methods	E. Erdem, A. Erdem, Visual saliency estimation by nonlinearly integrating features using region covariances , J. Vis. , vol. 13 (2013), pp.11	http://dx.doi.org/10.1016/j.ins.2017.10.011	methods	materials	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/br/bib0011	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/ctx/ctx0032		38	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-011/itrp/0041	'Re-scaling is performed to bring back the saliency maps to the original image size (M × N) using Bilinear interpolation [11][[ refid=''bib0011'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0036"""" view=""""all"""">Re-scaling is performed to bring back the saliency maps to the original image size (<ce:italic>M</ce:italic> × <ce:italic>N</ce:italic>) using Bilinear interpolation <ce:cross-ref id=""""crf0046"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>. Let <mml:math altimg=""""si18.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msup><mml:mover accent=""""true""""><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msup></mml:math> denote the interpolated image at its original size, as generated from the saliency map <ce:italic>S<ce:sup loc=""""post"""">k</ce:sup></ce:italic> at scale <ce:italic>k</ce:italic>. Since the properties of a region depend on the pixels within it, saliency prediction is governed by both its size and scale. Thus our algorithm is simultaneously employed over multiple scales, analogous to <ce:cross-ref id=""""crf0047"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>, for capturing the salient region(s) in the <ce:italic>MR</ce:italic> image at different levels of resolution. Those region(s) consistently highlighted over different resolutions are deemed to be the ones most likely to be salient. Therefore we superimpose these saliency maps, corresponding to the different scales, for computing the final map. For example, the integrated map over the four scales (of <ce:cross-ref id=""""crf0048"""" refid=""""fig0003"""">Fig. 3</ce:cross-ref>) contains all important information and is depicted in <ce:cross-ref id=""""crf0049"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref><ce:float-anchor refid=""""fig0004""""/>(a). The final saliency map is now computed as<ce:display><ce:formula id=""""eq0003""""><ce:label>(3)</ce:label><mml:math altimg=""""si19.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd columnalign=""""right""""><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mn>16</mml:mn><mml:mo>,</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:munder><mml:msup><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>×</mml:mo><mml:msup><mml:mover accent=""""true""""><mml:mi>S</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where <ce:italic>r<ce:sup loc=""""post"""">k</ce:sup></ce:italic> is the weight corresponding to the saliency map at size <ce:italic>k</ce:italic>. In the present study we have chosen <ce:italic>r<ce:sup loc=""""post"""">k</ce:sup></ce:italic> = 1/4, ∀ <ce:italic>k</ce:italic>. Finally a 25 × 25 mean filter is applied to smoothen the saliency map <ce:italic>S</ce:italic>, in order to help focus on the core region within the actual ROI in the resized image. This is depicted in <ce:cross-ref id=""""crf0050"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref>(b), and acts as the reference map for subsequent segmentation.</ce:para>""''"'	uses_method_in	FDY	
cites	Experiments	G. Pio, M. Ceci, D. D’Elia, C. Loglisci, D. Malerba, A novel biclustering algorithm for the discovery of meaningful biological correlations between micrornas and their target genes , BMC Bioinform. , vol. 14 (2013), pp.S8	http://dx.doi.org/10.1016/j.ins.2017.10.021	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/br/bib0033	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/ctx/ctx0046		52	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/itrp/0016	'In order to evaluate the clusters identified by HENPC, we performed a comparison with the system HOCCLUS2 [33][[ refid=''bib0033'' ]], which also discovers possibly overlapping and hierarchically organized clusters.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0119"""" view=""""all"""">In order to evaluate the clusters identified by HENPC, we performed a comparison with the system HOCCLUS2 <ce:cross-ref id=""""crf0092"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref>, which also discovers possibly overlapping and hierarchically organized clusters. It is tailored to work with two object types (i.e., it is a co-clustering algorithm) and was originally used in bioinformatics to discover biological correlations between microRNAs and target genes.</ce:para>""''"'	uses_method_in	FDY	
uses_method_in	Experiments	M.E.J. Newman, Modularity and community structure in networks , Proc. Natl. Acad. Sci. , vol. 103 (2006), pp.8577-8582	http://dx.doi.org/10.1016/j.ins.2017.10.021	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/br/bib0032	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/ctx/ctx0047		52	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/itrp/0017	'In particular, the identified clusters are evaluated in terms of a variant of the Q-Modularity [32][[ refid=''bib0032'' ]], which measures the quality of the clustering with respect to a random clustering.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0120"""" view=""""all"""">In order to perform a fair comparison of the clustering results, we consider an evaluation measure which is different from the optimization criterion adopted by both HENPC and HOCCLUS2. In particular, the identified clusters are evaluated in terms of a variant of the Q-Modularity <ce:cross-ref id=""""crf0093"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, which measures the quality of the clustering with respect to a random clustering. This variant is described in the following. Let:<ce:display><ce:formula id=""""ueq0002""""><mml:math altimg=""""si109.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>e</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>|</mml:mo><mml:mi>E</mml:mi><mml:mo>∪</mml:mo></mml:mrow><mml:mover accent=""""true""""><mml:mi>E</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mover accent=""""true""""><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:mi>t</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></ce:formula></ce:display>be a measure of the strength of the edges considering objects in cluster <ce:italic>G</ce:italic>′ and objects in cluster <ce:italic>G</ce:italic>′′, where <ce:italic>tuples</ce:italic>(<ce:italic>G</ce:italic>′, <ce:italic>G</ce:italic>′′) is the set of tuples that can be built between objects of different types belonging to clusters <ce:italic>G</ce:italic>′ and <ce:italic>G</ce:italic>′′. Intuitively, we aim at clusters for which <ce:italic>e</ce:italic>(<ce:italic>G</ce:italic>′, <ce:italic>G</ce:italic>′) values are generally large and values <ce:italic>e</ce:italic>(<ce:italic>G</ce:italic>′, <ce:italic>G</ce:italic>′′), <ce:italic>G</ce:italic>′ ≠ <ce:italic>G</ce:italic>′′ are generally small. Inspired by Newman <ce:cross-ref id=""""crf0094"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, we define the Q-Modularity for the clusters obtained at a hierarchical level <ce:italic>i</ce:italic> as:<ce:display><ce:formula id=""""eq0011""""><ce:label>(11)</ce:label><mml:math altimg=""""si110.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy=""""true"""">[</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mi>e</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy=""""true"""">]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>As regards the classification task, we compare HENPC with four competitor systems which are able to work on data organized in a heterogeneous network. They are:<ce:list id=""""celist0013""""><ce:list-item id=""""celistitem0042""""><ce:label>•</ce:label><ce:para id=""""para0121"""" view=""""all""""><ce:bold>MrSBC</ce:bold><ce:cross-ref id=""""crf0095"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>,<ce:cross-ref id=""""crf0096"""" refid=""""fn0009""""><ce:sup loc=""""post"""">9</ce:sup></ce:cross-ref><ce:footnote id=""""fn0009""""><ce:label>9</ce:label><ce:note-para id=""""cenotep0009"""" view=""""all""""><ce:inter-ref id=""""interref0007"""" xlink:href=""""http://www.di.uniba.it/~ceci/micFiles/systems/MURENA.html"""" xlink:type=""""simple"""">www.di.uniba.it/~ceci/micFiles/systems/MURENA.html</ce:inter-ref>.</ce:note-para></ce:footnote> which exploits the naïve Bayes classification method in the multi-relational setting.</ce:para></ce:list-item><ce:list-item id=""""celistitem0043""""><ce:label>•</ce:label><ce:para id=""""para0122"""" view=""""all""""><ce:bold>RelIBk</ce:bold><ce:cross-ref id=""""crf0097"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>, which is the multi-relational version of the k-NN algorithm and is available in RelWeka.<ce:cross-ref id=""""crf0098"""" refid=""""fn0010""""><ce:sup loc=""""post"""">10</ce:sup></ce:cross-ref><ce:footnote id=""""fn0010""""><ce:label>10</ce:label><ce:note-para id=""""cenotep0010"""" view=""""all""""><ce:inter-ref id=""""interref0008"""" xlink:href=""""http://kappa.arisco.pl/~adamw/home_page/rel_weka/"""" xlink:type=""""simple"""">kappa.arisco.pl/~adamw/home_page/rel_weka/</ce:inter-ref>.</ce:note-para></ce:footnote> As the distance measure, we adopt the Relational Instance-Based Learning (RIBL) measure <ce:cross-ref id=""""crf0099"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0044""""><ce:label>•</ce:label><ce:para id=""""para0123"""" view=""""all""""><ce:bold>RelSMO</ce:bold><ce:cross-ref id=""""crf0100"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>, which is the multi-relational version of Platt’s Sequential Minimal Optimization algorithm <ce:cross-ref id=""""crf0101"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> and is available in RelWeka.<ce:sup loc=""""post"""">10</ce:sup> This algorithm is based on kernel Support Vector Machines and exploits the kernel Minkowski RIBL set distance <ce:cross-ref id=""""crf0102"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0045""""><ce:label>•</ce:label><ce:para id=""""para0124"""" view=""""all""""><ce:bold>GNetMine</ce:bold><ce:cross-ref id=""""crf0103"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref>, a graph-based regularization framework which aims at preserving the network structure of each type of link separately.</ce:para></ce:list-item></ce:list></ce:para>""''"'	cites	FDY	
cites 	Experiments	M. Ceci, A. Appice, D. Malerba, Mr-SBC: a multi-relational naive bayes classifier , Knowledge Discovery in Databases: PKDD 2003, Springer (2003)	http://dx.doi.org/10.1016/j.ins.2017.10.021	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/br/bib0006	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/ctx/ctx0049		52	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/itrp/0039	'They are:•MrSBC[6][[ refid=''bib0006'' ]],99www.di.uniba.it/~ceci/micFiles/systems/MURENA.html.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0120"""" view=""""all"""">In order to perform a fair comparison of the clustering results, we consider an evaluation measure which is different from the optimization criterion adopted by both HENPC and HOCCLUS2. In particular, the identified clusters are evaluated in terms of a variant of the Q-Modularity <ce:cross-ref id=""""crf0093"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, which measures the quality of the clustering with respect to a random clustering. This variant is described in the following. Let:<ce:display><ce:formula id=""""ueq0002""""><mml:math altimg=""""si109.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>e</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>|</mml:mo><mml:mi>E</mml:mi><mml:mo>∪</mml:mo></mml:mrow><mml:mover accent=""""true""""><mml:mi>E</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mover accent=""""true""""><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:mi>t</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></ce:formula></ce:display>be a measure of the strength of the edges considering objects in cluster <ce:italic>G</ce:italic>′ and objects in cluster <ce:italic>G</ce:italic>′′, where <ce:italic>tuples</ce:italic>(<ce:italic>G</ce:italic>′, <ce:italic>G</ce:italic>′′) is the set of tuples that can be built between objects of different types belonging to clusters <ce:italic>G</ce:italic>′ and <ce:italic>G</ce:italic>′′. Intuitively, we aim at clusters for which <ce:italic>e</ce:italic>(<ce:italic>G</ce:italic>′, <ce:italic>G</ce:italic>′) values are generally large and values <ce:italic>e</ce:italic>(<ce:italic>G</ce:italic>′, <ce:italic>G</ce:italic>′′), <ce:italic>G</ce:italic>′ ≠ <ce:italic>G</ce:italic>′′ are generally small. Inspired by Newman <ce:cross-ref id=""""crf0094"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, we define the Q-Modularity for the clusters obtained at a hierarchical level <ce:italic>i</ce:italic> as:<ce:display><ce:formula id=""""eq0011""""><ce:label>(11)</ce:label><mml:math altimg=""""si110.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy=""""true"""">[</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mi>e</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy=""""true"""">]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>As regards the classification task, we compare HENPC with four competitor systems which are able to work on data organized in a heterogeneous network. They are:<ce:list id=""""celist0013""""><ce:list-item id=""""celistitem0042""""><ce:label>•</ce:label><ce:para id=""""para0121"""" view=""""all""""><ce:bold>MrSBC</ce:bold><ce:cross-ref id=""""crf0095"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>,<ce:cross-ref id=""""crf0096"""" refid=""""fn0009""""><ce:sup loc=""""post"""">9</ce:sup></ce:cross-ref><ce:footnote id=""""fn0009""""><ce:label>9</ce:label><ce:note-para id=""""cenotep0009"""" view=""""all""""><ce:inter-ref id=""""interref0007"""" xlink:href=""""http://www.di.uniba.it/~ceci/micFiles/systems/MURENA.html"""" xlink:type=""""simple"""">www.di.uniba.it/~ceci/micFiles/systems/MURENA.html</ce:inter-ref>.</ce:note-para></ce:footnote> which exploits the naïve Bayes classification method in the multi-relational setting.</ce:para></ce:list-item><ce:list-item id=""""celistitem0043""""><ce:label>•</ce:label><ce:para id=""""para0122"""" view=""""all""""><ce:bold>RelIBk</ce:bold><ce:cross-ref id=""""crf0097"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>, which is the multi-relational version of the k-NN algorithm and is available in RelWeka.<ce:cross-ref id=""""crf0098"""" refid=""""fn0010""""><ce:sup loc=""""post"""">10</ce:sup></ce:cross-ref><ce:footnote id=""""fn0010""""><ce:label>10</ce:label><ce:note-para id=""""cenotep0010"""" view=""""all""""><ce:inter-ref id=""""interref0008"""" xlink:href=""""http://kappa.arisco.pl/~adamw/home_page/rel_weka/"""" xlink:type=""""simple"""">kappa.arisco.pl/~adamw/home_page/rel_weka/</ce:inter-ref>.</ce:note-para></ce:footnote> As the distance measure, we adopt the Relational Instance-Based Learning (RIBL) measure <ce:cross-ref id=""""crf0099"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0044""""><ce:label>•</ce:label><ce:para id=""""para0123"""" view=""""all""""><ce:bold>RelSMO</ce:bold><ce:cross-ref id=""""crf0100"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>, which is the multi-relational version of Platt’s Sequential Minimal Optimization algorithm <ce:cross-ref id=""""crf0101"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> and is available in RelWeka.<ce:sup loc=""""post"""">10</ce:sup> This algorithm is based on kernel Support Vector Machines and exploits the kernel Minkowski RIBL set distance <ce:cross-ref id=""""crf0102"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0045""""><ce:label>•</ce:label><ce:para id=""""para0124"""" view=""""all""""><ce:bold>GNetMine</ce:bold><ce:cross-ref id=""""crf0103"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref>, a graph-based regularization framework which aims at preserving the network structure of each type of link separately.</ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_method_in	FDY	
uses_method_in	Experiments	J. Demšar, Statistical comparisons of classifiers over multiple data sets , J. Mach. Learn. Res. , vol. 7 (2006), pp.1-30	http://dx.doi.org/10.1016/j.ins.2017.10.021	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/ctx/ctx0053		52	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/itrp/0059	'In order to statistically compare HENPC with HOCCLUS2, we performed the Friedman test with the Nemenyi post-hoc tests and, following the suggestions made in [10][[ refid=''bib0010'' ]], we plot the graphs which summarize the results in Fig. 6.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007a"""" view=""""all"""">In order to statistically compare HENPC with HOCCLUS2, we performed the Friedman test with the Nemenyi post-hoc tests and, following the suggestions made in <ce:cross-ref id=""""crf0106"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>, we plot the graphs which summarize the results in <ce:cross-ref id=""""crf0107"""" refid=""""fig0006"""">Fig. 6</ce:cross-ref><ce:float-anchor refid=""""fig0006""""/>. By observing the graphs, we can conclude that HENPC is able to significantly outperform the competitor in all the considered datasets, especially in the case of the first and the second level of the hierarchy. This confirms that, even stopping the algorithm at the first hierarchical level, the behavior of HENPC is robust, independently of the considered dataset.</ce:para>""''"'	uses_method_in	FDY	
uses_method_in	Experiments	G. Pio, M. Ceci, D. D’Elia, C. Loglisci, D. Malerba, A novel biclustering algorithm for the discovery of meaningful biological correlations between micrornas and their target genes , BMC Bioinform. , vol. 14 (2013), pp.S8	http://dx.doi.org/10.1016/j.ins.2017.10.021	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/br/bib0033	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/ctx/ctx0052		52	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/itrp/0060	'As regards the parameter α, we follow the recommendations in [33][[ refid=''bib0033'' ]], where a similar merging approach is proposed: We set α=β−0.2.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0128"""" view=""""all"""">As regards the parameters of HENPC, we set <mml:math altimg=""""si113.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math> (the number of considered shortest meta-paths), in order to guarantee that the best meta-paths are considered, and <mml:math altimg=""""si114.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math> (for the aggregation of attribute values coming from connected nodes which do not appear in any meta-paths). As for the parameter <ce:italic>β</ce:italic>, since the distribution of scores can vary significantly among datasets, we compute the value of <ce:italic>β</ce:italic> such that we keep a given percentage of tuples. In particular, we consider 20%%, 40%% and 60%% of tuples. This also allows us to evaluate how the accuracy of the results changes when the number of tuples increases. As regards the parameter <ce:italic>α</ce:italic>, we follow the recommendations in <ce:cross-ref id=""""crf0104"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref>, where a similar merging approach is proposed: We set <mml:math altimg=""""si115.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mi>β</mml:mi><mml:mo>−</mml:mo><mml:mn>0.2</mml:mn></mml:mrow></mml:math>. Finally, we set <ce:italic>γ</ce:italic> to the values {0.7, 0.8, 0.9}, which, according to some preliminary experiments, generally lead to the best results.</ce:para>""''"'	uses_method_in	FDY	
cites	Experiments	A. Woznica, A. Kalousis, M. Hilario, Learning to combine distances for complex representations , Machine Learning, Proceedings of ICML 2007 (2007)	http://dx.doi.org/10.1016/j.ins.2017.10.021	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/br/bib0048	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/ctx/ctx0050		52	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-021/itrp/0066	'which exploits the naïve Bayes classification method in the multi-relational setting.•RelIBk[48][[ refid=''bib0048'' ]], which is the multi-relational version of the k-NN algorithm and is available in RelWeka.1010kappa.arisco.pl/~adamw/home_page/rel_weka/.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0120"""" view=""""all"""">In order to perform a fair comparison of the clustering results, we consider an evaluation measure which is different from the optimization criterion adopted by both HENPC and HOCCLUS2. In particular, the identified clusters are evaluated in terms of a variant of the Q-Modularity <ce:cross-ref id=""""crf0093"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, which measures the quality of the clustering with respect to a random clustering. This variant is described in the following. Let:<ce:display><ce:formula id=""""ueq0002""""><mml:math altimg=""""si109.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>e</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>|</mml:mo><mml:mi>E</mml:mi><mml:mo>∪</mml:mo></mml:mrow><mml:mover accent=""""true""""><mml:mi>E</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mover accent=""""true""""><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>→</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:mi>t</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></ce:formula></ce:display>be a measure of the strength of the edges considering objects in cluster <ce:italic>G</ce:italic>′ and objects in cluster <ce:italic>G</ce:italic>′′, where <ce:italic>tuples</ce:italic>(<ce:italic>G</ce:italic>′, <ce:italic>G</ce:italic>′′) is the set of tuples that can be built between objects of different types belonging to clusters <ce:italic>G</ce:italic>′ and <ce:italic>G</ce:italic>′′. Intuitively, we aim at clusters for which <ce:italic>e</ce:italic>(<ce:italic>G</ce:italic>′, <ce:italic>G</ce:italic>′) values are generally large and values <ce:italic>e</ce:italic>(<ce:italic>G</ce:italic>′, <ce:italic>G</ce:italic>′′), <ce:italic>G</ce:italic>′ ≠ <ce:italic>G</ce:italic>′′ are generally small. Inspired by Newman <ce:cross-ref id=""""crf0094"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, we define the Q-Modularity for the clusters obtained at a hierarchical level <ce:italic>i</ce:italic> as:<ce:display><ce:formula id=""""eq0011""""><ce:label>(11)</ce:label><mml:math altimg=""""si110.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy=""""true"""">[</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:munder><mml:mrow><mml:mi>e</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo>′</mml:mo><mml:mo>′</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy=""""true"""">]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>As regards the classification task, we compare HENPC with four competitor systems which are able to work on data organized in a heterogeneous network. They are:<ce:list id=""""celist0013""""><ce:list-item id=""""celistitem0042""""><ce:label>•</ce:label><ce:para id=""""para0121"""" view=""""all""""><ce:bold>MrSBC</ce:bold><ce:cross-ref id=""""crf0095"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>,<ce:cross-ref id=""""crf0096"""" refid=""""fn0009""""><ce:sup loc=""""post"""">9</ce:sup></ce:cross-ref><ce:footnote id=""""fn0009""""><ce:label>9</ce:label><ce:note-para id=""""cenotep0009"""" view=""""all""""><ce:inter-ref id=""""interref0007"""" xlink:href=""""http://www.di.uniba.it/~ceci/micFiles/systems/MURENA.html"""" xlink:type=""""simple"""">www.di.uniba.it/~ceci/micFiles/systems/MURENA.html</ce:inter-ref>.</ce:note-para></ce:footnote> which exploits the naïve Bayes classification method in the multi-relational setting.</ce:para></ce:list-item><ce:list-item id=""""celistitem0043""""><ce:label>•</ce:label><ce:para id=""""para0122"""" view=""""all""""><ce:bold>RelIBk</ce:bold><ce:cross-ref id=""""crf0097"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>, which is the multi-relational version of the k-NN algorithm and is available in RelWeka.<ce:cross-ref id=""""crf0098"""" refid=""""fn0010""""><ce:sup loc=""""post"""">10</ce:sup></ce:cross-ref><ce:footnote id=""""fn0010""""><ce:label>10</ce:label><ce:note-para id=""""cenotep0010"""" view=""""all""""><ce:inter-ref id=""""interref0008"""" xlink:href=""""http://kappa.arisco.pl/~adamw/home_page/rel_weka/"""" xlink:type=""""simple"""">kappa.arisco.pl/~adamw/home_page/rel_weka/</ce:inter-ref>.</ce:note-para></ce:footnote> As the distance measure, we adopt the Relational Instance-Based Learning (RIBL) measure <ce:cross-ref id=""""crf0099"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0044""""><ce:label>•</ce:label><ce:para id=""""para0123"""" view=""""all""""><ce:bold>RelSMO</ce:bold><ce:cross-ref id=""""crf0100"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>, which is the multi-relational version of Platt’s Sequential Minimal Optimization algorithm <ce:cross-ref id=""""crf0101"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> and is available in RelWeka.<ce:sup loc=""""post"""">10</ce:sup> This algorithm is based on kernel Support Vector Machines and exploits the kernel Minkowski RIBL set distance <ce:cross-ref id=""""crf0102"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0045""""><ce:label>•</ce:label><ce:para id=""""para0124"""" view=""""all""""><ce:bold>GNetMine</ce:bold><ce:cross-ref id=""""crf0103"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref>, a graph-based regularization framework which aims at preserving the network structure of each type of link separately.</ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_method_in	FDY	
cites	Experimental results and discussion	'The Guardian, How Enron''s great water adventure ended in tears , None (2002) , https://www.theguardian.com/business/2002/nov/05/corporatefraud.enron'	http://dx.doi.org/10.1016/j.ins.2017.10.049	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/br/bib0048	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/ctx/ctx0041		53	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/itrp/0033	'This fact enabled Enron to provide water distribution services under the Azuris Corporation brand [48][[ refid=''bib0048'' ]], which is what causes the origin of a sudden concept drift.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0048"""" view=""""all"""">Starting with the Enron corpus, <ce:cross-ref id=""""crf0116"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref><ce:float-anchor refid=""""fig0004""""/> shows different charts to initially exemplify the results obtained from the execution of our experimental workflow over a legitimate corpus. Specifically, <ce:cross-ref id=""""crf0117"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref>(a) depicts a frequency analysis for the topic ‘body of water’ that clearly fits a sudden drift behaviour. In particular, this topic seems to be connected with the purchase of Wessex Water by the Enron Corporation in 1998. This fact enabled Enron to provide water distribution services under the Azuris Corporation brand <ce:cross-ref id=""""crf0118"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>, which is what causes the origin of a sudden concept drift. As seen from the example of <ce:cross-ref id=""""crf0119"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref>(b), the topic ‘reservoir’ appears in a gradual way. In fact, as commented in <ce:cross-ref id=""""crf0120"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> both ‘reservoir’ and ‘body of water’ topics are directly connected because the expansion of Wessex under the administration of Enron through Argentina forced an improvement to the water supply systems (such as water towers or cisterns) to avoid failures.</ce:para>""''"'	cites	FDY	
cites	Experimental results and discussion	'The Guardian, How Enron''s great water adventure ended in tears , None (2002) , https://www.theguardian.com/business/2002/nov/05/corporatefraud.enron'	http://dx.doi.org/10.1016/j.ins.2017.10.049	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/br/bib0048	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/ctx/ctx0042		53	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/itrp/0034	'In fact, as commented in [48][[ refid=''bib0048'' ]] both ‘reservoir’ and ‘body of water’ topics are directly connected because the expansion of Wessex under the administration of Enron through Argentina forced an improvement to the water supply systems (such as water towers or cisterns) to avoid failures.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0048"""" view=""""all"""">Starting with the Enron corpus, <ce:cross-ref id=""""crf0116"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref><ce:float-anchor refid=""""fig0004""""/> shows different charts to initially exemplify the results obtained from the execution of our experimental workflow over a legitimate corpus. Specifically, <ce:cross-ref id=""""crf0117"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref>(a) depicts a frequency analysis for the topic ‘body of water’ that clearly fits a sudden drift behaviour. In particular, this topic seems to be connected with the purchase of Wessex Water by the Enron Corporation in 1998. This fact enabled Enron to provide water distribution services under the Azuris Corporation brand <ce:cross-ref id=""""crf0118"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>, which is what causes the origin of a sudden concept drift. As seen from the example of <ce:cross-ref id=""""crf0119"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref>(b), the topic ‘reservoir’ appears in a gradual way. In fact, as commented in <ce:cross-ref id=""""crf0120"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> both ‘reservoir’ and ‘body of water’ topics are directly connected because the expansion of Wessex under the administration of Enron through Argentina forced an improvement to the water supply systems (such as water towers or cisterns) to avoid failures.</ce:para>""''"'	cites	FDY	
cites	Experimental results and discussion	R. Kohavi, A study of cross-validation and bootstrap for accuracy estimation and model selection , Proc. 14th Int. Jt. Conf. Artif. Intell. - Vol. 2, Morgan Kaufmann Publishers Inc (1995)	http://dx.doi.org/10.1016/j.ins.2017.10.049	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/br/bib0025	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/ctx/ctx0048		53	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/itrp/0055	'Additionally, it is also very common to use the stratified k-fold cross-validation schemes in the spam filtering domain to ensure the representativeness of each fold when compared to the whole data [25][[ refid=''bib0025'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0061"""" view=""""all"""">Additionally, it is also very common to use the stratified <ce:italic>k-fold</ce:italic> cross-validation schemes in the spam filtering domain to ensure the representativeness of each fold when compared to the whole data <ce:cross-ref id=""""crf0167"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. Due to the flexibility of our evaluation proposal, it can be easily adapted to a stratified scenario by a slight modification in the algorithm. To this end, stage 0 will carry out two main tasks: (<ce:italic>i</ce:italic>) build separate groups of e-mails for all the possible classes (ham and spam) and (<ce:italic>ii</ce:italic>) sort the messages of each class by date. This procedure facilitates the subsequent distribution of all the e-mails into folders while maintaining the same proportion of messages belonging to the same date and class.</ce:para>""''"'	uses_data_from	FDY	
cites	Experimental results and discussion	N. Pérez-Díaz, D. Ruano-Ordás, F. Fdez-Riverola, J.R. Méndez, SDAI: an integral evaluation methodology for content-based spam filtering models , Expert Syst. Appl. , vol. 39 (2012), pp.12487-12500	http://dx.doi.org/10.1016/j.ins.2017.10.049	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/br/bib0034	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/ctx/ctx0049		53	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/itrp/0056	'Specifically related to the evaluation methodology used in the spam filtering domain is the contribution of Pérez–Díaz et al. [34][[ refid=''bib0034'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0062"""" view=""""all"""">Specifically related to the evaluation methodology used in the spam filtering domain is the contribution of Pérez–Díaz et al. <ce:cross-ref id=""""crf0168"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref>. In their work, the authors define a methodology to evaluate the efficiency and suitability of classifiers depending on the intrinsic characteristics of the environment (by using a stratified 10-fold cross-validation scheme). The authors determine four possible scenarios: (<ce:italic>i</ce:italic>) static environment, where the global filter performance is evaluated within a controlled environment; (<ce:italic>ii</ce:italic>) dynamic operation, where the accuracy of the filter is measured using auto-updating schemes; (<ce:italic>iii</ce:italic>) adaptive skills, able to measure filter accuracy when classifying messages from multiple senders (covering different topics); and (<ce:italic>iv</ce:italic>) internationalisation, which gives specific support to measure the ability of each filter to classify e-mails written in different languages. Although this methodology has been used as a reference to evaluate the accuracy of different techniques in the spam filtering domain, its adoption alters the logical order of the dataset causing the existence of artificial concept drift, and therefore, hampers the adequate assessment of the accuracy of each classifier.</ce:para>""''"'	cites	FDY	
cites	Experimental results and discussion	S.J. Delany, P. Cunningham, A. Tsymbal, L. Coyle, A case-based technique for tracking concept drift in spam filtering , Knowl.-Based Syst. , vol. 18 (2005), pp.187-195	http://dx.doi.org/10.1016/j.ins.2017.10.049	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/ctx/ctx0044		53	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-049/itrp/0115	'However, the problems associated with this situation have remained untreated until 2005 [10][[ refid=''bib0010'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0057"""" view=""""all"""">After analysing the results commented so far, it is obvious that concept drift is a common phenomenon, which occurs in the e-mail domain. However, the problems associated with this situation have remained untreated until 2005 <ce:cross-ref id=""""crf0138"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. In fact, relevant research works introduced multiple and effective techniques to improve anti-spam filtering accuracy without dealing with this matter <ce:cross-refs id=""""crf0139"""" refid=""""bib0004 bib0008 bib0011 bib0016 bib0017 bib0021 bib0033 bib0035 bib0040 bib0043 bib0045"""">[4,8,11,16,17,21,33,35,40,43,45][[ refid=''''bib0004 bib0008 bib0011 bib0016 bib0017 bib0021 bib0033 bib0035 bib0040 bib0043 bib0045'''' ]]</ce:cross-refs>. In such a situation, and taking into consideration that the intrinsic characteristics associated with each type of concept drift require the use of specific learning approaches and classification techniques, the authors in <ce:cross-refs id=""""crf0150"""" refid=""""bib0014 bib0022"""">[14,22][[ refid=''''bib0014 bib0022'''' ]]</ce:cross-refs> recommend the use of (<ce:italic>i</ce:italic>) single classifiers for sudden drift and (<ce:italic>ii</ce:italic>) different types of ensembles for both gradual drift (dynamic ensemble) and reocurring drift (contextual-based ensemble). However, these general recommendations seem unsuitable for the e-mail domain, where gradual and sudden forms of concept drift were found (the filter should be built up of a single classifier or an ensemble of classifiers but not both).</ce:para>""''"'	cites	FDY	
uses_data_from	Experimental results and analysis	L. Zhang, Y. Han, Y. Yang, M. Song, S. Yan, Q. Tian, Discovering discriminative graphlets for aerial image categories recognition , IEEE T-IP , vol. 22 (2013), pp.5071-5084	http://dx.doi.org/10.1016/j.ins.2017.10.051	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/br/bib0063	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/ctx/ctx0027		41	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/itrp/0007	'We experiment on the following five image sets: 1) ZJU aerial image [63][[ refid=''bib0063'' ]], which comprises of 20,946 aerial images from 10 categories.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0027"""" view=""""all"""">We experiment on the following five image sets: 1) ZJU aerial image <ce:cross-ref id=""""crf0052"""" refid=""""bib0063"""">[63][[ refid=''''bib0063'''' ]]</ce:cross-ref>, which comprises of 20,946 aerial images from 10 categories. Most of the aerial images are collected from metropolises, such as New York, Tokyo, and Beijing; 2) USC scene <ce:cross-ref id=""""crf0053"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref>, which consists of 375 video clips of three USC campus sites, <ce:italic>i.e.</ce:italic>, Ahmanson Center for Biological Science (ACB), Associate and Founders Park (AnF), and Frederick D. Fagg Park (FDF); 3) Scene-15, which contains 4485 scene images from 15 categories. For each category, 100 scene images are adopted for training while the rest are for testing; 4) Scene-67, which is comprised of 15,620 scene images from 67 categories. We randomly select 80 images from each category for training while leaving the rest for testing; 5) LHI, which has 100 sports images from 5 categories. The ground-truth segmentation are provided and thus we leverage them to generate graphlets for visualization.</ce:para>""''"'	cites	FDY	
uses_data_from	Experimental results and analysis	C. Siagian, L. Itti, Rapid biologically-inspired scene classification using features shared with visual attention , IEEE T-PAMI , vol. 29 (2007), pp.300-312	http://dx.doi.org/10.1016/j.ins.2017.10.051	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/br/bib0050	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/ctx/ctx0028		41	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/itrp/0010	'Most of the aerial images are collected from metropolises, such as New York, Tokyo, and Beijing; 2) USC scene [50][[ refid=''bib0050'' ]], which consists of 375 video clips of three USC campus sites, i.e., Ahmanson Center for Biological Science (ACB), Associate and Founders Park (AnF), and Frederick D. Fagg Park (FDF); 3) Scene-15, which contains 4485 scene images from 15 categories.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0027"""" view=""""all"""">We experiment on the following five image sets: 1) ZJU aerial image <ce:cross-ref id=""""crf0052"""" refid=""""bib0063"""">[63][[ refid=''''bib0063'''' ]]</ce:cross-ref>, which comprises of 20,946 aerial images from 10 categories. Most of the aerial images are collected from metropolises, such as New York, Tokyo, and Beijing; 2) USC scene <ce:cross-ref id=""""crf0053"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref>, which consists of 375 video clips of three USC campus sites, <ce:italic>i.e.</ce:italic>, Ahmanson Center for Biological Science (ACB), Associate and Founders Park (AnF), and Frederick D. Fagg Park (FDF); 3) Scene-15, which contains 4485 scene images from 15 categories. For each category, 100 scene images are adopted for training while the rest are for testing; 4) Scene-67, which is comprised of 15,620 scene images from 67 categories. We randomly select 80 images from each category for training while leaving the rest for testing; 5) LHI, which has 100 sports images from 5 categories. The ground-truth segmentation are provided and thus we leverage them to generate graphlets for visualization.</ce:para>""''"'	cites	FDY	
cites	Experimental results and analysis	L. Zhang, C. Chen, J. Bu, D. Cai, X. He, T.S. Huang, Active learning based on locally linear reconstruction , IEEE T-PAMI , vol. 33 (2011), pp.2026-2038	http://dx.doi.org/10.1016/j.ins.2017.10.051	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/br/bib0060	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/ctx/ctx0035		41	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/itrp/0055	'To justify the usefulness of the second component, we compare it with the active learning algorithm proposed by Zhang et al. [60][[ refid=''bib0060'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0037"""" view=""""all"""">To justify the usefulness of the second component, we compare it with the active learning algorithm proposed by Zhang et al. <ce:cross-ref id=""""crf0068"""" refid=""""bib0060"""">[60][[ refid=''''bib0060'''' ]]</ce:cross-ref>. The weighting matrix in <ce:cross-ref id=""""crf0069"""" refid=""""bib0060"""">[60][[ refid=''''bib0060'''' ]]</ce:cross-ref> is determined by a graphlet and its spatial neighbors inside each scene image. Compared to <ce:cross-ref id=""""crf0070"""" refid=""""bib0060"""">[60][[ refid=''''bib0060'''' ]]</ce:cross-ref>, our approach can dynamically tune the importance of different channels. In addition, the sparsity constraint can ensure that only a small fraction of visually/semantically salient graphlets are selected for constructing the gaze shifting kernel.</ce:para>""''"'	cites	FDY	
cites	Experimental results and analysis	L. Zhang, Y. Han, Y. Yang, M. Song, S. Yan, Q. Tian, Discovering discriminative graphlets for aerial image categories recognition , IEEE T-IP , vol. 22 (2013), pp.5071-5084	http://dx.doi.org/10.1016/j.ins.2017.10.051	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/br/bib0063	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/ctx/ctx0034		41	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/itrp/0056	'Further in Table 1, we present the recognition accuracy per category on the ZJU Aerial image [63][[ refid=''bib0063'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0032"""" view=""""all"""">Further in <ce:cross-ref id=""""crf0064"""" refid=""""tbl0001"""">Table 1</ce:cross-ref>, we present the recognition accuracy per category on the ZJU Aerial image <ce:cross-ref id=""""crf0065"""" refid=""""bib0063"""">[63][[ refid=''''bib0063'''' ]]</ce:cross-ref>. As can be seen, our method outperforms its competitors on most of the 10 categories.</ce:para>""''"'	cites	FDY	
cites	Experimental results and analysis	L. Zhang, C. Chen, J. Bu, D. Cai, X. He, T.S. Huang, Active learning based on locally linear reconstruction , IEEE T-PAMI , vol. 33 (2011), pp.2026-2038	http://dx.doi.org/10.1016/j.ins.2017.10.051	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/br/bib0060	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/ctx/ctx0037		41	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/itrp/0057	'Compared to [60][[ refid=''bib0060'' ]], our approach can dynamically tune the importance of different channels.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0037"""" view=""""all"""">To justify the usefulness of the second component, we compare it with the active learning algorithm proposed by Zhang et al. <ce:cross-ref id=""""crf0068"""" refid=""""bib0060"""">[60][[ refid=''''bib0060'''' ]]</ce:cross-ref>. The weighting matrix in <ce:cross-ref id=""""crf0069"""" refid=""""bib0060"""">[60][[ refid=''''bib0060'''' ]]</ce:cross-ref> is determined by a graphlet and its spatial neighbors inside each scene image. Compared to <ce:cross-ref id=""""crf0070"""" refid=""""bib0060"""">[60][[ refid=''''bib0060'''' ]]</ce:cross-ref>, our approach can dynamically tune the importance of different channels. In addition, the sparsity constraint can ensure that only a small fraction of visually/semantically salient graphlets are selected for constructing the gaze shifting kernel.</ce:para>""''"'	cites	FDY	
cites	Experimental results and analysis	L. Zhang, C. Chen, J. Bu, D. Cai, X. He, T.S. Huang, Active learning based on locally linear reconstruction , IEEE T-PAMI , vol. 33 (2011), pp.2026-2038	http://dx.doi.org/10.1016/j.ins.2017.10.051	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/br/bib0060	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/ctx/ctx0036		41	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/itrp/0058	'The weighting matrix in [60][[ refid=''bib0060'' ]] is determined by a graphlet and its spatial neighbors inside each scene image.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0037"""" view=""""all"""">To justify the usefulness of the second component, we compare it with the active learning algorithm proposed by Zhang et al. <ce:cross-ref id=""""crf0068"""" refid=""""bib0060"""">[60][[ refid=''''bib0060'''' ]]</ce:cross-ref>. The weighting matrix in <ce:cross-ref id=""""crf0069"""" refid=""""bib0060"""">[60][[ refid=''''bib0060'''' ]]</ce:cross-ref> is determined by a graphlet and its spatial neighbors inside each scene image. Compared to <ce:cross-ref id=""""crf0070"""" refid=""""bib0060"""">[60][[ refid=''''bib0060'''' ]]</ce:cross-ref>, our approach can dynamically tune the importance of different channels. In addition, the sparsity constraint can ensure that only a small fraction of visually/semantically salient graphlets are selected for constructing the gaze shifting kernel.</ce:para>""''"'	cites	FDY	
uses_method_in	Experimental results and analysis	L.-J. Li, H. Su, E.P. Xing, L. Fei-Fei, Object bank: a high-level image representation for scene classification and semantic feature sparsification , Proceedings of NIPS (2010)	http://dx.doi.org/10.1016/j.ins.2017.10.051	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/br/bib0033	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/ctx/ctx0030		41	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/itrp/0061	'al [33][[ refid=''bib0033'' ]]: The number of generic object detectors is fixed at 200, different regularizers LR1,LRG, and LRG1 were used, and it also has three SPM levels.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0029"""" view=""""all"""">In our experiments, we compare our GSK with six shallow image descriptors: the walk and tree kernels <ce:cross-ref id=""""crf0054"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>, and four SPM-based generic object recognition models, namely, SPM <ce:cross-ref id=""""crf0055"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, SC-SPM <ce:cross-ref id=""""crf0056"""" refid=""""bib0056"""">[56][[ refid=''''bib0056'''' ]]</ce:cross-ref>, LLC-SPM <ce:cross-ref id=""""crf0057"""" refid=""""bib0052"""">[52][[ refid=''''bib0052'''' ]]</ce:cross-ref>, and object bank-based SPM (OB-SPM). The parameter settings for the six methods were as follows. For the walk and tree kernels: Their sizes were tuned from one to 10 and the best recognition accuracies were recorded. For SPM, SC-SPM, and LLC-SPM: We constructed a three level spatial pyramid; then extracted over one million SIFT descriptors from 16 × 16 patches computed over a grid with spacing of 8 pixels from all the training aerial images. Finally, a codebook was generated by k-means clustering on these SIFT descriptors. In our experiments, different codebook sizes: 256, 512, and 1024, were applied. For OB-SPM, we followed the setup used in the experiment conducted by Li et. al <ce:cross-ref id=""""crf0058"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref>: The number of generic object detectors is fixed at 200, different regularizers LR1,LRG, and LRG1 were used, and it also has three SPM levels.</ce:para>""''"'	cites	FDY	
uses_method_in	Experimental results and analysis	P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, Y. LeCun, Overfeat: integrated recognition, localization and detection using convolutional networks, 2013,	http://dx.doi.org/10.1016/j.ins.2017.10.051	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/br/bib0047	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/ctx/ctx0033		41	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/itrp/0062	'3) Overfeat-5, an architecture based on the Overfeat paper [47][[ refid=''bib0047'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0030"""" view=""""all"""">Besides, deeply-learned features have made revolutionary changes in image recognition recently. Therefore, it is necessary to compare our approach with representative deep architectures. Following <ce:cross-ref id=""""crf0059"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>, four baseline deep architectures are employed: 1) ZF-5, a deep architecture based on Zeiler and Ferguss (ZF) “fast” (smaller) model <ce:cross-ref id=""""crf0060"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>, wherein the number “5” indicates that there are 5 convolutional layers. 2) Convnet-5, a modification of Krizhevsky et al.s network <ce:cross-ref id=""""crf0061"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>. The two pooling layers are incorporated after conv2 and conv3. 3) Overfeat-5, an architecture based on the Overfeat paper <ce:cross-ref id=""""crf0062"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref>. Compared to ZF-5/Convnet-5, the architecture produces a larger feature map before the last pooling layer. A larger filter number (512) is deployed in conv3 as well as the following convolutional layers. 4) SPP (5-sc), spatial pyramid pooling by resizing each image into five different scales {480, 576, 688, 864, 1200}, each of which indicates the larger value of the image width and height. For each image scale, we adopt a three level max pooling onto each image. The pooling window sizes are 5, 7, and 13 respectively, and the corresponding stride are 4, 6, and 13.</ce:para>""''"'	cites	FDY	
uses_method_in	Experimental results and analysis	A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks , Proceedings of NIPS (2012)	http://dx.doi.org/10.1016/j.ins.2017.10.051	results	discussion	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/br/bib0031>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/ctx/ctx0032>				http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/itrp/0063	'2) Convnet-5, a modification of Krizhevsky et al.s network [31][[ refid=''bib0031'' ]].'			FDY+AGA	infered_pred1
uses_data_from	Experimental results and analysis	B. Yao, X. Yang, S.-C. Zhu, Introduction to a large scale general purpose ground truth dataset: methodology, annotation tool, and benchmarks , EMMCVPR (2007)	http://dx.doi.org/10.1016/j.ins.2017.10.051	methods	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/br/bib0057	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/ctx/ctx0039		41	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/itrp/0064	'Since the ground-truth segments from the LHI [57][[ refid=''bib0057'' ]] are provided, we experiment on this data set.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0042"""" view=""""all"""">Last but not least, it is worthwhile to visualize the top-ranked graphlets by leveraging our sparsity-constrained ranking algorithm. Since the ground-truth segments from the LHI <ce:cross-ref id=""""crf0075"""" refid=""""bib0057"""">[57][[ refid=''''bib0057'''' ]]</ce:cross-ref> are provided, we experiment on this data set. As can be seen from <ce:cross-ref id=""""crf0076"""" refid=""""fig0007"""">Fig. 7</ce:cross-ref><ce:float-anchor refid=""""fig0007""""/>, these top-ranked graphlets attract the attention of human eye accurately, by inspecting the comparative accuracies with real human gaze shifting paths. This observation can partially explain the effectiveness of our scene categorization model.</ce:para>""''"'	uses_data_from	FDY	
cites	Experimental results and analysis	L. Zhang, Y. Han, Y. Yang, M. Song, S. Yan, Q. Tian, Discovering discriminative graphlets for aerial image categories recognition , IEEE T-IP , vol. 22 (2013), pp.5071-5084	http://dx.doi.org/10.1016/j.ins.2017.10.051	methods	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/br/bib0063	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/ctx/ctx0038		41	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-10-051/itrp/0065	'This reveals that 4-sized graphlets are highly representative for describing the local composition of aerial images in [63][[ refid=''bib0063'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0041"""" view=""""all"""">To analyze the effects of the maximum graphlet size on scene categorization, we inspect scene categorization accuracy by varying <ce:italic>T</ce:italic> continuously. As shown the left of <ce:cross-ref id=""""crf0072"""" refid=""""fig0006"""">Fig. 6</ce:cross-ref><ce:float-anchor refid=""""fig0006""""/>, we report the scene classification accuracy (on the ZJU aerial images) when the maximum graphlet size is tuned from one to 10. As can be seen, categorization accuracy increases significantly when <ce:italic>T</ce:italic> ∈ [1, 4] but maintains stable when <ce:italic>T</ce:italic> ∈ [5, 10]. This reveals that 4-sized graphlets are highly representative for describing the local composition of aerial images in <ce:cross-ref id=""""crf0073"""" refid=""""bib0063"""">[63][[ refid=''''bib0063'''' ]]</ce:cross-ref>. Considering the fact that the time cost is exponentially increasing with the graphlet size, we set <mml:math altimg=""""si45.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math> in our experiment. As shown on the right of <ce:cross-ref id=""""crf0074"""" refid=""""fig0006"""">Fig. 6</ce:cross-ref>, we report the performance when the number of graphlet in a path (<ce:italic>K</ce:italic>) is increased from one to 10. As shown, the prediction accuracy enhances quickly when <ce:italic>K</ce:italic> ∈ [1, 7] but remains nearly unchanged when <ce:italic>K</ce:italic> ∈ [7, 10]. Therefore, we set <mml:math altimg=""""si46.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:math>. This observations is consistent with human visual perception. Typically, human eyes fix onto fewer than seven locations within each scenery, since seven locations can well describe the semantics of each image.</ce:para>""''"'	cites	FDY	
cites_as_review	Introduction	M. Smit, E. Stroulia, Simulating service-oriented systems: a survey and the services-aware simulation framework , IEEE Trans. Serv. Comput. , vol. 6 (2013), pp.443-456	http://dx.doi.org/10.1016/j.ins.2017.12.048	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-12-048/br/bib0032	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-12-048/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-12-048/ctx/ctx0001		51	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2017-12-048/itrp/0022	'Service- oriented architecture (SOA) patterns provide a flexible support for building software applications that use Web services available in typically large-scale and complex networks [32][[ refid=''bib0032'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0001"""" view=""""all"""">Service- oriented architecture (SOA) patterns provide a flexible support for building software applications that use Web services available in typically large-scale and complex networks <ce:cross-ref id=""""crf0008"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>. Web services are self-contained and loosely coupled reusable software components distributed and invoked over the Internet <ce:cross-ref id=""""crf0009"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>. Compared with traditional stand-alone environments, the stochastic and unpredictable nature of open distributed environments based on SOA introduces new challenges in improving service-oriented software reliability <ce:cross-ref id=""""crf0010"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>. Actually, the challenges are twofold. First, it is difficult to build fully reliable or fault-free service-based softwares under limited development cost and the pressure of time to market <ce:cross-ref id=""""crf0011"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. Then, it is uncertain whether users previously know which Web services are malicious. This is because the internal designs and implementation details of remote Web services from the third party are unclear to some extent <ce:cross-ref id=""""crf0012"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	ANG	
cites_as_review	Experiments and applications	A. Fahad, N. Alshatri, Z. Tari, None et al, A survey of clustering algorithms for big data: taxonomy and empirical analysis , IEEE Trans. Emerg. Top. Comput. , vol. 2 (2014), pp.267-279	http://dx.doi.org/10.1016/j.ins.2018.01.001	methods	motivation	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-01-001/br/bib0047	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-01-001/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-01-001/ctx/ctx0045		45	4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-01-001/itrp/0061	'Cluster Accuracy (CA) is introduced to evaluate the clustering algorithms and the classification algorithms [47][[ refid=''bib0047'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0101"""" view=""""all"""">Although the clustering algorithm is a kind of unsupervised learning algorithm, for which it is not necessary to label the samples in advance, we pre-defined the class labels for all the samples in this experiment for comparison with the classification algorithms. Cluster Accuracy (CA) is introduced to evaluate the clustering algorithms and the classification algorithms <ce:cross-ref id=""""crf0110"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref>. CA measures the ratio of the number of correctly classified / clustered instances to that of pre-defined class labels. Let <ce:italic>X</ce:italic> be the inspection dataset in this experiment, let <ce:italic>C</ce:italic> be the set of classes / clusters detected by the corresponding algorithm, and let <ce:italic>L</ce:italic> be the set of pre-defined class labels. CA is defined in <ce:cross-ref id=""""crf0111"""" refid=""""eq0015"""">Eq. (15)</ce:cross-ref>:<ce:display><ce:formula id=""""eq0015""""><ce:label>(15)</ce:label><mml:math altimg=""""si50.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>C</mml:mi><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mi>max</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>X</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>where <ce:italic>C<ce:inf loc=""""post"""">i</ce:inf></ce:italic> is the set of data points in the <ce:italic>i</ce:italic>th class/cluster, <ce:italic>L<ce:inf loc=""""post"""">i</ce:inf></ce:italic> is the set of pre-defined class labels of the data points in <ce:italic>C<ce:inf loc=""""post"""">i</ce:inf></ce:italic>, and <ce:italic>K</ce:italic> is the size of <ce:italic>C. max</ce:italic>(<ce:italic>C<ce:inf loc=""""post"""">i</ce:inf></ce:italic>|<ce:italic>L<ce:inf loc=""""post"""">i</ce:inf></ce:italic>) is the number of data points that have the majority label in <ce:italic>C<ce:inf loc=""""post"""">i</ce:inf></ce:italic>. The greater value of <ce:italic>CA</ce:italic>, the higher the accuracy of the classification/clustering algorithm and the greater the purity that each cluster achieves. The comparison results of disease-symptom clustering based on different algorithms are illustrated in <ce:cross-ref id=""""crf0112"""" refid=""""fig0012"""">Fig. 12</ce:cross-ref><ce:float-anchor refid=""""fig0012""""/>.</ce:para>""''"'	uses_method_in	ANG	
cites_as_review	Introduction	D. Artz, Y. Gil, A survey of trust in computer science and the semantic web , Web Semant. Sci. Serv. Agents World Wide Web , vol. 5 (2007), pp.58-71	http://dx.doi.org/10.1016/j.ins.2018.01.033	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-01-033/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-01-033/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-01-033/ctx/ctx0004	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-01-033/itrpl/bib0001-bib0027-ctx0004	29	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-01-033/itrp/0034	'In this context trust is generally intended as a measure of the assured reliance on a specific feature of someone [1,16,27][[ refid=''bib0001 bib0016 bib0027'' ]], and it is exploited to rank participants in order to discover the best entities that is ‘safe” to interact with.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0002"""" view=""""all"""">PageRank has been widely adopted in several different application scenarios. In this paper, we propose a generalization of PageRank whose motivation stems from the concept of trust in virtual social networks. In this context trust is generally intended as a measure of the assured reliance on a specific feature of someone <ce:cross-refs id=""""crfs0007"""" refid=""""bib0001 bib0016 bib0027"""">[1,16,27][[ refid=''''bib0001 bib0016 bib0027'''' ]]</ce:cross-refs>, and it is exploited to rank participants in order to discover the <ce:italic>best</ce:italic> entities that is ‘safe” to interact with. This trust-based ranking approach allows to cope with uncertainty and risks <ce:cross-ref id=""""crf0009"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref>, a feature especially relevant in the case of lack of bodily presence of counterparts.</ce:para>""''"'	cites	ANG	
extends	Introduction	H. Shim, Estimating all frequency lighting using a color/depth image , Proceedings of the Nineteenth IEEE International Conference on Image Processing (2012)	http://dx.doi.org/10.1016/j.ins.2018.01.049	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-01-049/br/bib0041	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-01-049/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-01-049/ctx/ctx0007		86	6	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-01-049/itrp/0015	'This work extends our conference papers, [41][[ refid=''bib0041'' ]] and [11][[ refid=''bib0011'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">This work extends our conference papers, <ce:cross-ref id=""""crf0030"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> and <ce:cross-ref id=""""crf0031"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>. In <ce:cross-ref id=""""crf0032"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref>, we introduced a hybrid inverse lighting technique that demonstrates the effectiveness of hybrid lighting representation using simulation data. In <ce:cross-ref id=""""crf0033"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>, we proposed a segmentation-based image representation for handling a single non-homogeneous object through user interaction and evaluated its feasibility for simulation data. In this study, we introduce an automatic cluster-based object representation using a split-and-merge scheme that is effective for processing non-homogeneous objects. More importantly, we identify pixels corresponding to the shadows and inter-reflections and discard them to improve the robustness of inverse lighting. Thus, it is possible to handle non-convex objects for inverse lighting.</ce:para>""''"'	extends	ANG	
cites_as_review	Experimental evaluation	R. Navigli, Word sense disambiguation: a survey , ACM Comput. Surveys , vol. 41 (2009), pp.10	http://dx.doi.org/10.1016/j.ins.2018.02.047	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/br/bib0037>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/ctx/ctx0028>				http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/itrp/0017	'State of the art WSD methods do not only use machine learning for classification purposes, but also a combination of heuristics, domain specific information and deep resources such as thesaurus and lexical datasets (e.g. the WordNet) [37][[ refid=''bib0037'' ]].'			FDY+AGA	infered_pred1
cites_as_review	Experimental evaluation	R. Navigli, Word sense disambiguation: a survey , ACM Comput. Surveys , vol. 41 (2009), pp.10	http://dx.doi.org/10.1016/j.ins.2018.02.047	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/br/bib0037>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/ctx/ctx0029>				http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/itrp/0018	'A disadvantage associated to the use of supervised methods to undertake the word sense disambiguation problem is the painstaking, time-consuming effort required to build reliable datasets [37][[ refid=''bib0037'' ]].'			FDY+AGA	infered_pred1
cites_as_review	Introduction	R. Navigli, Word sense disambiguation: a survey , ACM Comput. Surveys , vol. 41 (2009), pp.10	http://dx.doi.org/10.1016/j.ins.2018.02.047	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/br/bib0037>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/ctx/ctx0002>				http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/itrp/0024	'This task is defined as the ability to computationally detect which sense is being conveyed in a particular context [37][[ refid=''bib0037'' ]].'			FDY+AGA	infered_pred1
cites_as_review	Introduction	R. Navigli, Word sense disambiguation: a survey , ACM Comput. Surveys , vol. 41 (2009), pp.10	http://dx.doi.org/10.1016/j.ins.2018.02.047	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/br/bib0037>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/ctx/ctx0006>				http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/itrp/0035	'Many approaches devised to solve ambiguities in texts employ machine learning methods, in which systems using supervised methods represent the state-of-the-art [37][[ refid=''bib0037'' ]].'			FDY+AGA	infered_pred1
cites_as_review	Experimental evaluation	R. Navigli, Word sense disambiguation: a survey , ACM Comput. Surveys , vol. 41 (2009), pp.10	http://dx.doi.org/10.1016/j.ins.2018.02.047	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/br/bib0037>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/ctx/ctx0030>				http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/itrp/0054	'For this reason, it becomes relevant to analyze the performance of WSD systems when only a few labelled instances are available for training [37][[ refid=''bib0037'' ]].'			FDY+AGA	infered_pred1
cites_as_review	Related works	R. Navigli, Word sense disambiguation: a survey , ACM Comput. Surveys , vol. 41 (2009), pp.10	http://dx.doi.org/10.1016/j.ins.2018.02.047	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/br/bib0037>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/ctx/ctx0012>				http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/itrp/0071	'The set of features employed typically are chosen to characterize the context in a myriad of forms [37][[ refid=''bib0037'' ]].'			FDY+AGA	infered_pred1
cites_as_review	Related works	R. Navigli, Word sense disambiguation: a survey , ACM Comput. Surveys , vol. 41 (2009), pp.10	http://dx.doi.org/10.1016/j.ins.2018.02.047	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/br/bib0037>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/ctx/ctx0011>				http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/itrp/0072	'This is mostly done by supervised classifiers [37][[ refid=''bib0037'' ]].'			FDY+AGA	infered_pred1
cites_as_review	Related works	R. Navigli, Word sense disambiguation: a survey , ACM Comput. Surveys , vol. 41 (2009), pp.10	http://dx.doi.org/10.1016/j.ins.2018.02.047	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/br/bib0037>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/ctx/ctx0010>				http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-047/itrp/0073	'Given a document represented as a sequence of words T={w1,w2,…,wn}, the objective is to assign appropriate sense(s) to all or some of the words wi ∈ T. In other words, the objective is to find a mapping A from words to senses, such that A(wi)⊆SD(wi), where SD(wi) is the set of senses encoded in a dictionary D for the word wi, and A(wi) is the subset of appropriate senses of wi ∈ T. One of the most popular approaches to tackle the WSD problem is the use of machine learning, since this task can be seen as a supervised classification problem, where senses represent the classes [37][[ refid=''bib0037'' ]].'			FDY+AGA	infered_pred1
cites_as_review	Introduction	C.L.P. Chen, C.Y. Zhang, Data-intensive applications, challenges, techniques and technologies: a survey on big data , Inf. Sci. , vol. 275 (2014), pp.314-347	http://dx.doi.org/10.1016/j.ins.2018.02.053	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-053/br/bib0006	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-053/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-053/ctx/ctx0001	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-053/itrpl/bib0006-bib0027-ctx0001	32	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-053/itrp/0017	'Online learners are generating a large amount of data about their learning behaviors with big data properties, which is valuable to the discovery of knowledge from learning patterns [6,27][[ refid=''bib0006 bib0027'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0001"""" view=""""all"""">With the rapid development of information and communication technologies, learning resources including text resources such as simple web pages, and multimedia resources such as videos have boomed over the past years. Online learners are generating a large amount of data about their learning behaviors with big data properties, which is valuable to the discovery of knowledge from learning patterns <ce:cross-refs id=""""crfs0001"""" refid=""""bib0006 bib0027"""">[6,27][[ refid=''''bib0006 bib0027'''' ]]</ce:cross-refs>. It is interesting and significant for end-users to learn something useful from learning experiences using their online learning resources and learning processes. This is because these successful learning curves can be used to guide the learning behaviors of others and forms an intelligent base for personalized services for on-line learning systems <ce:cross-ref id=""""crf0008"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>. As we know, the current learning services supported by new technologies, personalized recommendation is particularly important, due to its power to dramatically improve resource acquisition via customized supply for different individuals <ce:cross-ref id=""""crf0009"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>. However, traditional personalized recommendation approaches face several challenges, such as: (i) the accuracy of personalized recommendation; (ii) the quantification of the learning effect; and (iii) the cold-start of recommendation. Learning services not only offer learning resource recommendations, but also provide appropriate and specialized knowledge as well. Over the past years, people have tried to develop various recommendation systems to supply planned or manually adjusted knowledge structures. In contrast, we offer well-designed learning guidance supported by a personalized optimization in the recommendation system <ce:cross-ref id=""""crf0010"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_data_from	ANG	
cites_as_review	Introduction	S. Vishwakarma, A. Agrawal, A survey on activity recognition and behavior understanding in video surveillance , Visual Comput. , vol. 29 (2013), pp.983-1009	http://dx.doi.org/10.1016/j.ins.2018.02.065	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-065/br/bib0038	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-065/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-065/ctx/ctx0001		67	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-02-065/itrp/0022	'Human activity can be classified as low- and high-level activity based on its complexity and temporal scales [38][[ refid=''bib0038'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0002"""" view=""""all"""">Human activity can be classified as low- and high-level activity based on its complexity and temporal scales <ce:cross-ref id=""""crf0034p"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>. Low-level activity analysis is a well-studied problem; therefore, there are some practical and commercial applications of video analytics that can handle low activity levels (e.g., enter, exit, appear, and loiter) for surveillance systems. In the case of high-level activity analysis such as detecting violent events (e.g., group fighting), it remains an unsolved problem; hence, practical applications do not yet exist because of the complexity and diversity of activity appearance.</ce:para>""''"'	cites	ANG	
cites_as_review	Introduction	J.F. Roddick, M. Spiliopoulou, A survey of temporal knowledge discovery paradigms and methods , IEEE Trans. Knowl. Data Eng. , vol. 14 (2002), pp.750-767	http://dx.doi.org/10.1016/j.ins.2018.03.018	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-018/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-018/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-018/ctx/ctx0001		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-018/itrp/0026	'An event corresponds to a specified event type, which usually has a starting point, an end point, and a list of attributes that describe the event [39][[ refid=''bib0039'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0002a"""" view=""""all"""">As an operation occurs, an e-learning system instantly records the corresponding interactive event. An event corresponds to a specified event type, which usually has a starting point, an end point, and a list of attributes that describe the event <ce:cross-ref id=""""crf0002"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>. Educators may need to find the temporal characteristics of individuals’ behaviors to gain further insight into their learning habits, preferences, and cognitive efforts over time <ce:cross-ref id=""""crf0003"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>. However, this task is not easy to accomplish, as we typically are not able to obtain obvious cues from massive and fragmented events. These cues include detecting important events (<ce:italic>IE</ce:italic>s) and their temporal relations. These IEs and relations are both desired because the former represent particular preferences and habits, while the latter represent certain causal associations or temporal patterns. This paper aims to provide knowledge to system designers, teachers, leaders, and students that enables them to understand how individuals behave over time; moreover, it seeks to provide, for the first time, evidence supporting the promotion of certain <ce:italic>IE</ce:italic>s and temporal relations in human-computer interaction design.</ce:para>""''"'	cites	ANG	
extends	Introduction	Z. Xue, G. Li, Q. Huang, Joint multi-view representation learning and image tagging , AAAI Conference on Artificial Intelligence (2016)	http://dx.doi.org/10.1016/j.ins.2018.03.051	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-051/br/bib0048	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-051/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-051/ctx/ctx0009		51	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-051/itrp/0022	'A preliminary version of this paper has been published in [48][[ refid=''bib0048'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0008"""" view=""""all"""">A preliminary version of this paper has been published in <ce:cross-ref id=""""crf0016"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>. This paper extends <ce:cross-ref id=""""crf0017"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> from the following aspects. First, we introduce semantic subspace learning to further improve the discriminative ability of image representation in <ce:cross-ref id=""""crf0018"""" refid=""""sec0011"""">Section 3.3.2</ce:cross-ref>. Second, we adopt non-linear method to learn the projection functions in <ce:cross-ref id=""""crf0019"""" refid=""""sec0014"""">Section 3.5</ce:cross-ref>, which accurately maps the unlabeled data into the learned subspace. Finally, we conduct image annotation experiments in another dataset (ICPATC-12) to fully illustrate the effectiveness of OPSL.</ce:para>""''"'	cites	ANG	
cites_as_review	Experiments	A. Singhal, Modern information retrieval: a brief overview , IEEE Data Eng. Bull. , vol. 24 (2001), pp.35-43	http://dx.doi.org/10.1016/j.ins.2018.03.051	methods		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-051/br/bib0038	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-051/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-051/ctx/ctx0049		51	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-051/itrp/0054	'Average precision (P), average recall (R) and F1-score (F1) [38][[ refid=''bib0038'' ]] are computed for each test image, and the reported results are averaged across all test images.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0061"""" view=""""all"""">To conduct image annotation, we annotate the five most relevant tags to each image. Then four standard performance measures are adopted for performance evaluation. Average precision (P), average recall (R) and F1-score (F1) <ce:cross-ref id=""""crf0079"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> are computed for each test image, and the reported results are averaged across all test images. Moreover, similar to <ce:cross-ref id=""""crf0080"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> and <ce:cross-ref id=""""crf0081"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref>, Mean Average Precision (MAP), which is defined as the mean of average precision over each tag after retrieving relevant images, is adopted.</ce:para>""''"'	cites	ANG	
extends	Introduction	Z. Xue, G. Li, Q. Huang, Joint multi-view representation learning and image tagging , AAAI Conference on Artificial Intelligence (2016)	http://dx.doi.org/10.1016/j.ins.2018.03.051	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-051/br/bib0048	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-051/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-051/ctx/ctx0010		51	5	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-03-051/itrp/0087	'This paper extends [48][[ refid=''bib0048'' ]] from the following aspects.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0008"""" view=""""all"""">A preliminary version of this paper has been published in <ce:cross-ref id=""""crf0016"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>. This paper extends <ce:cross-ref id=""""crf0017"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> from the following aspects. First, we introduce semantic subspace learning to further improve the discriminative ability of image representation in <ce:cross-ref id=""""crf0018"""" refid=""""sec0011"""">Section 3.3.2</ce:cross-ref>. Second, we adopt non-linear method to learn the projection functions in <ce:cross-ref id=""""crf0019"""" refid=""""sec0014"""">Section 3.5</ce:cross-ref>, which accurately maps the unlabeled data into the learned subspace. Finally, we conduct image annotation experiments in another dataset (ICPATC-12) to fully illustrate the effectiveness of OPSL.</ce:para>""''"'	extends	ANG	
cites_as_review	Related work	J. Lee, F. Wu, W. Zhao, M. Ghaffari, L. Liao, D. Siegel, Prognostics and health management design for rotary machinery systems – reviews, methodology and applications , Mech. Syst. Signal Process. , vol. 42 (2014), pp.314-334	http://dx.doi.org/10.1016/j.ins.2018.04.026	related work		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/br/bib0032	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/ctx/ctx0001		76	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/itrp/0028	'Decision support systems are applied in many fields related to optimization of various logistics and planning processes, monitoring and risk management, etc. [32][[ refid=''bib0032'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">Decision support systems are applied in many fields related to optimization of various logistics and planning processes, monitoring and risk management, etc. <ce:cross-ref id=""""crf0031"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>. One can also find some elements of decision support solutions dedicated specifically to the mining industry <ce:cross-ref id=""""crf0032"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	ANG	
cites_as_review	Conceptual architecture	T.C. Fu, A review on time series data mining , Eng. Appl. Artif. Intell. , vol. 24 (2011), pp.164-181	http://dx.doi.org/10.1016/j.ins.2018.04.026			http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/br/bib0015	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/ctx/ctx0036		76	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/itrp/0053	'It also includes the tools responsible for data aggregation and unification, optional missing values imputation, as well as calculation of values of time-window-based features defined as a result of running the feature extraction and selection algorithms [15][[ refid=''bib0015'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0029a"""" view=""""all"""">We will go back to the ETL and DWH settings in <ce:cross-ref id=""""crf0068"""" refid=""""sec0004"""">Section 4</ce:cross-ref>. For now, let us take a closer look at the ETL2 module. From a data flow perspective, its aim is to deliver integrated data sets based on the chosen sources in the selected time range. It also includes the tools responsible for data aggregation and unification, optional missing values imputation, as well as calculation of values of time-window-based features defined as a result of running the feature extraction and selection algorithms <ce:cross-ref id=""""crf0069"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>. The outcomes of ETL2 are transmitted to the prediction module which can enrich them with additional features corresponding to the expected future sensor readings (referred as virtual sensors, see <ce:cross-ref id=""""crf0070"""" refid=""""sec0001"""">Section 1</ce:cross-ref>). Such data sets can be then utilized by diagnostic processes within the expert system module or transferred to the analytical module for further investigation. Some examples of algorithms currently implemented as a part of our analytical module’s functionality can be found in <ce:cross-ref id=""""crf0071"""" refid=""""sec0008"""">Section 8</ce:cross-ref>.</ce:para>""''"'	uses_data_from	ANG	
cites_as_review	Related work	J.A. Gama, I. Žliobaitė, A. Bifet, M. Pechenizkiy, A. Bouchachia, A survey on concept drift adaptation , ACM Comput. Surv. , vol. 46 (2014), pp.44:1-44:37	http://dx.doi.org/10.1016/j.ins.2018.04.026	related work		http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/br/bib0016	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/ctx/ctx0031		76	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/itrp/0054	'From the perspective of the evolving data, it is also important to combine the task of feature selection/extraction with the state-of-the-art approaches addressing the aforementioned concept drift [16][[ refid=''bib0016'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0023"""" view=""""all"""">As some of readings can be temporarily unreliable, it is also worth studying extensions of standard feature selection algorithms aiming at constructing more robust models <ce:cross-ref id=""""crf0059"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>. Moreover, one can work with feature subset ensembles which are somewhat analogous to the above-mentioned collections of reducts <ce:cross-ref id=""""crf0060"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>. From the perspective of the evolving data, it is also important to combine the task of feature selection/extraction with the state-of-the-art approaches addressing the aforementioned concept drift <ce:cross-ref id=""""crf0061"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>. It may be particularly useful to search for features that are indifferent with regard to the drifting data and treat them as a starting point for constructing robust forecasting models <ce:cross-ref id=""""crf0062"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>. This last-mentioned strategy was utilized in our system as well.</ce:para>""''"'	uses_data_from	ANG	
cites_as_review	Integration and storage of sensor readings	B. Khaleghi, A.M. Khamis, F. Karray, S.N. Razavi, Multisensor data fusion: a review of the state-of-the-art , Inf. Fusion , vol. 14 (2013), pp.28-44	http://dx.doi.org/10.1016/j.ins.2018.04.026			http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/br/bib0029	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/ctx/ctx0038	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/itrpl/bib0029-bib0037-ctx0038	76	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/itrp/0060	'Having all those data sources in a single place, provides a valuable opportunity to improve human safety and increases work efficiency [29,37][[ refid=''bib0029 bib0037'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0031"""" view=""""all"""">Our system integrates data from many other systems responsible for seismic or seismoacoustic monitoring, machinery monitoring, control of underground atmosphere, etc. Having all those data sources in a single place, provides a valuable opportunity to improve human safety and increases work efficiency <ce:cross-refs id=""""crfs0001"""" refid=""""bib0029 bib0037"""">[29,37][[ refid=''''bib0029 bib0037'''' ]]</ce:cross-refs>. However, those systems are provided by many different corporations and are developed using various technologies that are often focused on different types of sensors and different strategies of their utilization.</ce:para>""''"'	uses_data_from	ANG	
cites_as_review	Feature selection and feature subset ensembles	G. Chandrashekar, F. Sahin, A survey on feature selection methods , Comput. Electr. Eng. , vol. 40 (2014), pp.16-28	http://dx.doi.org/10.1016/j.ins.2018.04.026			http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/br/bib0009	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/sec/8	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/ctx/ctx0056	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/itrpl/bib0009-bib0010-ctx0056	76	9	http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/itrp/0064	'Feature selection is a typical task in knowledge discovery and data analytics [9,10][[ refid=''bib0009 bib0010'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0070"""" view=""""all"""">Feature selection is a typical task in knowledge discovery and data analytics <ce:cross-refs id=""""crfs0009"""" refid=""""bib0009 bib0010"""">[9,10][[ refid=''''bib0009 bib0010'''' ]]</ce:cross-refs>. In the case of designing decision support systems, the scope of feature selection is twofold, related to both interaction with domain experts and analysts while running a given system on-line, as well as off-line exploration of the gathered data in order to find out the best algorithms and prepare the best possible feature sets for further processing. It is herein worth noting that the step of feature selection – conducted independently or in an iterative fashion – is often taken into account while building systems aimed at equipment and environment monitoring in coal mines, in combination with various machine learning methods such as neural networks, support vector machines, etc. <ce:cross-refs id=""""crfs0010"""" refid=""""bib0008 bib0033"""">[8,33][[ refid=''''bib0008 bib0033'''' ]]</ce:cross-refs>.</ce:para>""''"'	uses_data_from	ANG	
cites_as_review	Related work	B. Khaleghi, A.M. Khamis, F. Karray, S.N. Razavi, Multisensor data fusion: a review of the state-of-the-art , Inf. Fusion , vol. 14 (2013), pp.28-44	http://dx.doi.org/10.1016/j.ins.2018.04.026	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/br/bib0029>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/ctx/ctx0010>				http://www.scar.disi.unibo.it/r/10-1016-j-ins-2018-04-026/itrp/0075	'A general overview of multi-sensor data fusion methods can be found in [29][[ refid=''bib0029'' ]].'			FDY+AGA	infered_pred1
extends	ViGOR recommendation results	Hopfgartner, F., Vallet, D., Vallet, & Jose, J. M. (2008). Search trails using user feedback to improve video search. In	http://dx.doi.org/10.1016/j.ipm.2014.06.004	results		http://www.scar.disi.unibo.it/r/10-1016-j-ipm-2014-06-004/br/b0105	http://www.scar.disi.unibo.it/r/10-1016-j-ipm-2014-06-004/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-ipm-2014-06-004/ctx/ctx0046		52	8	http://www.scar.disi.unibo.it/r/10-1016-j-ipm-2014-06-004/itrp/0021	'As described in Section 4.4, one of the recommendation approaches presented in this paper, the global recommendation, is an extension of a recommendation approach developed previously (Hopfgartner et al., 2008[[ refid=''b0105'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0330"""" view=""""all"""">To address hypothesis <ce:cross-ref refid=""""n0035"""" id=""""c0695"""">H2.4</ce:cross-ref>, a simulated analysis was performed. As described in Section <ce:cross-ref refid=""""s0065"""" id=""""c0605"""">4.4</ce:cross-ref>, one of the recommendation approaches presented in this paper, the global recommendation, is an extension of a recommendation approach developed previously (<ce:cross-ref refid=""""b0105"""" id=""""c0440"""">Hopfgartner et al., 2008[[ refid=''''b0105'''' ]]</ce:cross-ref>). We can thus investigate if our extension results in a more effective recommendation approach, thus giving more insight over our hypothesis relating to user performance. The previous recommendation approach was extended by its adaptation to the grouping paradigm available in ViGOR and the use of soft links. The former extension was necessary in order to take advantages of the new interaction model offered by ViGOR, the main goal of the latter extension, soft links, is to be able to discern between the multiple facets that occur during a typical search task executed in ViGOR.</ce:para>""''"'	extends	ANG	
uses_data_from	Performance evaluation	C. Thomsen, T.B. Pedersen, Building a web warehouse for accessibility data, in: Proceedings of DOLAP, 2006, pp. 43–50.	http://dx.doi.org/10.1016/j.is.2010.12.001	results		http://www.scar.disi.unibo.it/r/10-1016-j-is-2010-12-001/br/bib3	http://www.scar.disi.unibo.it/r/10-1016-j-is-2010-12-001/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-is-2010-12-001/ctx/ctx0008		36	4	http://www.scar.disi.unibo.it/r/10-1016-j-is-2010-12-001/itrp/0013	'In the experiments, the following two datasets are used: • EIAO dataset: This is a real-world dataset from the European Internet Accessibility Observatory (EIAO) project [3][[ refid=''bib3'' ]] which developed a tool for performing automatic evaluation of accessibility of web sites.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0525"""" view=""""all"""">In the experiments, the following two datasets are used: <ce:list id=""""li0090""""> <ce:list-item id=""""u0070""""> <ce:label> <mml:math altimg=""""si0205.gif"""" overflow=""""scroll""""> <mml:mo>•</mml:mo> </mml:math> </ce:label> <ce:para id=""""p0530"""" view=""""all""""> <ce:italic>EIAO dataset</ce:italic>: This is a real-world dataset from the European Internet Accessibility Observatory (EIAO) project <ce:cross-ref refid=""""bib3"""">[3][[ refid=''''bib3'''' ]]</ce:cross-ref> which developed a tool for performing automatic evaluation of accessibility of web sites. This project serves as the design inspiration for the 3XL triple-store. The EIAO dataset conforms to an OWL Lite ontology <ce:cross-ref refid=""""bib9"""">[9][[ refid=''''bib9'''' ]]</ce:cross-ref> which contains 16 classes and 75 properties. Among the properties, 18 are of type <ce:monospace>OWL:ObjectProperty</ce:monospace>, 57 are of type <ce:monospace>OWL:DataProperty</ce:monospace>, and 29 are multiproperties. </ce:para> </ce:list-item> <ce:list-item id=""""u0075""""> <ce:label> <mml:math altimg=""""si0206.gif"""" overflow=""""scroll""""> <mml:mo>•</mml:mo> </mml:math> </ce:label> <ce:para id=""""p0535"""" view=""""all""""> <ce:italic>LUBM dataset:</ce:italic> This is a synthetic dataset describing fictitious universities from the Lehigh University Benchmark (LUBM) <ce:cross-ref refid=""""bib4"""">[4][[ refid=''''bib4'''' ]]</ce:cross-ref> which is the de facto industry benchmark for OWL repository scalability. For 3XL, we use an ontology which is based on a subset of the published LUBM ontology, but only uses the 3XL-supported constructs and makes implicit subclass relationships explicit. Our ontology covers 20 classes and 20 properties. Among the properties, 13 are of type <ce:monospace>OWL:ObjectProperty</ce:monospace>, seven are of type <ce:monospace>OWL:DataProperty</ce:monospace>, and four are multiproperties. The ontology allows datasets generated by the (unmodified) LUBM generator to be loaded into 3XL. It is available from <ce:inter-ref xlink:href=""""http://www.cs.aau.dk/~xiliu/3xlsystem/"""" xlink:type=""""simple"""">www.cs.aau.dk/∼xiliu/3xlsystem/</ce:inter-ref>. </ce:para> </ce:list-item> </ce:list> </ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
extends	Preliminaries	M. Golfarelli, S. Rizzi, P. Biondi, myOLAP: an approach to express and evaluate OLAP preferences , IEEE Transactions on Knowledge and Data Engineering , vol. 23 (2011), pp.1050-1064	http://dx.doi.org/10.1016/j.is.2011.06.003			http://www.scar.disi.unibo.it/r/10-1016-j-is-2011-06-003/br/bib18	http://www.scar.disi.unibo.it/r/10-1016-j-is-2011-06-003/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-is-2011-06-003/ctx/ctx0043		64	7	http://www.scar.disi.unibo.it/r/10-1016-j-is-2011-06-003/itrp/0023	'In particular, our formalization of md-schemata is an extension of the one used in [18][[ refid=''bib18'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0205"""" view=""""all"""">In this section we introduce a basic formal setting to manipulate and query multidimensional data, and we introduce a running example. In particular, our formalization of md-schemata is an extension of the one used in <ce:cross-ref refid=""""bib18"""">[18][[ refid=''''bib18'''' ]]</ce:cross-ref>. Without loss of generality, we will assume that all measures are defined on the same domain of real numbers, <mml:math altimg=""""si0068.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""double-struck"""">R</mml:mi></mml:math>.<ce:enunciation id=""""enun0005""""><ce:label>Definition 1</ce:label><ce:section-title>Md-Schema</ce:section-title><ce:para id=""""p0210"""" view=""""all"""">An <ce:italic>md-schema</ce:italic> is a triple <mml:math altimg=""""si0069.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""script"""">D</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy=""""false"""">〈</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi><mml:mo>,</mml:mo><mml:mi>M</mml:mi><mml:mo stretchy=""""false"""">〉</mml:mo></mml:math> where:<ce:list id=""""li0025""""><ce:list-item id=""""u0090""""><ce:label>•</ce:label><ce:para id=""""p0215"""" view=""""all""""><mml:math altimg=""""si0070.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy=""""false"""">{</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy=""""false"""">}</mml:mo></mml:math> is a finite set of <ce:italic>attributes</ce:italic>, each defined on a categorical domain <mml:math altimg=""""si0071.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""italic"""">Dom</mml:mi><mml:mo stretchy=""""false"""">(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy=""""false"""">)</mml:mo></mml:math>;</ce:para></ce:list-item><ce:list-item id=""""u0095""""><ce:label>•</ce:label><ce:para id=""""p0220"""" view=""""all""""><mml:math altimg=""""si0072.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy=""""false"""">{</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy=""""false"""">}</mml:mo></mml:math> is a finite set of <ce:italic>hierarchies</ce:italic>, each characterized by (1) a subset <mml:math altimg=""""si0073.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""italic"""">Attr</mml:mi><mml:mo stretchy=""""false"""">(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy=""""false"""">)</mml:mo><mml:mo>⊆</mml:mo><mml:mi>A</mml:mi></mml:math> of attributes (such that the <mml:math altimg=""""si0074.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""italic"""">Attr</mml:mi><mml:mo stretchy=""""false"""">(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy=""""false"""">)</mml:mo></mml:math>''''s for <mml:math altimg=""""si0075.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:math> define a partition of <ce:italic>A</ce:italic>) and (2) a <ce:italic>roll-up</ce:italic> tree-structured partial order <mml:math altimg=""""si0076.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mrow><mml:mo>≽</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math> of <mml:math altimg=""""si0077.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""italic"""">Attr</mml:mi><mml:mo stretchy=""""false"""">(</mml:mo><mml:msub><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy=""""false"""">)</mml:mo></mml:math>;</ce:para></ce:list-item><ce:list-item id=""""u0100""""><ce:label>•</ce:label><ce:para id=""""p0225"""" view=""""all""""><mml:math altimg=""""si0078.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy=""""false"""">{</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy=""""false"""">}</mml:mo></mml:math> is a finite set of <ce:italic>measures</ce:italic>, each aggregable through a set of one or more aggregation operators, <mml:math altimg=""""si0079.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""italic"""">Agg</mml:mi><mml:mo stretchy=""""false"""">(</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy=""""false"""">)</mml:mo></mml:math>.</ce:para></ce:list-item></ce:list>For each hierarchy <ce:italic>h</ce:italic><ce:inf loc=""""post""""><ce:italic>i</ce:italic></ce:inf>, the root attribute of the order is called <ce:italic>dimension</ce:italic>, denoted by <ce:italic>DIM</ce:italic><ce:inf loc=""""post""""><ce:italic>i</ce:italic></ce:inf>, and determines the finest aggregation level for the hierarchy. A pair <mml:math altimg=""""si0080.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy=""""false"""">〈</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy=""""false"""">〉</mml:mo></mml:math> such that <mml:math altimg=""""si0081.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi>M</mml:mi></mml:math> and <mml:math altimg=""""si0082.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant=""""italic"""">Agg</mml:mi><mml:mo stretchy=""""false"""">(</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy=""""false"""">)</mml:mo></mml:math> is called a <ce:italic>metric</ce:italic> of <mml:math altimg=""""si0083.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""script"""">D</mml:mi></mml:math>.</ce:para></ce:enunciation><ce:enunciation id=""""enun0010""""><ce:label>Example 1</ce:label><ce:para id=""""p0230"""" view=""""all"""">In the running example we adopt in this paper, a set of local health-care departments participate in a collaborative network to integrate their data about admissions so as to enable more effective analysis of epidemics and health-care costs by the Ministry. For simplicity we will focus on two peers: the first, located in Rome, hosting data on hospitalizations at the most detailed level; the second, located in Florence, hosting data on admissions grouped by patient gender, residence city, and birth year. The underlying md-schemata for Rome and Florence are called <ce:sans-serif>HOSPITALIZATION</ce:sans-serif> and <ce:sans-serif>ADMISSIONS</ce:sans-serif>, respectively; their roll-up orders are shown in <ce:cross-ref refid=""""f0010"""">Fig. 2</ce:cross-ref><ce:float-anchor refid=""""f0010""""/>. Assuming that each hierarchy is named after its finest-level attribute, but capitalized, relationships <mml:math altimg=""""si0084.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mrow><mml:mi mathvariant=""""italic"""">DIM</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=""""sans-serif"""">Patient</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant=""""sans-serif"""">patient</mml:mi></mml:math> and <mml:math altimg=""""si0085.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""sans-serif"""">city</mml:mi><mml:msub><mml:mrow><mml:mo>≽</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant=""""sans-serif"""">Patient</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant=""""sans-serif"""">region</mml:mi></mml:math> hold. The <ce:sans-serif>HOSPITALIZATION</ce:sans-serif> md-schema includes measures <ce:sans-serif>cost</ce:sans-serif> and <ce:sans-serif>durationOfStay</ce:sans-serif>; <ce:sans-serif>ADMISSIONS</ce:sans-serif> includes measures <ce:sans-serif>totStayCost</ce:sans-serif>, <ce:sans-serif>totExamCost</ce:sans-serif>, <ce:sans-serif>totLength</ce:sans-serif>, <ce:sans-serif>maxLength</ce:sans-serif>, and <ce:sans-serif>numAdmissions</ce:sans-serif>. The aggregation operators exposed by the two md-schemata are as follows: <ce:display><ce:formula id=""""eq0005""""><mml:math altimg=""""si0086.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""italic"""">Agg</mml:mi><mml:mo stretchy=""""false"""">(</mml:mo><mml:mi mathvariant=""""sans-serif"""">cost</mml:mi><mml:mo stretchy=""""false"""">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy=""""false"""">{</mml:mo><mml:mtext><ce:monospace>sum</ce:monospace></mml:mtext><mml:mo>,</mml:mo><mml:mtext><ce:monospace>avg</ce:monospace></mml:mtext><mml:mo stretchy=""""false"""">}</mml:mo></mml:math></ce:formula></ce:display><ce:display><ce:formula id=""""eq0010""""><mml:math altimg=""""si0087.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""italic"""">Agg</mml:mi><mml:mo stretchy=""""false"""">(</mml:mo><mml:mi mathvariant=""""sans-serif"""">durationOfStay</mml:mi><mml:mo stretchy=""""false"""">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy=""""false"""">{</mml:mo><mml:mtext><ce:monospace>sum</ce:monospace></mml:mtext><mml:mo>,</mml:mo><mml:mtext><ce:monospace>avg</ce:monospace></mml:mtext><mml:mo>,</mml:mo><mml:mtext><ce:monospace>min</ce:monospace></mml:mtext><mml:mo>,</mml:mo><mml:mtext><ce:monospace>max</ce:monospace></mml:mtext><mml:mo stretchy=""""false"""">}</mml:mo></mml:math></ce:formula></ce:display><ce:display><ce:formula id=""""eq0015""""><mml:math altimg=""""si0088.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""italic"""">Agg</mml:mi><mml:mo stretchy=""""false"""">(</mml:mo><mml:mi mathvariant=""""sans-serif"""">totStayCost</mml:mi><mml:mo stretchy=""""false"""">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant=""""italic"""">Agg</mml:mi><mml:mo stretchy=""""false"""">(</mml:mo><mml:mi mathvariant=""""sans-serif"""">totExamCost</mml:mi><mml:mo stretchy=""""false"""">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant=""""italic"""">Agg</mml:mi><mml:mo stretchy=""""false"""">(</mml:mo><mml:mi mathvariant=""""sans-serif"""">totLength</mml:mi><mml:mo stretchy=""""false"""">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy=""""false"""">{</mml:mo><mml:mtext><ce:monospace>sum</ce:monospace></mml:mtext><mml:mo>,</mml:mo><mml:mtext><ce:monospace>avg</ce:monospace></mml:mtext><mml:mo stretchy=""""false"""">}</mml:mo></mml:math></ce:formula></ce:display><ce:display><ce:formula id=""""eq0020""""><mml:math altimg=""""si0089.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""italic"""">Agg</mml:mi><mml:mo stretchy=""""false"""">(</mml:mo><mml:mi mathvariant=""""sans-serif"""">maxLength</mml:mi><mml:mo stretchy=""""false"""">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy=""""false"""">{</mml:mo><mml:mtext><ce:monospace>max</ce:monospace></mml:mtext><mml:mo stretchy=""""false"""">}</mml:mo></mml:math></ce:formula></ce:display><ce:display><ce:formula id=""""eq0025""""><mml:math altimg=""""si0090.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""italic"""">Agg</mml:mi><mml:mo stretchy=""""false"""">(</mml:mo><mml:mi mathvariant=""""sans-serif"""">numAdmissions</mml:mi><mml:mo stretchy=""""false"""">)</mml:mo><mml:mo>=</mml:mo><mml:mo stretchy=""""false"""">{</mml:mo><mml:mtext><ce:monospace>sum</ce:monospace></mml:mtext><mml:mo stretchy=""""false"""">}</mml:mo></mml:math></ce:formula></ce:display>Note that the <ce:sans-serif>HOSPITALIZATION</ce:sans-serif> md-schema stores data at the maximum detail, so all its measures can in principle be aggregated using any operator. On the other hand, <ce:sans-serif>ADMISSIONS</ce:sans-serif> stores pre-aggregated data, so the (additive) measures <ce:sans-serif>totStayCost</ce:sans-serif>, <ce:sans-serif>totExamCost</ce:sans-serif>, and <ce:sans-serif>totLength</ce:sans-serif> can be also averaged thanks to the presence of <ce:sans-serif>numAdmissions</ce:sans-serif>, that acts as a support measure for the <ce:monospace>avg</ce:monospace> operator.</ce:para></ce:enunciation></ce:para>""''"'	extends	ANG	
extends	Conclusions	R.P.J.C. Bose, W.M.P. van der Aalst, Trace alignment in process mining: opportunities for process diagnostics , Proceedings of the International Conference on Business Process Management (BPM), Lecture Notes in Computer Science , vol. Vol. 6336 (2010), pp.227-242	http://dx.doi.org/10.1016/j.is.2011.08.003	conclusion		http://www.scar.disi.unibo.it/r/10-1016-j-is-2011-08-003/br/bib44	http://www.scar.disi.unibo.it/r/10-1016-j-is-2011-08-003/sec/11	http://www.scar.disi.unibo.it/r/10-1016-j-is-2011-08-003/ctx/ctx0057		57	10	http://www.scar.disi.unibo.it/r/10-1016-j-is-2011-08-003/itrp/0057	'This paper extends the work presented in [44][[ refid=''bib44'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0555"""" view=""""all"""">In this paper, we proposed a novel approach of aligning traces and showed that this approach uncovers interesting patterns and assists in getting better insights on process execution. We have listed some of the interesting questions in process diagnostics and showed how trace alignment can help in diagnostic efforts. This paper extends the work presented in <ce:cross-ref refid=""""bib44"""">[44][[ refid=''''bib44'''' ]]</ce:cross-ref>. In this extended paper, we discussed the various scenarios of misalignment and their impact on the resulting alignment. A metric that measures the degree of misalignment and three refinement techniques to cope with misalignments have been proposed. The approach has been implemented in ProM and evaluated using three case studies. This is just a first step in this direction. Due to the computational complexity of multiple trace alignment, automatic generation of high-quality alignments is still challenging and there is much to be done to fully exploit the potential of this approach. In our future work we will focus on the detection of outliers in an event log and study their influence on alignment (quality). We will also work on realignment strategies to improve the quality of alignments. </ce:para>""''"'	extends	ANG	
uses_method_in	Performance evaluation	C. Zhao, C. Sutton, Y. Diao, P.J. Shenoy, Distributed inference and query processing for RFID tracking and monitoring , Proceedings of the VLDB , vol. 4 (2011), pp.326-337	http://dx.doi.org/10.1016/j.is.2012.01.002	results		http://www.scar.disi.unibo.it/r/10-1016-j-is-2012-01-002/br/bib25	http://www.scar.disi.unibo.it/r/10-1016-j-is-2012-01-002/sec/8	http://www.scar.disi.unibo.it/r/10-1016-j-is-2012-01-002/ctx/ctx0032		36	7	http://www.scar.disi.unibo.it/r/10-1016-j-is-2012-01-002/itrp/0055	'We obtained the data trace from a simulated hospital environment by adapting the simulator in [25][[ refid=''bib25'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0760"""" view=""""all"""">We obtained the data trace from a simulated hospital environment by adapting the simulator in <ce:cross-ref refid=""""bib25"""">[25][[ refid=''''bib25'''' ]]</ce:cross-ref>. Our data trace contains 300,000 events for 90 medical tools scanned in eight locations. We ran the above query using our event-based framework. We ran the experiments using three algorithms: the any state evaluation method, the any state evaluation with the sorting optimization, and the any state evaluation with the selectivity based optimization.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Rya: storing and retrieving RDF	LUBM. 〈	http://dx.doi.org/10.1016/j.is.2013.07.001			http://www.scar.disi.unibo.it/r/10-1016-j-is-2013-07-001/br/bib14	http://www.scar.disi.unibo.it/r/10-1016-j-is-2013-07-001/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-is-2013-07-001/ctx/ctx0011		22	7	http://www.scar.disi.unibo.it/r/10-1016-j-is-2013-07-001/itrp/0027	'Table 5 shows an example triple taken from the LUBM [14][[ refid=''bib14'' ]] dataset.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0160"""" view=""""all""""><ce:cross-ref id=""""cr0180"""" refid=""""t0025"""">Table 5</ce:cross-ref><ce:float-anchor refid=""""t0025""""/> shows an example triple taken from the LUBM <ce:cross-ref id=""""cr0185"""" refid=""""bib14"""">[14][[ refid=''''bib14'''' ]]</ce:cross-ref> dataset. The triple expresses the fact that a particular professor (subject) earned his/her degree (predicate) from a given university (the object, of type URI). <ce:cross-ref id=""""cr0190"""" refid=""""t0030"""">Table 6</ce:cross-ref><ce:float-anchor refid=""""t0030""""/> shows how the triple is stored in the three table indexes SPO, POS, and OSP. As before, for ease of reading, we use comma as separator in the examples, but the Unicode null character <mml:math altimg=""""si0002.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mo>â§¹</mml:mo></mml:math><ce:italic>u0000</ce:italic> is used in practice. In each table, the triple is stored in the Row ID part of the table, and the three components of the triple are concatenated in the order corresponding to the particular table.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
cites	Research methodology and results	D. Hildebrand, R.L. Ott, Statistical Thinking for Managers , None, Brooks/Cole Publishing Company (1998)	http://dx.doi.org/10.1016/j.is.2013.08.001	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-is-2013-08-001/br/bib45	http://www.scar.disi.unibo.it/r/10-1016-j-is-2013-08-001/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-is-2013-08-001/ctx/ctx0042		53	6	http://www.scar.disi.unibo.it/r/10-1016-j-is-2013-08-001/itrp/0026	'Values greater than 0.3 are rare in real data [45][[ refid=''bib45'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0335"""" view=""""all"""">Two raters who are proficient in ER modeling coded both the survey items measuring expertise (independent variables) and also the errors in the ER diagram (dependent variable). In <ce:cross-ref id=""""cr0385"""" refid=""""s0020"""">Section 2.2</ce:cross-ref>, we described a correct schema that used specific representations, e.g., a weak entity class captured attributes associated with a relationship. However, participants were not penalized for choosing an alternate suitable representation, such as associating attributes with the relationship without a weak class. Inter-rater reliability was calculated using Cohen''''s kappa and was found to be at least 0.8 for all errors. Any differences in coding between the raters were examined and resolved. To test our hypotheses, the number of subjects who achieved each expertise level (as well as the number who did not) and the number of participants who made each error type (as well as those who did not) was counted. The relative frequency of occurrence of each type of error is reported in <ce:float-anchor refid=""""t0055""""/><ce:cross-ref id=""""cr0390"""" refid=""""t0055"""">Table 11</ce:cross-ref> (<ce:cross-ref id=""""cr0395"""" refid=""""s0065"""">Section 4</ce:cross-ref>). A series of Chi-square tests was performed to test the hypotheses. The Chi-square test of independence assesses whether the perceived dependence on the sample data is spurious or real (<ce:italic>α</ce:italic>=.05). In cases where a cell had less than 5 observations, Fisher''''s exact test was used instead. In addition, we calculated strength of association (<ce:italic>λ</ce:italic>) for all significant relationships. The value of <ce:italic>λ</ce:italic> ranges between 0 and 1; the higher the <ce:italic>λ</ce:italic> the better the prediction of the value of the dependent variable based on the value of the independent variable. Values greater than 0.3 are rare in real data <ce:cross-ref id=""""cr0400"""" refid=""""bib45"""">[45][[ refid=''''bib45'''' ]]</ce:cross-ref>. Chi-square tests showed that control variables were not significant.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
cites	Appendix C	J.A. Hanley, K.O. Hajian-Tilaki, Sampling variability of nonparametric estimates of the area under receiver operating characteristic curves: an update , Acad Radiol , vol. 4 (1977), pp.49-58	http://dx.doi.org/10.1016/j.jbi.2014.02.013			<http://www.scar.disi.unibo.it/r/10-1016-j-jbi-2014-02-013/br/b0180>	<http://www.scar.disi.unibo.it/r/10-1016-j-jbi-2014-02-013/sec/sec14>	<http://www.scar.disi.unibo.it/r/10-1016-j-jbi-2014-02-013/ctx/ctx0065>				http://www.scar.disi.unibo.it/r/10-1016-j-jbi-2014-02-013/itrp/0043	'Hanley and Hajian-Tilaki [36][[ refid=''b0180'' ]] restated the DeLong’s method of calculating the variance of the accuracy index in a single diagnostic test is as follows: [[ formulaid=''id48_pos0'' ]]'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Results	T.A. Davis, , Direct Methods for Sparse Linear Systems, Society for Industrial and Applied Mathematics (SIAM) , vol. vol. 2 (2006), pp.None	http://dx.doi.org/10.1016/j.jcp.2012.09.008	results		<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/br/b0125>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/ctx/ctx0022>				http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/itrp/0001	'The steady-state solutions are found using a fully consistent Newton method, applied directly to the Eqs. (10), with the linear systems solved using a direct sparse solver [25][[ refid=''b0125'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Results	P.L. Roe, Approximate Riemann solvers parameter vectors and difference schemes , J. Comput. Phys. , vol. 43 (1981), pp.357-372	http://dx.doi.org/10.1016/j.jcp.2012.09.008	results		<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/br/b0165>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/ctx/ctx0021>				http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/itrp/0004	'The scheme (10) is implemented in a straight-forward way, and we use Roe’s method for the numerical fluxes (5)[33][[ refid=''b0165'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Line-based discontinuous Galerkin discretization	P.-O. Persson, J. Peraire, Curved mesh generation and mesh refinement using Lagrangian solid mechanics, in: 47th AIAA Aerospace Sciences Meeting and Exhibit, Orlando, Florida, AIAA-2009-949.	http://dx.doi.org/10.1016/j.jcp.2012.09.008			<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/br/b0105>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/ctx/ctx0006>				http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/itrp/0032	'The node positions xijk are given by some curved mesh generation procedure [21][[ refid=''b0105'' ]], and we define [[ formulaid=''id10_pos0'' ]] which clearly satisfies our interpolation requirement [[ formulaid=''id10_pos1'' ]] This allows us to easily compute G(X) at any point X, which will involve the derivatives ϕi′(ξ) of the shape functions.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Results	J. Peraire, N.C. Nguyen, B. Cockburn, An implicit high-order hybridizable discontinuous Galerkin method for linear convection–diffusion equations , J. Comput. Phys. , vol. 228 (2009), pp.3232-3254	http://dx.doi.org/10.1016/j.jcp.2012.09.008	results		<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/br/b0080>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/ctx/ctx0019>				http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/itrp/0036	'For the stabilized scheme (bottom two tables), we obtain a somewhat higher order for the q variables, which could be used as part of a postprocessing step to further increase the order of convergence for the solution u[16][[ refid=''b0080'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Temporal discretization and nonlinear solvers	R. Alexander, Diagonally implicit Runge–Kutta methods for stiff O.D.E.’s , SIAM J. Numer. Anal. , vol. 14 (1977), pp.1006-1021	http://dx.doi.org/10.1016/j.jcp.2012.09.008			<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/br/b0130>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/ctx/ctx0012>				http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/itrp/0039	'In particular, we use the following L-stable, three-stage, third-order accurate method [26][[ refid=''b0130'' ]]: [[ formulaid=''id20_pos1'' ]] [[ formulaid=''id20_pos2'' ]] with s=3 and the coefficients given by the Runge–Kutta tableaux below.We also use implicit time-stepping for computing steady-state solutions, by a sequence of increasing timesteps Δt and a final step without the time derivatives.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Temporal discretization and nonlinear solvers	R. Alexander, Diagonally implicit Runge–Kutta methods for stiff O.D.E.’s , SIAM J. Numer. Anal. , vol. 14 (1977), pp.1006-1021	http://dx.doi.org/10.1016/j.jcp.2012.09.008			<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/br/b0130>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/ctx/ctx0011>				http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/itrp/0040	'We also use this form for implicit time-stepping using Diagonally Implicit Runge–Kutta (DIRK) schemes [26][[ refid=''b0130'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Temporal discretization and nonlinear solvers	T.A. Davis, , Direct Methods for Sparse Linear Systems, Society for Industrial and Applied Mathematics (SIAM) , vol. vol. 2 (2006), pp.None	http://dx.doi.org/10.1016/j.jcp.2012.09.008			<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/br/b0125>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/ctx/ctx0010>				http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/itrp/0041	'In our examples, we solve these equations using a standard sparse direct solver [25][[ refid=''b0125'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Temporal discretization and nonlinear solvers	Y. Saad, M.H. Schultz, GMRES: a generalized minimal residual algorithm for solving nonsymmetric linear systems , SIAM J. Sci. Statist. Comput. , vol. 7 (1986), pp.856-869	http://dx.doi.org/10.1016/j.jcp.2012.09.008			<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/br/b0155>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/ctx/ctx0017>				http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/itrp/0042	'The linear systems are solved using a preconditioned GMRES method [31][[ refid=''b0155'' ]], with the low-cost sparse block-Jacobi preconditioner A∼ described above.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Temporal discretization and nonlinear solvers	T.A. Davis, , Direct Methods for Sparse Linear Systems, Society for Industrial and Applied Mathematics (SIAM) , vol. vol. 2 (2006), pp.None	http://dx.doi.org/10.1016/j.jcp.2012.09.008			<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/br/b0125>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/ctx/ctx0016>				http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/itrp/0043	'In our implementation, we store all matrices in a general purpose compressed column storage format [25][[ refid=''b0125'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Temporal discretization and nonlinear solvers	T.A. Davis, , Direct Methods for Sparse Linear Systems, Society for Industrial and Applied Mathematics (SIAM) , vol. vol. 2 (2006), pp.None	http://dx.doi.org/10.1016/j.jcp.2012.09.008			<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/br/b0125>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/ctx/ctx0014>				http://www.scar.disi.unibo.it/r/10-1016-j-jcp-2012-09-008/itrp/0047	'When solving the linear systems involving the preconditioning matrix (I-αΔtA∼), we use a sparse direct LU-factorization with fill-reducing ordering for each block [25][[ refid=''b0125'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Research methodology	Lalita Achanuphab. Retrieved January 20, 2014:	http://dx.doi.org/10.1016/j.jesit.2015.12.002	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-jesit-2015-12-002/br/bib0005>	<http://www.scar.disi.unibo.it/r/10-1016-j-jesit-2015-12-002/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-jesit-2015-12-002/ctx/ctx0018>				http://www.scar.disi.unibo.it/r/10-1016-j-jesit-2015-12-002/itrp/0007	'Fig. 3 shows how the research study describes the first research, First step; Physical pulse is defined pulse (Lalita Achanuphab, 2014[[ refid=''bib0005'' ]]) that represents the heartbeat rhythm is defined as the number of beats per minute.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Introduction	Wannachart Kataichan. Retrieved January 29, 2014:	http://dx.doi.org/10.1016/j.jesit.2015.12.002	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-jesit-2015-12-002/br/bib0010>	<http://www.scar.disi.unibo.it/r/10-1016-j-jesit-2015-12-002/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-jesit-2015-12-002/ctx/ctx0003>				http://www.scar.disi.unibo.it/r/10-1016-j-jesit-2015-12-002/itrp/0015	'Pulse (Wannachart Kataichan, 2014[[ refid=''bib0010'' ]]) can be explained other words, the shock waves of blood flow caused by the compression of the left ventricular wall of the artery is expanded into a rhythm.'		<http://purl.org/spar/cito/extends>		top100compsc
uses_method_in	Research methodology	S.O. Ismaila, O.G. Akanbi, S.O. Oderinu, Design of ergonomically compliant desks and chairs for primary pupils in Ibadan, Nigeria , J. Eng. Sci. Technol. , vol. 10 (2015), pp.35-46	http://dx.doi.org/10.1016/j.jestch.2016.08.004	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/br/b0100>	<http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/ctx/ctx0022>				http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/itrp/0001	'In order to know the major problems (health status) with regard to the use of the available furniture, ergonomic assessment (health survey) for students who have been at colleges for longer period of time was performed with the help of designed questionnaires as it was also suggested by [20][[ refid=''b0100'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Research methodology	J.F.M. Molenbroek, Y.M.T. Kroon-Ramaekers, C.J. Snijders, Revision of the design of a standard for the dimensions of school furniture , Ergonomics , vol. 46 (2003), pp.681-694	http://dx.doi.org/10.1016/j.jestch.2016.08.004	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/br/b0165>	<http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/ctx/ctx0027>				http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/itrp/0009	'Designing of standard furniture needs directly involvement of anthropometric measurements [33][[ refid=''b0165'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites_as_review	Research methodology	K.M. Robinette, H. Daanen, (n.d.), Lessons learned from CAESAR: a 3-D anthropometric survey, in: Proceedings of the XVth Triennial Congress of the International Ergonomics Association, Ergonomics in the Digital Age, August 24–29, 2003 Paper Number 00730.	http://dx.doi.org/10.1016/j.jestch.2016.08.004	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/br/b0200>	<http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/ctx/ctx0024>				http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/itrp/0010	'In such scenario, Ref. [40][[ refid=''b0200'' ]] stated that, “Since many of the traditional measurements have been used for many years, and since it may be many years before everyone has a 3-D scanner with the ability to identify pre-marked landmarks, it was felt it would be important to take some measurements the traditional way”.'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites	Results and discussion	S.O. Ismaila, A. Musa, S. Adejuyigbe, O. Akinyemi, Anthropometric design of furniture for use in tertiary institutions in Abeokuta, South-Western Nigeria , Eng. Rev. , vol. 33 (2013), pp.179-192	http://dx.doi.org/10.1016/j.jestch.2016.08.004	results	discussion	<http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/br/b0105>	<http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/ctx/ctx0030>				http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/itrp/0042	'With the help of literature survey, Ref. [21][[ refid=''b0105'' ]] encourages designers to adapt “designing for an Adjustable Range”, this means that classrooms furniture are required to be adjustable.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Literature review	B. Biswas, F.B. Zahid, R. Ara, M.S. Parvez, A.S.M. Hoque, Mismatch between classroom furniture and anthropometric measurements of Bangladeshi primary school students , International Conference on Mechanical, Industrial and Energy Engineering, 25–26 December, 2014. Khulna, Bangladesh (2014)	http://dx.doi.org/10.1016/j.jestch.2016.08.004			<http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/br/b0055>	<http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/ctx/ctx0014>				http://www.scar.disi.unibo.it/r/10-1016-j-jestch-2016-08-004/itrp/0061	'The presence of less survey regarding anthropometric data has been due to that majority of colleges or universities administration’s procure ready-made furniture which mostly fit few users (students) [11][[ refid=''b0055'' ]].'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
uses_method_in	The proposed ETL processes model (EMD)	R. Kimball, J. Caserta, The Data Warehouse ETL Toolkit. Practical Techniques for Extracting, Cleaning, Conforming and Delivering Data , None, Wiley (2004)	http://dx.doi.org/10.1016/j.jksuci.2011.05.005	model		<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2011-05-005/br/b0055>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2011-05-005/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2011-05-005/ctx/ctx0024>				http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2011-05-005/itrp/0010	'– Generating the mapping document according to Kimball’s standards (Kimball and Caserta, 2004[[ refid=''b0055'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Models of ETL processes	Staudt, M., Vaduva, A., Vetterli, T., 1999. Metadata Management and Data Warehousing. Technical Report, The Department of Information Technology (IFI) at the University of Zurich.	http://dx.doi.org/10.1016/j.jksuci.2011.05.005	model		<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2011-05-005/br/b0150>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2011-05-005/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2011-05-005/ctx/ctx0008>				http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2011-05-005/itrp/0014	'• Data warehousing tool (ETL) (Staudt et al., 1999[[ refid=''b0150'' ]]): includes a transformation process where the correspondence between the sources data and the target DW data is defined.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Experimental setup	G. Bergmann, Á. Horváth, I. Ráth, D. Varró, A. Balogh, Z. Balogh, A. Ökrös, Incremental evaluation of model queries over EMF models , Model Driven Engineering Languages and Systems, Lecture Notes in Computer Science, Springer (2010)	http://dx.doi.org/10.1016/j.jksuci.2016.06.007	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/br/b0020>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/ctx/ctx0020>				http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/itrp/0004	'The execution time and consumed memory are also calculated in this way by Bergmann et al. (2010)[[ refid=''b0020'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites_as_review	NoSQL databases	R. Hecht, S. Jablonski, NoSQL evaluation: a use case oriented survey , Proceedings – 2011 International Conference on Cloud and Service Computing, CSC 2011 (2011)	http://dx.doi.org/10.1016/j.jksuci.2016.06.007	data		<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/br/b0055>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/ctx/ctx0009>				http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/itrp/0009	'Most well-known examples of key-value stores are Redis1, Memcached2.•Document store: The data are stored in collections that contain key-value pairs which encapsulate key value pairs in JSON (Javascript Object Notation) or JSON like documents (Hecht and Jablonski, 2011[[ refid=''b0055'' ]]).'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites_as_review	Introduction	V. Abramova, J. Bernardino, P. Furtado, Which NoSQL database? A performance overview , Open J. Databases , vol. 1 (2014), pp.17-24	http://dx.doi.org/10.1016/j.jksuci.2016.06.007	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/br/b0005>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/ctx/ctx0001>				http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/itrp/0010	'However, with the constant growth of stored data, the limitations of relational database management systems such as scalability and storage, and efficiency losing of query due to the large volumes of data, and the storage and management of larger databases become challenging (Abramova et al., 2014[[ refid=''b0005'' ]]).'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites_as_review	Introduction	V. Abramova, J. Bernardino, P. Furtado, Which NoSQL database? A performance overview , Open J. Databases , vol. 1 (2014), pp.17-24	http://dx.doi.org/10.1016/j.jksuci.2016.06.007	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/br/b0005>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/ctx/ctx0007>				http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/itrp/0021	'NoSQL databases serves the data from volatile memory (i.e. random access memory – RAM) instead of non-volatile memory (i.e. hard drive) in order to increase the speed of querying since I/O (Input/Output) data access is slow (Abramova et al., 2014[[ refid=''b0005'' ]]).'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites_as_review	Related works	R. Hecht, S. Jablonski, NoSQL evaluation: a use case oriented survey , Proceedings – 2011 International Conference on Cloud and Service Computing, CSC 2011 (2011)	http://dx.doi.org/10.1016/j.jksuci.2016.06.007	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/br/b0055>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/ctx/ctx0013>				http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/itrp/0024	'Hecht and Jablonski present a use case oriented survey on NoSQL databases (Hecht and Jablonski, 2011[[ refid=''b0055'' ]]).'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites_as_review	Related works	V. Abramova, J. Bernardino, P. Furtado, Which NoSQL database? A performance overview , Open J. Databases , vol. 1 (2014), pp.17-24	http://dx.doi.org/10.1016/j.jksuci.2016.06.007	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/br/b0005>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/ctx/ctx0014>				http://www.scar.disi.unibo.it/r/10-1016-j-jksuci-2016-06-007/itrp/0032	'Abramova et al. (2014)[[ refid=''b0005'' ]] use Yahoo!'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
uses_method_in	Results	E. Gilbert, K. Karahalios, Widespread worry and the stock market , Fourth International AAAI Conference on Weblogs and Social Media (2010) , http://www.aaai.org/ocs/index.php/ICWSM/ICWSM10/paper/download/1513/1833	http://dx.doi.org/10.1016/j.jocs.2010.12.007	results		<http://www.scar.disi.unibo.it/r/10-1016-j-jocs-2010-12-007/br/bib0085>	<http://www.scar.disi.unibo.it/r/10-1016-j-jocs-2010-12-007/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-jocs-2010-12-007/ctx/ctx0023>				http://www.scar.disi.unibo.it/r/10-1016-j-jocs-2010-12-007/itrp/0003	'We therefore use Granger causality analysis in a similar fashion to [17][[ refid=''bib0085'' ]]; we are not testing actual causation but whether one time series has predictive information about the other or not.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Results	G. Leng, G. Prasad, T.M. McGinnity, An on-line algorithm for creating self-organizing fuzzy neural networks , Neural Networks: The Official Journal of the International Neural Network Society , vol. 17 (2004), pp.1477-1493 , http://www.ncbi.nlm.nih.gov/pubmed/15541949	http://dx.doi.org/10.1016/j.jocs.2010.12.007	results		<http://www.scar.disi.unibo.it/r/10-1016-j-jocs-2010-12-007/br/bib0140>	<http://www.scar.disi.unibo.it/r/10-1016-j-jocs-2010-12-007/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-jocs-2010-12-007/ctx/ctx0025>				http://www.scar.disi.unibo.it/r/10-1016-j-jocs-2010-12-007/itrp/0013	'To better address these non-linear effects and assess the contribution that public mood assessments can make in predictive models of DJIA values, we compare the performance of a Self-organizing Fuzzy Neural Network (SOFNN) model [28][[ refid=''bib0140'' ]] that predicts DJIA values on the basis of two sets of inputs: (1) the past 3 days of DJIA values, and (2) the same combined with various permutations of our mood time series (explained below).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
extends	Related work	H. Kim, H. Lim, J. Jeong, H. Jo, J. Lee, Task-aware virtual machine scheduling for I/O performance, in: Proc. VEE, 2009.	http://dx.doi.org/10.1016/j.jpdc.2010.11.005	related work		http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2010-11-005/br/br000110	http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2010-11-005/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2010-11-005/ctx/ctx0024		37	7	http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2010-11-005/itrp/0009	'This paper extends our prior work [22][[ refid=''br000110'' ]] with a broader point of view in terms of the semantic gap in virtual CPU management.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000465"""" view=""""all"""">This paper extends our prior work <ce:cross-ref refid=""""br000110"""">[22][[ refid=''''br000110'''' ]]</ce:cross-ref> with a broader point of view in terms of the semantic gap in virtual CPU management. This section compares our work with previous research on VM scheduling and inference techniques using gray-box knowledge. </ce:para>""''"'	extends	AGA+ANG	tba_50_classified_extends_semweb
cites	Previous related work	Yunfeng Gu, A. Boukerche, Xun Ye, Regina B. Araujo, Supporting multi-dimensional range query in HD Tree, in: Distributed Simulation and Real Time Applications, DS-RT’10, 2010 IEEE/ACM 14th International Symposium on. 17-20 Oct, Fairfax, Virginia, USA (Ph.D.Work), 2010, pp. 71–78.	http://dx.doi.org/10.1016/j.jpdc.2011.04.003	related work		http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2011-04-003/br/br000065	http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2011-04-003/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2011-04-003/ctx/ctx0010		15	4	http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2011-04-003/itrp/0002	'There are two direct observations described in [13][[ refid=''br000065'' ]] concerning recursive decomposition: (1) data localities extend exponentially as the recursive decomposition of data space goes deeper; and (2) data localities expand exponentially as the dimensionality of data space goes higher.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000045"""" view=""""all"""">We all know that a simple tree structure has many difficulties surviving in a distributed environment. However, the hierarchical structure has the non-comparable advantage of maintaining data locality preserved from multi-dimensional space partitioning. There are two direct observations described in <ce:cross-ref refid=""""br000065"""">[13][[ refid=''''br000065'''' ]]</ce:cross-ref> concerning recursive decomposition: (1) data localities extend exponentially as the recursive decomposition of data space goes deeper; and (2) data localities expand exponentially as the dimensionality of data space goes higher. Therefore, the <ce:italic>system constraint</ce:italic> for multi-dimensional range query can be stated as follows: how to accommodate and maintain data locality preserved from recursive decomposition among data ranges with an exponentially extending and expanding rate. Obviously, none of the existing P2P overlay systems were originally designed and proposed to resolve this constraint. Because a tree structure has a natural connection to recursive decomposition, our recent work intends to adapt the hierarchical tree structure to the distributed environment. </ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_extends_semweb
extends	Introduction	Angelo Furno, Eugenio Zimeo, Efficient cooperative discovery of service compositions in unstructured P2P networks, in: Parallel, Distributed and Network-Based Processing (PDP), 2013 21st Euromicro International Conference on, 2013, pp. 58–67.	http://dx.doi.org/10.1016/j.jpdc.2014.06.006	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2014-06-006/br/br000135	http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2014-06-006/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2014-06-006/ctx/ctx0013		70	10	http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2014-06-006/itrp/0091	'This paper extends the one in [27][[ refid=''br000135'' ]] and reports on a more in-depth analysis of the proposed cooperative composition, summarized as follows.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000095"""" view=""""all"""">This paper extends the one in <ce:cross-ref id=""""cf000080"""" refid=""""br000135"""">[27][[ refid=''''br000135'''' ]]</ce:cross-ref> and reports on a more in-depth analysis of the proposed cooperative composition, summarized as follows. Each peer of a service network can publish semantically described services in a local registry (by using a shared set of ontologies even though unshared ontologies could be used by implementing ontology mapping techniques) and perform local or distributed discovery of both atomic and composite services, whose parts could be allocated to any of the peers’ registry. The query content supports its routing across the network towards the target peer. We assume that the lower level overlay network (that in the following we call <ce:italic>connectivity graph</ce:italic>) could be either a topic-specific Semantic Overlay Network (SON) or an uninformed overlay network. In the former, peers are connected through the links of the routing tables that are indexed with specific concepts (the ones related to the predicates that characterize queries’ pre- and post-conditions). In the latter, each link represents only the knowledge of the identity of a peer (e.g. the one hosted by a neighbour node).</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
extends	Introduction	A. Buluç, E. Duriakova, A. Fox, J. Gilbert, S. Kamil, A. Lugowski, L. Oliker, S. Williams, High-productivity and high-performance analysis of filtered semantic graphs , Proceedings of the IPDPS, IEEE Computer Society (2013)	http://dx.doi.org/10.1016/j.jpdc.2014.08.010	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2014-08-010/br/br000040	http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2014-08-010/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2014-08-010/ctx/ctx0007		36	9	http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2014-08-010/itrp/0023	'This paper expands on the work first published as a conference paper at IPDPS [8][[ refid=''br000040'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000090"""" view=""""all"""">The rest of the paper is organized as follows. Section <ce:cross-ref id=""""cf000125"""" refid=""""s000010"""">2</ce:cross-ref> gives background on the graph-analytical systems our work targets and builds upon. Section <ce:cross-ref id=""""cf000130"""" refid=""""s000025"""">3</ce:cross-ref> is the technical heart of the paper, which describes how we meet performance challenges by using selective, embedded, just-in-time specialization. Section <ce:cross-ref id=""""cf000135"""" refid=""""s000045"""">4</ce:cross-ref> presents Python-defined objects that enable the user to declare their attribute types directly in Python, enabling a much board set of applications. Section <ce:cross-ref id=""""cf000140"""" refid=""""s000100"""">6</ce:cross-ref> proposes a theoretical model that can be used to evaluate the performance of our implementations, giving “Roofline” bounds on the performance of breadth-first search in terms of architectural parameters of a parallel machine, and the permeability of the filter (that is, the percentage of edges that pass the filter). Section <ce:cross-ref id=""""cf000145"""" refid=""""s000080"""">5</ce:cross-ref> gives details about the experimental setting and Section <ce:cross-ref id=""""cf000150"""" refid=""""s000105"""">7</ce:cross-ref> presents our experimental results. In Section <ce:cross-ref id=""""cf000155"""" refid=""""s000130"""">8</ce:cross-ref>, we precisely analyze the performance implications of selective just-in translation using hardware performance counters. We survey related work in Section <ce:cross-ref id=""""cf000160"""" refid=""""s000135"""">9</ce:cross-ref>. Section <ce:cross-ref id=""""cf000165"""" refid=""""s000140"""">10</ce:cross-ref> gives our conclusions and some remarks on future directions and problems. This paper expands on the work first published as a conference paper at IPDPS <ce:cross-ref id=""""cf000170"""" refid=""""br000040"""">[8][[ refid=''''br000040'''' ]]</ce:cross-ref>.</ce:para>""''"'	extends	ANG	
uses_data_from	Performance evaluation	W.W. Cohen, Enron email dataset , None (None) , http://www.cs.cmu.edu/~enron	http://dx.doi.org/10.1016/j.jpdc.2016.05.017	results		http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2016-05-017/br/br000055	http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2016-05-017/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2016-05-017/ctx/ctx0011		41	6	http://www.scar.disi.unibo.it/r/10-1016-j-jpdc-2016-05-017/itrp/0072	'We run the experiments on a real world dataset: the Enron Email Dataset [11][[ refid=''br000055'' ]], which are a total of 200, 399 messages belonging to 158 users.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p000440"""" view=""""all"""">We use JAVA language to implement the proposed full-text retrieval scheme. We carry out the experiments on a server running Windows 7 with a 64-bit, 2.9 GHz CPU and 4 GB main memory. We run the experiments on a real world dataset: the Enron Email Dataset <ce:cross-ref id=""""cf000275"""" refid=""""br000055"""">[11][[ refid=''''br000055'''' ]]</ce:cross-ref>, which are a total of 200, 399 messages belonging to 158 users. In our experiments, the parameters of our scheme include: <mml:math altimg=""""si17.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>m</mml:mi></mml:math>, <mml:math altimg=""""si41.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>h</mml:mi></mml:math>, <mml:math altimg=""""si10.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>k</mml:mi></mml:math>, and <mml:math altimg=""""si19.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>p</mml:mi></mml:math>. The parameters of our scheme in the experiments are shown in <ce:cross-ref id=""""cf000280"""" refid=""""t000010"""">Table 2</ce:cross-ref><ce:float-anchor refid=""""t000010""""/>. In the experiments, we use the keyed hash function HMAC-SHA1 <ce:cross-ref id=""""cf000285"""" refid=""""br000015"""">[3][[ refid=''''br000015'''' ]]</ce:cross-ref> to build the Bloom filter. The performance of our technique is evaluated on the query precision, the query efficiency, as well as the maintenance overhead.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
extends	Related works	G. Si, J. Yang, J. Xu, S. Wen, W. Tian, An Evaluation Model for Dependability of Internet-scale Software on Basis of Bayesian Networks , Proceeding of the 36th IEEE Computer Software and Applications Conference (COMPSAC’2012), vol. 42 (2012)	http://dx.doi.org/10.1016/j.jss.2013.08.035	related work		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2013-08-035/br/bib0095	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2013-08-035/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2013-08-035/ctx/ctx0021		24	4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2013-08-035/itrp/0005	'This paper is an extension of our earlier published COMPSAC 2012 conference paper (Guannan Si et al., 2012[[ refid=''bib0095'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""par0095"""" view=""""all"""">All the research results mentioned above either consider software as an entire system or consider dependability as an entire metric. The main contribution of this paper is method of calculating dependability of Internet-scale software. The method can: (1) calculate dependability of an entity according to its attributes; (2) calculate dependability of a system according to its entities. In this way, people can evaluate Internet-scale software dependability of a whole Internet-scale software system according to the attributes of its entities. This paper is an extension of our earlier published COMPSAC 2012 conference paper (<ce:cross-ref id=""""crf0190"""" refid=""""bib0095"""">Guannan Si et al., 2012[[ refid=''''bib0095'''' ]]</ce:cross-ref>). Dynamic metrics calculation based on trustworthiness evaluation is added, as well as an experiment validation.</ce:para>""''"'	extends	ANG	
extends	Introduction	B. Jiang, W.K. Chan, Bypassing code coverage approximation limitations via effective input-based randomized test case prioritization , Proceedings of the 37th Annual International Computer Software and Applications Conference (COMPSAC 2013), IEEE Computer Society (2013)	http://dx.doi.org/10.1016/j.jss.2015.03.066	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2015-03-066/br/bib0025	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2015-03-066/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2015-03-066/ctx/ctx0012		86	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2015-03-066/itrp/0108	'This work significantly extends its preliminary version (Jiang and Chan, 2013[[ refid=''bib0025'' ]]): (1) It generalizes the family of LBS techniques by presenting five more new techniques and evaluates the family against more existing techniques for benchmarking.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0017"""" view=""""all"""">This work significantly extends its preliminary version (<ce:cross-ref id=""""crf0025"""" refid=""""bib0025"""">Jiang and Chan, 2013[[ refid=''''bib0025'''' ]]</ce:cross-ref>): (1) It generalizes the family of LBS techniques by presenting five more new techniques and evaluates the family against more existing techniques for benchmarking. (2) It reports a new experiment that investigates the impact of candidate set size and beam width on the effectiveness of the family. (3) It presents a new case study on comparing this family with several adapted classical search-based test case prioritization algorithms (Greedy, ART, and Genetic).</ce:para>""''"'	extends	ANG	
extends	Motivation	F. Mandreoli, R. Martoglia, W. Penzo, G. Villani, Flexible Query Answering on Graph-modeled Data , EDBT (2009)	http://dx.doi.org/10.1016/j.jss.2015.07.028	motivation		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2015-07-028/br/bib0025	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2015-07-028/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2015-07-028/ctx/ctx0016		77	9	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2015-07-028/itrp/0126	'This paper extends and improves our previous work (Mandreoli et al., 2009[[ refid=''bib0025'' ]]) in almost every respect.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0026"""" view=""""all"""">This paper extends and improves our previous work (<ce:cross-ref id=""""crf0026"""" refid=""""bib0025"""">Mandreoli et al., 2009[[ refid=''''bib0025'''' ]]</ce:cross-ref>) in almost every respect. A large part of the improvement effort has been focused on the design of the novel indexing scheme and on the analysis of different implementation strategies for the involved data structures (<ce:cross-ref id=""""crf0027"""" refid=""""sec0009"""">Section 4</ce:cross-ref>). In particular, we practically show that the new scheme accelerates complex query processing tasks (<ce:cross-ref id=""""crf0028"""" refid=""""sec0016"""">Section 6</ce:cross-ref>) and provides crucial advantages both in terms of querying performance (one order of magnitude faster execution times, on average) and storage requirements (indexing space reduced to as little as 4% of the original requirements). We also provide new effectiveness and efficiency comparisons, highlighting the benefits of the <ce:small-caps>GeX</ce:small-caps>approach w.r.t. the most relevant state of the art proposals, and evaluating the impact of the different implementation strategies.</ce:para>""''"'	extends	ANG	
cites	Introduction	J. Dean, S. Ghemawat, Mapreduce: simplified data processing on large clusters , Commun. ACM , vol. 51 (2008), pp.107-113	http://dx.doi.org/10.1016/j.jss.2016.07.007	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-07-007/br/bib0019	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-07-007/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-07-007/ctx/ctx0009		46	5	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-07-007/itrp/0039	'In the case of provisional applications such as scientific calculations or MapReduce (Dean and Ghemawat, 2008[[ refid=''bib0019'' ]]) jobs, high latency also extends the execution time and accordingly increases resource costs.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all"""">Network plays a key role in the performance of distributed cloud services. Hence, communicating VMs should be placed on clouds that have low latency inter se for high QoS. Another factor is the latency between the user base and selected clouds. In the case of provisional applications such as scientific calculations or MapReduce (<ce:cross-ref id=""""crf0043"""" refid=""""bib0019"""">Dean and Ghemawat, 2008[[ refid=''''bib0019'''' ]]</ce:cross-ref>) jobs, high latency also extends the execution time and accordingly increases resource costs. Better latency optimization is vital for distributed, soft real-time services and applications (e.g. video streaming, online gaming) to run on federated cloud. Cloud computing may find a new area of application in real-time software provided that the network related challenges are overcome (<ce:cross-ref id=""""crf0044"""" refid=""""bib0023"""">García-Valls et al., 2014[[ refid=''''bib0023'''' ]]</ce:cross-ref>).</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
extends	Introduction	A. Shatnawi, A. Seriai, H.A. Sahraoui, Recovering architectural variability of a family of product variants , Software reuse for dynamic systems in the cloud and beyond - 14th international conference on software reuse, ICSR2015 (2015)	http://dx.doi.org/10.1016/j.jss.2016.07.039	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-07-039/br/bib0050	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-07-039/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-07-039/ctx/ctx0016		90	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-07-039/itrp/0169	'This journal paper is an extended version of our conference paper published in Shatnawi et al. (2015b[[ refid=''bib0050'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0009"""" view=""""all"""">This journal paper is an extended version of our conference paper published in <ce:cross-ref id=""""crf0035"""" refid=""""bib0050"""">Shatnawi et al. (2015b[[ refid=''''bib0050'''' ]]</ce:cross-ref>). This extension includes: (i) identifying new categories of architecture variability (e.g. internal and external component variability, variability of groups of dependencies, and dependencies related to optional component distribution). (ii) Deep analysis of the problem of SPLA identification. (iii) More details and deep analysis of the proposed solution. (iv) Related work classification. (v) Presentation of new results related to the identification of groups of variability. (vi) The pros and cons discussion. (vii ) Threats to validity discussion.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	A taxonomical classification and mapping of the research	R.E. Boyatzis, Transforming Qualitative Information: Thematic Analysis and Code Development , None, Sage Publications (1998)	http://dx.doi.org/10.1016/j.jss.2016.08.039			http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-08-039/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-08-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-08-039/ctx/ctx0036		96	9	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-08-039/itrp/0050	'Specifically, in the context of Fig. 5 the literature is generally classified into approaches for i) operational ii) evolution specific and iii) development related issues of robotics.2.Thematic Classification extends the generic classification by adding details based on the primary focus of research in a collection of related studies to identify and represent the recurring research themes using thematic analysis (Boyatzis, 1998[[ refid=''bib0010'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0050"""" view=""""all"""">The taxonomy in <ce:cross-ref id=""""crf0103"""" refid=""""fig0005"""">Fig. 5</ce:cross-ref><ce:float-anchor refid=""""fig0005""""/> provides a systematic <ce:italic>identification, naming</ce:italic> and <ce:italic>classification</ce:italic> of various research themes based on the similarity or distinctions of their relative contributions to answer <ce:bold>RQ 2</ce:bold>. By analyzing some relevant studies (e.g., (<ce:cross-refs id=""""crf0104"""" refid=""""bib0045 bib0007"""">Medvidovic and Taylor, 2000, Babar et al., 2004[[ refid=''''bib0045 bib0007'''' ]]</ce:cross-refs>)) and following some of the guidelines from <ce:italic>ACM Computing Classification System</ce:italic><ce:cross-ref id=""""crf0106"""" refid=""""cit_2""""><ce:sup loc=""""post"""">2</ce:sup></ce:cross-ref> and <ce:italic>Computing Research Repository</ce:italic><ce:cross-ref id=""""crf0107"""" refid=""""cit_3""""><ce:sup loc=""""post"""">3</ce:sup></ce:cross-ref> we derived the following categories:<ce:list id=""""celist0009""""><ce:list-item id=""""celistitem0018""""><ce:label>1.</ce:label><ce:para id=""""para0053"""" view=""""all""""><ce:italic><ce:bold>Generic Classification</ce:bold></ce:italic> that highlights the role of software architecture to support the operations, evolution (post-deployment) and development (pre-deployment) phases of robotic systems. The generic classification is used to organize the results (reviewed studies) into three distinct areas. Specifically, in the context of <ce:cross-ref id=""""crf0108"""" refid=""""fig0005"""">Fig. 5</ce:cross-ref> the literature is generally classified into approaches for i) operational ii) evolution specific and iii) development related issues of robotics.</ce:para></ce:list-item><ce:list-item id=""""celistitem0019""""><ce:label>2.</ce:label><ce:para id=""""para0054"""" view=""""all""""><ce:italic><ce:bold>Thematic Classification</ce:bold></ce:italic> extends the generic classification by adding details based on the primary focus of research in a collection of related studies to identify and represent the recurring research themes using thematic analysis (<ce:cross-ref id=""""crf0109"""" refid=""""bib0010"""">Boyatzis, 1998[[ refid=''''bib0010'''' ]]</ce:cross-ref>). We identified three predominant themes as i) coordination (11 studies, i.e., 20% approx. of the reviewed studies), ii) adaptation and reengineering (13 studies, i.e., 23%), and iii) modeling, design and programming (32 studies, i.e., 57%) of robotics in <ce:cross-ref id=""""crf0110"""" refid=""""fig0005"""">Fig. 5.</ce:cross-ref></ce:para></ce:list-item></ce:list></ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Conclusions, limitations and future lines	FI-WARE PPP Office, 2012, Official web site.	http://dx.doi.org/10.1016/j.jss.2016.11.025	conclusion		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-11-025/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-11-025/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-11-025/ctx/ctx0046		46	5	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2016-11-025/itrp/0013	'The use of FAST as part of the technology foundation (FI-WARE) behind the European public-private partnership on the Internet of the Future (FI-PPP, 2012[[ refid=''bib0023'' ]]) extends the life cycle to R&D projects covering areas as far apart as the transportation of goods and people, energy efficiency or bank management in the framework of smart cities.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0154"""" view=""""all"""">Additionally, we are using and testing the proposed TW within two on-going FP7 research projects: 4CaaSt (<ce:cross-ref id=""""crf0113"""" refid=""""bib0001"""">4CaaSt Project, 2012[[ refid=''''bib0001'''' ]]</ce:cross-ref>) (Building the Platform-as-a-Service of the Future) as part of its Mashup-as-a-Service solution, and FI-WARE (<ce:cross-ref id=""""crf0114"""" refid=""""bib0022"""">FI-WARE Project, 2012[[ refid=''''bib0022'''' ]]</ce:cross-ref>) (Future Internet Core Platform) as part of its applications and services ecosystem and generic delivery framework enablers for EUPs to build application mashups. The project users are experts in wide-ranging domains and are proficient users of the Internet and office automation software. However, they have very little technical or programming knowledge. So we expect to study users as part of these projects in order to update and refine our approach. The use of FAST as part of the technology foundation (FI-WARE) behind the European public-private partnership on the Internet of the Future (<ce:cross-ref id=""""crf0115"""" refid=""""bib0023"""">FI-PPP, 2012[[ refid=''''bib0023'''' ]]</ce:cross-ref>) extends the life cycle to R&amp;D projects covering areas as far apart as the transportation of goods and people, energy efficiency or bank management in the framework of smart cities.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
extends	Introduction: context and problem statement	S. Kallel, B. Tramoni, C. Tibermacine, C. Dony, A.H. Kacem, Automatic translation of architecture constraint specifications into components , Proceedings of the Ninth European Conference on Software Architecture, Springer (2015)	http://dx.doi.org/10.1016/j.jss.2017.01.032	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-01-032/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-01-032/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-01-032/ctx/ctx0006		46	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-01-032/itrp/0025	'This paper is an extension of a previous communication (Kallel et al., 2015[[ refid=''bib0023'' ]]) at ECSA (the European Conference on Software Architecture) 2015.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all"""">This paper is an extension of a previous communication (<ce:cross-ref id=""""crf0020"""" refid=""""bib0023"""">Kallel et al., 2015[[ refid=''''bib0023'''' ]]</ce:cross-ref>) at ECSA (the <ce:italic>European Conference on Software Architecture</ce:italic>) 2015. In this paper, we have particularly:<ce:list id=""""celist0003""""><ce:list-item id=""""celistitem0005""""><ce:label>•</ce:label><ce:para id=""""para0015"""" view=""""all"""">added a new step to the process, for generating executable programs, making thus possible the checking of architecture constraints on programs and at runtime;</ce:para></ce:list-item><ce:list-item id=""""celistitem0006""""><ce:label>•</ce:label><ce:para id=""""para0016"""" view=""""all"""">extended the process by generating constraint-services;</ce:para></ce:list-item><ce:list-item id=""""celistitem0007""""><ce:label>•</ce:label><ce:para id=""""para0017"""" view=""""all"""">illustrated the process with other richer examples;</ce:para></ce:list-item><ce:list-item id=""""celistitem0008""""><ce:label>•</ce:label><ce:para id=""""para0018"""" view=""""all"""">conducted a new experiment and made additional measurements;</ce:para></ce:list-item><ce:list-item id=""""celistitem0009""""><ce:label>•</ce:label><ce:para id=""""para0019"""" view=""""all"""">applied our process in a real-world system and showed the usability of our approach;</ce:para></ce:list-item><ce:list-item id=""""celistitem0010""""><ce:label>•</ce:label><ce:para id=""""para0020"""" view=""""all"""">largely extended the related works.</ce:para></ce:list-item></ce:list></ce:para>""''"'	extends	AGA+ANG	tba_50_classified_extends_semweb
cites_as_review	Introduction	T. Ermilov, A. Khalili, S. Auer, Ubiquitous semantic applications: a systematic literature review , Int. J. Semant. Web Inf. Syst. , vol. 10 (2014), pp.66-99	http://dx.doi.org/10.1016/j.jss.2017.05.048	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-05-048/br/bib0026	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-05-048/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-05-048/ctx/ctx0005		114	9	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-05-048/itrp/0010	'As a result, in addition to the problem of an expanding test input space, there are additional issues (i.e., mobility, usability, customizability, heterogeneity, collaboration, accessibility, evolvability, interoperability, scalability) that must be considered (Ermilov et al., 2014[[ refid=''bib0026'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0009"""" view=""""all"""">The definition of context remains elusive (<ce:cross-ref id=""""crf0007"""" refid=""""bib0025"""">Dourish, 2004[[ refid=''''bib0025'''' ]]</ce:cross-ref>; <ce:cross-ref id=""""crf0008"""" refid=""""bib0053"""">Pérez et al., 2009[[ refid=''''bib0053'''' ]]</ce:cross-ref>; <ce:cross-ref id=""""crf0009"""" refid=""""bib0052"""">Perera et al., 2014[[ refid=''''bib0052'''' ]]</ce:cross-ref>; <ce:cross-ref id=""""crf0010"""" refid=""""bib0030"""">Greenberg, 2001[[ refid=''''bib0030'''' ]]</ce:cross-ref>). <ce:cross-ref id=""""crf0011"""" refid=""""bib0024"""">Dey and Abowd (2000)[[ refid=''''bib0024'''' ]]</ce:cross-ref> define <ce:italic>context</ce:italic> as any information that can be used to characterize the situation of entities that are considered relevant to the interaction between users and applications. The capacity of identifying context changes and adapt the system behavior accordingly is called context-awareness<ce:italic>.</ce:italic> The authors further elaborate that in context-aware applications, contextual data is continuously changing. Therefore, the context-aware software has an increased ability to interact with other systems and devices, enlarging the possibilities of interaction not just with humans but also with other types of actors. As a result, in addition to the problem of an expanding test input space, there are additional issues (i.e., mobility, usability, customizability, heterogeneity, collaboration, accessibility, evolvability, interoperability, scalability) that must be considered (<ce:cross-ref id=""""crf0012"""" refid=""""bib0026"""">Ermilov et al., 2014[[ refid=''''bib0026'''' ]]</ce:cross-ref>).</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Implementation	None Document Object Model Core., , None (2017)	http://dx.doi.org/10.1016/j.jss.2017.06.038	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/br/bib0015	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/ctx/ctx0020		43	8	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/itrp/0005	'The information that are used by SearchDOMDep (Algorithm 1) is determined by the semantic of the API according to DOM specification (Document Object Model Core, 2017[[ refid=''bib0015'' ]]), e.g., input.value is a DNRead instruction performed on DOM element input, and it is unnecessary to search the subtree of input to find dependences.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0069"""" view=""""all""""><ce:italic>DOM dependence analysis.</ce:italic> We regard a JavaScript instruction as a DOM instruction if the operating object or returned value is DOM element. The information that are used by <ce:italic>SearchDOMDep</ce:italic> (<ce:cross-ref id=""""crf0100"""" refid=""""tbl0008"""">Algorithm 1</ce:cross-ref>) is determined by the semantic of the API according to DOM specification (<ce:cross-ref id=""""crf0101"""" refid=""""bib0015"""">Document Object Model Core, 2017[[ refid=''''bib0015'''' ]]</ce:cross-ref>), e.g., <ce:italic>input.value</ce:italic> is a DNRead instruction performed on DOM element <ce:italic>input</ce:italic>, and it is unnecessary to search the subtree of <ce:italic>input</ce:italic> to find dependences.</ce:para>""''"'	uses_method_in	FDY	
uses_method_in	Implementation	K. Sen, S. Kalasapur, T. Brutch, S. Gibbs, Jalangi: a selective record-replay and dynamic analysis framework for JavaScript , Proceedings of the Joint Meeting on Foundations of Software Engineering(ESEC/FSE) (2013)	http://dx.doi.org/10.1016/j.jss.2017.06.038	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/br/bib0010>	<http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/ctx/ctx0021>				http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/itrp/0006	'For Rule 2 in Section 3.4, we modify the instrumentation module of Jalangi (Sen et al., 2013[[ refid=''bib0010'' ]]) to capture the enter point and the exit point of each branch for the corresponding path condition, we further judge whether there are writing instructions between these two points.'			FDY+AGA	infered_pred1
uses_method_in	Implementation	K. Sen, S. Kalasapur, T. Brutch, S. Gibbs, Jalangi: a selective record-replay and dynamic analysis framework for JavaScript , Proceedings of the Joint Meeting on Foundations of Software Engineering(ESEC/FSE) (2013)	http://dx.doi.org/10.1016/j.jss.2017.06.038	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/br/bib0010>	<http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/ctx/ctx0019>				http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/itrp/0050	'To trace dependences dynamically, we incorporate the idea of shadow execution (Sen et al., 2013[[ refid=''bib0010'' ]]), in which the analysis can update and access the shadow value of a variable v. The shadow value records the value of def(v).'			FDY+AGA	infered_pred1
uses_method_in	Implementation	K. Sen, S. Kalasapur, T. Brutch, S. Gibbs, Jalangi: a selective record-replay and dynamic analysis framework for JavaScript , Proceedings of the Joint Meeting on Foundations of Software Engineering(ESEC/FSE) (2013)	http://dx.doi.org/10.1016/j.jss.2017.06.038	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/br/bib0010>	<http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/ctx/ctx0018>				http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/itrp/0051	'We instrument JavaScript code using Jalangi (Sen et al., 2013[[ refid=''bib0010'' ]]) to capture all executed JavaScript (including DOM) instructions.'			FDY+AGA	infered_pred1
uses_method_in	Implementation	J. Mickens, J. Elson, J. Howell, Mugshot : Deterministic Capture and Replay for JavaScript Applications , Proceedings of the USENIX Conference on Networked Systems Design and Implementation(NSDI) (2010)	http://dx.doi.org/10.1016/j.jss.2017.06.038	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/br/bib0008	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/ctx/ctx0017		43	8	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-06-038/itrp/0056	'We adopted a similar record-replay mechanism to Mugshot (Mickens et al., 2010[[ refid=''bib0008'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0065"""" view=""""all"""">Our implementation JSTrace is based on JavaScript record-replay. We adopted a similar record-replay mechanism to Mugshot (<ce:cross-ref id=""""crf0096"""" refid=""""bib0008"""">Mickens et al., 2010[[ refid=''''bib0008'''' ]]</ce:cross-ref>). We extended the replay phase to support event trace reduction. JSTrace is entirely written in JavaScript and transparent to users. Thus, JSTrace is easy to deploy.</ce:para>""''"'	cites	FDY	
extends	Introduction	H. Yang, X. Sun, Y.D. Bin Li and, DR_PSF: enhancing developer recommendation by leveraging personalized source-code files , The 40th IEEE Computer Society International Conference on Computers, Software and Applications (2016)	http://dx.doi.org/10.1016/j.jss.2017.09.021	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-09-021/br/bib0042	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-09-021/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-09-021/ctx/ctx0011		50	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-09-021/itrp/0085	'This article extends a preliminary study published as a research paper in a conference (Yang et al., 2016[[ refid=''bib0042'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0009"""" view=""""all"""">Developer recommendation is more concerned by bug triagers while supplementation information would be finally used by developers. In our approach, we think that when our approach recommends developers with supplementary information, bug triagers can better understand the bug assigning procedure based on the supplementary information why the incoming bugs are assigned to some developers rather than directly used the recommendation results generated by a developer recommendation approach. This article extends a preliminary study published as a research paper in a conference (<ce:cross-ref id=""""crf0018"""" refid=""""bib0042"""">Yang et al., 2016[[ refid=''''bib0042'''' ]]</ce:cross-ref>). It extends the preliminary study in various ways: (1) <ce:italic>EDR_SI</ce:italic> provides more personalized supplementary information for each developer, such as developer network and source-code change history. The empirical study shows the effectiveness of these supplementary information. (2) We evaluate the developer recommendation of <ce:italic>EDR_SI</ce:italic> to show that our approach can recommend junior developers well. That is, if the experience of junior developers can be efficiently extended, they (junior developers) can be recommended effectively. (3) A wider experiment with more subjects and metrics, is performed to fully evaluate the proposed <ce:italic>EDR_SI</ce:italic>.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Method	B. Kitchenham, S. Charters, Guidelines for performing Systematic Literature Reviews in Software Engineering , Engineering (2007)	http://dx.doi.org/10.1016/j.jss.2017.11.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/br/bib0034	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/ctx/ctx0057		177	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/itrp/0183	'The main goal of an SLR is to identify, evaluate and interpret the research results related to questions, topic area, or phenomenon and gather evidence to base conclusions (Kitchenham and Charters, 2007[[ refid=''bib0034'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0057"""" view=""""all"""">The main goal of an SLR is to identify, evaluate and interpret the research results related to questions, topic area, or phenomenon and gather evidence to base conclusions (<ce:cross-ref id=""""crf0103"""" refid=""""bib0034"""">Kitchenham and Charters, 2007[[ refid=''''bib0034'''' ]]</ce:cross-ref>).</ce:para>""''"'	cites	FDY	
uses_method_in	Method	Start-state of the art through systematic review tool , None (2015) , http://lapes.dc.ufscar.br/tools/start_tool	http://dx.doi.org/10.1016/j.jss.2017.11.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/br/bib0036	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/ctx/ctx0059		177	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/itrp/0203	'A software tool, named StArt (State of the Art through Systematic Reviews) (LAPES, 2015[[ refid=''bib0036'' ]]), was used to support the SLR execution.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0061"""" view=""""all"""">A software tool, named StArt (State of the Art through Systematic Reviews) (<ce:cross-ref id=""""crf0108"""" refid=""""bib0036"""">LAPES, 2015[[ refid=''''bib0036'''' ]]</ce:cross-ref>), was used to support the SLR execution. This tool is used to guide researchers conducting SLRs. StArt has been empirically evaluated, and it was demonstrated that such tool had positive results in the execution of SLRs (<ce:cross-ref id=""""crf0109"""" refid=""""bib0027"""">Hernandes et al., 2012[[ refid=''''bib0027'''' ]]</ce:cross-ref>).</ce:para>""''"'	cites	FDY	
uses_method_in	Method	C. Wohlin, Guidelines for snowballing in systematic literature studies and a replication in software engineering , Proceedings of the 18th International Conference on Evaluation and Assessment in Software Engineering, ACM (2014)	http://dx.doi.org/10.1016/j.jss.2017.11.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/br/bib0050	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/ctx/ctx0073		177	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/itrp/0243	'Our snowballing process is inspired by Wohlin''s guidelines (Wohlin, 2014[[ refid=''bib0050'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0118"""" view=""""all"""">Our snowballing process is inspired by Wohlin''''s guidelines (<ce:cross-ref id=""""crf0156"""" refid=""""bib0050"""">Wohlin, 2014[[ refid=''''bib0050'''' ]]</ce:cross-ref>). The intention of this step was to find any relevant paper that had not been considered based on papers already assessed as relevant. We performed author snowballing with the authors of the selected papers. We used the selected papers to realise the backward and forward snowballing. The references of each selected paper were analysed. Google Scholar (scholar.google.com) and DPBL computer science bibliography (<ce:inter-ref id=""""interref0021"""" xlink:href=""""http://dblp.uni-trier.de/"""" xlink:type=""""simple"""">http://dblp.uni-trier.de/</ce:inter-ref>) were used to identify the papers that cite the selected papers of this SLR.</ce:para>""''"'	cites	FDY	
uses_method_in	Method	B. Kitchenham, S. Charters, Guidelines for performing Systematic Literature Reviews in Software Engineering , Engineering (2007)	http://dx.doi.org/10.1016/j.jss.2017.11.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/br/bib0034	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/ctx/ctx0074		177	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/itrp/0249	'After selection and quality analysis, we performed data extraction of selected papers based on Kitchenham and Charters (2007[[ refid=''bib0034'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0119"""" view=""""all"""">After selection and quality analysis, we performed data extraction of selected papers based on <ce:cross-ref id=""""crf0157"""" refid=""""bib0034"""">Kitchenham and Charters (2007[[ refid=''''bib0034'''' ]]</ce:cross-ref>). During this stage, data were extracted from each of the 96 primary studies included in this SLR according to a predefined extraction form detailed in <ce:cross-ref id=""""crf0158"""" refid=""""tbl0007"""">Table 7</ce:cross-ref><ce:float-anchor refid=""""tbl0007""""/>. This form enabled us to record full details of the papers under review and to be specific about how each of them addressed our research questions. Data extraction was aided by the StArt tool. A Spreadsheet was used to extract some fields not supported by StArt, such as the image construct proposed by the extensions.</ce:para>""''"'	uses_data_from	FDY	
cites	Method	'R. Miles, K. Hamilton, Learning UML 2.0 , None, O''Reilly (2006)'	http://dx.doi.org/10.1016/j.jss.2017.11.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/br/bib0040	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/ctx/ctx0068		177	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/itrp/0284	'Considering the way new concepts are proposed, an extension can be developed using a light-weight or heavy-weight (Miles and Hamilton, 2006[[ refid=''bib0040'' ]]) strategy.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0107"""" view=""""all"""">Extending a modelling language is to add new constructs (<ce:cross-ref id=""""crf0139"""" refid=""""bib0004"""">Brambilla et al., 2012[[ refid=''''bib0004'''' ]]</ce:cross-ref>). Considering the way new concepts are proposed, an extension can be developed using a light-weight or heavy-weight (<ce:cross-ref id=""""crf0140"""" refid=""""bib0040"""">Miles and Hamilton, 2006[[ refid=''''bib0040'''' ]]</ce:cross-ref>) strategy. The light-weight mechanisms are a way of proposing extensions with a low syntactic impact by means of textual markers to represent stereotypes, constraints and tagged values. The heavy-weight extensions introduce new graphical representations in concrete syntax and involve the proposal of new metaclasses in the abstract syntax, therefore significantly impacting the modelling language.</ce:para>""''"'	cites	FDY	
cites	Method	, Social Modelling for Requirements Engineering, The MIT Press (2011)	http://dx.doi.org/10.1016/j.jss.2017.11.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/br/bib0055	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/ctx/ctx0066		177	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/itrp/0288	'A manual search was realised in seven editions of the International iStar workshop (2008, 2010, 2011, 2013, 2014, 2015 and 2016)44http://www.cin.ufpe.br/∼istar08/site/.http://sunsite.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-586/http://www.cin.ufpe.br/∼istar11/arquivos/iStar11-proceedings.pdfhttp://ceur-ws.org/Vol-978/http://ceur-ws.org/Vol-1157/http://ceur-ws.org/Vol-1674/ and in the book Social Modelling for Requirements Engineering (OMG Unified Modelling Language 2011[[ refid=''bib0055'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0088"""" view=""""all"""">A manual search was realised in seven editions of the International iStar workshop (2008, 2010, 2011, 2013, 2014, 2015 and 2016)<ce:cross-ref id=""""crf0137"""" refid=""""cit_4""""><ce:sup loc=""""post"""">4</ce:sup></ce:cross-ref><ce:footnote id=""""cit_4""""><ce:label>4</ce:label><ce:note-para id=""""notep0003"""" view=""""all""""><ce:inter-ref id=""""interref0013"""" xlink:href=""""http://www.cin.ufpe.br/~istar08/site/"""" xlink:type=""""simple"""">http://www.cin.ufpe.br/∼istar08/site/</ce:inter-ref>.</ce:note-para><ce:note-para id=""""notep0004"""" view=""""all""""><ce:inter-ref id=""""interref0014"""" xlink:href=""""http://sunsite.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-586/"""" xlink:type=""""simple"""">http://sunsite.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-586/</ce:inter-ref></ce:note-para><ce:note-para id=""""notep0005"""" view=""""all""""><ce:inter-ref id=""""interref0015"""" xlink:href=""""http://www.cin.ufpe.br/~istar11/arquivos/iStar11-proceedings.pdf"""" xlink:type=""""simple"""">http://www.cin.ufpe.br/∼istar11/arquivos/iStar11-proceedings.pdf</ce:inter-ref></ce:note-para><ce:note-para id=""""notep0006"""" view=""""all""""><ce:inter-ref id=""""interref0016"""" xlink:href=""""http://ceur-ws.org/Vol-978/"""" xlink:type=""""simple"""">http://ceur-ws.org/Vol-978/</ce:inter-ref></ce:note-para><ce:note-para id=""""notep0007"""" view=""""all""""><ce:inter-ref id=""""interref0017"""" xlink:href=""""http://ceur-ws.org/Vol-1157/"""" xlink:type=""""simple"""">http://ceur-ws.org/Vol-1157/</ce:inter-ref></ce:note-para><ce:note-para id=""""notep0008"""" view=""""all""""><ce:inter-ref id=""""interref0018"""" xlink:href=""""http://ceur-ws.org/Vol-1674/"""" xlink:type=""""simple"""">http://ceur-ws.org/Vol-1674/</ce:inter-ref></ce:note-para></ce:footnote> and in the book Social Modelling for Requirements Engineering (<ce:cross-ref id=""""crf0138"""" refid=""""bib0055"""">OMG Unified Modelling Language 2011[[ refid=''''bib0055'''' ]]</ce:cross-ref>). The proceedings of the two first editions of international iStar workshop (2001 and 2005) are not available.</ce:para>""''"'	cites	FDY	
cites	Method	M. Brambilla, J. Cabot, M. Wimmer, Model-Driven Software Engineering in Practice , None, Morgan & Claypool Publishers series Synthesis Lectures on Software Engineering (2012)	http://dx.doi.org/10.1016/j.jss.2017.11.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/ctx/ctx0067		177	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/itrp/0289	'Extending a modelling language is to add new constructs (Brambilla et al., 2012[[ refid=''bib0004'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0107"""" view=""""all"""">Extending a modelling language is to add new constructs (<ce:cross-ref id=""""crf0139"""" refid=""""bib0004"""">Brambilla et al., 2012[[ refid=''''bib0004'''' ]]</ce:cross-ref>). Considering the way new concepts are proposed, an extension can be developed using a light-weight or heavy-weight (<ce:cross-ref id=""""crf0140"""" refid=""""bib0040"""">Miles and Hamilton, 2006[[ refid=''''bib0040'''' ]]</ce:cross-ref>) strategy. The light-weight mechanisms are a way of proposing extensions with a low syntactic impact by means of textual markers to represent stereotypes, constraints and tagged values. The heavy-weight extensions introduce new graphical representations in concrete syntax and involve the proposal of new metaclasses in the abstract syntax, therefore significantly impacting the modelling language.</ce:para>""''"'	cites	FDY	
uses_method_in	Method	N. Goodman, Languages of Art: An Approach to a Theory of Symbols , None, Bobbs-Merrill Co. (1968)	http://dx.doi.org/10.1016/j.jss.2017.11.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/br/bib0026	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/ctx/ctx0064		177	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/itrp/0290	'The research questions RQ3, RQ6 and RQ8 were inspired on the notational system, as defined in semiotic clarity (Goodman, 1968[[ refid=''bib0026'' ]]) (See Section 2.3).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0080"""" view=""""all"""">The research questions RQ3, RQ6 and RQ8 were inspired on the notational system, as defined in semiotic clarity (<ce:cross-ref id=""""crf0132"""" refid=""""bib0026"""">Goodman, 1968[[ refid=''''bib0026'''' ]]</ce:cross-ref>) (See <ce:cross-ref id=""""crf0133"""" refid=""""sec0005"""">Section 2.3</ce:cross-ref>). When there is not a 1:1 correspondence, one or more anomalies may occur. These anomalies can be symbol deficit, symbol redundancy, symbol overload and symbol excess. We think this analysis is important to requirements engineers that intend to use two extensions together (modelling mobile systems and security, for example), thus they can identify if there are conflicts between them. Therefore, researchers that intend to propose modelling tools can identify the gap between the syntaxes of iStar extensions.</ce:para>""''"'	uses_method_in	FDY	
cites	Method	E. Yu, Towards modelling and reasoning support for early phase requirements engineering , Proceedings of the 3rd IEEE international Conference on Requirements Engineering (1997)	http://dx.doi.org/10.1016/j.jss.2017.11.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/br/bib0052	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/ctx/ctx0065		177	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/itrp/0291	'The search period starts in 1990 when iStar was proposed by Eric Yu in his thesis (Yu, 1997[[ refid=''bib0052'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0085"""" view=""""all"""">The search period starts in 1990 when iStar was proposed by Eric Yu in his thesis (<ce:cross-ref id=""""crf0135"""" refid=""""bib0052"""">Yu, 1997[[ refid=''''bib0052'''' ]]</ce:cross-ref>). The search period finishes in 2016. The search was realised in title, keywords and abstract based on terms presented in <ce:cross-ref id=""""crf0136"""" refid=""""tbl0005"""">Table 5</ce:cross-ref><ce:float-anchor refid=""""tbl0005""""/>. These search terms for different types of software engineering articles were combined in the following way: (T1 AND T2 AND T3 AND (T4 OR T5)). The string was adapted to each electronic database. We used the iStar and Goal-oriented Requirement Language (GRL) as terms related to modelling language. We also used TROPOS, the main methodology based on iStar. The URN (User Requirements Notation) was not considered because it is a merge between GRL and Use Case Maps. Therefore, it is not part of the scope of this research, as mentioned at the beginning of this section.</ce:para>""''"'	cites	FDY	
uses_method_in	Method	Start-state of the art through systematic review tool , None (2015) , http://lapes.dc.ufscar.br/tools/start_tool	http://dx.doi.org/10.1016/j.jss.2017.11.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/br/bib0036	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/ctx/ctx0062		177	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/itrp/0292	'Next, we identified the duplicated papers with the help of StArt (LAPES December 2015[[ refid=''bib0036'' ]]), this tool detects the similarity level between the papers and it facilitates the repeated identification.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0067"""" view=""""all"""">Next, we identified the duplicated papers with the help of StArt (<ce:cross-ref id=""""crf0126"""" refid=""""bib0036"""">LAPES December 2015[[ refid=''''bib0036'''' ]]</ce:cross-ref>), this tool detects the similarity level between the papers and it facilitates the repeated identification. When two papers were considered duplicated, we made the choice of which should remain based on the number of citations from each of them in Google Scholar.</ce:para>""''"'	cites	FDY	
cites	Method	X. Franch, A. Mate, J.C. Trujillo, C. Cares, On the joint use of i* with other modelling frameworks: a vision paper , IEEE International Requirements Engineering Conference (2011)	http://dx.doi.org/10.1016/j.jss.2017.11.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/br/bib0084	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/ctx/ctx0063		177	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/itrp/0293	'The joint use of iStar with other existing modelling frameworks is discussed in Franch et al. (2011[[ refid=''bib0084'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0076"""" view=""""all"""">It is out of the scope of this research to analyse mergers between iStar and other existing languages. The joint use of iStar with other existing modelling frameworks is discussed in <ce:cross-ref id=""""crf0130"""" refid=""""bib0084"""">Franch et al. (2011[[ refid=''''bib0084'''' ]]</ce:cross-ref>).</ce:para>""''"'	cites	FDY	
cites	Method	E.M. Hernandes, A. Zamboni, S Fabbri, Thommazo AD Using GQM and tam to evaluate start—a tool that supports systematic review , CLEI Electron J. , vol. 15 (2012), pp.1-13	http://dx.doi.org/10.1016/j.jss.2017.11.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/ctx/ctx0060		177	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-023/itrp/0294	'StArt has been empirically evaluated, and it was demonstrated that such tool had positive results in the execution of SLRs (Hernandes et al., 2012[[ refid=''bib0027'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0061"""" view=""""all"""">A software tool, named StArt (State of the Art through Systematic Reviews) (<ce:cross-ref id=""""crf0108"""" refid=""""bib0036"""">LAPES, 2015[[ refid=''''bib0036'''' ]]</ce:cross-ref>), was used to support the SLR execution. This tool is used to guide researchers conducting SLRs. StArt has been empirically evaluated, and it was demonstrated that such tool had positive results in the execution of SLRs (<ce:cross-ref id=""""crf0109"""" refid=""""bib0027"""">Hernandes et al., 2012[[ refid=''''bib0027'''' ]]</ce:cross-ref>).</ce:para>""''"'	cites	FDY	
uses_method_in	Implementation	M.E. Vara Larsen, J. Deantoni, B. Combemale, F. Mallet, A Behavioral Coordination Operator Language (BCOoL) , International Conference on Model Driven Engineering Languages and Systems (MODELS), ACM (2015)	http://dx.doi.org/10.1016/j.jss.2017.11.025	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-025/br/bib0063	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-025/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-025/ctx/ctx0020		42	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-025/itrp/0004	'The coordination engine supports the behavioral coordination of heterogeneous models, based on coordination patterns defined using BCOoL (Vara Larsen et al., 2015[[ refid=''bib0063'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0200"""" view=""""all"""">Using the framework, we implemented four different execution engines. The Java engine is dedicated to operational semantics that are entirely defined using any Java-based language, such as Java, Xtend (<ce:cross-ref id=""""crf0117"""" refid=""""bib0021"""">Efftinge et al., 2012[[ refid=''''bib0021'''' ]]</ce:cross-ref>) or Kermeta (<ce:cross-ref id=""""crf0118"""" refid=""""bib0032"""">Jézéquel et al., 2013[[ refid=''''bib0032'''' ]]</ce:cross-ref>). The Java+MoCCML engine is dedicated to operational semantics where the (possibly concurrent and timed) control is described in the MoCCML formal language (<ce:cross-ref id=""""crf0119"""" refid=""""bib0018"""">Deantoni et al., 2015[[ refid=''''bib0018'''' ]]</ce:cross-ref>), while the execution rules are written in any Java based language (e.g., Kermeta) (<ce:cross-ref id=""""crf0120"""" refid=""""bib0014"""">Combemale et al., 2013[[ refid=''''bib0014'''' ]]</ce:cross-ref>). The xMOF engine supports the execution of operational semantics defined with xMOF (<ce:cross-ref id=""""crf0121"""" refid=""""bib0046"""">Mayerhofer et al., 2013[[ refid=''''bib0046'''' ]]</ce:cross-ref>). The coordination engine supports the behavioral coordination of heterogeneous models, based on coordination patterns defined using BCOoL (<ce:cross-ref id=""""crf0122"""" refid=""""bib0063"""">Vara Larsen et al., 2015[[ refid=''''bib0063'''' ]]</ce:cross-ref>). We plan to implement more execution engines to integrate more metaprogramming approaches in the future.</ce:para>""''"'	cites	FDY	
uses_method_in	Implementation	T. Mayerhofer, P. Langer, M. Wimmer, G. Kappel, xMOF: Executable DSMLs based on fUML , 6th Int. Conf. on Soft. Lang. Eng. (SLE), Springer (2013)	http://dx.doi.org/10.1016/j.jss.2017.11.025	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-025/br/bib0046	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-025/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-025/ctx/ctx0019		42	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-025/itrp/0062	'The xMOF engine supports the execution of operational semantics defined with xMOF (Mayerhofer et al., 2013[[ refid=''bib0046'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0200"""" view=""""all"""">Using the framework, we implemented four different execution engines. The Java engine is dedicated to operational semantics that are entirely defined using any Java-based language, such as Java, Xtend (<ce:cross-ref id=""""crf0117"""" refid=""""bib0021"""">Efftinge et al., 2012[[ refid=''''bib0021'''' ]]</ce:cross-ref>) or Kermeta (<ce:cross-ref id=""""crf0118"""" refid=""""bib0032"""">Jézéquel et al., 2013[[ refid=''''bib0032'''' ]]</ce:cross-ref>). The Java+MoCCML engine is dedicated to operational semantics where the (possibly concurrent and timed) control is described in the MoCCML formal language (<ce:cross-ref id=""""crf0119"""" refid=""""bib0018"""">Deantoni et al., 2015[[ refid=''''bib0018'''' ]]</ce:cross-ref>), while the execution rules are written in any Java based language (e.g., Kermeta) (<ce:cross-ref id=""""crf0120"""" refid=""""bib0014"""">Combemale et al., 2013[[ refid=''''bib0014'''' ]]</ce:cross-ref>). The xMOF engine supports the execution of operational semantics defined with xMOF (<ce:cross-ref id=""""crf0121"""" refid=""""bib0046"""">Mayerhofer et al., 2013[[ refid=''''bib0046'''' ]]</ce:cross-ref>). The coordination engine supports the behavioral coordination of heterogeneous models, based on coordination patterns defined using BCOoL (<ce:cross-ref id=""""crf0122"""" refid=""""bib0063"""">Vara Larsen et al., 2015[[ refid=''''bib0063'''' ]]</ce:cross-ref>). We plan to implement more execution engines to integrate more metaprogramming approaches in the future.</ce:para>""''"'	cites	FDY	
cites	Implementation	E. Bousse, T. Degueule, D. Vojtisek, T. Mayerhofer, J. Deantoni, B. Combemale, Execution Framework of the GEMOC Studio (Tool Demo) , Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering, Amsterdam, Netherlands (2016)	http://dx.doi.org/10.1016/j.jss.2017.11.025	methods		http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-025/br/bib0007	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-025/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-025/ctx/ctx0016		42	7	http://www.scar.disi.unibo.it/r/10-1016-j-jss-2017-11-025/itrp/0074	'This framework was previously presented in detail in Bousse et al. (2016)[[ refid=''bib0007'' ]], and we summarize thereafter its main aspects and features.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0196"""" view=""""all"""">We applied the pattern that we presented in <ce:cross-ref id=""""crf0114"""" refid=""""sec0008"""">Section 4</ce:cross-ref>, defining that an <ce:italic>execution engine</ce:italic> sends notifications to <ce:italic>execution listeners</ce:italic>, to implement a complete Java <ce:italic>execution framework</ce:italic> for the GEMOC Modeling Workbench. This framework was previously presented in detail in <ce:cross-ref id=""""crf0115"""" refid=""""bib0007"""">Bousse et al. (2016)[[ refid=''''bib0007'''' ]]</ce:cross-ref>, and we summarize thereafter its main aspects and features.</ce:para>""''"'	cites	FDY	
extends	Introduction	A. Anjos, M. Chakka, S. Marcel, Motion-based counter-measures to photo attacks in face recognition , IET Biomet. , vol. 3 (2014), pp.147-158	http://dx.doi.org/10.1016/j.jvcir.2017.12.004	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-jvcir-2017-12-004/br/b0060	http://www.scar.disi.unibo.it/r/10-1016-j-jvcir-2017-12-004/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-jvcir-2017-12-004/ctx/ctx0007		64	8	http://www.scar.disi.unibo.it/r/10-1016-j-jvcir-2017-12-004/itrp/0042	'The present article extends the work of Anjos et al. [12][[ refid=''b0060'' ]] by identifying discriminant motion cues for the detection of both photo and video attacks under various spoofing scenarios.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0015"""" view=""""all"""">Facing this evolution of spoofing stratagems, numerous anti-spoofing solutions have been developed over the years. Hardware-based protection measures use extra hardware for the anti-spoofing task to measure intrinsic body attributes of the client such as body temperature, heart rate and skin reflectance or body reactions provoked by an external stimuli such as eye-blinking in response to a flashing light. Reversely, software-based countermeasures only use the data acquired by the authentication sensor, usually a webcam, to detect spoofing attacks. Image processing techniques extract the discriminant information between real and fake faces contained in texture, motion or scenic cues. Despite the early popularity of motion-based methods in photo attack detection, motion-based countermeasures have been somehow overlooked due to their lack of robustness against video or mask attacks. Instead, static-based countermeasures have been widely investigated using texture descriptors <ce:cross-refs id=""""r0005"""" refid=""""b0030 b0035 b0040"""">[6–8][[ refid=''''b0030 b0035 b0040'''' ]]</ce:cross-refs>, band-pass filters <ce:cross-refs id=""""r0010"""" refid=""""b0045 b0050"""">[9,10][[ refid=''''b0045 b0050'''' ]]</ce:cross-refs> and image quality assessment <ce:cross-ref id=""""c0075"""" refid=""""b0055"""">[11][[ refid=''''b0055'''' ]]</ce:cross-ref>. During the second IJCB competition, the combination of texture and motion anti-spoofing solutions achieved superior results and showed how both motion and texture information complements each other. Unfortunately, the contribution of motion-based countermeasures is not clearly stated in the litterature especially regarding video attack detection. To the best of our knowledge, only the work of Anjos et al. <ce:cross-ref id=""""c0080"""" refid=""""b0060"""">[12][[ refid=''''b0060'''' ]]</ce:cross-ref> provides a comparative study of motion-based countermeasures but the evaluation is limited to the detection of print attacks only. The present article extends the work of Anjos et al. <ce:cross-ref id=""""c0085"""" refid=""""b0060"""">[12][[ refid=''''b0060'''' ]]</ce:cross-ref> by identifying discriminant motion cues for the detection of both photo and video attacks under various spoofing scenarios. A new motion-based countermeasure is proposed to capture these cues and assess their reliability for fake face detection in the context of non-cooperative face identification. We argue that motion-cues are capable of dealing with most of the photo and video attack scenarios contained in the latest public spoof databases due to extra discriminant movements which are conveyed when performing an attack. Indeed, we identify at least three types of unnatural motions: (i) absence of motion, (ii) hand-shaking movements and (iii) simulated movements. The first type of unnatural motions is characteristic of photo attacks displayed on a fixed support while the second type corresponds to attacks performed by hand-holding the fake face in front of the sensor. Also, camera shakes generated when acquiring the face used for spoofing constitutes another source of unusual hand-shaking movements that can be inconsistent with the sensor motion during authentication. Finally, manipulations on printed photos such as warping, bending or simulating eye-blinks to simulate liveness produce unrealistic movements. Mask attacks are also considered in this work although their current quality is still imperfect with only rigid mask data available for the moment. But ultimately high quality masks will be able to fit the shape of the face while being flexible enough to mimic real face movements.</ce:para>""''"'	extends	ANG	
extends	Activity recognition model	I. González Díaz, V. Buso, J. Benois-Pineau, G. Bourmaud, R. Megret, Modeling instrumental activities of daily living in egocentric vision as sequences of active objects and context for alzheimer disease research , Proceedings of the 1st ACM International Workshop on Multimedia Indexing and Information Retrieval for Healthcare, MIIRH ’13, ACM (2013)	http://dx.doi.org/10.1016/j.jvcir.2018.01.009	model		http://www.scar.disi.unibo.it/r/10-1016-j-jvcir-2018-01-009/br/b0040	http://www.scar.disi.unibo.it/r/10-1016-j-jvcir-2018-01-009/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-jvcir-2018-01-009/ctx/ctx0036		66	5	http://www.scar.disi.unibo.it/r/10-1016-j-jvcir-2018-01-009/itrp/0050	'In this section we present the global activity recognition model, which extends our research conducted in [8][[ refid=''b0040'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0075"""" view=""""all"""">In this section we present the global activity recognition model, which extends our research conducted in <ce:cross-ref id=""""c0175"""" refid=""""b0040"""">[8][[ refid=''''b0040'''' ]]</ce:cross-ref>. We begin by presenting the model inputs. Then we elaborate on the temporal features we built upon. Finally, we study different ways of combining model inputs in temporal multi-modal features via different novel fusion schemes.</ce:para>""''"'	extends	ANG	
extends	Introduction	A. Furnari, G.M. Farinella, S. Battiato, Temporal segmentation of egocentric videos to highlight personal locations of interest , European Conference on Computer Vision Workshops (EPIC), LNCS, Springer , vol. vol. 9913 (2016), pp.474-489	http://dx.doi.org/10.1016/j.jvcir.2018.01.019	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-jvcir-2018-01-019/br/b0105	http://www.scar.disi.unibo.it/r/10-1016-j-jvcir-2018-01-019/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-jvcir-2018-01-019/ctx/ctx0010		59	5	http://www.scar.disi.unibo.it/r/10-1016-j-jvcir-2018-01-019/itrp/0077	'This paper extends our previous work [21][[ refid=''b0105'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0045"""" view=""""all"""">This paper extends our previous work <ce:cross-ref id=""""c0035"""" refid=""""b0105"""">[21][[ refid=''''b0105'''' ]]</ce:cross-ref>. In particular, we present the proposed method in greater details and analyzes the impact of each component and related parameters more thoroughly. We extend the experimental analysis by defining a novel performance measure designed to evaluate segmentation accuracy from a shot-retrieval point of view. New comparisons with many state of the art methods are also introduced. Finally, we publicly release the code implementing the proposed method and evaluation measures.</ce:para>""''"'	extends	ANG	
uses_method_in	Discussion and conclusion	Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A. L., 2014. Semantic image segmentation with deep convolutional nets and fully connected CRFs. arXiv preprint arXiv:	http://dx.doi.org/10.1016/j.media.2016.10.004	discussion	conclusion	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/br/bib0007>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/ctx/ctx0073>				http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/itrp/0028	'Finally, we presented the first application of a 3D fully connected CRF on medical data, employed as a post-processing step to refine the network’s output, a method that has also been shown promising for processing 2D natural images (Chen et al., 2014[[ refid=''bib0007'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method	K. He, X. Zhang, S. Ren, J. Sun, Delving deep into rectifiers: Surpassing human-level performance on imagenet classification , Proceedings of the IEEE International Conference on Computer Vision (2015)	http://dx.doi.org/10.1016/j.media.2016.10.004	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/br/bib0022>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/ctx/ctx0046>				http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/itrp/0035	'To better preserve the signal in the initial training stage we adopt a scheme recently derived for ReLu-based networks by He et al. (2015)[[ refid=''bib0022'' ]] and initialize the kernel weights of our system by sampling from the normal distribution N(0,2/nlin).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Method	Ioffe, S., Szegedy, C., 2015. Batch normalization: accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:	http://dx.doi.org/10.1016/j.media.2016.10.004	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/br/bib0026>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/ctx/ctx0047>				http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/itrp/0036	'A phenomenon of similar nature that hinders the network’s performance is the “internal covariate shift” (Ioffe and Szegedy, 2015[[ refid=''bib0026'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Additional details on network configurations	K. He, X. Zhang, S. Ren, J. Sun, Delving deep into rectifiers: Surpassing human-level performance on imagenet classification , Proceedings of the IEEE International Conference on Computer Vision (2015)	http://dx.doi.org/10.1016/j.media.2016.10.004			<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/br/bib0022>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/sec/appendix-b>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/ctx/ctx0080>				http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/itrp/0053	'They all use the PReLu non-linearity (He et al., 2015[[ refid=''bib0022'' ]]).'			FDY+AGA	infered_pred1
cites	Evaluation on clinical data	O. Maier, B.H. Menze, ISLES 2015 – A public evaluation benchmark for ischemic stroke lesion segmentation from multispectral MRI , Med. Image Anal. , vol. 35 (2017), pp.250-269	http://dx.doi.org/10.1016/j.media.2016.10.004	results	data	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/br/bib0041>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/ctx/ctx0065>				http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/itrp/0056	'We participated in the 2015 Ischemic Stroke Lesion Segmentation (ISLES) challenge, where our system achieved the best results among all participants on sub-acute ischemic stroke lesions (Maier et al., 2017[[ refid=''bib0041'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method	Ioffe, S., Szegedy, C., 2015. Batch normalization: accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:	http://dx.doi.org/10.1016/j.media.2016.10.004	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/br/bib0026>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/ctx/ctx0048>				http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/itrp/0058	'For countering it, we adopt the recently proposed Batch Normalisation (BN) technique to all hidden layers (Ioffe and Szegedy, 2015[[ refid=''bib0026'' ]]), which allows normalization of the FM activations at every optimization step in order to better preserve the signal.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Method	Springenberg, J. T., Dosovitskiy, A., Brox, T., Riedmiller, M., 2014. Striving for simplicity: the all convolutional net. arXiv preprint arXiv:	http://dx.doi.org/10.1016/j.media.2016.10.004	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/br/bib0059>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/ctx/ctx0039>				http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/itrp/0082	'Its size, φl, increases at each subsequent layer l and is given by the 3-dimensional vector: [[ formulaid=''id12_pos0'' ]] where κl,τl∈N3 are vectors expressing the size of the kernels and stride of the receptive field at layer l. τl is given by the product of the strides of kernels in layers preceding l. In this work only unary strides are used, as larger strides downsample the FMs (Springenberg et al., 2014[[ refid=''bib0059'' ]]), which is unwanted behaviour for accurate segmentation.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Evaluation on clinical data	J.E. Iglesias, C.-Y. Liu, P.M. Thompson, Z. Tu, Robust brain extraction across datasets and comparison with publicly available methods , Med. Imaging IEEE Trans. , vol. 30 (2011), pp.1617-1634	http://dx.doi.org/10.1016/j.media.2016.10.004	results	data	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/br/bib0024>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/ctx/ctx0057>				http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/itrp/0084	'Brain masks were obtained using the ROBEX tool (Iglesias et al., 2011[[ refid=''bib0024'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method	P. Krähenbühl, V. Koltun, Efficient inference in fully connected CRFs with gaussian edge potentials , Adv. Neural Inf. Process. Syst , vol. 24 (2011), pp.109-117	http://dx.doi.org/10.1016/j.media.2016.10.004	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/br/bib0031>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/ctx/ctx0052>				http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/itrp/0092	'Krähenbühl and Koltun (2011)[[ refid=''bib0031'' ]] observed that if the penalty function is defined as a linear combination of Gaussian kernels, k(fi,fj)=∑m=1Mw(m)k(m)(fi,fj), the model lends itself for very efficient inference with mean field approximation, after expressing message passing as convolutions with the Gaussian kernels in the space of the feature vectors fi, fj.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Method	P. Krähenbühl, V. Koltun, Efficient inference in fully connected CRFs with gaussian edge potentials , Adv. Neural Inf. Process. Syst , vol. 24 (2011), pp.109-117	http://dx.doi.org/10.1016/j.media.2016.10.004	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/br/bib0031>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/ctx/ctx0051>				http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/itrp/0093	'We employ a fully connected CRF (Krähenbühl and Koltun, 2011[[ refid=''bib0031'' ]]) as a post-processing step to achieve more structured predictions.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_data_from	Evaluation on clinical data	B.H. Menze, A. Jakab, S. Bauer, J. Kalpathy-Cramer, K. Farahani, J. Kirby, Y. Burren, N. Porz, J. Slotboom, R. Wiest, The multimodal brain tumor image segmentation benchmark (BRATS) , Med. Imaging IEEE Trans. , vol. 34 (2015), pp.1993-2024	http://dx.doi.org/10.1016/j.media.2016.10.004	results	data	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/br/bib0042>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/ctx/ctx0063>				http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/itrp/0113	'For brain tumours, we evaluate our system on the data from the 2015 Brain Tumour Segmentation Challenge (BRATS) (Menze et al., 2015[[ refid=''bib0042'' ]]).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Additional details on network configurations	K. He, X. Zhang, S. Ren, J. Sun, Delving deep into rectifiers: Surpassing human-level performance on imagenet classification , Proceedings of the IEEE International Conference on Computer Vision (2015)	http://dx.doi.org/10.1016/j.media.2016.10.004			<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/br/bib0022>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/sec/appendix-b>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/ctx/ctx0082>				http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/itrp/0120	'Deeper models (and the “Shallow+” model in Section 3.3) use the weight initialisation scheme of He et al. (2015)[[ refid=''bib0022'' ]].'			FDY+AGA	infered_pred1
cites	Discussion and conclusion	A. Rao, C. Ledig, V. Newcombe, D. Menon, D. Rueckert, Contusion segmentation from subjects with traumatic brain injury: a random forest framework , Biomedical Imaging (ISBI), 2014 IEEE 11th International Symposium on, IEEE (2014)	http://dx.doi.org/10.1016/j.media.2016.10.004	discussion	conclusion	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/br/bib0050>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/ctx/ctx0074>				http://www.scar.disi.unibo.it/r/10-1016-j-media-2016-10-004/itrp/0123	'As a comparison, we improved over the reported performance of the pipeline in Rao et al. (2014)[[ refid=''bib0050'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
extends	Introduction	Z. Wu, Y. Gao, F. Shi, V. Jewells, D. Shen, Automatic hippocampal subfield segmentation from 3t multi-modality images , International Workshop on Machine Learning in Medical Imaging, Springer (2016)	http://dx.doi.org/10.1016/j.media.2017.09.006	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-media-2017-09-006/br/bib0061	http://www.scar.disi.unibo.it/r/10-1016-j-media-2017-09-006/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-media-2017-09-006/ctx/ctx0018		41	3	http://www.scar.disi.unibo.it/r/10-1016-j-media-2017-09-006/itrp/0067	'This paper significantly extends our previous workshop paper (Wu et al., 2016[[ refid=''bib0061'' ]]) in the following aspects.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0010"""" view=""""all"""">This paper significantly extends our previous workshop paper (<ce:cross-ref id=""""crf0021"""" refid=""""bib0061"""">Wu et al., 2016[[ refid=''''bib0061'''' ]]</ce:cross-ref>) in the following aspects. a) More details of the method are provided; b) Experiments on newly labeled dataset (4 subjects) from the HCP dataset (<ce:cross-ref id=""""crf0022"""" refid=""""bib0050"""">Van Essen et al., 2013[[ refid=''''bib0050'''' ]]</ce:cross-ref>) are also included to evaluate the benefits of employing multi-modality features from 3T T1, 3T T2, and 3T rs-fMRI data. Previously, we only used 3T T1 MRI and 3T rs-fMRI; c) More comparisons with state-of-art methods are also included.</ce:para>""''"'	extends	ANG	
extends	Introduction	Z. Wu, S.H. Park, Y. Guo, Y. Gao, D. Shen, Regression guided deformable models for segmentation of multiple brain ROIs , Proceedings of International Workshop on Machine Learning in Medical Imaging, Springer (2016)	http://dx.doi.org/10.1016/j.media.2017.11.001	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-media-2017-11-001/br/bib0061	http://www.scar.disi.unibo.it/r/10-1016-j-media-2017-11-001/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-media-2017-11-001/ctx/ctx0024		40	4	http://www.scar.disi.unibo.it/r/10-1016-j-media-2017-11-001/itrp/0017	'This paper significantly extends our previous workshop paper (Wu et al., 2016[[ refid=''bib0061'' ]]) in aspects of both technique and application.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0009"""" view=""""all"""">Regarding the learning of joint classification and regression forest as a discriminative procedure while the deformable model segmentation as a generative procedure, the contribution of our method can be summarized in the following three aspects. <ce:italic>First</ce:italic>, rather than directly using CRRF result as the segmentation, the regression result of CRRF is used to robustly guide a deformable segmentation model to fit for the target ROI. This strategy not only solves the sensitivity issue of initialization that exists in the traditional deformable segmentation models, but also avoids the isolated segmentations and the jagged ROI boundaries that might exist in the classification based segmentation methods. <ce:italic>Second</ce:italic>, the discriminative ability of CRRF over the whole brain was boosted by combining the initial context features (extracted from the fast linear registration results) with the appearance features. <ce:italic>Third</ce:italic>, integrating the discriminative power of CRRF and the generative power of deformable model in a multi-resolution framework contributes to an efficient segmentation. To validate the effectiveness of our proposed method, we evaluate it on three widely used public datasets, including IXI atlas dataset (<ce:cross-refs id=""""crfs0007"""" refid=""""bib0022 bib0023"""">Gousias et al., 2008; Hammers et al., 2003[[ refid=''''bib0022 bib0023'''' ]]</ce:cross-refs>) (<ce:inter-ref id=""""interref0001"""" xlink:href=""""http://brain-development.org/brain-atlases/"""" xlink:type=""""simple"""">http://brain-development.org/brain-atlases/</ce:inter-ref>), LONI dataset (<ce:cross-ref id=""""crf0039"""" refid=""""bib0046"""">Shattuck et al., 2008[[ refid=''''bib0046'''' ]]</ce:cross-ref>), and SATA dataset (<ce:cross-ref id=""""crf0040"""" refid=""""bib0003"""">Asman et al., 2013[[ refid=''''bib0003'''' ]]</ce:cross-ref>). For all these datasets, our proposed method outperforms the state-of-the-art methods, including sparse patch based label fusion (SPBL) (<ce:cross-ref id=""""crf0041"""" refid=""""bib0060"""">Wu et al., 2012[[ refid=''''bib0060'''' ]]</ce:cross-ref>) and hierarchical sparse patch based label fusion (HSPBL) (<ce:cross-ref id=""""crf0042"""" refid=""""bib0057"""">Wu et al., 2015[[ refid=''''bib0057'''' ]]</ce:cross-ref>), in terms of both segmentation accuracy and computational cost. This paper significantly extends our previous workshop paper (<ce:cross-ref id=""""crf0043"""" refid=""""bib0061"""">Wu et al., 2016[[ refid=''''bib0061'''' ]]</ce:cross-ref>) in aspects of both technique and application. <ce:italic>From the technical point of view</ce:italic>, the additional initial context features are combined with the appearance features for boosting the discriminative ability of CRRF. While in the previous workshop paper, only the appearance features were used. This combination enables us to extend from partial brain ROIs segmentation in the workshop paper to the whole brain ROIs segmentation in this work. Without using initial context features, many brain ROIs (especially the small cortical regions) failed to be segmented. For example, there are 18 ROIs (out of 83 ROIs) failed to be segmented in the IXI atlas dataset without using initial context features. <ce:italic>From the application point of view</ce:italic>, we extended our validation by applying the method to the entire brain ROIs, employing also two more datasets (LONI and SATA), as well as including more sophisticated comparisons with the state-of-the-art brain segmentation methods.</ce:para>""''"'	extends	ANG	
cites_as_review	Related work	B.T. Truong, S. Venkatesh, Video abstraction: a systematic review and classification , ACM Trans. Multimedia Comput. Commun. Appl. , vol. 3 (2007), pp.1-37	http://dx.doi.org/10.1016/j.neucom.2012.06.056	related work		http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2012-06-056/br/bib4	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2012-06-056/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2012-06-056/ctx/ctx0003		29	5	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2012-06-056/itrp/0018	'A number of video summarization techniques have been presented in the research literature [4][[ refid=''bib4'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0035"""" view=""""all"""">Video summarization is the process of generating the montage of a given video that indicates its main theme and contents. The video summaries are abbreviated surrogates of the original semantic content from the video, which can subsequently be integrated into a range of applications, such as interactive browsing and searching system, thereby offering the user an indispensable means of managing and effectively accessing digital video content. A number of video summarization techniques have been presented in the research literature <ce:cross-ref id=""""cr0085"""" refid=""""bib4"""">[4][[ refid=''''bib4'''' ]]</ce:cross-ref>. There are several ways to represent a video summary, including mosaic images <ce:cross-refs id=""""crs0005"""" refid=""""bib5 bib6"""">[5,6][[ refid=''''bib5 bib6'''' ]]</ce:cross-refs>, a set of key frames <ce:cross-refs id=""""crs0010"""" refid=""""bib7 bib8 bib9"""">[7–9][[ refid=''''bib7 bib8 bib9'''' ]]</ce:cross-refs>, key objects <ce:cross-refs id=""""crs0015"""" refid=""""bib10 bib11"""">[10,11][[ refid=''''bib10 bib11'''' ]]</ce:cross-refs>, or a reduced-length video <ce:cross-ref id=""""cr0090"""" refid=""""bib12"""">[12][[ refid=''''bib12'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites	Related work	'S.H. Cooray, H.Bredin, L.Q. Xu, N.E, O''Connor, An interactive and multi-level framework for summarising user generated videos, in: Proceedings of the ACM Conference on Multimedia, New York, USA, 2009, pp. 685–688.'	http://dx.doi.org/10.1016/j.neucom.2012.06.056	related work		http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2012-06-056/br/bib17	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2012-06-056/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2012-06-056/ctx/ctx0014		29	5	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2012-06-056/itrp/0044	'Most recently, Cooray et al. [17][[ refid=''bib17'' ]] proposed an interactive and multi-level framework for generating personalized summaries by giving users the flexibility to select a summarization criterion and specify the summary length.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0045"""" view=""""all"""">The central task in video summarization is identifying the “important” or “exciting” sections. Finding a generic definition for visual importance is difficult due to the lack of tools for modeling human cognition and affection <ce:cross-ref id=""""cr0095"""" refid=""""bib19"""">[19][[ refid=''''bib19'''' ]]</ce:cross-ref>. However, this is relatively easy when the video belongs to a domain with a fairly rigid and known structure. For example, Ju et al. <ce:cross-ref id=""""cr0100"""" refid=""""bib20"""">[20][[ refid=''''bib20'''' ]]</ce:cross-ref> proposed a system for summarizing videos of conference presentations, using the intensity of the presenter''''s movements to find the “important” sections. In another example, Yow et al. <ce:cross-ref id=""""cr0105"""" refid=""""bib21"""">[21][[ refid=''''bib21'''' ]]</ce:cross-ref> developed a system which identifies “exciting” sections of soccer match broadcasts by tracking the position of the ball in relation to the goals. Although it is difficult to develop the summarization system targeting home video without a clear structure, there are still some systems emerging with varying degrees of success. For example, Zhai and Shah <ce:cross-ref id=""""cr0110"""" refid=""""bib23"""">[23][[ refid=''''bib23'''' ]]</ce:cross-ref> developed a statistical framework using the Markov Chain Monte Carlo technique for segmenting home video into logical temporal units. Girgensohn et al. <ce:cross-ref id=""""cr0115"""" refid=""""bib24"""">[24][[ refid=''''bib24'''' ]]</ce:cross-ref> proposed a semi-automatic approach for home video editing by analyzing the types of camera motions. Mei et al. <ce:cross-ref id=""""cr0120"""" refid=""""bib25"""">[25][[ refid=''''bib25'''' ]]</ce:cross-ref> adopted psychological theories to infer the intentions of the user and used them to help home video summarization. Despite many promising efforts, most past video summarization systems share the same approach in that they try to define a single set of summarization rules that fits all users, and have generally been indifferent to users'''' individual preferences. However, mobile users tend to expect more personalized summaries that are in step with their individual tastes and preferences. Most recently, Cooray et al. <ce:cross-ref id=""""cr0125"""" refid=""""bib17"""">[17][[ refid=''''bib17'''' ]]</ce:cross-ref> proposed an interactive and multi-level framework for generating personalized summaries by giving users the flexibility to select a summarization criterion and specify the summary length. Takeuchi and Sugimoto <ce:cross-ref id=""""cr0130"""" refid=""""bib26"""">[26][[ refid=''''bib26'''' ]]</ce:cross-ref> presented a user-adaptive home video summarization system that analyzes content of the user''''s personal photo library to learn user preferences. Valdés and Martinez <ce:cross-ref id=""""cr0135"""" refid=""""bib27"""">[27][[ refid=''''bib27'''' ]]</ce:cross-ref> presented an application called RISPlayer for real-time and interactive summarization during video playback. However, these approaches mainly focused on providing users the ability to control relevant parameters (such as summary length <ce:cross-ref id=""""cr0140"""" refid=""""bib18"""">[18][[ refid=''''bib18'''' ]]</ce:cross-ref>, or redundancy weight <ce:cross-refs id=""""crs0035"""" refid=""""bib22 bib27"""">[22,27][[ refid=''''bib22 bib27'''' ]]</ce:cross-refs>) to create personalized video summaries. This focus on parameters may lead to a poor user experience since these parameters may be difficult to understand for people who do not have deep knowledge of computer vision. Thus, new summarization methods are needed that can be used to generate personalized summaries while minimizing the demands put on users in terms of time and conscious mental effort. Based on these considerations, we developed a novel mobile application that can generate personalized summaries by learning user preferences with user feedback.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Related work	Meng Wang, Bingbing Ni, Xian-Sheng. Hua, Tat-Seng Chua, Assistive tagging: a survey of multimedia tagging with human–computer joint exploration, , ACM Comput. Surv. , vol. 44 (2012), pp.None	http://dx.doi.org/10.1016/j.neucom.2012.12.021	related work		http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2012-12-021/br/bib10	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2012-12-021/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2012-12-021/ctx/ctx0010		27	4	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2012-12-021/itrp/0033	'Except for automatic image annotation, assistive tagging [10][[ refid=''bib10'' ]], namely tagging by combining human''s intelligence and computer''s computation power has drawn a lot of attention too.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0040"""" view=""""all"""">Various methods are intended to automatically annotate images. There is work on learning mappings from visual features to semantic labels in the machine learning communities and image processing <ce:cross-refs refid=""""bib8 bib9"""">[8,9][[ refid=''''bib8 bib9'''' ]]</ce:cross-refs>. The methods take a set of labeled images as input and learn which low level visual features correspond to higher level semantic labels. Then the mapping can be applied to suggest labels for unlabeled images based on visual features alone. Except for automatic image annotation, assistive tagging <ce:cross-ref refid=""""bib10"""">[10][[ refid=''''bib10'''' ]]</ce:cross-ref>, namely tagging by combining human''''s intelligence and computer''''s computation power has drawn a lot of attention too. Wang et al. categorize existing assistive tagging into three paradigms: (1) tagging with data selection and organization; (2) tag recommendation; and (3) tag processing. For a more detailed account of content-based analysis in the field of image annotation we think of the ESP game <ce:cross-ref refid=""""bib11"""">[11][[ refid=''''bib11'''' ]]</ce:cross-ref>. ESP game is a tool for adding meaningful labels to images using a computer. Users suggest tags for photos that appear on their screen and earn points when suggesting the same tags as another player.</ce:para>""''"'	cites	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Related work	A. Yilmaz, O. Javed, M. Shah, Object tracking , ACM Comput. Surv. (2006)	http://dx.doi.org/10.1016/j.neucom.2013.02.001	related work		http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2013-02-001/br/bib5	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2013-02-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2013-02-001/ctx/ctx0003		45	4	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2013-02-001/itrp/0026	'Multiple target tracking (MTT) has been studied extensively, and an in-depth review of the literature regarding this issue can be found in a recent survey by Yilmaz et al. [5][[ refid=''bib5'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0035"""" view=""""all"""">Multiple target tracking (MTT) has been studied extensively, and an in-depth review of the literature regarding this issue can be found in a recent survey by Yilmaz et al. <ce:cross-ref refid=""""bib5"""">[5][[ refid=''''bib5'''' ]]</ce:cross-ref>. Typically, multi-target tracking can be achieved through a data association <ce:cross-ref refid=""""bib4"""">[4][[ refid=''''bib4'''' ]]</ce:cross-ref>. The multi-hypothesis tracker (MHT) <ce:cross-refs refid=""""bib6 bib7"""">[6,7][[ refid=''''bib6 bib7'''' ]]</ce:cross-refs> attempts to keep track of all possible association hypotheses over time, and can be viewed as the most successful algorithm for multi-target tracking based on a data-oriented perspective. However, the MHT algorithm is computationally exponential, both in memory and time, which makes its application difficult. The nearest neighbor standard filter (NNSF) <ce:cross-ref refid=""""bib4"""">[4][[ refid=''''bib4'''' ]]</ce:cross-ref> associates each target with the closest measurement in the target state space, and employs a particle filter <ce:cross-ref refid=""""bib8"""">[8][[ refid=''''bib8'''' ]]</ce:cross-ref> or Kalman filter <ce:cross-refs refid=""""bib9 bib10"""">[9,10][[ refid=''''bib9 bib10'''' ]]</ce:cross-refs> to complete its tracking. However, this simple procedure prunes away many feasible hypotheses, and cannot solve the “labeling” problems when the targets are crowded together. In this respect, a wider approach to multi-target tracking is achieved by exploiting a joint state space representation that concatenates the states of all the targets together <ce:cross-refs refid=""""bib11 bib12 bib13"""">[11–13][[ refid=''''bib11 bib12 bib13'''' ]]</ce:cross-refs>, or inferring this joint data association problem through the characterization of all possible associations between the targets and observations, such as through a joint probabilistic data association filter (JPDAF) <ce:cross-refs refid=""""bib4 bib14 bib15"""">[4,14,15][[ refid=''''bib4 bib14 bib15'''' ]]</ce:cross-refs>, Monte Carlo technique-based JPDA algorithms (MC-JPDAF) <ce:cross-refs refid=""""bib16 bib17"""">[16,17][[ refid=''''bib16 bib17'''' ]]</ce:cross-refs>, and a Markov chain Monte Carlo data association (MCMC-DA) <ce:cross-refs refid=""""bib18 bib19 bib20"""">[18–20][[ refid=''''bib18 bib19 bib20'''' ]]</ce:cross-refs>. More recently, Huang et al. <ce:cross-ref refid=""""bib21"""">[21][[ refid=''''bib21'''' ]]</ce:cross-ref> used the “low-frequency” terms of a Fourier decomposition to represent the distributions over the data association. This method can maintain and update the permutation distribution directly in the Fourier domain, allowing for polynomial time band-limited approximations. However, with an increase in the number of tracking targets, the state space becomes increasingly large, and obtaining an accurate MAP estimation in a large state space becomes quite difficult. Furthermore, the computational complexity of most of the methods mentioned above grows exponentially with an increase in the number of tracking targets.</ce:para>""''"'	cites_as_review	AGA+ANG	50_classified_citesAsReview_semweb
cites_as_review	Methods and recent developments	M. Zeiler, Hierarchical Convolutional Deep Learning in Computer Vision (Ph.D. thesis) , None (New York University, 2014)	http://dx.doi.org/10.1016/j.neucom.2015.09.116	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib19>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0009>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0002	'There are three main advantages of the convolution operation [19][[ refid=''bib19'' ]]: 1) the weight sharing mechanism in the same feature map reduces the number of parameters 2) local connectivity learns correlations among neighboring pixels 3) invariance to the location of the object.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Methods and recent developments	M.D. Zeiler, D. Krishnan, G.W. Taylor, et al., Deconvolutional networks, in: Proceedings of the CVPR, 2010.	http://dx.doi.org/10.1016/j.neucom.2015.09.116	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib116>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0120>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0008	'The hierarchical sparse coding is utilized in another research [116][[ refid=''bib116'' ]] to learn features for images in an unsupervised fashion.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites_as_review	Introduction	L. Deng, A tutorial survey of architectures, algorithms, and applications for deep learning , APSIPA Trans. Signal Inf. Process. , vol. 3 (2014), pp.e2	http://dx.doi.org/10.1016/j.neucom.2015.09.116	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib9>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0002>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0015	'There are mainly three important reasons for the booming of deep learning today: the dramatically increased chip processing abilities (e.g. GPU units), the significantly lowered cost of computing hardware, and the considerable advances in the machine learning algorithms [9][[ refid=''bib9'' ]].'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites	Methods and recent developments	C.Y. Liou, W.C. Cheng, J.W. Liou, Autoencoder for words , Neurocomputing , vol. 139 (2014), pp.84-96	http://dx.doi.org/10.1016/j.neucom.2015.09.116	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib75>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0094>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0043	'The autoencoder is a special type of artificial neural network used for learning efficient encodings [75][[ refid=''bib75'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Methods and recent developments	Q.V. Le, Building high-level features using large scale unsupervised learning, in: Proceedings of the ICASSP, 2013.	http://dx.doi.org/10.1016/j.neucom.2015.09.116	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib84>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0099>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0044	'A quite well-known variant of the sparse autoencoder is a nine-layer locally connected sparse autoencoder with pooling and local contrast normalization [84][[ refid=''bib84'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Methods and recent developments	A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks, in: Proceedings of the NIPS, 2012.	http://dx.doi.org/10.1016/j.neucom.2015.09.116	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib6>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0039>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0063	'Weight decay works by adding an extra term to the cost function to penalize the parameters, preventing them from exactly modeling the training data and therefore helping to generalize to new examples [6][[ refid=''bib6'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Methods and recent developments	L. Younes, On the convergence of Markovian stochastic algorithms with rapidly decreasing ergodicity rates , Stoch.: Int. J. Probab. Stoch. Process. , vol. 65 (1999), pp.177-228	http://dx.doi.org/10.1016/j.neucom.2015.09.116	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib161>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0082>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0085	'When training the network, a DBM would jointly train all layers of a specific unsupervised model, and instead of maximizing the likelihood directly, the DBM uses a stochastic maximum likelihood (SML) [161][[ refid=''bib161'' ]] based algorithm to maximize the lower bound on the likelihood, i.e. performing only one or a few updates using a Markov chain Monte Carlo (MCMC) method between each parameter update.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Methods and recent developments	A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks, in: Proceedings of the NIPS, 2012.	http://dx.doi.org/10.1016/j.neucom.2015.09.116	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib6>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0027>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0110	'The well-known AlexNet [6][[ refid=''bib6'' ]] employed two distinct forms of data augmentation: the first form of data augmentation consists of generating image translations and horizontal reflections, and the second form consists of altering the intensities of the RGB channels in training images.'		<http://purl.org/spar/cito/usesDataFrom>		top100compsc
cites	Methods and recent developments	B.A. Olshausen, D.J. Field, Sparse coding with an overcomplete basis set: a strategy employed by V1? , Vis. Res. , vol. 37 (1997), pp.3311-3325	http://dx.doi.org/10.1016/j.neucom.2015.09.116	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib94>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0104>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0145	'The purpose of sparse coding is to learn an over-complete set of basic functions to describe the input data [94][[ refid=''bib94'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Methods and recent developments	C. Szegedy, W. Liu, Y. Jia, et al., Going deeper with convolutions, in: Proceedings of the CVPR, 2015.	http://dx.doi.org/10.1016/j.neucom.2015.09.116	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib20>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0052>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0171	'One intuitive idea is to improve the performance of CNNs by increasing their size, which includes increasing the depth (the number of levels) and the width (the number of units at each level) [20][[ refid=''bib20'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Methods and recent developments	S. Gao, I.W.H. Tsang, L.T. Chia, Laplacian sparse coding, hypergraph laplacian sparse coding, and applications , Pattern Anal. Mach. Intell. IEEE Trans. , vol. 35 (2013), pp.92-104	http://dx.doi.org/10.1016/j.neucom.2015.09.116	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib114>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0118>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0195	'Gao et al. [114][[ refid=''bib114'' ]] further raised a Hyper-graph Laplacian Sparse Coding (HLSC) method, which extends the LSC to the case where the similarity among the instances is defined by a hyper graph.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Methods and recent developments	J. Ngiam, Z. Chen, D. Chia, et al., Tiled convolutional neural networks, in: Proceedings of the NIPS, 2010.	http://dx.doi.org/10.1016/j.neucom.2015.09.116	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib160>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0040>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0215	'Weight tying allows models to learn good representations of the input data by reducing the number of parameters in Convolutional Neural Networks [160][[ refid=''bib160'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Methods and recent developments	O. Russakovsky, J. Deng, H. Su, Imagenet large scale visual recognition challenge , Int. J. Comput. Vis. , vol. 115 (2015), pp.211-252	http://dx.doi.org/10.1016/j.neucom.2015.09.116	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib189>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0042>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0217	'The network was trained on ImageNet and integrated various regularization techniques, such as data augmentation, dropout, etc. AlexNet won the ILSVRC2012 competition [189][[ refid=''bib189'' ]], and set the tone for the surge of interest in deep convolutional neural network architectures.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Methods and recent developments	A. Chambolle, R.A. De Vore, N.Y. Lee, Nonlinear wavelet image processing: variational problems, compression, and noise removal through wavelet shrinkage , Image Process. IEEE Trans. , vol. 7 (1998), pp.319-335	http://dx.doi.org/10.1016/j.neucom.2015.09.116	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib107>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0111>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0248	'A popular algorithm for sparse coding inference is the Iterative Shrinkage-Thresholding Algorithm (ISTA) [107][[ refid=''bib107'' ]], which takes a gradient step to optimize the reconstruction term, followed by a sparsity term which has a closed form shrinkage operation.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Trends and challenges	C.F. Cadieu, H. Hong, D.L.K. Yamins, Deep neural networks rival the representation of primate IT cortex for core visual object recognition , PloS Comput. Biol. , vol. 10 (2014), pp.e1003963	http://dx.doi.org/10.1016/j.neucom.2015.09.116			<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib123>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0208>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0252	'However, we cannot conclude that the representational performance of a CNN rivals that of the brain [123][[ refid=''bib123'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Applications and results	D. Erhan, C. Szegedy, A. Toshev, et al., Scalable object detection using deep neural networks, in: Proceedings of the CVPR, 2014.	http://dx.doi.org/10.1016/j.neucom.2015.09.116	results	motivation	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/br/bib147>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/ctx/ctx0147>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2015-09-116/itrp/0297	'To handle multiple instances of the same object in the image, DeepMultiBox [147][[ refid=''bib147'' ]] also showed a saliency-inspired neural network model.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Experiments	H.M. Wallach, Topic modeling: beyond bag-of-words , Proceedings of the Twenty-third International Conference on Machine Learning, ACM (2006)	http://dx.doi.org/10.1016/j.neucom.2017.01.062	methods		http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-062/br/bib0043	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-062/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-062/ctx/ctx0028		33	4	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-062/itrp/0009	'Because sizes of images from this dataset are different from each, we extract bag-of-words [42][[ refid=''bib0043'' ]], local binary patterns, edge direction histogram as 3 views.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0027"""" view=""""all"""">WebKB consists of 4 subsets of documents over 6 categories. There are 3 features extracted from 3 views in one web page, including the text on it, the anchor text on the hyperlink pointing to it and the text in its title. 3Sources is a benchmark multi-view dataset which contains 3 well-known online news sources: BBC, Reuters and the Guardian. Each source was extracted as one view and 169 stories which were reported in these 3 sources were selected by this dataset. Cora consists of 2708 scientific publications which come from 7 classes. Contents and cites are utilized as 2 views in Cora. For those face datasets (ORL and Yale), we extract features using gray-scale intensity, local binary patterns and edge direction histogram as 3 views. Caltech 101 is a benchmark image dataset which contains 9144 images from 102 classes. Because sizes of images from this dataset are different from each, we extract bag-of-words <ce:cross-ref id=""""crf0065"""" refid=""""bib0043"""">[42][[ refid=''''bib0043'''' ]]</ce:cross-ref>, local binary patterns, edge direction histogram as 3 views.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experiments	M. Everingham, L.V. Gool, C.K.I. Williams, J. Winn, A. Zisserman, The pascal visual object classes (VOC) challenge , Int. J. Comput. Vis. , vol. 88 (2010), pp.303-338	http://dx.doi.org/10.1016/j.neucom.2017.01.081	methods		http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-081/br/bib0046	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-081/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-081/ctx/ctx0036		36	4	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-081/itrp/0042	'We train BING on the PASCAL VOC dataset [46][[ refid=''bib0046'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0044"""" view=""""all"""">In order to demonstrate the compatibility of our approach, we test the retrieval performance with different kinds of object regions. We make a comparison among three object proposal methods: EdgeBoxes, Selective Search <ce:cross-ref id=""""crf0085"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> and BING <ce:cross-ref id=""""crf0086"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref>. Both EdgeBoxes and Selective Search are unsupervised methods. We use the Selective Search’s “fast mode” to extract object proposals. BING employs two stages cascaded SVM to measure the objectness. We train BING on the PASCAL VOC dataset <ce:cross-ref id=""""crf0087"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref>. The average detection time of EdgeBoxes, Selective Search and BING is 0.2s, 8s and 0.006s, respectively. The comparison is shown in <ce:cross-ref id=""""crf0088"""" refid=""""fig0009"""">Fig. 9</ce:cross-ref><ce:float-anchor refid=""""fig0009""""/>. No matter which object detection method is used, our approach brings consistent improvement over the baseline. Though BING is very efficient, its performance is a little worse than EdgeBoxes and Selective Search. Based on the results, EdgeBoxes is a good choice for our method.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experiments	N. Dalal, B. Triggs, Histograms of oriented gradients for human detection , Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition,, IEEE , vol. vol. 1 (2005), pp.886-893	http://dx.doi.org/10.1016/j.neucom.2017.01.084	methods		http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-084/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-084/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-084/ctx/ctx0047		65	4	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-084/itrp/0029	'INRIA pedestrian dataset [4][[ refid=''bib0004'' ]] is among the most popular and oldest datasets for pedestrian detection.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0034"""" view=""""all"""">INRIA pedestrian dataset <ce:cross-ref id=""""crf0074"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref> is among the most popular and oldest datasets for pedestrian detection. It has various backgrounds and high-quality annotations of pedestrians. Though the quantity is small, the diversity of images brings a stronger generalisation capacity than some other datasets <ce:cross-ref id=""""crf0075"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>. Since the resolution of images in INRIA dataset is not fixed, we resize all images to 500× 500 pixels, which is the default input size of FCN model. The resolution of persons in INRIA is relatively large, so we set the extraction window size to 128 × 64 pixels.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experiments	P. Dollar, C. Wojek, B. Schiele, P. Perona, Pedestrian detection: an evaluation of the state of the art , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 34 (2012), pp.743-761	http://dx.doi.org/10.1016/j.neucom.2017.01.084	methods		http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-084/br/bib0044	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-084/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-084/ctx/ctx0045		65	4	http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-01-084/itrp/0109	'Collected from a vehicle driving through streets in an urban region, the Caltech dataset [44][[ refid=''bib0044'' ]] consists of nearly ten hours of videos.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0033"""" view=""""all"""">This is a large-scale, challenging dataset and has been serving as a standard benchmark for pedestrian detection. Collected from a vehicle driving through streets in an urban region, the Caltech dataset <ce:cross-ref id=""""crf0072"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> consists of nearly ten hours of videos. There are a total of 350,000 bounding boxes and 2300 unique pedestrians annotated in the dataset. The sampling rate is 30 fps and the resolution of every frame is 640× 480. We use set00-04 as training set, set05 as validation set, and the remaining set06-10 as test set. In our experiment, we extract one sample out of every 10 frames in the training set and the validation set, and the sample interval is 30 for the test set. The performance is measured under the “Reasonable Set” <ce:cross-ref id=""""crf0073"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> in which the height of pedestrians is taller than 50 pixels.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Introduction	A. Lavin, S. Ahmad, Evaluating real-time anomaly detection algorithms – the Numenta anomaly benchmark , Proceedings of the 14th International Conference on Machine Learning Application, IEEE (2015)	http://dx.doi.org/10.1016/j.neucom.2017.04.070	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-04-070/br/bib0002>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-04-070/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-04-070/ctx/ctx0028>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-04-070/itrp/0017	'The HTM implementation and documentation are available as open-source.1 In Section 3 we review the Numenta Anomaly Benchmark (NAB) [2][[ refid=''bib0002'' ]], a rigorous benchmark dataset and scoring methodology we created for evaluating real-time anomaly detection algorithms.'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites_as_review	Introduction	V. Chandola, A. Banerjee, V. Kumar, Anomaly detection: a survey , ACM Comput. Surv. , vol. 41 (2009), pp.1-72	http://dx.doi.org/10.1016/j.neucom.2017.04.070	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-04-070/br/bib0006>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-04-070/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-04-070/ctx/ctx0004>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-04-070/itrp/0038	'Many anomaly detection approaches exist, both supervised (e.g. support vector machines and decision trees [6][[ refid=''bib0006'' ]]) and unsupervised (e.g. clustering), yet the vast majority of anomaly detection methods are for processing data in batches, and unsuitable for real-time streaming applications.'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
uses_method_in	Anomaly detection using HTM	Y. Cui, S. Ahmad, J. Hawkins, Continuous online sequence learning with an unsupervised neural network model , Neural Comput , vol. 28 (2016), pp.2474-2504	http://dx.doi.org/10.1016/j.neucom.2017.04.070			<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-04-070/br/bib0049>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-04-070/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-04-070/ctx/ctx0034>				http://www.scar.disi.unibo.it/r/10-1016-j-neucom-2017-04-070/itrp/0046	'In our implementation we use the standard HTM system [49][[ refid=''bib0049'' ]] and a standard set of parameters (See Supplementary Section S3 for the complete list).'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Introduction	A.J. Hey, S. Tansley, K.M. Tolle, The Fourth Paradigm: Data-Intensive Scientific Discovery , None, Microsoft Research Redmond (2009)	http://dx.doi.org/10.1016/j.parco.2014.08.002	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-parco-2014-08-002/br/b0005	http://www.scar.disi.unibo.it/r/10-1016-j-parco-2014-08-002/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-parco-2014-08-002/ctx/ctx0001		36	5	http://www.scar.disi.unibo.it/r/10-1016-j-parco-2014-08-002/itrp/0014	'Data-intensive science simultaneously derives from and creates the need for large quantities of data [1][[ refid=''b0005'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0005"""" view=""""all"""">Data-intensive science simultaneously derives from and creates the need for large quantities of data <ce:cross-ref id=""""c0005"""" refid=""""b0005"""">[1][[ refid=''''b0005'''' ]]</ce:cross-ref>. As such, scientists increasingly need to discover and analyze new datasets from diverse sources. Beyond the sheer volume of data, issues posed by the resultant data heterogeneity are often overlooked. Examples include: vocabularies in Comma-Separated Values (CSV) <ce:cross-ref id=""""c0010"""" refid=""""b0010"""">[2][[ refid=''''b0010'''' ]]</ce:cross-ref> and Resource Description Framework (RDF) <ce:cross-ref id=""""c0015"""" refid=""""b0015"""">[3][[ refid=''''b0015'''' ]]</ce:cross-ref> formats from the Global Change Master Directory (GCMD) <ce:cross-ref id=""""c0020"""" refid=""""b0020"""">[4][[ refid=''''b0020'''' ]]</ce:cross-ref>; NetCDF <ce:cross-ref id=""""c0025"""" refid=""""b0025"""">[5][[ refid=''''b0025'''' ]]</ce:cross-ref> data files from the Atmospheric Radiation Measurement (ARM) <ce:cross-ref id=""""c0030"""" refid=""""b0030"""">[6][[ refid=''''b0030'''' ]]</ce:cross-ref> climate research facility; and web pages from the International Soil Moisture Network (ISMN) <ce:cross-ref id=""""c0035"""" refid=""""b0035"""">[7][[ refid=''''b0035'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
extends	Introduction	I. González-Díaz, D. García-García, F. Díaz-de María, A spatially aware generative model for image classification, topic discovery and segmentation, in: International Conference on Image Processing, Cairo, Egypt, 2009, pp. 781–784.	http://dx.doi.org/10.1016/j.patcog.2013.01.034	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2013-01-034/br/bib10	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2013-01-034/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2013-01-034/ctx/ctx0004		41	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2013-01-034/itrp/0028	'This paper complements and extends our previous work described in [10][[ refid=''bib10'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0015"""" view=""""all"""">This paper complements and extends our previous work described in <ce:cross-ref refid=""""bib10"""">[10][[ refid=''''bib10'''' ]]</ce:cross-ref>. Specifically, the model proposed in this paper has been built on LDA instead of PLSA; we have moved from an <ce:italic>intra-topic</ce:italic> to an <ce:italic>inter-topic</ce:italic> influence model, improving the modeling of the spatial arrangement of the topics; we have introduced a novel KLR-based appearance model; and, finally, the experimental evaluation has been significantly extended.</ce:para>""''"'	extends	AGA+ANG	tba_50_classified_extends_semweb
extends	Introduction	L. Wang, J. Xue, N. Zheng, G. Hua, Automatic salient object extraction with contextual cue, in: The 13th International Conference on Computer Vision, 2011, pp. 1–8.	http://dx.doi.org/10.1016/j.patcog.2013.03.028	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2013-03-028/br/bib21	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2013-03-028/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2013-03-028/ctx/ctx0014		73	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2013-03-028/itrp/0112	'This paper is an extended version of our previous work in [21][[ refid=''bib21'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0090"""" view=""""all"""">This paper is an extended version of our previous work in <ce:cross-ref id=""""cr0270"""" refid=""""bib21"""">[21][[ refid=''''bib21'''' ]]</ce:cross-ref>. We have extended it by including our recent theoretical and experimental improvements. We have expanded and structured the related works, and have analyzed and discussed the convergence of the proposed iterative algorithm for the employed energy minimization framework. Moreover, the efficiency of the method and alternatives to cut down complexity have been discussed. Finally, we have added experiments to assess the performances of the method in the context of both segmentation and image matting.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
extends	Introduction	P. Papadakis, F. Pirri, Consistent pose normalization of non-rigid shapes using one-class support vector machines, in: IEEE International Conference of Computer Vision and Pattern Recognition Workshop on Non-Rigid Shape Analysis and Deformable Image Alignment (NORDIA), 2011.	http://dx.doi.org/10.1016/j.patcog.2013.06.024	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2013-06-024/br/bib5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2013-06-024/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2013-06-024/ctx/ctx0004		23	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2013-06-024/itrp/0015	'This paper complements and extends previous work presented in [5][[ refid=''bib5'' ]] mainly in the following aspects: (i) a thorough elaboration is provided in support of the formulation of the optimization problem, choice of the kernel, the setting of the parameters and implementation details, (ii) additional qualitative examples are provided from training to evaluation and (iii) the proposed approach is effectively employed to improve the performance of non-rigid 3D shape retrieval in several standard benchmarks.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0035"""" view=""""all"""">This paper complements and extends previous work presented in <ce:cross-ref id=""""cr0035"""" refid=""""bib5"""">[5][[ refid=''''bib5'''' ]]</ce:cross-ref> mainly in the following aspects: (i) a thorough elaboration is provided in support of the formulation of the optimization problem, choice of the kernel, the setting of the parameters and implementation details, (ii) additional qualitative examples are provided from training to evaluation and (iii) the proposed approach is effectively employed to improve the performance of non-rigid 3D shape retrieval in several standard benchmarks.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
uses_data_from	A Bayesian scoring function	Masakazu Suzuki, Seiichi Uchida, Akihiro Nomura, A ground-truthed mathematical character and symbol image database, in: International Conference on Document Analysis and Recognition, 2005, pp. 675–679.	http://dx.doi.org/10.1016/j.patcog.2015.02.017			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2015-02-017/br/bib15	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2015-02-017/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2015-02-017/ctx/ctx0017		28	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2015-02-017/itrp/0032	'We collected symbol occurrence and co-occurrence rates from the Infty project corpus [15][[ refid=''bib15'' ]] as well as from the sources of University of Waterloo course notes for introductory algebra and calculus courses.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0575"""" view=""""all"""">We collected symbol occurrence and co-occurrence rates from the Infty project corpus <ce:cross-ref id=""""cr0160"""" refid=""""bib15"""">[15][[ refid=''''bib15'''' ]]</ce:cross-ref> as well as from the <ce:inline-figure baseline=""""1""""><ce:link locator=""""fx1""""/></ce:inline-figure> sources of University of Waterloo course notes for introductory algebra and calculus courses. The symbol occurrence rate <mml:math altimg=""""si0182.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>r</mml:mi><mml:mo>(</mml:mo><mml:mi>α</mml:mi><mml:mo>)</mml:mo></mml:math> is the number of expressions in which the symbol <ce:italic>α</ce:italic> appeared and the co-occurrence rate <mml:math altimg=""""si0183.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi>c</mml:mi><mml:mo>(</mml:mo><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>)</mml:mo></mml:math> is the number of expressions containing both <ce:italic>α</ce:italic> and <ce:italic>β</ce:italic>.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Results and evaluation	K.K. Reddy, M. Shah, Recognizing 50 human action categories of web videos , Mach. Vis. Appl. , vol. 24 (2013), pp.971-981	http://dx.doi.org/10.1016/j.patcog.2016.03.011	results		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2016-03-011/br/bib32	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2016-03-011/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2016-03-011/ctx/ctx0035		43	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2016-03-011/itrp/0031	'The UCF50 dataset was introduced in [32][[ refid=''bib32'' ]], consists of 50 sport action categories and all the videos denoting the actions were collected from YouTube.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0105"""" view=""""all"""">The UCF50 dataset was introduced in <ce:cross-ref id=""""cr0370"""" refid=""""bib32"""">[32][[ refid=''''bib32'''' ]]</ce:cross-ref>, consists of 50 sport action categories and all the videos denoting the actions were collected from YouTube. The dataset consists of more than 100 video clips for each category and gives plenty of variety in terms of camera motion, object appearance and pose, object scale, viewpoint, cluttered background, illumination conditions, etc. The official train/test splits are available at <ce:cross-ref id=""""cr0375"""" refid=""""bib33"""">[33][[ refid=''''bib33'''' ]]</ce:cross-ref> and were used in this paper to maintain comparability with the previous literature on these datasets.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_method_in	Diagnosing deep age estimation models	Z. Song, Visual image recognition system with object-level image representation, (Ph.D. thesis), National University of Singapore, 2012.	http://dx.doi.org/10.1016/j.patcog.2017.01.005	model		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-005/br/bib34	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-005/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-005/ctx/ctx0023		42	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-005/itrp/0002	'Following [34][[ refid=''bib34'' ]], we conduct experiments on this dataset using a four-fold cross validation protocol.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0105"""" view=""""all""""><ce:bold>WebFace Dataset</ce:bold>: The WebFace dataset contains 59,930 face images. Age ranges from 1 to 80 years old. The WebFace dataset is also a multi-ethnic dataset with additional gender labels. Unlike Morph II, this dataset is captured in the wild environment, images contain large pose and expression variations, which makes this dataset much more challenging. Following <ce:cross-ref id=""""cr0300"""" refid=""""bib34"""">[34][[ refid=''''bib34'''' ]]</ce:cross-ref>, we conduct experiments on this dataset using a four-fold cross validation protocol.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experiments	M. Rastegari, A. Farhadi, D. Forsyth, Attribute discovery via predictable discriminative binary codes, in: ECCV, 2012.	http://dx.doi.org/10.1016/j.patcog.2017.01.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-006/br/bib37	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-006/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-006/ctx/ctx0037		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-006/itrp/0087	'We also experiment with 32-bit data-driven attributes (DDA) learned from the training data by [37][[ refid=''bib37'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0210"""" view=""""all"""">For <ce:italic>PKU-REID</ce:italic>, we define 30 attributes (shown in <ce:cross-ref id=""""cr0430"""" refid=""""t0005"""">Table 1</ce:cross-ref><ce:float-anchor refid=""""t0005""""/>) and manually annotate them for every image. We also experiment with 32-bit data-driven attributes (DDA) learned from the training data by <ce:cross-ref id=""""cr0435"""" refid=""""bib37"""">[37][[ refid=''''bib37'''' ]]</ce:cross-ref>. For <ce:italic>PRID</ce:italic>, we use the publicly available attributes provided by <ce:cross-ref id=""""cr0440"""" refid=""""bib21"""">[21][[ refid=''''bib21'''' ]]</ce:cross-ref>. For <ce:italic>iLIDS-VID</ce:italic>, we learn 32-bit DDA learned by <ce:cross-ref id=""""cr0445"""" refid=""""bib37"""">[37][[ refid=''''bib37'''' ]]</ce:cross-ref>. When using manually attributes for training, we learn a linear binary SVMs as in <ce:cross-ref id=""""cr0450"""" refid=""""bib20"""">[20][[ refid=''''bib20'''' ]]</ce:cross-ref> to predict the same attributes for testing. Meanwhile, we use the DDA model which are trained on training sets by <ce:cross-ref id=""""cr0455"""" refid=""""bib37"""">[37][[ refid=''''bib37'''' ]]</ce:cross-ref> to get the 32-bit DDA of testing sets.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_method_in	Experiments	Z. Song, Visual Image Recognition System With Object-level Image Representation, (Ph.D. thesis), National University of Singapore, 2012.	http://dx.doi.org/10.1016/j.patcog.2017.01.007	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-007/br/bib51	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-007/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-007/ctx/ctx0027		32	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-007/itrp/0007	'Following [51][[ refid=''bib51'' ]], we conduct experiments on this dataset using a four-fold cross validation protocol.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0190"""" view=""""all""""><ce:italic><ce:bold>WebFace dataset:</ce:bold></ce:italic> The WebFace dataset contains 59,930 face images. The ages range from 1 to 80<ce:hsp sp=""""0.25""""/>years old. The WebFace dataset is also a multi-ethnic dataset. In contrast with the Morph II dataset, this dataset is captured in the wild. The images contain large pose and expression variations, which make this dataset much more challenging. Following <ce:cross-ref id=""""cr0455"""" refid=""""bib51"""">[51][[ refid=''''bib51'''' ]]</ce:cross-ref>, we conduct experiments on this dataset using a four-fold cross validation protocol.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experiments	G. Guo, L. Wen, S. Yan, Face authentication with makeup changes , IEEE Trans. Circuits Syst. Video Technol. , vol. 24 (2014), pp.814-825	http://dx.doi.org/10.1016/j.patcog.2017.01.011	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-011/br/bib1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-011/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-011/ctx/ctx0022		33	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-011/itrp/0001	'Dataset1 for makeups and non-makeups: To qualitatively evaluate our method, we use the dataset collected in [1][[ refid=''bib1'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0155"""" view=""""all""""><ce:italic>Dataset1 for makeups and non-makeups</ce:italic>: To qualitatively evaluate our method, we use the dataset collected in <ce:cross-ref id=""""cr0210"""" refid=""""bib1"""">[1][[ refid=''''bib1'''' ]]</ce:cross-ref>. There are 1002 face images of 501 female adults. Each individual has two images, one for makeup and the other for non-makeup. To the best of our knowledge, this dataset is the largest one we can access.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experiments	M.-M. Cheng, N.J. Mitra, X. Huang, P.H.S. Torr, S.-M. Hu, Global contrast based salient region detection , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 37 (2015), pp.569-582	http://dx.doi.org/10.1016/j.patcog.2017.01.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-012/br/bib53	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-012/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-012/ctx/ctx0040		47	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-012/itrp/0020	'The MSRA10K dataset [53][[ refid=''bib53'' ]] is composed of 10,000 images randomly selected from the MSRA dataset.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0215"""" view=""""all"""">The proposed salient object detection model is evaluated on the four datasets, including SOD,<ce:cross-ref id=""""cr0445"""" refid=""""fn1""""><ce:sup loc=""""post"""">1</ce:sup></ce:cross-ref> ECSSD,<ce:cross-ref id=""""cr0450"""" refid=""""fn2""""><ce:sup loc=""""post"""">2</ce:sup></ce:cross-ref> MSRA10K<ce:cross-ref id=""""cr0455"""" refid=""""fn3""""><ce:sup loc=""""post"""">3</ce:sup></ce:cross-ref> and DUT-OMRON.<ce:cross-ref id=""""cr0460"""" refid=""""fn4""""><ce:sup loc=""""post"""">4</ce:sup></ce:cross-ref> The SOD dataset <ce:cross-ref id=""""cr0465"""" refid=""""bib52"""">[52][[ refid=''''bib52'''' ]]</ce:cross-ref> only contains 300 images, but it covers various nature scene categories, such as portraits, animals, landscapes, beaches and so on. The SOD dataset is known for the most challenging dataset of saliency detection. The ECSSD dataset <ce:cross-ref id=""""cr0470"""" refid=""""bib28"""">[28][[ refid=''''bib28'''' ]]</ce:cross-ref> consists of 1000 images along with pixel-wise ground truth. There are many semantically meaningful but structurally complex nature images. This also makes this dataset suitable to evaluate the robustness of different salient object detection algorithms. The MSRA10K dataset <ce:cross-ref id=""""cr0475"""" refid=""""bib53"""">[53][[ refid=''''bib53'''' ]]</ce:cross-ref> is composed of 10,000 images randomly selected from the MSRA dataset. It is also the largest saliency detection benchmark, to the best of our knowledge. The DUT-OMRON dataset <ce:cross-ref id=""""cr0480"""" refid=""""bib17"""">[17][[ refid=''''bib17'''' ]]</ce:cross-ref> contains 5168 high quality images manually selected from more than 140,000 images. Both of the MSRA10K and DUT-OMRON datasets are the newest and most challenging datasets proposed in last two years.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experiments	C. Yang, L. Zhang, H. Lu, X. Ruan, M.-H. Yang, Saliency detection via graph-based manifold ranking, in: Proceedings of the IEEE Conference Comput. Vis. Pattern Recognit. (CVPR), IEEE, 2013, pp. 3166–3173.	http://dx.doi.org/10.1016/j.patcog.2017.01.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-012/br/bib17	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-012/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-012/ctx/ctx0041		47	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-012/itrp/0021	'The DUT-OMRON dataset [17][[ refid=''bib17'' ]] contains 5168 high quality images manually selected from more than 140,000 images.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0215"""" view=""""all"""">The proposed salient object detection model is evaluated on the four datasets, including SOD,<ce:cross-ref id=""""cr0445"""" refid=""""fn1""""><ce:sup loc=""""post"""">1</ce:sup></ce:cross-ref> ECSSD,<ce:cross-ref id=""""cr0450"""" refid=""""fn2""""><ce:sup loc=""""post"""">2</ce:sup></ce:cross-ref> MSRA10K<ce:cross-ref id=""""cr0455"""" refid=""""fn3""""><ce:sup loc=""""post"""">3</ce:sup></ce:cross-ref> and DUT-OMRON.<ce:cross-ref id=""""cr0460"""" refid=""""fn4""""><ce:sup loc=""""post"""">4</ce:sup></ce:cross-ref> The SOD dataset <ce:cross-ref id=""""cr0465"""" refid=""""bib52"""">[52][[ refid=''''bib52'''' ]]</ce:cross-ref> only contains 300 images, but it covers various nature scene categories, such as portraits, animals, landscapes, beaches and so on. The SOD dataset is known for the most challenging dataset of saliency detection. The ECSSD dataset <ce:cross-ref id=""""cr0470"""" refid=""""bib28"""">[28][[ refid=''''bib28'''' ]]</ce:cross-ref> consists of 1000 images along with pixel-wise ground truth. There are many semantically meaningful but structurally complex nature images. This also makes this dataset suitable to evaluate the robustness of different salient object detection algorithms. The MSRA10K dataset <ce:cross-ref id=""""cr0475"""" refid=""""bib53"""">[53][[ refid=''''bib53'''' ]]</ce:cross-ref> is composed of 10,000 images randomly selected from the MSRA dataset. It is also the largest saliency detection benchmark, to the best of our knowledge. The DUT-OMRON dataset <ce:cross-ref id=""""cr0480"""" refid=""""bib17"""">[17][[ refid=''''bib17'''' ]]</ce:cross-ref> contains 5168 high quality images manually selected from more than 140,000 images. Both of the MSRA10K and DUT-OMRON datasets are the newest and most challenging datasets proposed in last two years.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experiments	Q. Yan, L. Xu, J. Shi, J. Jia, Hierarchical saliency detection, in: Proceedings of the IEEE Conference Comput. Vis. Pattern Recognit. (CVPR), IEEE, 2013, pp. 1155–1162.	http://dx.doi.org/10.1016/j.patcog.2017.01.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-012/br/bib28	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-012/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-012/ctx/ctx0039		47	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-012/itrp/0072	'The ECSSD dataset [28][[ refid=''bib28'' ]] consists of 1000 images along with pixel-wise ground truth.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0215"""" view=""""all"""">The proposed salient object detection model is evaluated on the four datasets, including SOD,<ce:cross-ref id=""""cr0445"""" refid=""""fn1""""><ce:sup loc=""""post"""">1</ce:sup></ce:cross-ref> ECSSD,<ce:cross-ref id=""""cr0450"""" refid=""""fn2""""><ce:sup loc=""""post"""">2</ce:sup></ce:cross-ref> MSRA10K<ce:cross-ref id=""""cr0455"""" refid=""""fn3""""><ce:sup loc=""""post"""">3</ce:sup></ce:cross-ref> and DUT-OMRON.<ce:cross-ref id=""""cr0460"""" refid=""""fn4""""><ce:sup loc=""""post"""">4</ce:sup></ce:cross-ref> The SOD dataset <ce:cross-ref id=""""cr0465"""" refid=""""bib52"""">[52][[ refid=''''bib52'''' ]]</ce:cross-ref> only contains 300 images, but it covers various nature scene categories, such as portraits, animals, landscapes, beaches and so on. The SOD dataset is known for the most challenging dataset of saliency detection. The ECSSD dataset <ce:cross-ref id=""""cr0470"""" refid=""""bib28"""">[28][[ refid=''''bib28'''' ]]</ce:cross-ref> consists of 1000 images along with pixel-wise ground truth. There are many semantically meaningful but structurally complex nature images. This also makes this dataset suitable to evaluate the robustness of different salient object detection algorithms. The MSRA10K dataset <ce:cross-ref id=""""cr0475"""" refid=""""bib53"""">[53][[ refid=''''bib53'''' ]]</ce:cross-ref> is composed of 10,000 images randomly selected from the MSRA dataset. It is also the largest saliency detection benchmark, to the best of our knowledge. The DUT-OMRON dataset <ce:cross-ref id=""""cr0480"""" refid=""""bib17"""">[17][[ refid=''''bib17'''' ]]</ce:cross-ref> contains 5168 high quality images manually selected from more than 140,000 images. Both of the MSRA10K and DUT-OMRON datasets are the newest and most challenging datasets proposed in last two years.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_method_in	Experiments	J. Shi, J. Malik, Normalized cuts and image segmentation , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 22 (2000), pp.888-905	http://dx.doi.org/10.1016/j.patcog.2017.01.035	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-035/br/bib0052	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-035/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-035/ctx/ctx0042		56	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-01-035/itrp/0023	'SingleV1, SingleV2: We run spectral clustering [52][[ refid=''bib0052'' ]] on the two views under the condition that all views have complete data examples.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0055"""" view=""""all""""><ce:bold>SingleV1, SingleV2:</ce:bold> We run spectral clustering <ce:cross-ref id=""""crf0073"""" refid=""""bib0052"""">[52][[ refid=''''bib0052'''' ]]</ce:cross-ref> on the two views under the condition that all views have complete data examples. <ce:bold>CCA:</ce:bold> We use the canonical correlation analysis to obtain the latent representation of multi-view data and then apply <ce:italic>k</ce:italic>-means on the obtained representation. <ce:bold>PairwiseSC, CentroidSC:</ce:bold> Two regularization frameworks developed by Kumar et al. <ce:cross-ref id=""""crf0074"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref> for multi-view spectral clustering. <ce:bold>MultiCF:</ce:bold> Wang et al. <ce:cross-ref id=""""crf0075"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> proposed a structure sparsity based multi-view clustering method. <ce:bold>RMSC:</ce:bold> Xia et al. <ce:cross-ref id=""""crf0076"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> developed a multi-view spectral clustering method, which is based on low rank and sparse decomposition of the transition matrix. <ce:bold>PVC:</ce:bold> Li et al. <ce:cross-ref id=""""crf0077"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> proposed a non-negative matrix factorization based incomplete multi-view clustering method. <ce:bold>PairwiseSC++, CentroidSC++, RMSC++:</ce:bold> We denote the PairwiseSC, CentroidSC and RMSC methods with the preprocessing of the kernel matrix under the two settings using <ce:cross-refs id=""""crfs0014"""" refid=""""bib0028 bib0029"""">[28,29][[ refid=''''bib0028 bib0029'''' ]]</ce:cross-refs> as PairwiseSC++, CentroidSC++, RMSC++ respectively.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
cites_as_review	Related work	Y. Bengio, A.C. Courville, P. Vincent, Representation learning: a review and new perspectives , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 35 (2013), pp.1798-1828	http://dx.doi.org/10.1016/j.patcog.2017.02.009	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-02-009/br/bib0047>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-02-009/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-02-009/ctx/ctx0012>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-02-009/itrp/0094	'A variety of deep learning methods have been proposed to directly learn rich hierarchical feature representations from raw data [47][[ refid=''bib0047'' ]].'			FDY+AGA	infered_pred1
cites_as_review	Related works	Y. Bengio, A. Courville, P. Vincent, Representation learning: a review and new perspectives , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 35 (2013), pp.1798-1828	http://dx.doi.org/10.1016/j.patcog.2017.02.035	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-02-035/br/bib0020>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-02-035/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-02-035/ctx/ctx0008>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-02-035/itrp/0011	'AEs are a commonly used deep learning architecture for unsupervised representation learning [20][[ refid=''bib0020'' ]].'			FDY+AGA	infered_pred1
uses_data_from	Experiments	A. Torralba, R. Fergus, W. Freeman, 80 million tiny images: a large data set for nonparametric object and scene recognition , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 30 (2008), pp.1958-1970	http://dx.doi.org/10.1016/j.patcog.2017.03.004	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-03-004/br/bib0076	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-03-004/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-03-004/ctx/ctx0045		55	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-03-004/itrp/0126	'CIFAR10 is a subset of the 80M tiny images [76][[ refid=''bib0076'' ]] which consists of 60,000 32 × 32 color images from 10 classes (e.g., airplane, automobile, bird, ship, etc.).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0043"""" view=""""all"""">CIFAR10 is a subset of the 80M tiny images <ce:cross-ref id=""""crf0121"""" refid=""""bib0076"""">[76][[ refid=''''bib0076'''' ]]</ce:cross-ref> which consists of 60,000 32 × 32 color images from 10 classes (e.g., airplane, automobile, bird, ship, etc.). There are 6000 images for each class and each image is represented as a 384-dimensional GIST <ce:cross-ref id=""""crf0122"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> feature vector. We randomly partition the whole database into two parts: a training set of 6000 samples for learning hash functions and a test set of 54,000 samples for queries. For supervised and semi-supervised methods, 50 samples randomly chosen from the training set are used as labeled data while the rest are treated as unlabeled ones. For unsupervised methods, the whole training set is treated as unlabeled data.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Lighting-aware face frontalization (LAFF)	R. Gross, I. Matthews, J. Cohn, T. Kanade, S. Baker, Multi-pie , Image Vis. Comput. , vol. 28 (2010), pp.807-813	http://dx.doi.org/10.1016/j.patcog.2017.03.024			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-03-024/br/bib0002	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-03-024/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-03-024/ctx/ctx0044		60	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-03-024/itrp/0073	'In our experiments, the bootstrap set is formed by the frontal images from 12 identities under 20 lighting conditions from session one in MultiPIE [2][[ refid=''bib0002'' ]] database.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0026"""" view=""""all"""">A small bootstrap set containing <ce:italic>N</ce:italic> (<ce:italic>N=12</ce:italic> in our experiments) identities under <ce:italic>M</ce:italic> (<ce:italic>M=20</ce:italic> in our experiments) unknown independent illumination (totally <ce:italic>M</ce:italic> × <ce:italic>N</ce:italic> images) is adopted. <ce:italic>Q<ce:inf loc=""""post"""">y</ce:inf></ce:italic> of a input image <ce:italic>Y</ce:italic>(<ce:italic>u, v</ce:italic>) can be calculated as<ce:display><ce:formula id=""""eq0006""""><ce:label>(6)</ce:label><mml:math altimg=""""si21.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>Y</mml:mi><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>M</mml:mi></mml:msubsup><mml:msub><mml:mover accent=""""true""""><mml:mi>A</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display>where <mml:math altimg=""""si22.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mover accent=""""true""""><mml:mi>A</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is the average of images under illumination <ce:italic>j</ce:italic> in the bootstrap set and <ce:italic>x<ce:inf loc=""""post"""">j</ce:inf></ce:italic> is linear combination coefficient which can be determined by the bootstrap set images and the input image <ce:italic>Y</ce:italic>(<ce:italic>u, v</ce:italic>). In our experiments, the bootstrap set is formed by the frontal images from 12 identities under 20 lighting conditions from session <ce:italic>one</ce:italic> in MultiPIE <ce:cross-ref id=""""crf0080"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref> database. The selection of identities hardly affects final result <ce:cross-ref id=""""crf0081"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>. Example bootstrap set images (gray level) from one identity is shown in <ce:cross-ref id=""""crf0082"""" refid=""""fig0005"""">Fig. 5</ce:cross-ref><ce:float-anchor refid=""""fig0005""""/>.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
cites	Experiments	W. Zheng, S. Gong, T. Xiang, Reidentification by relative distance comparison , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 35 (2013), pp.653-668	http://dx.doi.org/10.1016/j.patcog.2017.04.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/br/bib0033	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/ctx/ctx0035		46	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/itrp/0066	'Some state-of-the-art metric learning based methods are introduced as following:1.RDC[33][[ refid=''bib0033'' ]] is a typical metric learning based method in early researches for person re-identification problem.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0058"""" view=""""all"""">To verify the effectiveness of the proposed method, comparison experiments will be done with existing state-of-the-art methods. The comparison algorithms chosen in this paper are mainly metric learning based method for the reason that the proposed method is also metric learning based. Some state-of-the-art metric learning based methods are introduced as following:<ce:list id=""""celist0002""""><ce:list-item id=""""celistitem0007""""><ce:label>1.</ce:label><ce:para id=""""para0059"""" view=""""all""""><ce:bold>RDC</ce:bold><ce:cross-ref id=""""crf0111"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> is a typical metric learning based method in early researches for person re-identification problem. It is commonly used in the comparison experiments. RDC solve the re-identification task by transform the distance measure problem into a subspace learning problem. And an iterative optimization algorithm was proposed to learn a set of orthogonal projection vectors that form the subspace.</ce:para></ce:list-item><ce:list-item id=""""celistitem0008""""><ce:label>2.</ce:label><ce:para id=""""para0060"""" view=""""all""""><ce:bold>ITML</ce:bold><ce:cross-ref id=""""crf0112"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref> formulate the similarity of person images distance with information-theoretic approach. It also solve the person re-identification problem by learning Mahalanobis distance. Different from traditional metric learning methods, ITML learn a set of Manalanobis distances to approach to the existing Mahalanobis distance defined by the covariance matrix of a multivariate Gaussian distribution by an information-theoretic setting.</ce:para></ce:list-item><ce:list-item id=""""celistitem0009""""><ce:label>3.</ce:label><ce:para id=""""para0061"""" view=""""all""""><ce:bold>KISSME</ce:bold><ce:cross-ref id=""""crf0113"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> is based on a distribution hypothesis. This method learning a Mahalanobis distance for person re-identification problem based on a distribution hypothesis which assumes the difference vector of positive sample pairs and positive sample pairs features are following two different Gaussian distribution.</ce:para></ce:list-item><ce:list-item id=""""celistitem0010""""><ce:label>4.</ce:label><ce:para id=""""para0062"""" view=""""all""""><ce:bold>LMNN</ce:bold><ce:cross-ref id=""""crf0114"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> is a classic metric learning based method which learns a Mahalanobis distance for classification problems. This method is proposed for face recognition task. The distance is learned by forcing the samples close to its k nearest neighbours and be far away with the rest samples.</ce:para></ce:list-item><ce:list-item id=""""celistitem0011""""><ce:label>5.</ce:label><ce:para id=""""para0063"""" view=""""all""""><ce:bold>Improved Deep</ce:bold><ce:cross-ref id=""""crf0115"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> is a classic deep learning based method. It improves the SCNN deep structure with a neighborhood differences structure. The structure utilize a neighborhood difference operation to generate the similarity map for identification features learning. The final deep features are measured by softmax function.</ce:para></ce:list-item><ce:list-item id=""""celistitem0012""""><ce:label>6.</ce:label><ce:para id=""""para0064"""" view=""""all""""><ce:bold>MLAPG</ce:bold><ce:cross-ref id=""""crf0116"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> considers the metric learning for person re-identification from the smoothness of the metric. It learn the Mahalanobis distance by formulate a log-logistic loss function with positive semi-define constraint. Besides, considering the balance between positive pairs and negative pairs, MLAPG method give different weights to positive pairs and negative pairs with an asymmetric weighting strategy.</ce:para></ce:list-item><ce:list-item id=""""celistitem0013""""><ce:label>7.</ce:label><ce:para id=""""para0065"""" view=""""all""""><ce:bold>QXDA</ce:bold><ce:cross-ref id=""""crf0117"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> is one of the best performance metric learning based methods. The authors propose a handcraft feature and a metric distance and achieve a good performance for person re-identification problem. The proposed metric distance method introduce LDA and KISSME approaches.</ce:para></ce:list-item></ce:list></ce:para>""''"'		ANG	
cites	Experiments	W. Li, R. Zhao, X. Wang, Human reidentification with transferred metric learning , Asian Conference on Computer Vision (2012)	http://dx.doi.org/10.1016/j.patcog.2017.04.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/ctx/ctx0038		46	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/itrp/0080	'This method learning a Mahalanobis distance for person re-identification problem based on a distribution hypothesis which assumes the difference vector of positive sample pairs and positive sample pairs features are following two different Gaussian distribution.4.LMNN[39][[ refid=''bib0039'' ]] is a classic metric learning based method which learns a Mahalanobis distance for classification problems.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0058"""" view=""""all"""">To verify the effectiveness of the proposed method, comparison experiments will be done with existing state-of-the-art methods. The comparison algorithms chosen in this paper are mainly metric learning based method for the reason that the proposed method is also metric learning based. Some state-of-the-art metric learning based methods are introduced as following:<ce:list id=""""celist0002""""><ce:list-item id=""""celistitem0007""""><ce:label>1.</ce:label><ce:para id=""""para0059"""" view=""""all""""><ce:bold>RDC</ce:bold><ce:cross-ref id=""""crf0111"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> is a typical metric learning based method in early researches for person re-identification problem. It is commonly used in the comparison experiments. RDC solve the re-identification task by transform the distance measure problem into a subspace learning problem. And an iterative optimization algorithm was proposed to learn a set of orthogonal projection vectors that form the subspace.</ce:para></ce:list-item><ce:list-item id=""""celistitem0008""""><ce:label>2.</ce:label><ce:para id=""""para0060"""" view=""""all""""><ce:bold>ITML</ce:bold><ce:cross-ref id=""""crf0112"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref> formulate the similarity of person images distance with information-theoretic approach. It also solve the person re-identification problem by learning Mahalanobis distance. Different from traditional metric learning methods, ITML learn a set of Manalanobis distances to approach to the existing Mahalanobis distance defined by the covariance matrix of a multivariate Gaussian distribution by an information-theoretic setting.</ce:para></ce:list-item><ce:list-item id=""""celistitem0009""""><ce:label>3.</ce:label><ce:para id=""""para0061"""" view=""""all""""><ce:bold>KISSME</ce:bold><ce:cross-ref id=""""crf0113"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> is based on a distribution hypothesis. This method learning a Mahalanobis distance for person re-identification problem based on a distribution hypothesis which assumes the difference vector of positive sample pairs and positive sample pairs features are following two different Gaussian distribution.</ce:para></ce:list-item><ce:list-item id=""""celistitem0010""""><ce:label>4.</ce:label><ce:para id=""""para0062"""" view=""""all""""><ce:bold>LMNN</ce:bold><ce:cross-ref id=""""crf0114"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> is a classic metric learning based method which learns a Mahalanobis distance for classification problems. This method is proposed for face recognition task. The distance is learned by forcing the samples close to its k nearest neighbours and be far away with the rest samples.</ce:para></ce:list-item><ce:list-item id=""""celistitem0011""""><ce:label>5.</ce:label><ce:para id=""""para0063"""" view=""""all""""><ce:bold>Improved Deep</ce:bold><ce:cross-ref id=""""crf0115"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> is a classic deep learning based method. It improves the SCNN deep structure with a neighborhood differences structure. The structure utilize a neighborhood difference operation to generate the similarity map for identification features learning. The final deep features are measured by softmax function.</ce:para></ce:list-item><ce:list-item id=""""celistitem0012""""><ce:label>6.</ce:label><ce:para id=""""para0064"""" view=""""all""""><ce:bold>MLAPG</ce:bold><ce:cross-ref id=""""crf0116"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> considers the metric learning for person re-identification from the smoothness of the metric. It learn the Mahalanobis distance by formulate a log-logistic loss function with positive semi-define constraint. Besides, considering the balance between positive pairs and negative pairs, MLAPG method give different weights to positive pairs and negative pairs with an asymmetric weighting strategy.</ce:para></ce:list-item><ce:list-item id=""""celistitem0013""""><ce:label>7.</ce:label><ce:para id=""""para0065"""" view=""""all""""><ce:bold>QXDA</ce:bold><ce:cross-ref id=""""crf0117"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> is one of the best performance metric learning based methods. The authors propose a handcraft feature and a metric distance and achieve a good performance for person re-identification problem. The proposed metric distance method introduce LDA and KISSME approaches.</ce:para></ce:list-item></ce:list></ce:para>""''"'		ANG	
cites	Previous works	W. Li, R. Zhao, T. Xiao, X. Wang, Deepreid: deep filter pairing neural network for person re-identification , IEEE Conference on Computer Vision and Pattern Recognition (2014)	http://dx.doi.org/10.1016/j.patcog.2017.04.012			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/ctx/ctx0019		46	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/itrp/0081	'Li et al. [27][[ refid=''bib0027'' ]] proposed a filter pairing neural network for person re-identification, while the parameter learning of deep network needs large sample size, Li et al. built the largest dataset for person re-identification in their work.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0021"""" view=""""all"""">Recently, deep learning has drawn much attention in the area of computer vision and machine learning due to its successes in various pattern recognition and artificial intelligence related tasks. It is powerful in feature representation. Compared to metric learning based methods, the deep learning based method is end to end that works on the raw data directly. It learns the semantic features and recognition model in an uniform deep structure. In the former researches, Bromley et al. <ce:cross-ref id=""""crf0053"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> proposed a siamese architecture to matching image pairs. It was used in the fields like face recognition firstly. And the early deep learning researches on person re-identification task were commonly based on this architecture. Recently, many deep learning based methods <ce:cross-refs id=""""crfs0009"""" refid=""""bib0026 bib0027 bib0028 bib0029 bib0030 bib0031"""">[26–31][[ refid=''''bib0026 bib0027 bib0028 bib0029 bib0030 bib0031'''' ]]</ce:cross-refs> have been proposed. Li et al. <ce:cross-ref id=""""crf0054"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> proposed a filter pairing neural network for person re-identification, while the parameter learning of deep network needs large sample size, Li et al. built the largest dataset for person re-identification in their work. The deep network proposed by Ahmed <ce:cross-ref id=""""crf0055"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> is similar to the filter pairing neural network, but different in structure and filter size. There is a cross-input neighborhood differences structure in the middle of this deep network. And this novel structure of deep network reached a good recognition rate. The deep learning network proposed by Dong et al. <ce:cross-ref id=""""crf0056"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> was a siamese convolutional neural network, SCNN. In the framework of Yi et al. <ce:cross-ref id=""""crf0057"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref>, the images were cut in an overlapped way to three body structures. These three different overlapped parts were learned in three same network jointly. This way of learning sample with joint networks of overlapped body structures is now a common framework in person re-identification task.</ce:para>""''"'		ANG	
cites	Previous works	S.C. Dong, M. Cristani, M. Stoppa, L. Bazzani, V. Murino, Custom pictorial structures for re-identification , British Machine Vision Conference (2011)	http://dx.doi.org/10.1016/j.patcog.2017.04.012			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/br/bib0021	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/ctx/ctx0013		46	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/itrp/0088	'Dong et al. [21][[ refid=''bib0021'' ]] designed a novel appearance model based on pictorial structures information of human body.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0020"""" view=""""all"""">Except for color and texture based features, the body structure is utilized to adapt to the appearance changes. Dong et al. <ce:cross-ref id=""""crf0050"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> designed a novel appearance model based on pictorial structures information of human body. And the human body was represented by 6 joint rectangles. When extracting features, they weighted the body structure with the saliency regions. Furthermore, researchers proposed methods matching person across cameras by the saliency detection directly <ce:cross-refs id=""""crfs0008"""" refid=""""bib0022 bib0023 bib0024 bib0025"""">[22–25][[ refid=''''bib0022 bib0023 bib0024 bib0025'''' ]]</ce:cross-refs>. Zhao et al. <ce:cross-ref id=""""crf0051"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref> matched the person by a SVM structure with the learned saliency patches. And they also proposed a novel saliency learning based method <ce:cross-ref id=""""crf0052"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> which was unsupervised. Adjacency constrained is used to deal with the misalignment problem in this method. And then the pedestrian image saliency was learned to patch match.</ce:para>""''"'		ANG	
cites	Previous works	S. Liao, Y. Hu, X. Zhu, S.Z. Li, Person re-identification by local maximal occurrence representation and metric learning , IEEE Conf. Comput. Vis. Pattern Recogn. , vol. 8 (2015), pp.2197-2206	http://dx.doi.org/10.1016/j.patcog.2017.04.012			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/br/bib0007	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/ctx/ctx0012		46	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-012/itrp/0089	'Liao et al. [7][[ refid=''bib0007'' ]] proposed the LOMO feature which combined the color histogram features with the texture histogram features of different scales.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0019"""" view=""""all"""">As the challenges aforementioned, it is difficult to find a robust appearance representation to be the feature of individual description. Researches on person re-identification seek a representation which could describe the similarity of positive pairs and the difference of the negative pairs. Traditional color based features and texture based features, like LBP, Gablor filters, Schmid fiters are not robust to appearance changes. Liu et al. <ce:cross-ref id=""""crf0047"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> proposed a Attribute-Restricted Latent Topic Model for person re-identification. They designed an intermediate representation for human appearance modeling. Conventional color and texture based features are clustered to form codebooks. Yang et al. <ce:cross-ref id=""""crf0048"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref> used the color names as the appearance feature which is more robust. They proposed a novel representation, SCNCD, to describe colors of person appearance. The color names feature based method had a much better matching result in person re-identification task than a fusion feature combined with HSV and Lab color histogram and texture feature, LBPs <ce:cross-refs id=""""crfs0007"""" refid=""""bib0008 bib0009"""">[8,9][[ refid=''''bib0008 bib0009'''' ]]</ce:cross-refs>. Liao et al. <ce:cross-ref id=""""crf0049"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> proposed the LOMO feature which combined the color histogram features with the texture histogram features of different scales. It is now a common feature used in person re-identification task.</ce:para>""''"'		ANG	
cites	Related work	Z. Li, S. Chang, F. Liang, T.S. Huang, L. Cao, J.R. Smith, Learning locally-adaptive decision functions for person verification , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (2013)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0017	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0026		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0011	'Li et al. [17][[ refid=''bib0017'' ]] proposed the Locally Adaptive Decision Functions (LADF) approach, which could be viewed as a joint model of a distance metric and a locally adapted thresholding rule.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0024"""" view=""""all"""">Besides feature representation, a large number of efforts have been made to learn optimal matching metrics to narrow the distances between matched persons and enlarge the distances between different ones <ce:cross-refs id=""""crfs0010"""" refid=""""bib0012 bib0013 bib0014 bib0016 bib0017 bib0041"""">[12–14,16,17,41][[ refid=''''bib0012 bib0013 bib0014 bib0016 bib0017 bib0041'''' ]]</ce:cross-refs>. For example, the Probabilistic Relative Distance Comparison (PRDC) model was presented in <ce:cross-ref id=""""crf0067"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> to maximize the probability of a pair of true match having a smaller distance than that of a wrong matched pair. Koestinger et al. <ce:cross-ref id=""""crf0068"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref> formulated the KISSME algorithm by computing the difference between the within-class and between-class covariance metrics. Li et al. <ce:cross-ref id=""""crf0069"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> proposed the Locally Adaptive Decision Functions (LADF) approach, which could be viewed as a joint model of a distance metric and a locally adapted thresholding rule. The Cross-view Quadratic Discriminant Analysis (XQDA) <ce:cross-ref id=""""crf0070"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> metric algorithm was an extension of KISSME by learning a dimension reduction projection and distance metric simultaneously. Those metric learning algorithms mainly focused on learning a unified model for all the training samples. Recently, a few works considered the local distribution or individual priority. In <ce:cross-ref id=""""crf0071"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> multiple local metrics are learned and then combined with a global metric to avoid overfitting. Zhang et al. <ce:cross-ref id=""""crf0072"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref> proposed to learn a classifier specifically for each pedestrian such that the matching model is highly tuned to the individual appearance.</ce:para>""''"'		ANG	
cites	Related work	S. Liao, Y. Hu, X. Zhu, S.Z. Li, Person re-identification by local maximal occurrence representation and metric learning , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (2015)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0012	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0027		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0012	'The Cross-view Quadratic Discriminant Analysis (XQDA) [12][[ refid=''bib0012'' ]] metric algorithm was an extension of KISSME by learning a dimension reduction projection and distance metric simultaneously.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0024"""" view=""""all"""">Besides feature representation, a large number of efforts have been made to learn optimal matching metrics to narrow the distances between matched persons and enlarge the distances between different ones <ce:cross-refs id=""""crfs0010"""" refid=""""bib0012 bib0013 bib0014 bib0016 bib0017 bib0041"""">[12–14,16,17,41][[ refid=''''bib0012 bib0013 bib0014 bib0016 bib0017 bib0041'''' ]]</ce:cross-refs>. For example, the Probabilistic Relative Distance Comparison (PRDC) model was presented in <ce:cross-ref id=""""crf0067"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> to maximize the probability of a pair of true match having a smaller distance than that of a wrong matched pair. Koestinger et al. <ce:cross-ref id=""""crf0068"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref> formulated the KISSME algorithm by computing the difference between the within-class and between-class covariance metrics. Li et al. <ce:cross-ref id=""""crf0069"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> proposed the Locally Adaptive Decision Functions (LADF) approach, which could be viewed as a joint model of a distance metric and a locally adapted thresholding rule. The Cross-view Quadratic Discriminant Analysis (XQDA) <ce:cross-ref id=""""crf0070"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> metric algorithm was an extension of KISSME by learning a dimension reduction projection and distance metric simultaneously. Those metric learning algorithms mainly focused on learning a unified model for all the training samples. Recently, a few works considered the local distribution or individual priority. In <ce:cross-ref id=""""crf0071"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> multiple local metrics are learned and then combined with a global metric to avoid overfitting. Zhang et al. <ce:cross-ref id=""""crf0072"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref> proposed to learn a classifier specifically for each pedestrian such that the matching model is highly tuned to the individual appearance.</ce:para>""''"'		ANG	
cites	Related work	W.-S. Zheng, S. Gong, T. Xiang, Person re-identification by probabilistic relative distance comparison , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, IEEE (2011)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0013	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0024		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0013	'For example, the Probabilistic Relative Distance Comparison (PRDC) model was presented in [13][[ refid=''bib0013'' ]] to maximize the probability of a pair of true match having a smaller distance than that of a wrong matched pair.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0024"""" view=""""all"""">Besides feature representation, a large number of efforts have been made to learn optimal matching metrics to narrow the distances between matched persons and enlarge the distances between different ones <ce:cross-refs id=""""crfs0010"""" refid=""""bib0012 bib0013 bib0014 bib0016 bib0017 bib0041"""">[12–14,16,17,41][[ refid=''''bib0012 bib0013 bib0014 bib0016 bib0017 bib0041'''' ]]</ce:cross-refs>. For example, the Probabilistic Relative Distance Comparison (PRDC) model was presented in <ce:cross-ref id=""""crf0067"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> to maximize the probability of a pair of true match having a smaller distance than that of a wrong matched pair. Koestinger et al. <ce:cross-ref id=""""crf0068"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref> formulated the KISSME algorithm by computing the difference between the within-class and between-class covariance metrics. Li et al. <ce:cross-ref id=""""crf0069"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> proposed the Locally Adaptive Decision Functions (LADF) approach, which could be viewed as a joint model of a distance metric and a locally adapted thresholding rule. The Cross-view Quadratic Discriminant Analysis (XQDA) <ce:cross-ref id=""""crf0070"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> metric algorithm was an extension of KISSME by learning a dimension reduction projection and distance metric simultaneously. Those metric learning algorithms mainly focused on learning a unified model for all the training samples. Recently, a few works considered the local distribution or individual priority. In <ce:cross-ref id=""""crf0071"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> multiple local metrics are learned and then combined with a global metric to avoid overfitting. Zhang et al. <ce:cross-ref id=""""crf0072"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref> proposed to learn a classifier specifically for each pedestrian such that the matching model is highly tuned to the individual appearance.</ce:para>""''"'		ANG	
cites	Related work	M. Koestinger, M. Hirzer, P. Wohlhart, P.M. Roth, H. Bischof, Large scale metric learning from equivalence constraints , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (2012)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0016	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0025		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0014	'Koestinger et al. [16][[ refid=''bib0016'' ]] formulated the KISSME algorithm by computing the difference between the within-class and between-class covariance metrics.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0024"""" view=""""all"""">Besides feature representation, a large number of efforts have been made to learn optimal matching metrics to narrow the distances between matched persons and enlarge the distances between different ones <ce:cross-refs id=""""crfs0010"""" refid=""""bib0012 bib0013 bib0014 bib0016 bib0017 bib0041"""">[12–14,16,17,41][[ refid=''''bib0012 bib0013 bib0014 bib0016 bib0017 bib0041'''' ]]</ce:cross-refs>. For example, the Probabilistic Relative Distance Comparison (PRDC) model was presented in <ce:cross-ref id=""""crf0067"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> to maximize the probability of a pair of true match having a smaller distance than that of a wrong matched pair. Koestinger et al. <ce:cross-ref id=""""crf0068"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref> formulated the KISSME algorithm by computing the difference between the within-class and between-class covariance metrics. Li et al. <ce:cross-ref id=""""crf0069"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> proposed the Locally Adaptive Decision Functions (LADF) approach, which could be viewed as a joint model of a distance metric and a locally adapted thresholding rule. The Cross-view Quadratic Discriminant Analysis (XQDA) <ce:cross-ref id=""""crf0070"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> metric algorithm was an extension of KISSME by learning a dimension reduction projection and distance metric simultaneously. Those metric learning algorithms mainly focused on learning a unified model for all the training samples. Recently, a few works considered the local distribution or individual priority. In <ce:cross-ref id=""""crf0071"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> multiple local metrics are learned and then combined with a global metric to avoid overfitting. Zhang et al. <ce:cross-ref id=""""crf0072"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref> proposed to learn a classifier specifically for each pedestrian such that the matching model is highly tuned to the individual appearance.</ce:para>""''"'		ANG	
cites	Related work	V.E. Liong, J. Lu, Y. Ge, Regularized local metric learning for person re-identification , Pattern Recognit. Lett. , vol. 68 (2015), pp.288-296	http://dx.doi.org/10.1016/j.patcog.2017.04.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0041	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0028		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0015	'In [41][[ refid=''bib0041'' ]] multiple local metrics are learned and then combined with a global metric to avoid overfitting.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0024"""" view=""""all"""">Besides feature representation, a large number of efforts have been made to learn optimal matching metrics to narrow the distances between matched persons and enlarge the distances between different ones <ce:cross-refs id=""""crfs0010"""" refid=""""bib0012 bib0013 bib0014 bib0016 bib0017 bib0041"""">[12–14,16,17,41][[ refid=''''bib0012 bib0013 bib0014 bib0016 bib0017 bib0041'''' ]]</ce:cross-refs>. For example, the Probabilistic Relative Distance Comparison (PRDC) model was presented in <ce:cross-ref id=""""crf0067"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> to maximize the probability of a pair of true match having a smaller distance than that of a wrong matched pair. Koestinger et al. <ce:cross-ref id=""""crf0068"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref> formulated the KISSME algorithm by computing the difference between the within-class and between-class covariance metrics. Li et al. <ce:cross-ref id=""""crf0069"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> proposed the Locally Adaptive Decision Functions (LADF) approach, which could be viewed as a joint model of a distance metric and a locally adapted thresholding rule. The Cross-view Quadratic Discriminant Analysis (XQDA) <ce:cross-ref id=""""crf0070"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> metric algorithm was an extension of KISSME by learning a dimension reduction projection and distance metric simultaneously. Those metric learning algorithms mainly focused on learning a unified model for all the training samples. Recently, a few works considered the local distribution or individual priority. In <ce:cross-ref id=""""crf0071"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> multiple local metrics are learned and then combined with a global metric to avoid overfitting. Zhang et al. <ce:cross-ref id=""""crf0072"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref> proposed to learn a classifier specifically for each pedestrian such that the matching model is highly tuned to the individual appearance.</ce:para>""''"'		ANG	
cites	Related work	Y. Zhang, B. Li, H. Lu, A. Irie, X. Ruan, Sample-specific svm learning for person re-identification , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, CVPR (2016)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0042	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0029		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0016	'Zhang et al. [42][[ refid=''bib0042'' ]] proposed to learn a classifier specifically for each pedestrian such that the matching model is highly tuned to the individual appearance.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0024"""" view=""""all"""">Besides feature representation, a large number of efforts have been made to learn optimal matching metrics to narrow the distances between matched persons and enlarge the distances between different ones <ce:cross-refs id=""""crfs0010"""" refid=""""bib0012 bib0013 bib0014 bib0016 bib0017 bib0041"""">[12–14,16,17,41][[ refid=''''bib0012 bib0013 bib0014 bib0016 bib0017 bib0041'''' ]]</ce:cross-refs>. For example, the Probabilistic Relative Distance Comparison (PRDC) model was presented in <ce:cross-ref id=""""crf0067"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> to maximize the probability of a pair of true match having a smaller distance than that of a wrong matched pair. Koestinger et al. <ce:cross-ref id=""""crf0068"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref> formulated the KISSME algorithm by computing the difference between the within-class and between-class covariance metrics. Li et al. <ce:cross-ref id=""""crf0069"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> proposed the Locally Adaptive Decision Functions (LADF) approach, which could be viewed as a joint model of a distance metric and a locally adapted thresholding rule. The Cross-view Quadratic Discriminant Analysis (XQDA) <ce:cross-ref id=""""crf0070"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> metric algorithm was an extension of KISSME by learning a dimension reduction projection and distance metric simultaneously. Those metric learning algorithms mainly focused on learning a unified model for all the training samples. Recently, a few works considered the local distribution or individual priority. In <ce:cross-ref id=""""crf0071"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> multiple local metrics are learned and then combined with a global metric to avoid overfitting. Zhang et al. <ce:cross-ref id=""""crf0072"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref> proposed to learn a classifier specifically for each pedestrian such that the matching model is highly tuned to the individual appearance.</ce:para>""''"'		ANG	
cites	Related work	D. Gray, H. Tao, Viewpoint invariant pedestrian recognition with an ensemble of localized features , Proceedings of European Conference on Computer Vision, Springer (2008)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0005	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0008		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0017	'For example, the Ensemble of Localized Features (ELF) [5][[ refid=''bib0005'' ]] was proposed to against viewpoint variants.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0018"""" view=""""all"""">Extensive researches on designing robust hand-crafted descriptors <ce:cross-refs id=""""crfs0006"""" refid=""""bib0005 bib0006 bib0007 bib0009 bib0011 bib0012 bib0027 bib0028 bib0029 bib0030 bib0031 bib0032"""">[5–7,9,11,12,27–32][[ refid=''''bib0005 bib0006 bib0007 bib0009 bib0011 bib0012 bib0027 bib0028 bib0029 bib0030 bib0031 bib0032'''' ]]</ce:cross-refs> have emerged in recent years. For example, the Ensemble of Localized Features (ELF) <ce:cross-ref id=""""crf0053"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> was proposed to against viewpoint variants. Later, a number of works <ce:cross-refs id=""""crfs0007"""" refid=""""bib0013 bib0033"""">[13,33][[ refid=''''bib0013 bib0033'''' ]]</ce:cross-refs> employ the ELF feature <ce:cross-ref id=""""crf0054"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> to describe pedestrians. Based on individual body configuration, Farenzena et al. <ce:cross-ref id=""""crf0055"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref> formulated the Symmetry-Driven Accumulation of Local Features (SDALF) descriptor, where the weighted HSV histogram, the Maximally Stable Color Regions (MSCR) and the Recurrent Highly Structured Patches (RHSP) were combined to provide complementary information. Zheng et al. <ce:cross-ref id=""""crf0056"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> utilized the Bag-of-Words(BOW) technique to aggregate the 11-dim color names descriptor for each local patch. Recently, a preeminent Local Maximal Occurrence (LOMO) <ce:cross-ref id=""""crf0057"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> descriptor was put forward, showing great robustness against low resolutions and appearance changes. The idea of LOMO was later followed by Chen et al. <ce:cross-ref id=""""crf0058"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>, where a similar sets of features were extracted. Motivated by the appearance structure of person images, Matsukawa et al. <ce:cross-ref id=""""crf0059"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> proposed the Gaussian of Gaussian (GOG) descriptor to describe color and texture cues.</ce:para>""''"'		ANG	
uses_data_from	Experiments	R. Zhao, W. Ouyang, X. Wang, Learning mid-level filters for person re-identification , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, IEEE (2014)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0062	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0047		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0028	'The CUHK01 dataset [62][[ refid=''bib0062'' ]] is a multi-shot person re-identification dataset recorded by two different cameras in a campus environment.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0054"""" view=""""all"""">The CUHK01 dataset <ce:cross-ref id=""""crf0131"""" refid=""""bib0062"""">[62][[ refid=''''bib0062'''' ]]</ce:cross-ref> is a multi-shot person re-identification dataset recorded by two different cameras in a campus environment. This dataset contains 971 persons and each person has two images in each camera view, which results in 3884 images in total. The probe set images mainly capture the frontal view (or back view) of an individual, while the gallery set images record the side view of a person with more variations of viewpoints and poses, making it challenging for pedestrian re-identification.</ce:para>""''"'		ANG	
cites	Introduction	, None, Springer (2014)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0002		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0056	'Generally, the person re-identification system [4][[ refid=''bib0004'' ]] can be divided into four steps: pedestrian detection, feature extraction, feature transform and similarity estimation, which can be seen in Fig. 1.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0008"""" view=""""all"""">Generally, the person re-identification system <ce:cross-ref id=""""crf0049"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref> can be divided into four steps: pedestrian detection, feature extraction, feature transform and similarity estimation, which can be seen in <ce:cross-ref id=""""crf0050"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref><ce:float-anchor refid=""""fig0001""""/>. Most of the existing efforts focus on seeking either the robust feature representations <ce:cross-refs id=""""crfs0001"""" refid=""""bib0005 bib0006 bib0007 bib0008 bib0009 bib0010 bib0011 bib0012"""">[5–12][[ refid=''''bib0005 bib0006 bib0007 bib0008 bib0009 bib0010 bib0011 bib0012'''' ]]</ce:cross-refs> or discriminative matching metrics <ce:cross-refs id=""""crfs0002"""" refid=""""bib0012 bib0013 bib0014 bib0015 bib0016 bib0017 bib0018"""">[12–18][[ refid=''''bib0012 bib0013 bib0014 bib0015 bib0016 bib0017 bib0018'''' ]]</ce:cross-refs> for addressing the above challenges when re-identifying people. Although many of these approaches have achieved inspiring results, they do not give sufficient consideration to the feature transformation.</ce:para>""''"'		ANG	
uses_method_in	Experiments	R. Zhao, W. Ouyang, X. Wang, Learning mid-level filters for person re-identification , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, IEEE (2014)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0062	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0048		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0095	'According to the experimental settings in [62][[ refid=''bib0062'' ]], we normalize all the images to 160 × 60 pixels and randomly select 485 image pairs for training and take the left for testing.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0055"""" view=""""all"""">According to the experimental settings in <ce:cross-ref id=""""crf0132"""" refid=""""bib0062"""">[62][[ refid=''''bib0062'''' ]]</ce:cross-ref>, we normalize all the images to 160 × 60 pixels and randomly select 485 image pairs for training and take the left for testing. The experiments are implemented for 10 trails, and the average results are reported. <ce:cross-ref id=""""crf0133"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref><ce:float-anchor refid=""""fig0004""""/>(a) shows the comparisons of the proposed algorithm with GOG <ce:cross-ref id=""""crf0134"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, XQDA <ce:cross-ref id=""""crf0135"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>, IDLA <ce:cross-ref id=""""crf0136"""" refid=""""bib0052"""">[52][[ refid=''''bib0052'''' ]]</ce:cross-ref>, Mirror <ce:cross-ref id=""""crf0137"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>, MidFilter <ce:cross-ref id=""""crf0138"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>, SalMatch <ce:cross-ref id=""""crf0139"""" refid=""""bib0053"""">[53][[ refid=''''bib0053'''' ]]</ce:cross-ref>, eSDC <ce:cross-ref id=""""crf0140"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>, ITML <ce:cross-ref id=""""crf0141"""" refid=""""bib0063"""">[63][[ refid=''''bib0063'''' ]]</ce:cross-ref>, LMNN <ce:cross-ref id=""""crf0142"""" refid=""""bib0064"""">[64][[ refid=''''bib0064'''' ]]</ce:cross-ref> and SDALF <ce:cross-ref id=""""crf0143"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>. Our method with LOMO feature obviously outperforms previous methods and achieves the best rank-1 recognition rate of 72.02%, which improves the XQDA+LOMO method in <ce:cross-ref id=""""crf0144"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> with a large margin by 8.81%. The proposed model with GOG descriptor gains an improvement with 2.47% in terms of rank-1 matching rate comparing with GOG <ce:cross-ref id=""""crf0145"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> algorithm, demonstrating remarkable advantages in large-scale person re-identification tasks.</ce:para>""''"'		ANG	
uses_method_in	Experiments	S. Liao, G. Zhao, V. Kellokumpu, M. Pietikäinen, S.Z. Li, Modeling pixel process with scale invariant local patterns for background subtraction in complex scenes , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, IEEE (2010)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0051	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0035		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0111	'Specifically, for the LOMO feature, we extract the HSV joint histogram and the SILTP [51][[ refid=''bib0051'' ]] histogram with three scales to describe the pedestrian appearance.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0046"""" view=""""all"""">In this paper, we extract the LOMO <ce:cross-ref id=""""crf0086"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> and GOG <ce:cross-ref id=""""crf0087"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> descriptors for feature representation. Specifically, for the LOMO feature, we extract the HSV joint histogram and the SILTP <ce:cross-ref id=""""crf0088"""" refid=""""bib0051"""">[51][[ refid=''''bib0051'''' ]]</ce:cross-ref> histogram with three scales to describe the pedestrian appearance. To reduce the influence of background information, we do not consider the five pixels at the left and right side, for a person generally locating in the center of an bounding box. This gains simplicity and efficiency in contrast with techniques that use complex background model. While for the GOG feature, we follow the process in <ce:cross-ref id=""""crf0089"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>. We reduce the dimension of both descriptors following the procedure in <ce:cross-ref id=""""crf0090"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> to eliminate harmonic and white noise.</ce:para>""''"'		ANG	
uses_method_in	Experiments	T. Matsukawa, T. Okabe, E. Suzuki, Y. Sato, Hierarchical gaussian descriptor for person re-identification , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, CVPR (2016)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0032	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0036		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0115	'While for the GOG feature, we follow the process in [32][[ refid=''bib0032'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0046"""" view=""""all"""">In this paper, we extract the LOMO <ce:cross-ref id=""""crf0086"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> and GOG <ce:cross-ref id=""""crf0087"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> descriptors for feature representation. Specifically, for the LOMO feature, we extract the HSV joint histogram and the SILTP <ce:cross-ref id=""""crf0088"""" refid=""""bib0051"""">[51][[ refid=''''bib0051'''' ]]</ce:cross-ref> histogram with three scales to describe the pedestrian appearance. To reduce the influence of background information, we do not consider the five pixels at the left and right side, for a person generally locating in the center of an bounding box. This gains simplicity and efficiency in contrast with techniques that use complex background model. While for the GOG feature, we follow the process in <ce:cross-ref id=""""crf0089"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>. We reduce the dimension of both descriptors following the procedure in <ce:cross-ref id=""""crf0090"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> to eliminate harmonic and white noise.</ce:para>""''"'		ANG	
uses_method_in	Experiments	D. Gray, S. Brennan, H. Tao, Evaluating appearance models for recognition, reacquisition, and tracking , Proceedings of IEEE International Workshop on Performance Evaluation for Tracking and Surveillance, PETS, Citeseer , vol. 3 (2007), pp.None	http://dx.doi.org/10.1016/j.patcog.2017.04.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0045	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0033		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0119	'The standard Cumulative Match Characteristic (CMC) [45][[ refid=''bib0045'' ]] curve is employed to compare the performance of the proposed algorithm with state-of-the-art methods.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0045"""" view=""""all"""">In this section, we evaluate our approach on six public available datasets, including five two camera views datasets (the VIPeR datset <ce:cross-ref id=""""crf0079"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref>, the QUML GRID dataset <ce:cross-ref id=""""crf0080"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref>, the PRID 450S dataset <ce:cross-ref id=""""crf0081"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref>, the CUHK01 dataset <ce:cross-ref id=""""crf0082"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>, the CUHK03 dataset <ce:cross-ref id=""""crf0083"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref>) and a multi-view database (the WARD dataset <ce:cross-ref id=""""crf0084"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref>). The standard Cumulative Match Characteristic (CMC) <ce:cross-ref id=""""crf0085"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> curve is employed to compare the performance of the proposed algorithm with state-of-the-art methods. Experiments on the six challenging databases demonstrate the effectiveness and superiority of the proposed model.</ce:para>""''"'		ANG	
uses_data_from	Experiments	D. Gray, S. Brennan, H. Tao, Evaluating appearance models for recognition, reacquisition, and tracking , Proceedings of IEEE International Workshop on Performance Evaluation for Tracking and Surveillance, PETS, Citeseer , vol. 3 (2007), pp.None	http://dx.doi.org/10.1016/j.patcog.2017.04.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0045	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0038		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0129	'The VIPeR dataset [45][[ refid=''bib0045'' ]] contains 632 pedestrian image pairs captured from two disjoint camera views in outdoor scenarios.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0048"""" view=""""all"""">The VIPeR dataset <ce:cross-ref id=""""crf0092"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> contains 632 pedestrian image pairs captured from two disjoint camera views in outdoor scenarios. All the images are normalized to 128 × 48 pixels for experiments. It is one of the most challenging and widely used dataset, which suffers from significant viewpoint variations, illumination differences and pose changes across different views.</ce:para>""''"'		ANG	
cites	Related work	L. Zheng, L. Shen, L. Tian, S. Wang, J. Wang, Q. Tian, Scalable person re-identification: a benchmark , Proceedings of IEEE International Conference on Computer Vision, ICCV (2015)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0030	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0011		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0140	'Zheng et al. [30][[ refid=''bib0030'' ]] utilized the Bag-of-Words(BOW) technique to aggregate the 11-dim color names descriptor for each local patch.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0018"""" view=""""all"""">Extensive researches on designing robust hand-crafted descriptors <ce:cross-refs id=""""crfs0006"""" refid=""""bib0005 bib0006 bib0007 bib0009 bib0011 bib0012 bib0027 bib0028 bib0029 bib0030 bib0031 bib0032"""">[5–7,9,11,12,27–32][[ refid=''''bib0005 bib0006 bib0007 bib0009 bib0011 bib0012 bib0027 bib0028 bib0029 bib0030 bib0031 bib0032'''' ]]</ce:cross-refs> have emerged in recent years. For example, the Ensemble of Localized Features (ELF) <ce:cross-ref id=""""crf0053"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> was proposed to against viewpoint variants. Later, a number of works <ce:cross-refs id=""""crfs0007"""" refid=""""bib0013 bib0033"""">[13,33][[ refid=''''bib0013 bib0033'''' ]]</ce:cross-refs> employ the ELF feature <ce:cross-ref id=""""crf0054"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> to describe pedestrians. Based on individual body configuration, Farenzena et al. <ce:cross-ref id=""""crf0055"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref> formulated the Symmetry-Driven Accumulation of Local Features (SDALF) descriptor, where the weighted HSV histogram, the Maximally Stable Color Regions (MSCR) and the Recurrent Highly Structured Patches (RHSP) were combined to provide complementary information. Zheng et al. <ce:cross-ref id=""""crf0056"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> utilized the Bag-of-Words(BOW) technique to aggregate the 11-dim color names descriptor for each local patch. Recently, a preeminent Local Maximal Occurrence (LOMO) <ce:cross-ref id=""""crf0057"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> descriptor was put forward, showing great robustness against low resolutions and appearance changes. The idea of LOMO was later followed by Chen et al. <ce:cross-ref id=""""crf0058"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>, where a similar sets of features were extracted. Motivated by the appearance structure of person images, Matsukawa et al. <ce:cross-ref id=""""crf0059"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> proposed the Gaussian of Gaussian (GOG) descriptor to describe color and texture cues.</ce:para>""''"'		ANG	
cites	Related work	M. Farenzena, L. Bazzani, A. Perina, V. Murino, M. Cristani, Person re-identification by symmetry-driven accumulation of local features , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (2010)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0006	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0010		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0141	'Based on individual body configuration, Farenzena et al. [6][[ refid=''bib0006'' ]] formulated the Symmetry-Driven Accumulation of Local Features (SDALF) descriptor, where the weighted HSV histogram, the Maximally Stable Color Regions (MSCR) and the Recurrent Highly Structured Patches (RHSP) were combined to provide complementary information.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0018"""" view=""""all"""">Extensive researches on designing robust hand-crafted descriptors <ce:cross-refs id=""""crfs0006"""" refid=""""bib0005 bib0006 bib0007 bib0009 bib0011 bib0012 bib0027 bib0028 bib0029 bib0030 bib0031 bib0032"""">[5–7,9,11,12,27–32][[ refid=''''bib0005 bib0006 bib0007 bib0009 bib0011 bib0012 bib0027 bib0028 bib0029 bib0030 bib0031 bib0032'''' ]]</ce:cross-refs> have emerged in recent years. For example, the Ensemble of Localized Features (ELF) <ce:cross-ref id=""""crf0053"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> was proposed to against viewpoint variants. Later, a number of works <ce:cross-refs id=""""crfs0007"""" refid=""""bib0013 bib0033"""">[13,33][[ refid=''''bib0013 bib0033'''' ]]</ce:cross-refs> employ the ELF feature <ce:cross-ref id=""""crf0054"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> to describe pedestrians. Based on individual body configuration, Farenzena et al. <ce:cross-ref id=""""crf0055"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref> formulated the Symmetry-Driven Accumulation of Local Features (SDALF) descriptor, where the weighted HSV histogram, the Maximally Stable Color Regions (MSCR) and the Recurrent Highly Structured Patches (RHSP) were combined to provide complementary information. Zheng et al. <ce:cross-ref id=""""crf0056"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> utilized the Bag-of-Words(BOW) technique to aggregate the 11-dim color names descriptor for each local patch. Recently, a preeminent Local Maximal Occurrence (LOMO) <ce:cross-ref id=""""crf0057"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> descriptor was put forward, showing great robustness against low resolutions and appearance changes. The idea of LOMO was later followed by Chen et al. <ce:cross-ref id=""""crf0058"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>, where a similar sets of features were extracted. Motivated by the appearance structure of person images, Matsukawa et al. <ce:cross-ref id=""""crf0059"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> proposed the Gaussian of Gaussian (GOG) descriptor to describe color and texture cues.</ce:para>""''"'		ANG	
cites	Related work	W. Li, X. Wang, Locally aligned feature transforms across views , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, IEEE (2013)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0024	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0017		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0142	'In [24][[ refid=''bib0024'' ]], multiple linear projections were learned to transform the partitioned samples into different feature subspaces according to the feature similarity.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0022"""" view=""""all"""">Although the hand-crafted features proposed in recent two years have achieved impressive performance, their representation power can be further improved by feature transformation model. For instance, the dictionary learning based methods <ce:cross-refs id=""""crfs0009"""" refid=""""bib0035 bib0036 bib0037"""">[35–37][[ refid=''''bib0035 bib0036 bib0037'''' ]]</ce:cross-refs> have attempted to learn the linear encodings for improving representation power of extracted features. In <ce:cross-ref id=""""crf0060"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, multiple linear projections were learned to transform the partitioned samples into different feature subspaces according to the feature similarity. Chen et al. <ce:cross-ref id=""""crf0061"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> proposed the Mirror Representation algorithm to alleviate the view-specific feature distortion problem for person re-identification. In <ce:cross-ref id=""""crf0062"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, pedestrian descriptors were matched in a discriminative null space, where images of the same person were collapsed into a single point. Wang et al. <ce:cross-ref id=""""crf0063"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> explored the cross-view support consistency and the cross-view projection consistency to adjust each query-gallery pair distance metric.</ce:para>""''"'		ANG	
cites	Related work	T. Matsukawa, T. Okabe, E. Suzuki, Y. Sato, Hierarchical gaussian descriptor for person re-identification , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, CVPR (2016)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0032	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0014		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0149	'Motivated by the appearance structure of person images, Matsukawa et al. [32][[ refid=''bib0032'' ]] proposed the Gaussian of Gaussian (GOG) descriptor to describe color and texture cues.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0018"""" view=""""all"""">Extensive researches on designing robust hand-crafted descriptors <ce:cross-refs id=""""crfs0006"""" refid=""""bib0005 bib0006 bib0007 bib0009 bib0011 bib0012 bib0027 bib0028 bib0029 bib0030 bib0031 bib0032"""">[5–7,9,11,12,27–32][[ refid=''''bib0005 bib0006 bib0007 bib0009 bib0011 bib0012 bib0027 bib0028 bib0029 bib0030 bib0031 bib0032'''' ]]</ce:cross-refs> have emerged in recent years. For example, the Ensemble of Localized Features (ELF) <ce:cross-ref id=""""crf0053"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> was proposed to against viewpoint variants. Later, a number of works <ce:cross-refs id=""""crfs0007"""" refid=""""bib0013 bib0033"""">[13,33][[ refid=''''bib0013 bib0033'''' ]]</ce:cross-refs> employ the ELF feature <ce:cross-ref id=""""crf0054"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> to describe pedestrians. Based on individual body configuration, Farenzena et al. <ce:cross-ref id=""""crf0055"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref> formulated the Symmetry-Driven Accumulation of Local Features (SDALF) descriptor, where the weighted HSV histogram, the Maximally Stable Color Regions (MSCR) and the Recurrent Highly Structured Patches (RHSP) were combined to provide complementary information. Zheng et al. <ce:cross-ref id=""""crf0056"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> utilized the Bag-of-Words(BOW) technique to aggregate the 11-dim color names descriptor for each local patch. Recently, a preeminent Local Maximal Occurrence (LOMO) <ce:cross-ref id=""""crf0057"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> descriptor was put forward, showing great robustness against low resolutions and appearance changes. The idea of LOMO was later followed by Chen et al. <ce:cross-ref id=""""crf0058"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>, where a similar sets of features were extracted. Motivated by the appearance structure of person images, Matsukawa et al. <ce:cross-ref id=""""crf0059"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> proposed the Gaussian of Gaussian (GOG) descriptor to describe color and texture cues.</ce:para>""''"'		ANG	
uses_data_from	Experiments	P.M. Roth, M. Hirzer, M. Köstinger, C. Beleznai, H. Bischof, Mahalanobis distance learning for person re-identification , Person Re-Identification, Springer (2014)	http://dx.doi.org/10.1016/j.patcog.2017.04.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/br/bib0047	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/ctx/ctx0045		63	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-022/itrp/0152	'The PRID 450S dataset [47][[ refid=''bib0047'' ]] contains 450 single-shot image pairs depicting walking humans recorded from two spatially disjoint camera views.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0052"""" view=""""all"""">The PRID 450S dataset <ce:cross-ref id=""""crf0122"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref> contains 450 single-shot image pairs depicting walking humans recorded from two spatially disjoint camera views. All the images are normalized into 128 × 48 pixels for evaluation and an experimental setting of 10 random trials is provided for this dataset. For each trial, half of the image pairs are randomly selected for training and the other half are used for testing.</ce:para>""''"'		ANG	
uses_data_from	Experimental results	G. Argenziano, H.P. Soyer, V. De Giorgi, D. Piccolo, P. Carli, M. Delfino, A. Ferrari, V. Hofmann-Wellenhog, D. Massi, G. Mazzocchetti, M. Scalvenzi, I.H. Wolf, Interactive Atlas of Dermoscopy , None, EDRA Medical Publishing & New Media (2000)	http://dx.doi.org/10.1016/j.patcog.2017.04.023	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-023/br/bib0005	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-023/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-023/ctx/ctx0056		69	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-023/itrp/0083	'The experiments were performed using a dataset of 804 images selected from the EDRA atlas [5][[ refid=''bib0005'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0063"""" view=""""all"""">The experiments were performed using a dataset of 804 images selected from the EDRA atlas <ce:cross-ref id=""""crf0078"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>. This is a multi-source database acquired at different hospitals. The experimental dataset contains 241 examples of melanoma and 563 examples of benign lesions belonging to the following classes: blue nevi, Clark nevi, Spitz nevi, combined nevi, congenital nevi, and dermal nevi. All of the images were analyzed by several experts during a consensus meeting. Each image is associated with a set of text labels stating which are the observed criteria. The total number of medical annotations is 10 (6 colors, 2 texture structures, and 2 color structures). For computational purposes, an additional label defined as <ce:italic>other structures/no structures</ce:italic> was added to the systems to deal with lesions that: (i) did not exhibit any of the assessed texture and color structures: or (ii) exhibited more clinical criteria besides the ones considered in this work. Labels associated with texture and color structures are available for all the images. However, color labels are only available for a subset of 344 images. <ce:cross-ref id=""""crf0079"""" refid=""""tbl0001"""">Tables 1</ce:cross-ref><ce:float-anchor refid=""""tbl0001""""/> and <ce:cross-ref id=""""crf0080"""" refid=""""tbl0002"""">2</ce:cross-ref><ce:float-anchor refid=""""tbl0002""""/> show the number of lesions that are labeled with each criterion.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experiments	H. Jegou, M. Douze, C. Schmid, Hamming embedding and weak geometric consistency for large scale image search , Proceedings of European Conference on Computer Vision (2008)	http://dx.doi.org/10.1016/j.patcog.2017.04.030	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-030/br/bib0063	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-030/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-030/ctx/ctx0064		72	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-030/itrp/0020	'All images come from the tiny image set, Holidays image set and Flickr [63][[ refid=''bib0063'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0055"""" view=""""all""""><ce:bold>GIST</ce:bold>: Similar to SIFT, this dataset contains a learning set, a base set and a query set. These sets have 500<ce:hsp sp=""""0.2""""/>K, 1<ce:hsp sp=""""0.2""""/>M and 1<ce:hsp sp=""""0.2""""/>K 960-dimensional GIST descriptors respectively. All images come from the tiny image set, Holidays image set and Flickr <ce:cross-ref id=""""crf0148"""" refid=""""bib0063"""">[63][[ refid=''''bib0063'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experiments	H. Jegou, M. Douze, C. Schmid, Hamming embedding and weak geometric consistency for large scale image search , Proceedings of European Conference on Computer Vision (2008)	http://dx.doi.org/10.1016/j.patcog.2017.04.030	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-030/br/bib0063	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-030/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-030/ctx/ctx0063		72	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-04-030/itrp/0120	'SIFT: The dataset is composed of three image sets: a learning set with 100K 128-dimenional SIFT descriptors extracted from Flickr images, a base set and a query set respectively containing 1M descriptors and 10K descriptors from the INRIA Holidays images [63][[ refid=''bib0063'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0054"""" view=""""all""""><ce:bold>SIFT</ce:bold>: The dataset is composed of three image sets: a learning set with 100<ce:hsp sp=""""0.2""""/>K 128-dimenional SIFT descriptors extracted from Flickr images, a base set and a query set respectively containing 1<ce:hsp sp=""""0.2""""/>M descriptors and 10<ce:hsp sp=""""0.2""""/>K descriptors from the INRIA Holidays images <ce:cross-ref id=""""crf0147"""" refid=""""bib0063"""">[63][[ refid=''''bib0063'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
cites	Introduction	D. Qin, S. Gammeter, L. Bossard, T. Quack, L. van Gool, Hello neighbor: accurate object retrieval with k-reciprocal nearest neighbors , CVPR’2011 (2011)	http://dx.doi.org/10.1016/j.patcog.2017.05.009	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0038	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0022		71	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0001	'Two different neighborhood sizes (k and kmax) are required in [38][[ refid=''bib0038'' ]], separating different parts of the ranked retrieval list with different distance measures.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all"""">The main contributions of the proposed approach in face of the related work are highlighted as follows:<ce:list id=""""celist0003""""><ce:list-item id=""""celistitem0005""""><ce:label>•</ce:label><ce:para id=""""para0015"""" view=""""all"""">Although the reciprocal references have been broadly exploited last years <ce:cross-refs id=""""crfs0022"""" refid=""""bib0023 bib0024 bib0038 bib0039 bib0040"""">[23,24,38–40][[ refid=''''bib0023 bib0024 bib0038 bib0039 bib0040'''' ]]</ce:cross-refs>, the proposed algorithm mainly differs from the other approaches regarding the use of Connected Components and the graph construction at different depths of the <ce:italic>k</ce:italic>-neighborhood, which enables a more gradual analysis at different levels of similarity. More specifically regarding <ce:cross-refs id=""""crfs0023"""" refid=""""bib0023 bib0038"""">[23,38][[ refid=''''bib0023 bib0038'''' ]]</ce:cross-refs>, we can emphasize:<ce:list id=""""celist0004""""><ce:list-item id=""""celistitem0006""""><ce:label>–</ce:label><ce:para id=""""para0016"""" view=""""all"""">The Graph Fusion <ce:cross-ref id=""""crf0174"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> also takes into account the <ce:italic>k</ce:italic>-reciprocal neighborhood for building the graph, but requires the computation of the Jaccard measure for assigning weight to edges, while the proposed method uses only information of reciprocal neighborhood. The Graph Fusion <ce:cross-ref id=""""crf0175"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> performs a ranking step using a transition matrix based on PageRank or a greedy algorithm, while our proposal exploits the Connected Components;</ce:para></ce:list-item><ce:list-item id=""""celistitem0007""""><ce:label>–</ce:label><ce:para id=""""para0017"""" view=""""all"""">The reciprocal neighborhood is also exploited in <ce:cross-ref id=""""crf0176"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, which uses a directed graph, while the propose method uses a weighted undirected graph. Two different neighborhood sizes (<ce:italic>k</ce:italic> and <ce:italic>k<ce:inf loc=""""post"""">max</ce:inf></ce:italic>) are required in <ce:cross-ref id=""""crf0177"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, separating different parts of the ranked retrieval list with different distance measures. In opposite, the proposed method considers only one neighborhood size, computing an uniform single measure.</ce:para></ce:list-item></ce:list></ce:para></ce:list-item><ce:list-item id=""""celistitem0008""""><ce:label>•</ce:label><ce:para id=""""para0018"""" view=""""all"""">The proposed algorithm requires lower computational efforts than diffusion-based approaches <ce:cross-refs id=""""crfs0024"""" refid=""""bib0020 bib0021 bib0022 bib0026"""">[20–22,26][[ refid=''''bib0020 bib0021 bib0022 bib0026'''' ]]</ce:cross-refs>. Such methods compute successive powers of affinity matrices, while the connectivity of the proposed graph is defined in terms of only top-<ce:italic>k</ce:italic> positions. On the other hand, when compared to other rank-based approaches <ce:cross-refs id=""""crfs0025"""" refid=""""bib0033 bib0034"""">[33,34][[ refid=''''bib0033 bib0034'''' ]]</ce:cross-refs>, the proposed method provides a geometric and more intuitive interpretation of the data;</ce:para></ce:list-item><ce:list-item id=""""celistitem0009""""><ce:label>•</ce:label><ce:para id=""""para0019"""" view=""""all"""">The proposed algorithm is related to the manifold learning method based on the correlation graph <ce:cross-ref id=""""crf0178"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>, which defines the graph connectivity using different levels of correlation measures and exploits strongly Connected Components. In contrast, the proposed method provides a simpler and more efficient formulation, in terms of reciprocal references and Connected Components.</ce:para></ce:list-item></ce:list></ce:para>""''"'		ANG	
uses_data_from	Experimental evaluation	D. Nistér, H. Stewénius, Scalable recognition with a vocabulary tree , IEEE Conference on Computer Vision and Pattern Recognition (CVPR’2006) , vol. 2 (2006), pp.2161-2168	http://dx.doi.org/10.1016/j.patcog.2017.05.009	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0050>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0047>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0030	'Due to the small number of images per class, the UKBench [50][[ refid=''bib0050'' ]] dataset is very challenger for unsupervised manifold learning and post-processing methods.'			FDY+AGA	infered_pred1
uses_data_from	Experimental evaluation	L. J. Latecki, R. Lakamper and T. Eckhardt, Shape descriptors for non-rigid shapes with a single closed contour, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2000, pp. 424–429.	http://dx.doi.org/10.1016/j.patcog.2017.05.009	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0045>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0042>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0034	'The results are described as following:•Shape retrieval: The experiments for shape retrieval considering the MPEG-7 [45][[ refid=''bib0045'' ]] dataset and six different descriptors are presented in Table 3.'			FDY+AGA	infered_pred1
uses_data_from	Experimental evaluation	H. Jegou, M. Douze, C. Schmid, Hamming embedding and weak geometric consistency for large scale image search , European Conference on Computer Vision (2008)	http://dx.doi.org/10.1016/j.patcog.2017.05.009	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0049>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0066>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0037	'Table 10 shows the MAP scores obtained on the Holidays [49][[ refid=''bib0049'' ]] dataset, in comparison with various recent image retrieval approaches.'			FDY+AGA	infered_pred1
cites	Introduction	Y. Liu, D. Zhang, G. Lu, W.-Y. Ma, A survey of content-based image retrieval with high-level semantics , Pattern Recognit. , vol. 40 (2007), pp.262-282	http://dx.doi.org/10.1016/j.patcog.2017.05.009	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0009	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0005		71	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0047	'Mainly due to this difficulties, the research focus was gradually shifted from designing low-level features to aspects related to higher level aspects [9][[ refid=''bib0009'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0008"""" view=""""all"""">Mainly due to this difficulties, the research focus was gradually shifted from designing low-level features to aspects related to higher level aspects <ce:cross-ref id=""""crf0159"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>. Based on this assumption, the use of machine learning methods was quickly spread in order to associate low-level features with high-level query concepts. In image retrieval applications, for example, several relevance feedback approaches <ce:cross-refs id=""""crfs0013"""" refid=""""bib0010 bib0011 bib0012 bib0013"""">[10–13][[ refid=''''bib0010 bib0011 bib0012 bib0013'''' ]]</ce:cross-refs> have been proposed. Such approaches obtain supervised information through user interactions with the aim of learning new distance measures capable of encoding user preferences.</ce:para>""''"'		ANG	
uses_data_from	Experimental evaluation	D. Nistér, H. Stewénius, Scalable recognition with a vocabulary tree , IEEE Conference on Computer Vision and Pattern Recognition (CVPR’2006) , vol. 2 (2006), pp.2161-2168	http://dx.doi.org/10.1016/j.patcog.2017.05.009	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0050>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0069>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0065	'Table 11 presents the results obtained by the proposed manifold learning algorithm results on the UKBench [50][[ refid=''bib0050'' ]] dataset.'			FDY+AGA	infered_pred1
uses_data_from	Experimental evaluation	L. J. Latecki, R. Lakamper and T. Eckhardt, Shape descriptors for non-rigid shapes with a single closed contour, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2000, pp. 424–429.	http://dx.doi.org/10.1016/j.patcog.2017.05.009	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0045>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0058>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0069	'Each point represent one image of MPEG-7 [45][[ refid=''bib0045'' ]] dataset.'			FDY+AGA	infered_pred1
uses_data_from	Experimental evaluation	H. Jegou, M. Douze, C. Schmid, Hamming embedding and weak geometric consistency for large scale image search , European Conference on Computer Vision (2008)	http://dx.doi.org/10.1016/j.patcog.2017.05.009	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0049>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0038>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0091	'All images are considered as query images for most of datasets, except for Holidays [49][[ refid=''bib0049'' ]], which uses 500 queries for comparison purposes.'			FDY+AGA	infered_pred1
uses_data_from	Experimental evaluation	H. Jegou, M. Douze, C. Schmid, Hamming embedding and weak geometric consistency for large scale image search , European Conference on Computer Vision (2008)	http://dx.doi.org/10.1016/j.patcog.2017.05.009	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0049>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0053>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0104	'The experiments conducted on the Holidays [49][[ refid=''bib0049'' ]] dataset considered analogous conditions.'			FDY+AGA	infered_pred1
uses_data_from	Experimental evaluation	D. Nistér, H. Stewénius, Scalable recognition with a vocabulary tree , IEEE Conference on Computer Vision and Pattern Recognition (CVPR’2006) , vol. 2 (2006), pp.2161-2168	http://dx.doi.org/10.1016/j.patcog.2017.05.009	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0050>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0051>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0106	'Table 6 presents the results obtained by the proposed method on UKBench [50][[ refid=''bib0050'' ]] dataset.'			FDY+AGA	infered_pred1
uses_data_from	Experimental evaluation	P. Brodatz, Textures: A Photographic Album for Artists and Designers , None, Dover (1966)	http://dx.doi.org/10.1016/j.patcog.2017.05.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0047	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0044		71	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0133	'Table 3 presents the experimental results, where positive gains were obtained for all color descriptors, ranging from +8.25% to +20.71%.•Texture retrieval:Table 3 also presents the effectiveness results obtained for three different texture descriptors on the Brodatz [47][[ refid=''bib0047'' ]] dataset.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0079"""" view=""""all"""">The effectiveness of the proposed manifold learning algorithm is first evaluated in general image retrieval tasks, considering shape, color, and texture features. The results are described as following:<ce:list id=""""celist0007""""><ce:list-item id=""""celistitem0018""""><ce:label>•</ce:label><ce:para id=""""para0080"""" view=""""all""""><ce:bold>Shape retrieval:</ce:bold> The experiments for shape retrieval considering the MPEG-7 <ce:cross-ref id=""""crf0220"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> dataset and six different descriptors are presented in <ce:cross-ref id=""""crf0221"""" refid=""""tbl0003"""">Table 3</ce:cross-ref><ce:float-anchor refid=""""tbl0003""""/>. Significant positive gains can observed for all descriptors, ranging from +9.42% to <ce:bold>+40.75%</ce:bold>. For example, the effectiveness of SS <ce:cross-ref id=""""crf0222"""" refid=""""bib0054"""">[54][[ refid=''''bib0054'''' ]]</ce:cross-ref> shape descriptor was improved from 37.67% to 53.02%.<ce:cross-ref id=""""crf0223"""" refid=""""fn0002""""><ce:sup loc=""""post"""">2</ce:sup></ce:cross-ref><ce:footnote id=""""fn0002""""><ce:label>2</ce:label><ce:note-para id=""""cenotep0002"""" view=""""all"""">The relative gains reported refer to the results obtained by the best parameters.</ce:note-para></ce:footnote></ce:para></ce:list-item><ce:list-item id=""""celistitem0019""""><ce:label>•</ce:label><ce:para id=""""para0081"""" view=""""all""""><ce:bold>Color retrieval:</ce:bold>The experiments involving color retrieval were conducted on Soccer dataset <ce:cross-ref id=""""crf0224"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref>, considering three different descriptors. <ce:cross-ref id=""""crf0225"""" refid=""""tbl0003"""">Table 3</ce:cross-ref> presents the experimental results, where positive gains were obtained for all color descriptors, ranging from +8.25% to +20.71%.</ce:para></ce:list-item><ce:list-item id=""""celistitem0020""""><ce:label>•</ce:label><ce:para id=""""para0082"""" view=""""all""""><ce:bold>Texture retrieval:</ce:bold><ce:cross-ref id=""""crf0226"""" refid=""""tbl0003"""">Table 3</ce:cross-ref> also presents the effectiveness results obtained for three different texture descriptors on the Brodatz <ce:cross-ref id=""""crf0227"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref> dataset. We can observe positive gains ranging from +6.96% to +15.82%. The obtained gains are statistical significant for all considered descriptors.</ce:para></ce:list-item></ce:list></ce:para>""''"'		ANG	
uses_data_from	Experimental evaluation	B. Leibe, B. Schiele, Analyzing appearance and contour based methods for object categorization , CVPR , vol. 2 (2003), pp.None	http://dx.doi.org/10.1016/j.patcog.2017.05.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0048	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0045		71	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0134	'Experiments conducted for object retrieval tasks considered four color descriptors on the ETH-80 [48][[ refid=''bib0048'' ]] dataset.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0086"""" view=""""all"""">Experiments conducted for object retrieval tasks considered four color descriptors on the ETH-80 <ce:cross-ref id=""""crf0229"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> dataset. All experiments considered fixed values of parameters (<ce:italic>k</ce:italic> = 20 and <ce:italic>T</ce:italic> = 1). <ce:cross-ref id=""""crf0230"""" refid=""""tbl0005"""">Table 5</ce:cross-ref><ce:float-anchor refid=""""tbl0005""""/> presents the MAP scores of each descriptor.</ce:para>""''"'		ANG	
uses_data_from	Experimental evaluation	L. J. Latecki, R. Lakamper and T. Eckhardt, Shape descriptors for non-rigid shapes with a single closed contour, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2000, pp. 424–429.	http://dx.doi.org/10.1016/j.patcog.2017.05.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0045	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0063		71	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0135	'Table 9 presents the results on the MPEG-7 [45][[ refid=''bib0045'' ]] dataset in comparison with several state-of-the-art post-processing methods.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0101"""" view=""""all""""><ce:cross-ref id=""""crf0265"""" refid=""""tbl0009"""">Table 9</ce:cross-ref><ce:float-anchor refid=""""tbl0009""""/> presents the results on the MPEG-7 <ce:cross-ref id=""""crf0266"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> dataset in comparison with several state-of-the-art post-processing methods. The MPEG-7 dataset is very frequently used as benchmark for unsupervised post-processing methods in the literature. The bull’s eye score (Recall@40), which counts all matching shapes within the top-40 ranked images, is used as evaluation measure. The proposed approach is evaluated in comparison with diverse post-processing methods considering the same features, given by four shape descriptors: IDSC <ce:cross-ref id=""""crf0267"""" refid=""""bib0056"""">[56][[ refid=''''bib0056'''' ]]</ce:cross-ref>, ASC <ce:cross-ref id=""""crf0268"""" refid=""""bib0058"""">[58][[ refid=''''bib0058'''' ]]</ce:cross-ref>, CFD <ce:cross-ref id=""""crf0269"""" refid=""""bib0057"""">[57][[ refid=''''bib0057'''' ]]</ce:cross-ref>, and AIR <ce:cross-ref id=""""crf0270"""" refid=""""bib0059"""">[59][[ refid=''''bib0059'''' ]]</ce:cross-ref>. We can observe that the proposed algorithm achieves the best scores for most of them, including a bull’s eye score of <ce:bold>100%</ce:bold> achieved for the AIR <ce:cross-ref id=""""crf0271"""" refid=""""bib0059"""">[59][[ refid=''''bib0059'''' ]]</ce:cross-ref> descriptor.</ce:para>""''"'		ANG	
uses_data_from	Experimental evaluation	H. Jegou, M. Douze, C. Schmid, Hamming embedding and weak geometric consistency for large scale image search , European Conference on Computer Vision (2008)	http://dx.doi.org/10.1016/j.patcog.2017.05.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0049	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0055		71	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0136	'Table 7 presents the results on the Holidays [49][[ refid=''bib0049'' ]] dataset.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0092"""" view=""""all"""">The experiments conducted on the Holidays <ce:cross-ref id=""""crf0240"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref> dataset considered analogous conditions. Instead of local descriptors, we used other CNN feature: Overfeat <ce:cross-ref id=""""crf0241"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>. Once the number of relevant images per class is smaller, unsupervised manifold learning tasks are even challenger. <ce:cross-ref id=""""crf0242"""" refid=""""tbl0007"""">Table 7</ce:cross-ref><ce:float-anchor refid=""""tbl0007""""/> presents the results on the Holidays <ce:cross-ref id=""""crf0243"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref> dataset. Effectiveness gains can be observed for all features, reaching a MAP score of <ce:bold>86.19%</ce:bold> of the fusion of ACC color and CNN-Overfeat features.</ce:para>""''"'		ANG	
uses_data_from	Experimental evaluation	D. Nistér, H. Stewénius, Scalable recognition with a vocabulary tree , IEEE Conference on Computer Vision and Pattern Recognition (CVPR’2006) , vol. 2 (2006), pp.2161-2168	http://dx.doi.org/10.1016/j.patcog.2017.05.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0050	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0070		71	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0137	'The UKBench [50][[ refid=''bib0050'' ]] dataset is often used as benchmark for both general retrieval approaches and unsupervised post-processing methods.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0103"""" view=""""all""""><ce:cross-ref id=""""crf0276"""" refid=""""tbl0011"""">Table 11</ce:cross-ref><ce:float-anchor refid=""""tbl0011""""/> presents the results obtained by the proposed manifold learning algorithm results on the UKBench <ce:cross-ref id=""""crf0277"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref> dataset. The UKBench <ce:cross-ref id=""""crf0278"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref> dataset is often used as benchmark for both general retrieval approaches and unsupervised post-processing methods. Analogous to the Holidays dataset, a comparison with the Graph Fusion <ce:cross-ref id=""""crf0279"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> method using the same features is also presented. The proposed Rec. kNN Graph + CCs algorithm yielded a N-S scores of <ce:bold>3.93</ce:bold>, the best score in comparison with other recent state-of-the-art methods.</ce:para>""''"'		ANG	
cites	Experimental evaluation	S. Zhang, M. Yang, T. Cour, K. Yu, D. Metaxas, Query specific rank fusion for image retrieval , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 37 (2015), pp.803-815	http://dx.doi.org/10.1016/j.patcog.2017.05.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0067		71	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0138	'The Graph Fusion [23][[ refid=''bib0023'' ]], which is a recent and relevant unsupervised related method, is used as baseline.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0102"""" view=""""all""""><ce:cross-ref id=""""crf0272"""" refid=""""tbl0010"""">Table 10</ce:cross-ref><ce:float-anchor refid=""""tbl0010""""/> shows the MAP scores obtained on the Holidays <ce:cross-ref id=""""crf0273"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref> dataset, in comparison with various recent image retrieval approaches. Once different features are used by the compared approaches, a comparison considering the same features used by our method is also included. The Graph Fusion <ce:cross-ref id=""""crf0274"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>, which is a recent and relevant unsupervised related method, is used as baseline. The parameters settings was followed the same values used by the proposed method (<mml:math altimg=""""si41.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math>) and fusion tasks was perfomed by the graph density variation <ce:cross-ref id=""""crf0275"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. As we can observe, the effectiveness results are very high, superior to the most of considered methods.</ce:para>""''"'		ANG	
uses_method_in	Experimental evaluation	A.S. Razavian, H. Azizpour, J. Sullivan, S. Carlsson, CNN features off-the-shelf: an astounding baseline for recognition, in: IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW’14), (2014) pp. 512–519.	http://dx.doi.org/10.1016/j.patcog.2017.05.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/ctx/ctx0054		71	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-009/itrp/0139	'Instead of local descriptors, we used other CNN feature: Overfeat [4][[ refid=''bib0004'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0092"""" view=""""all"""">The experiments conducted on the Holidays <ce:cross-ref id=""""crf0240"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref> dataset considered analogous conditions. Instead of local descriptors, we used other CNN feature: Overfeat <ce:cross-ref id=""""crf0241"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>. Once the number of relevant images per class is smaller, unsupervised manifold learning tasks are even challenger. <ce:cross-ref id=""""crf0242"""" refid=""""tbl0007"""">Table 7</ce:cross-ref><ce:float-anchor refid=""""tbl0007""""/> presents the results on the Holidays <ce:cross-ref id=""""crf0243"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref> dataset. Effectiveness gains can be observed for all features, reaching a MAP score of <ce:bold>86.19%</ce:bold> of the fusion of ACC color and CNN-Overfeat features.</ce:para>""''"'		ANG	
cites	Related work	Y. Zhen, P. Rai, H. Zha, L. Carin, Cross-modal similarity learning via pairs, preferences, and active supervision , Proceedings of the 29th AAAI Conference on Artificial Intelligence, January 25-30, 2015, Austin, Texas, USA (2015)	http://dx.doi.org/10.1016/j.patcog.2017.05.011	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/br/bib0028	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/ctx/ctx0022		37	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/itrp/0001	'And to our best knowledge, there is the only work [28][[ refid=''bib0028'' ]] with regard to cross modal similarity metric learning leveraging active sampling technique.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0017"""" view=""""all"""">In contrast, active similarity learning from data with multiple modalities remains largely underexploited. And to our best knowledge, there is the only work <ce:cross-ref id=""""crf0018"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> with regard to cross modal similarity metric learning leveraging active sampling technique. But it mainly focuses on learning cross modal similarities while we concentrate on how to exploit active sampling methods effectively to ease the massive requirement of labeled data for cross modal similarity learning. Zhen et al. <ce:cross-ref id=""""crf0019"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> present a probabilistic nonparametric Bayesian framework with weak supervision for learning cross modal similarities while we learn cross modal similarity exploiting both the inter-modal and intra-modal similarities in a shared subspace using pairwise correlation. Due to the usage of Markov Chain Monte Carlo for approximate inference and doing dynamic programming for active selection, their method becomes less efficient in cross modal similarity learning tasks. Compared with their learning model, ours is simple and efficient. With regard to active learning, they select most informative weak constraints based on the uncertainty and diversity principle using entropy theory while our active sampling strategy is based on similarity disagreement among different modalities.</ce:para>""''"'		ANG	
cites	Related work	Y. Zhen, P. Rai, H. Zha, L. Carin, Cross-modal similarity learning via pairs, preferences, and active supervision , Proceedings of the 29th AAAI Conference on Artificial Intelligence, January 25-30, 2015, Austin, Texas, USA (2015)	http://dx.doi.org/10.1016/j.patcog.2017.05.011	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/br/bib0028	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/ctx/ctx0023		37	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/itrp/0002	'Zhen et al. [28][[ refid=''bib0028'' ]] present a probabilistic nonparametric Bayesian framework with weak supervision for learning cross modal similarities while we learn cross modal similarity exploiting both the inter-modal and intra-modal similarities in a shared subspace using pairwise correlation.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0017"""" view=""""all"""">In contrast, active similarity learning from data with multiple modalities remains largely underexploited. And to our best knowledge, there is the only work <ce:cross-ref id=""""crf0018"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> with regard to cross modal similarity metric learning leveraging active sampling technique. But it mainly focuses on learning cross modal similarities while we concentrate on how to exploit active sampling methods effectively to ease the massive requirement of labeled data for cross modal similarity learning. Zhen et al. <ce:cross-ref id=""""crf0019"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> present a probabilistic nonparametric Bayesian framework with weak supervision for learning cross modal similarities while we learn cross modal similarity exploiting both the inter-modal and intra-modal similarities in a shared subspace using pairwise correlation. Due to the usage of Markov Chain Monte Carlo for approximate inference and doing dynamic programming for active selection, their method becomes less efficient in cross modal similarity learning tasks. Compared with their learning model, ours is simple and efficient. With regard to active learning, they select most informative weak constraints based on the uncertainty and diversity principle using entropy theory while our active sampling strategy is based on similarity disagreement among different modalities.</ce:para>""''"'		ANG	
cites	Related work	S. Ebert, M. Fritz, B. Schiele, Active metric learning for object recognition , Proceedings of Pattern Recognition - Joint 34th DAGM and 36th OAGM Symposium, August 28-31, 2012, Graz, Austria (2012)	http://dx.doi.org/10.1016/j.patcog.2017.05.011	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/br/bib0024	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/ctx/ctx0020		37	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/itrp/0003	'The method presented in [24][[ refid=''bib0024'' ]] analyzed several active sample selection strategies in terms of exploration and exploitation trade-offs.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">There have been some methods proposed to utilize active learning for improving single-modal similarity learning. For example, the approach proposed in <ce:cross-ref id=""""crf0015"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> selected those unlabeled sample pairs with the greatest uncertainty based on entropy theory in relative distance. The method presented in <ce:cross-ref id=""""crf0016"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref> analyzed several active sample selection strategies in terms of exploration and exploitation trade-offs. In <ce:cross-ref id=""""crf0017"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>, an information-theoretic criterion was presented to select the relative constraints which lead to the highest expected gain in information about the classes of examples. These methods however ignore the semantic gap and diverse feature spaces for objects with multiple modalities and cannot be applied in cross modal problems directly.</ce:para>""''"'		ANG	
cites	Related work	S. Xiong, R. Rosales, Y. Pei, X.Z. Fern, Active metric learning from relative comparisons, CoRR abs/1409.4155(2014).	http://dx.doi.org/10.1016/j.patcog.2017.05.011	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/ctx/ctx0021		37	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/itrp/0004	'In [27][[ refid=''bib0027'' ]], an information-theoretic criterion was presented to select the relative constraints which lead to the highest expected gain in information about the classes of examples.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">There have been some methods proposed to utilize active learning for improving single-modal similarity learning. For example, the approach proposed in <ce:cross-ref id=""""crf0015"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> selected those unlabeled sample pairs with the greatest uncertainty based on entropy theory in relative distance. The method presented in <ce:cross-ref id=""""crf0016"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref> analyzed several active sample selection strategies in terms of exploration and exploitation trade-offs. In <ce:cross-ref id=""""crf0017"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>, an information-theoretic criterion was presented to select the relative constraints which lead to the highest expected gain in information about the classes of examples. These methods however ignore the semantic gap and diverse feature spaces for objects with multiple modalities and cannot be applied in cross modal problems directly.</ce:para>""''"'		ANG	
uses_method_in	The proposed method	C. Kang, S. Liao, Y. He, J. Wang, W. Niu, S. Xiang, C. Pan, Cross-modal similarity learning: a low rank bilinear formulation , Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, October 19-23, 2015, Melbourne, VIC, Australia (2015)	http://dx.doi.org/10.1016/j.patcog.2017.05.011	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/br/bib0034	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/ctx/ctx0026		37	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/itrp/0005	'Note that the key difference between the above framework and the method in [34][[ refid=''bib0034'' ]] are that we additionally consider the intra-modal similarity and their method does not utilize active sampling technique to reduce the labeling cost.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0024"""" view=""""all"""">With the definition above, we follow the method in <ce:cross-ref id=""""crf0021"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> to define the following objective function:<ce:display><ce:formula id=""""eq0005""""><ce:label>(5)</ce:label><mml:math altimg=""""si24.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:munder><mml:mi>min</mml:mi><mml:mi>M</mml:mi></mml:munder><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>S</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant=""""bold-italic"""">o</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant=""""bold-italic"""">o</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mrow><mml:mo>∥</mml:mo><mml:mi>M</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:mo>*</mml:mo></mml:msub></mml:mrow></mml:mrow></mml:math></ce:formula></ce:display>where the nuclear norm ||<ce:italic>M</ce:italic>||<ce:inf loc=""""post"""">*</ce:inf> as the regularization term tries to discover the structures between two modalities, and <ce:italic>w<ce:inf loc=""""post"""">ij</ce:inf></ce:italic> is the weight of pair (<ce:bold><ce:italic>o</ce:italic></ce:bold><ce:inf loc=""""post""""><ce:italic>i</ce:italic></ce:inf>, <ce:bold><ce:italic>o</ce:italic></ce:bold><ce:inf loc=""""post""""><ce:italic>j</ce:italic></ce:inf>), which balances the effect of positive and negative pairs. For simplicity, <ce:italic>w<ce:inf loc=""""post"""">ij</ce:inf></ce:italic> are set as <mml:math altimg=""""si25.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant=""""script"""">S</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:math> for all positive pairs and <mml:math altimg=""""si26.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant=""""script"""">D</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:math> for all negative pairs in the experiments, where | · | returns the number of elements in a set. The above optimization problem can be solved by an accelerated proximal gradient algorithm (APG). Note that the key difference between the above framework and the method in <ce:cross-ref id=""""crf0022"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> are that we additionally consider the intra-modal similarity and their method does not utilize active sampling technique to reduce the labeling cost. Based on the above similarity learning framework, we then propose our active sampling strategy in the following subsection, which is the main contribution of this work.</ce:para>""''"'		ANG	
cites	The proposed method	C. Kang, S. Liao, Y. He, J. Wang, W. Niu, S. Xiang, C. Pan, Cross-modal similarity learning: a low rank bilinear formulation , Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, October 19-23, 2015, Melbourne, VIC, Australia (2015)	http://dx.doi.org/10.1016/j.patcog.2017.05.011	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/br/bib0034	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/ctx/ctx0024		37	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/itrp/0009	'Under this setting, Kang et al. [34][[ refid=''bib0034'' ]] proposed a heterogeneous similarity learning algorithm by fitting the observed constraints with a nuclear norm penalty, where the similarity between two heterogeneous objects xi and zj is defined as SM(xi,zj)=xiTMzj.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0022"""" view=""""all"""">Under this setting, Kang et al. <ce:cross-ref id=""""crf0020"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> proposed a heterogeneous similarity learning algorithm by fitting the observed constraints with a nuclear norm penalty, where the similarity between two heterogeneous objects <ce:bold><ce:italic>x</ce:italic></ce:bold><ce:inf loc=""""post""""><ce:italic>i</ce:italic></ce:inf> and <ce:bold><ce:italic>z</ce:italic></ce:bold><ce:inf loc=""""post""""><ce:italic>j</ce:italic></ce:inf> is defined as <mml:math altimg=""""si12.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant=""""bold-italic"""">x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant=""""bold-italic"""">z</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant=""""bold-italic"""">x</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mi>M</mml:mi><mml:msub><mml:mi mathvariant=""""bold-italic"""">z</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math>. Here <ce:italic>S<ce:inf loc=""""post"""">M</ce:inf></ce:italic>(<ce:bold><ce:italic>x</ce:italic></ce:bold><ce:inf loc=""""post""""><ce:italic>i</ce:italic></ce:inf>, <ce:bold><ce:italic>z</ce:italic></ce:bold><ce:inf loc=""""post""""><ce:italic>j</ce:italic></ce:inf>) is a bilinear similarity metric function parameterized by <mml:math altimg=""""si13.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>M</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant=""""double-struck"""">R</mml:mi><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:math>. One shortcoming of this method is that it ignores the similarity between intra-modal instances, which are also valuable for similarity learning. Therefore, we adopt the joint feature representation of <mml:math altimg=""""si14.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi mathvariant=""""bold-italic"""">o</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:mi mathvariant=""""bold-italic"""">x</mml:mi><mml:mo>;</mml:mo><mml:mi mathvariant=""""bold-italic"""">z</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:math> and redefine the similarity between two examples as:<ce:display><ce:formula id=""""eq0002""""><ce:label>(2)</ce:label><mml:math altimg=""""si15.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant=""""bold-italic"""">o</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant=""""bold-italic"""">o</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant=""""bold-italic"""">o</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mi>M</mml:mi><mml:msub><mml:mi mathvariant=""""bold-italic"""">o</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>where <mml:math altimg=""""si16.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>M</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant=""""double-struck"""">R</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>z</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math> is a symmetric matrix and <mml:math altimg=""""si17.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant=""""bold-italic"""">o</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant=""""bold-italic"""">o</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>∈</mml:mo><mml:mi mathvariant=""""double-struck"""">R</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math> which means the similarity value can be negative (dissimilar) or positive (similar).</ce:para>""''"'		ANG	
uses_method_in	The proposed method	C. Kang, S. Liao, Y. He, J. Wang, W. Niu, S. Xiang, C. Pan, Cross-modal similarity learning: a low rank bilinear formulation , Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, October 19-23, 2015, Melbourne, VIC, Australia (2015)	http://dx.doi.org/10.1016/j.patcog.2017.05.011	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/br/bib0034>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/ctx/ctx0025>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/itrp/0010	'With the definition above, we follow the method in [34][[ refid=''bib0034'' ]] to define the following objective function: [[ formulaid=''id9_pos0'' ]] where the nuclear norm ||M||* as the regularization term tries to discover the structures between two modalities, and wij is the weight of pair (oi, oj), which balances the effect of positive and negative pairs.'			FDY+AGA	infered_pred1
cites	Introduction	B. Settles, Active Learning Literature Survey , Computer Sciences Technical Report 1648, University of Wisconsin-Madison (2010)	http://dx.doi.org/10.1016/j.patcog.2017.05.011	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/ctx/ctx0004		37	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/itrp/0037	'Active learning is a leading approach to reduce the labeling cost by actively querying the most important supervised information from the oracle [18][[ refid=''bib0018'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">Active learning is a leading approach to reduce the labeling cost by actively querying the most important supervised information from the oracle <ce:cross-ref id=""""crf0003"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. The key task of active learning is to design an effective selection strategy such that the queried information could improve the model most. During the past decades, different active selection strategies have been designed, and successfully applied into various applications <ce:cross-refs id=""""crfs0003"""" refid=""""bib0019 bib0020 bib0021 bib0022 bib0023"""">[19–23][[ refid=''''bib0019 bib0020 bib0021 bib0022 bib0023'''' ]]</ce:cross-refs>. Similarity learning usually requires a lot of labeled training data, and mostly leads to high labeling cost for data with multi-modal. Active learning is very suitable for this task to reduce the labeling cost and this is the motivation of many existing studies on active learning for similarity learning <ce:cross-refs id=""""crfs0004"""" refid=""""bib0024 bib0025 bib0026 bib0027 bib0028"""">[24–28][[ refid=''''bib0024 bib0025 bib0026 bib0027 bib0028'''' ]]</ce:cross-refs>. Some of those studies try to query the class labels for the most informative instances and then force the instances within the same class to have larger similarity <ce:cross-refs id=""""crfs0005"""" refid=""""bib0024 bib0025"""">[24,25][[ refid=''''bib0024 bib0025'''' ]]</ce:cross-refs>. Some other studies directly ask the oracle to compare selected instances and feedback their relative similarities <ce:cross-refs id=""""crfs0006"""" refid=""""bib0026 bib0027 bib0028"""">[26–28][[ refid=''''bib0026 bib0027 bib0028'''' ]]</ce:cross-refs>. However, most of them focus on designing selection strategies for single-modal similarity learning <ce:cross-refs id=""""crfs0007"""" refid=""""bib0024 bib0025 bib0026 bib0027"""">[24–27][[ refid=''''bib0024 bib0025 bib0026 bib0027'''' ]]</ce:cross-refs>, and cannot be directly applied to the cross-modal scenario.</ce:para>""''"'		ANG	
cites	Related work	V.E. Liong, J. Lu, Y.-P. Tan, J. Zhou, Deep coupled metric learning for cross-modal matching , IEEE Trans. Multimedia , vol. PP (2016), pp.None	http://dx.doi.org/10.1016/j.patcog.2017.05.011	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/br/bib0029	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/ctx/ctx0010		37	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/itrp/0070	'For instance, Liong et al. [29][[ refid=''bib0029'' ]] proposed a new deep coupled metric learning method for cross modal matching, which develops two sets of hierarchical nonlinear transformations by feedforward neural networks.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">To solve the problems mentioned above, a number of cross modal methods have been extensively studied in recent years. For instance, Liong et al. <ce:cross-ref id=""""crf0008"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> proposed a new deep coupled metric learning method for cross modal matching, which develops two sets of hierarchical nonlinear transformations by feedforward neural networks. On one hand, they employ a large margin criterion to minimize intra-class variation and maximize inter-class variation to exploit more discriminative information. On the other hand, difference of data pair captured from two modalities of the same class is minimized to reduce the modality gap. Based on a compact binary face descriptor (CBFD), Lu et al. <ce:cross-ref id=""""crf0009"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> proposed a coupled CBFD method for face recognition by maximizing the correlation of two learned binary vectors of instance pair within the same class, which reduces the modality gap of heterogeneous faces at the feature level. Based on canonical correlation analysis, a novel cross-modal retrieval algorithm was proposed considering the high-order relationship among pairs and treating the intra- and inter-pair correlation discriminatively <ce:cross-ref id=""""crf0010"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>. In <ce:cross-ref id=""""crf0011"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>, an online multi-modal distance metric learning approach was presented, which simultaneously learns optimal metrics on individual modalities and their optimal combination. Based on the kernel density estimation and the kernel trick, nonlinear metric learning frameworks were proposed in <ce:cross-refs id=""""crfs0008"""" refid=""""bib0010 bib0015 bib0032"""">[10,15,32][[ refid=''''bib0010 bib0015 bib0032'''' ]]</ce:cross-refs> to address the challenge of heterogeneous features. In <ce:cross-ref id=""""crf0012"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref>, the correlation between multi-modal data were captured in terms of their sharing hidden variables and discriminative ranking functions. Two models applicable to cross modal retrieval were proposed in <ce:cross-ref id=""""crf0013"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> based on low-level correlations and semantic abstraction matching. The methods proposed in <ce:cross-refs id=""""crfs0009"""" refid=""""bib0034 bib0035 bib0036"""">[34–36][[ refid=''''bib0034 bib0035 bib0036'''' ]]</ce:cross-refs> exploited the low-rank bilinear similarity learning mechanism to improve their efficiencies and scalability.</ce:para>""''"'		ANG	
cites	Related work	J.C. Pereira, E. Coviello, G. Doyle, N. Rasiwasia, G.R.G. Lanckriet, R. Levy, N. Vasconcelos, On the role of correlation and abstraction in cross-modal multimedia retrieval , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 36 (2014), pp.521-535	http://dx.doi.org/10.1016/j.patcog.2017.05.011	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/br/bib0013	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/ctx/ctx0016		37	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/itrp/0074	'Two models applicable to cross modal retrieval were proposed in [13][[ refid=''bib0013'' ]] based on low-level correlations and semantic abstraction matching.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">To solve the problems mentioned above, a number of cross modal methods have been extensively studied in recent years. For instance, Liong et al. <ce:cross-ref id=""""crf0008"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> proposed a new deep coupled metric learning method for cross modal matching, which develops two sets of hierarchical nonlinear transformations by feedforward neural networks. On one hand, they employ a large margin criterion to minimize intra-class variation and maximize inter-class variation to exploit more discriminative information. On the other hand, difference of data pair captured from two modalities of the same class is minimized to reduce the modality gap. Based on a compact binary face descriptor (CBFD), Lu et al. <ce:cross-ref id=""""crf0009"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> proposed a coupled CBFD method for face recognition by maximizing the correlation of two learned binary vectors of instance pair within the same class, which reduces the modality gap of heterogeneous faces at the feature level. Based on canonical correlation analysis, a novel cross-modal retrieval algorithm was proposed considering the high-order relationship among pairs and treating the intra- and inter-pair correlation discriminatively <ce:cross-ref id=""""crf0010"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>. In <ce:cross-ref id=""""crf0011"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>, an online multi-modal distance metric learning approach was presented, which simultaneously learns optimal metrics on individual modalities and their optimal combination. Based on the kernel density estimation and the kernel trick, nonlinear metric learning frameworks were proposed in <ce:cross-refs id=""""crfs0008"""" refid=""""bib0010 bib0015 bib0032"""">[10,15,32][[ refid=''''bib0010 bib0015 bib0032'''' ]]</ce:cross-refs> to address the challenge of heterogeneous features. In <ce:cross-ref id=""""crf0012"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref>, the correlation between multi-modal data were captured in terms of their sharing hidden variables and discriminative ranking functions. Two models applicable to cross modal retrieval were proposed in <ce:cross-ref id=""""crf0013"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> based on low-level correlations and semantic abstraction matching. The methods proposed in <ce:cross-refs id=""""crfs0009"""" refid=""""bib0034 bib0035 bib0036"""">[34–36][[ refid=''''bib0034 bib0035 bib0036'''' ]]</ce:cross-refs> exploited the low-rank bilinear similarity learning mechanism to improve their efficiencies and scalability.</ce:para>""''"'		ANG	
cites	Related work	F. Wu, X. Jiang, X. Li, S. Tang, W. Lu, Z. Zhang, Y. Zhuang, Cross-modal learning to rank via latent joint representation , IEEE Trans. Image Process. , vol. 24 (2015), pp.1497-1509	http://dx.doi.org/10.1016/j.patcog.2017.05.011	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/br/bib0033	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/ctx/ctx0015		37	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-05-011/itrp/0075	'In [33][[ refid=''bib0033'' ]], the correlation between multi-modal data were captured in terms of their sharing hidden variables and discriminative ranking functions.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">To solve the problems mentioned above, a number of cross modal methods have been extensively studied in recent years. For instance, Liong et al. <ce:cross-ref id=""""crf0008"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> proposed a new deep coupled metric learning method for cross modal matching, which develops two sets of hierarchical nonlinear transformations by feedforward neural networks. On one hand, they employ a large margin criterion to minimize intra-class variation and maximize inter-class variation to exploit more discriminative information. On the other hand, difference of data pair captured from two modalities of the same class is minimized to reduce the modality gap. Based on a compact binary face descriptor (CBFD), Lu et al. <ce:cross-ref id=""""crf0009"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> proposed a coupled CBFD method for face recognition by maximizing the correlation of two learned binary vectors of instance pair within the same class, which reduces the modality gap of heterogeneous faces at the feature level. Based on canonical correlation analysis, a novel cross-modal retrieval algorithm was proposed considering the high-order relationship among pairs and treating the intra- and inter-pair correlation discriminatively <ce:cross-ref id=""""crf0010"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>. In <ce:cross-ref id=""""crf0011"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>, an online multi-modal distance metric learning approach was presented, which simultaneously learns optimal metrics on individual modalities and their optimal combination. Based on the kernel density estimation and the kernel trick, nonlinear metric learning frameworks were proposed in <ce:cross-refs id=""""crfs0008"""" refid=""""bib0010 bib0015 bib0032"""">[10,15,32][[ refid=''''bib0010 bib0015 bib0032'''' ]]</ce:cross-refs> to address the challenge of heterogeneous features. In <ce:cross-ref id=""""crf0012"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref>, the correlation between multi-modal data were captured in terms of their sharing hidden variables and discriminative ranking functions. Two models applicable to cross modal retrieval were proposed in <ce:cross-ref id=""""crf0013"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> based on low-level correlations and semantic abstraction matching. The methods proposed in <ce:cross-refs id=""""crfs0009"""" refid=""""bib0034 bib0035 bib0036"""">[34–36][[ refid=''''bib0034 bib0035 bib0036'''' ]]</ce:cross-refs> exploited the low-rank bilinear similarity learning mechanism to improve their efficiencies and scalability.</ce:para>""''"'		ANG	
cites	Related work	F. Yin, C.-L. Liu, Handwritten chinese text line segmentation by clustering with distance metric learning , Pattern Recognit. , vol. 42 (2009), pp.3146-3157	http://dx.doi.org/10.1016/j.patcog.2017.06.012	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/br/bib0030	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/ctx/ctx0022		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/itrp/0001	'In [30][[ refid=''bib0030'' ]], the distance metric is learned for addressing the text line segmentation problem.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">In the single-view graph case, some efforts have been made in enhancing the discriminability of cluster structure <ce:cross-refs id=""""crfs0007"""" refid=""""bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031"""">[13,19,21,26–31][[ refid=''''bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031'''' ]]</ce:cross-refs>. For instance, Yang et al. <ce:cross-ref id=""""crf0027"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> propose a boosting framework for preserving both visual and semantic similarities for image retrieval systems. Yeung and Chang <ce:cross-ref id=""""crf0028"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> propose an extension of RCA using both positive and negative equivalent constraints. In <ce:cross-ref id=""""crf0029"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, the distance metric is learned for addressing the text line segmentation problem. In <ce:cross-ref id=""""crf0030"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>, an adaptive Semi-supervised Clustering Kernel Method based on Metric learning (SCKMM) is proposed to solve some problems in semi-supervised clustering, e.g. violation problem of pairwise constraints. More recently, Tao et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> propose the Manifold Ranking-Based Matrix Factorization (MRMF) model focusing on the feature information to solve the saliency detection problem. Another work Dual-Regularized KISS (DR-KISS) <ce:cross-ref id=""""crf0032"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> improves the accuracy of person re-identification problem by developing a more discriminative distance metric learning. In <ce:cross-ref id=""""crf0033"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, the distance metric is learned based on the commute time. Zhao et al. <ce:cross-ref id=""""crf0034"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> explore the possibility of using a geometric space embedding to learn the random-walk distances, including: 1) hitting time; 2) commute time; 3) personalized PageRank. Another research work that takes into account the metric learning is the distance dynamics <ce:cross-ref id=""""crf0035"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>, which regards the given graph as a dynamic system where the interaction strength of the nodes changes gradually, leading to more discriminative metric. Very recently, motif is utilized to enhance the cluster structure <ce:cross-ref id=""""crf0036"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, which is one of the most common higher-order structures, i.e., the small subgraphs describing different features in graph. However, all the above methods are limited to the single-view graph, and due to the complex topological structure consisting of the intra-view connection and the inter-view coupling, it remains a challenging issue to learn discriminative metric in multi-view graph.</ce:para>""''"'		ANG	
cites	Related work	X. Yin, S. Chen, E. Hu, D. Zhang, Semi-supervised clustering with metric learning: an adaptive kernel method , Pattern Recognit. , vol. 43 (2010), pp.1320-1333	http://dx.doi.org/10.1016/j.patcog.2017.06.012	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/br/bib0031	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/ctx/ctx0023		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/itrp/0002	'In [31][[ refid=''bib0031'' ]], an adaptive Semi-supervised Clustering Kernel Method based on Metric learning (SCKMM) is proposed to solve some problems in semi-supervised clustering, e.g. violation problem of pairwise constraints.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">In the single-view graph case, some efforts have been made in enhancing the discriminability of cluster structure <ce:cross-refs id=""""crfs0007"""" refid=""""bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031"""">[13,19,21,26–31][[ refid=''''bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031'''' ]]</ce:cross-refs>. For instance, Yang et al. <ce:cross-ref id=""""crf0027"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> propose a boosting framework for preserving both visual and semantic similarities for image retrieval systems. Yeung and Chang <ce:cross-ref id=""""crf0028"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> propose an extension of RCA using both positive and negative equivalent constraints. In <ce:cross-ref id=""""crf0029"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, the distance metric is learned for addressing the text line segmentation problem. In <ce:cross-ref id=""""crf0030"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>, an adaptive Semi-supervised Clustering Kernel Method based on Metric learning (SCKMM) is proposed to solve some problems in semi-supervised clustering, e.g. violation problem of pairwise constraints. More recently, Tao et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> propose the Manifold Ranking-Based Matrix Factorization (MRMF) model focusing on the feature information to solve the saliency detection problem. Another work Dual-Regularized KISS (DR-KISS) <ce:cross-ref id=""""crf0032"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> improves the accuracy of person re-identification problem by developing a more discriminative distance metric learning. In <ce:cross-ref id=""""crf0033"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, the distance metric is learned based on the commute time. Zhao et al. <ce:cross-ref id=""""crf0034"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> explore the possibility of using a geometric space embedding to learn the random-walk distances, including: 1) hitting time; 2) commute time; 3) personalized PageRank. Another research work that takes into account the metric learning is the distance dynamics <ce:cross-ref id=""""crf0035"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>, which regards the given graph as a dynamic system where the interaction strength of the nodes changes gradually, leading to more discriminative metric. Very recently, motif is utilized to enhance the cluster structure <ce:cross-ref id=""""crf0036"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, which is one of the most common higher-order structures, i.e., the small subgraphs describing different features in graph. However, all the above methods are limited to the single-view graph, and due to the complex topological structure consisting of the intra-view connection and the inter-view coupling, it remains a challenging issue to learn discriminative metric in multi-view graph.</ce:para>""''"'		ANG	
cites	Related work	L. Yang, R. Jin, L. Mummert, R. Sukthankar, A. Goode, B. Zheng, S.C. Hoi, M. Satyanarayanan, A boosting framework for visuality-preserving distance metric learning and its application to medical image retrieval , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 32 (2010), pp.30-44	http://dx.doi.org/10.1016/j.patcog.2017.06.012	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/br/bib0028	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/ctx/ctx0020		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/itrp/0003	'For instance, Yang et al. [28][[ refid=''bib0028'' ]] propose a boosting framework for preserving both visual and semantic similarities for image retrieval systems.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">In the single-view graph case, some efforts have been made in enhancing the discriminability of cluster structure <ce:cross-refs id=""""crfs0007"""" refid=""""bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031"""">[13,19,21,26–31][[ refid=''''bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031'''' ]]</ce:cross-refs>. For instance, Yang et al. <ce:cross-ref id=""""crf0027"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> propose a boosting framework for preserving both visual and semantic similarities for image retrieval systems. Yeung and Chang <ce:cross-ref id=""""crf0028"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> propose an extension of RCA using both positive and negative equivalent constraints. In <ce:cross-ref id=""""crf0029"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, the distance metric is learned for addressing the text line segmentation problem. In <ce:cross-ref id=""""crf0030"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>, an adaptive Semi-supervised Clustering Kernel Method based on Metric learning (SCKMM) is proposed to solve some problems in semi-supervised clustering, e.g. violation problem of pairwise constraints. More recently, Tao et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> propose the Manifold Ranking-Based Matrix Factorization (MRMF) model focusing on the feature information to solve the saliency detection problem. Another work Dual-Regularized KISS (DR-KISS) <ce:cross-ref id=""""crf0032"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> improves the accuracy of person re-identification problem by developing a more discriminative distance metric learning. In <ce:cross-ref id=""""crf0033"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, the distance metric is learned based on the commute time. Zhao et al. <ce:cross-ref id=""""crf0034"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> explore the possibility of using a geometric space embedding to learn the random-walk distances, including: 1) hitting time; 2) commute time; 3) personalized PageRank. Another research work that takes into account the metric learning is the distance dynamics <ce:cross-ref id=""""crf0035"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>, which regards the given graph as a dynamic system where the interaction strength of the nodes changes gradually, leading to more discriminative metric. Very recently, motif is utilized to enhance the cluster structure <ce:cross-ref id=""""crf0036"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, which is one of the most common higher-order structures, i.e., the small subgraphs describing different features in graph. However, all the above methods are limited to the single-view graph, and due to the complex topological structure consisting of the intra-view connection and the inter-view coupling, it remains a challenging issue to learn discriminative metric in multi-view graph.</ce:para>""''"'		ANG	
cites	Related work	D.-Y. Yeung, H. Chang, Extending the relevant component analysis algorithm for metric learning using both positive and negative equivalence constraints , Pattern Recognit. , vol. 39 (2006), pp.1007-1010	http://dx.doi.org/10.1016/j.patcog.2017.06.012	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/br/bib0029	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/ctx/ctx0021		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/itrp/0004	'Yeung and Chang [29][[ refid=''bib0029'' ]] propose an extension of RCA using both positive and negative equivalent constraints.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">In the single-view graph case, some efforts have been made in enhancing the discriminability of cluster structure <ce:cross-refs id=""""crfs0007"""" refid=""""bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031"""">[13,19,21,26–31][[ refid=''''bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031'''' ]]</ce:cross-refs>. For instance, Yang et al. <ce:cross-ref id=""""crf0027"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> propose a boosting framework for preserving both visual and semantic similarities for image retrieval systems. Yeung and Chang <ce:cross-ref id=""""crf0028"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> propose an extension of RCA using both positive and negative equivalent constraints. In <ce:cross-ref id=""""crf0029"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, the distance metric is learned for addressing the text line segmentation problem. In <ce:cross-ref id=""""crf0030"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>, an adaptive Semi-supervised Clustering Kernel Method based on Metric learning (SCKMM) is proposed to solve some problems in semi-supervised clustering, e.g. violation problem of pairwise constraints. More recently, Tao et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> propose the Manifold Ranking-Based Matrix Factorization (MRMF) model focusing on the feature information to solve the saliency detection problem. Another work Dual-Regularized KISS (DR-KISS) <ce:cross-ref id=""""crf0032"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> improves the accuracy of person re-identification problem by developing a more discriminative distance metric learning. In <ce:cross-ref id=""""crf0033"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, the distance metric is learned based on the commute time. Zhao et al. <ce:cross-ref id=""""crf0034"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> explore the possibility of using a geometric space embedding to learn the random-walk distances, including: 1) hitting time; 2) commute time; 3) personalized PageRank. Another research work that takes into account the metric learning is the distance dynamics <ce:cross-ref id=""""crf0035"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>, which regards the given graph as a dynamic system where the interaction strength of the nodes changes gradually, leading to more discriminative metric. Very recently, motif is utilized to enhance the cluster structure <ce:cross-ref id=""""crf0036"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, which is one of the most common higher-order structures, i.e., the small subgraphs describing different features in graph. However, all the above methods are limited to the single-view graph, and due to the complex topological structure consisting of the intra-view connection and the inter-view coupling, it remains a challenging issue to learn discriminative metric in multi-view graph.</ce:para>""''"'		ANG	
cites	Related work	J.A. Albano, D.W. Messinger, Euclidean commute time distance embedding and its application to spectral anomaly detection , SPIE Defense, Security, and Sensing, 2012, International Society for Optics and Photonics (2012)	http://dx.doi.org/10.1016/j.patcog.2017.06.012	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/br/bib0032	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/ctx/ctx0026		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/itrp/0005	'In [32][[ refid=''bib0032'' ]], the distance metric is learned based on the commute time.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">In the single-view graph case, some efforts have been made in enhancing the discriminability of cluster structure <ce:cross-refs id=""""crfs0007"""" refid=""""bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031"""">[13,19,21,26–31][[ refid=''''bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031'''' ]]</ce:cross-refs>. For instance, Yang et al. <ce:cross-ref id=""""crf0027"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> propose a boosting framework for preserving both visual and semantic similarities for image retrieval systems. Yeung and Chang <ce:cross-ref id=""""crf0028"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> propose an extension of RCA using both positive and negative equivalent constraints. In <ce:cross-ref id=""""crf0029"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, the distance metric is learned for addressing the text line segmentation problem. In <ce:cross-ref id=""""crf0030"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>, an adaptive Semi-supervised Clustering Kernel Method based on Metric learning (SCKMM) is proposed to solve some problems in semi-supervised clustering, e.g. violation problem of pairwise constraints. More recently, Tao et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> propose the Manifold Ranking-Based Matrix Factorization (MRMF) model focusing on the feature information to solve the saliency detection problem. Another work Dual-Regularized KISS (DR-KISS) <ce:cross-ref id=""""crf0032"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> improves the accuracy of person re-identification problem by developing a more discriminative distance metric learning. In <ce:cross-ref id=""""crf0033"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, the distance metric is learned based on the commute time. Zhao et al. <ce:cross-ref id=""""crf0034"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> explore the possibility of using a geometric space embedding to learn the random-walk distances, including: 1) hitting time; 2) commute time; 3) personalized PageRank. Another research work that takes into account the metric learning is the distance dynamics <ce:cross-ref id=""""crf0035"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>, which regards the given graph as a dynamic system where the interaction strength of the nodes changes gradually, leading to more discriminative metric. Very recently, motif is utilized to enhance the cluster structure <ce:cross-ref id=""""crf0036"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, which is one of the most common higher-order structures, i.e., the small subgraphs describing different features in graph. However, all the above methods are limited to the single-view graph, and due to the complex topological structure consisting of the intra-view connection and the inter-view coupling, it remains a challenging issue to learn discriminative metric in multi-view graph.</ce:para>""''"'		ANG	
cites	Related work	X. Zhao, A. Chang, A.D. Sarma, H. Zheng, B.Y. Zhao, On the embeddability of random walk distances , Proc. VLDB Endowment , vol. 6 (2013), pp.1690-1701	http://dx.doi.org/10.1016/j.patcog.2017.06.012	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/br/bib0019	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/ctx/ctx0027		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/itrp/0006	'Zhao et al. [19][[ refid=''bib0019'' ]] explore the possibility of using a geometric space embedding to learn the random-walk distances, including: 1) hitting time; 2) commute time; 3) personalized PageRank.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">In the single-view graph case, some efforts have been made in enhancing the discriminability of cluster structure <ce:cross-refs id=""""crfs0007"""" refid=""""bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031"""">[13,19,21,26–31][[ refid=''''bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031'''' ]]</ce:cross-refs>. For instance, Yang et al. <ce:cross-ref id=""""crf0027"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> propose a boosting framework for preserving both visual and semantic similarities for image retrieval systems. Yeung and Chang <ce:cross-ref id=""""crf0028"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> propose an extension of RCA using both positive and negative equivalent constraints. In <ce:cross-ref id=""""crf0029"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, the distance metric is learned for addressing the text line segmentation problem. In <ce:cross-ref id=""""crf0030"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>, an adaptive Semi-supervised Clustering Kernel Method based on Metric learning (SCKMM) is proposed to solve some problems in semi-supervised clustering, e.g. violation problem of pairwise constraints. More recently, Tao et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> propose the Manifold Ranking-Based Matrix Factorization (MRMF) model focusing on the feature information to solve the saliency detection problem. Another work Dual-Regularized KISS (DR-KISS) <ce:cross-ref id=""""crf0032"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> improves the accuracy of person re-identification problem by developing a more discriminative distance metric learning. In <ce:cross-ref id=""""crf0033"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, the distance metric is learned based on the commute time. Zhao et al. <ce:cross-ref id=""""crf0034"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> explore the possibility of using a geometric space embedding to learn the random-walk distances, including: 1) hitting time; 2) commute time; 3) personalized PageRank. Another research work that takes into account the metric learning is the distance dynamics <ce:cross-ref id=""""crf0035"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>, which regards the given graph as a dynamic system where the interaction strength of the nodes changes gradually, leading to more discriminative metric. Very recently, motif is utilized to enhance the cluster structure <ce:cross-ref id=""""crf0036"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, which is one of the most common higher-order structures, i.e., the small subgraphs describing different features in graph. However, all the above methods are limited to the single-view graph, and due to the complex topological structure consisting of the intra-view connection and the inter-view coupling, it remains a challenging issue to learn discriminative metric in multi-view graph.</ce:para>""''"'		ANG	
cites	Related work	D. Tao, J. Cheng, M. Song, X. Lin, Manifold ranking-based matrix factorization for saliency detection , IEEE Trans. Neural Netw. Learn. Syst. , vol. 27 (2016), pp.1122-1134	http://dx.doi.org/10.1016/j.patcog.2017.06.012	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/br/bib0026	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/ctx/ctx0024		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/itrp/0007	'More recently, Tao et al. [26][[ refid=''bib0026'' ]] propose the Manifold Ranking-Based Matrix Factorization (MRMF) model focusing on the feature information to solve the saliency detection problem.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">In the single-view graph case, some efforts have been made in enhancing the discriminability of cluster structure <ce:cross-refs id=""""crfs0007"""" refid=""""bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031"""">[13,19,21,26–31][[ refid=''''bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031'''' ]]</ce:cross-refs>. For instance, Yang et al. <ce:cross-ref id=""""crf0027"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> propose a boosting framework for preserving both visual and semantic similarities for image retrieval systems. Yeung and Chang <ce:cross-ref id=""""crf0028"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> propose an extension of RCA using both positive and negative equivalent constraints. In <ce:cross-ref id=""""crf0029"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, the distance metric is learned for addressing the text line segmentation problem. In <ce:cross-ref id=""""crf0030"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>, an adaptive Semi-supervised Clustering Kernel Method based on Metric learning (SCKMM) is proposed to solve some problems in semi-supervised clustering, e.g. violation problem of pairwise constraints. More recently, Tao et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> propose the Manifold Ranking-Based Matrix Factorization (MRMF) model focusing on the feature information to solve the saliency detection problem. Another work Dual-Regularized KISS (DR-KISS) <ce:cross-ref id=""""crf0032"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> improves the accuracy of person re-identification problem by developing a more discriminative distance metric learning. In <ce:cross-ref id=""""crf0033"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, the distance metric is learned based on the commute time. Zhao et al. <ce:cross-ref id=""""crf0034"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> explore the possibility of using a geometric space embedding to learn the random-walk distances, including: 1) hitting time; 2) commute time; 3) personalized PageRank. Another research work that takes into account the metric learning is the distance dynamics <ce:cross-ref id=""""crf0035"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>, which regards the given graph as a dynamic system where the interaction strength of the nodes changes gradually, leading to more discriminative metric. Very recently, motif is utilized to enhance the cluster structure <ce:cross-ref id=""""crf0036"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, which is one of the most common higher-order structures, i.e., the small subgraphs describing different features in graph. However, all the above methods are limited to the single-view graph, and due to the complex topological structure consisting of the intra-view connection and the inter-view coupling, it remains a challenging issue to learn discriminative metric in multi-view graph.</ce:para>""''"'		ANG	
cites	Related work	D. Tao, Y. Guo, M. Song, Y. Li, Z. Yu, Y.Y. Tang, Person re-identification by dual-regularized kiss metric learning , IEEE Trans. Image Process. , vol. 25 (2016), pp.2726-2738	http://dx.doi.org/10.1016/j.patcog.2017.06.012	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/ctx/ctx0025		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/itrp/0008	'Another work Dual-Regularized KISS (DR-KISS) [27][[ refid=''bib0027'' ]] improves the accuracy of person re-identification problem by developing a more discriminative distance metric learning.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">In the single-view graph case, some efforts have been made in enhancing the discriminability of cluster structure <ce:cross-refs id=""""crfs0007"""" refid=""""bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031"""">[13,19,21,26–31][[ refid=''''bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031'''' ]]</ce:cross-refs>. For instance, Yang et al. <ce:cross-ref id=""""crf0027"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> propose a boosting framework for preserving both visual and semantic similarities for image retrieval systems. Yeung and Chang <ce:cross-ref id=""""crf0028"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> propose an extension of RCA using both positive and negative equivalent constraints. In <ce:cross-ref id=""""crf0029"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, the distance metric is learned for addressing the text line segmentation problem. In <ce:cross-ref id=""""crf0030"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>, an adaptive Semi-supervised Clustering Kernel Method based on Metric learning (SCKMM) is proposed to solve some problems in semi-supervised clustering, e.g. violation problem of pairwise constraints. More recently, Tao et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> propose the Manifold Ranking-Based Matrix Factorization (MRMF) model focusing on the feature information to solve the saliency detection problem. Another work Dual-Regularized KISS (DR-KISS) <ce:cross-ref id=""""crf0032"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> improves the accuracy of person re-identification problem by developing a more discriminative distance metric learning. In <ce:cross-ref id=""""crf0033"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, the distance metric is learned based on the commute time. Zhao et al. <ce:cross-ref id=""""crf0034"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> explore the possibility of using a geometric space embedding to learn the random-walk distances, including: 1) hitting time; 2) commute time; 3) personalized PageRank. Another research work that takes into account the metric learning is the distance dynamics <ce:cross-ref id=""""crf0035"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>, which regards the given graph as a dynamic system where the interaction strength of the nodes changes gradually, leading to more discriminative metric. Very recently, motif is utilized to enhance the cluster structure <ce:cross-ref id=""""crf0036"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, which is one of the most common higher-order structures, i.e., the small subgraphs describing different features in graph. However, all the above methods are limited to the single-view graph, and due to the complex topological structure consisting of the intra-view connection and the inter-view coupling, it remains a challenging issue to learn discriminative metric in multi-view graph.</ce:para>""''"'		ANG	
cites	Related work	J. Shao, Z. Han, Q. Yang, T. Zhou, Community detection based on distance dynamics , KDD 2015, ACM (2015)	http://dx.doi.org/10.1016/j.patcog.2017.06.012	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/br/bib0013	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/ctx/ctx0028		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/itrp/0009	'Another research work that takes into account the metric learning is the distance dynamics [13][[ refid=''bib0013'' ]], which regards the given graph as a dynamic system where the interaction strength of the nodes changes gradually, leading to more discriminative metric.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">In the single-view graph case, some efforts have been made in enhancing the discriminability of cluster structure <ce:cross-refs id=""""crfs0007"""" refid=""""bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031"""">[13,19,21,26–31][[ refid=''''bib0013 bib0019 bib0021 bib0026 bib0027 bib0028 bib0029 bib0030 bib0031'''' ]]</ce:cross-refs>. For instance, Yang et al. <ce:cross-ref id=""""crf0027"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> propose a boosting framework for preserving both visual and semantic similarities for image retrieval systems. Yeung and Chang <ce:cross-ref id=""""crf0028"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> propose an extension of RCA using both positive and negative equivalent constraints. In <ce:cross-ref id=""""crf0029"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, the distance metric is learned for addressing the text line segmentation problem. In <ce:cross-ref id=""""crf0030"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>, an adaptive Semi-supervised Clustering Kernel Method based on Metric learning (SCKMM) is proposed to solve some problems in semi-supervised clustering, e.g. violation problem of pairwise constraints. More recently, Tao et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> propose the Manifold Ranking-Based Matrix Factorization (MRMF) model focusing on the feature information to solve the saliency detection problem. Another work Dual-Regularized KISS (DR-KISS) <ce:cross-ref id=""""crf0032"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> improves the accuracy of person re-identification problem by developing a more discriminative distance metric learning. In <ce:cross-ref id=""""crf0033"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, the distance metric is learned based on the commute time. Zhao et al. <ce:cross-ref id=""""crf0034"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> explore the possibility of using a geometric space embedding to learn the random-walk distances, including: 1) hitting time; 2) commute time; 3) personalized PageRank. Another research work that takes into account the metric learning is the distance dynamics <ce:cross-ref id=""""crf0035"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>, which regards the given graph as a dynamic system where the interaction strength of the nodes changes gradually, leading to more discriminative metric. Very recently, motif is utilized to enhance the cluster structure <ce:cross-ref id=""""crf0036"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, which is one of the most common higher-order structures, i.e., the small subgraphs describing different features in graph. However, all the above methods are limited to the single-view graph, and due to the complex topological structure consisting of the intra-view connection and the inter-view coupling, it remains a challenging issue to learn discriminative metric in multi-view graph.</ce:para>""''"'		ANG	
cites	Introduction	P.J. Mucha, T. Richardson, K. Macon, M.A. Porter, J.-P. Onnela, Community structure in time-dependent, multiscale, and multiplex networks , Science , vol. 328 (2010), pp.876-878	http://dx.doi.org/10.1016/j.patcog.2017.06.012	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/br/bib0014	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/ctx/ctx0005		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/itrp/0038	'As the rapid development of the web technology, in particular in the social network, there emerge some multi-view graphs [14][[ refid=''bib0014'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">As the rapid development of the web technology, in particular in the social network, there emerge some multi-view graphs <ce:cross-ref id=""""crf0011"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref>. For instance, in social network, it is often the case that each user has various accounts in different social platforms which are coupled by some common bonds, e.g. Email address. Each platform is taken as a view in the social network. It is possible for a user to behave slightly differently in various views and the social behaviours in different views may influence each other, which means that the inter-view coupling should be taken into account for discovering the relationship among nodes in the same view <ce:cross-ref id=""""crf0012"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>. In two different views, when a user in one view is more similar to itself in another view (i.e., more similar linkage structure and interaction strength), the strength of the inter-view coupling between this pair of views is stronger <ce:cross-ref id=""""crf0013"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>. Due to the complex interplay between the intra-view connection and the inter-view coupling, multi-view graph partitioning encounters more challenges than that in single-view graph. Although some methods have been developed for multi-view graph partitioning <ce:cross-refs id=""""crfs0003"""" refid=""""bib0014 bib0017 bib0018"""">[14,17,18][[ refid=''''bib0014 bib0017 bib0018'''' ]]</ce:cross-refs>, most of them are only based on the original topological structure without learning more discriminative metric space.</ce:para>""''"'		ANG	
cites	Introduction	C. Shi, Y. Li, J. Zhang, Y. Sun, P.S. Yu, A survey of heterogeneous information network analysis , IEEE Trans. Knowl. Data Eng. , vol. 29 (2017), pp.17-37	http://dx.doi.org/10.1016/j.patcog.2017.06.012	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/br/bib0015	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/ctx/ctx0006		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/itrp/0039	'It is possible for a user to behave slightly differently in various views and the social behaviours in different views may influence each other, which means that the inter-view coupling should be taken into account for discovering the relationship among nodes in the same view [15][[ refid=''bib0015'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">As the rapid development of the web technology, in particular in the social network, there emerge some multi-view graphs <ce:cross-ref id=""""crf0011"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref>. For instance, in social network, it is often the case that each user has various accounts in different social platforms which are coupled by some common bonds, e.g. Email address. Each platform is taken as a view in the social network. It is possible for a user to behave slightly differently in various views and the social behaviours in different views may influence each other, which means that the inter-view coupling should be taken into account for discovering the relationship among nodes in the same view <ce:cross-ref id=""""crf0012"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>. In two different views, when a user in one view is more similar to itself in another view (i.e., more similar linkage structure and interaction strength), the strength of the inter-view coupling between this pair of views is stronger <ce:cross-ref id=""""crf0013"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>. Due to the complex interplay between the intra-view connection and the inter-view coupling, multi-view graph partitioning encounters more challenges than that in single-view graph. Although some methods have been developed for multi-view graph partitioning <ce:cross-refs id=""""crfs0003"""" refid=""""bib0014 bib0017 bib0018"""">[14,17,18][[ refid=''''bib0014 bib0017 bib0018'''' ]]</ce:cross-refs>, most of them are only based on the original topological structure without learning more discriminative metric space.</ce:para>""''"'		ANG	
uses_method_in	The proposed model	P. Jaccard, Etude comparative de la distribution florale dans une portion des Alpes et du Jura , None, Impr. Corbaz (1901)	http://dx.doi.org/10.1016/j.patcog.2017.06.012	model		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/br/bib0033	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/ctx/ctx0032		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-012/itrp/0050	'Before performing the update of the relation metric, some initializations are required to transform the original graph into the initial metric space based on the Jaccard similarity [33][[ refid=''bib0033'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0020"""" view=""""all"""">Before performing the update of the relation metric, some initializations are required to transform the original graph into the initial metric space based on the Jaccard similarity <ce:cross-ref id=""""crf0041"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref>. For the sake of simplicity and without loss of generality, we consider the original value of the inter-view coupling as 1. For the given multi-view graph, the intra-view connection can be either weighted or unweighted, where different initialization strategies are used.</ce:para>""''"'		ANG	
cites	Introduction	V. Vapnik, The Nature of Statistical Learning Theory , None, Springer (1995)	http://dx.doi.org/10.1016/j.patcog.2017.06.018	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-018/br/bib0042	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-018/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-018/ctx/ctx0020		39	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-018/itrp/0003	'In [42][[ refid=''bib0042'' ]], Vapnik further verified that local learning based approaches usually lead to lower empirical errors than global ones.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">Actually, as claimed by Bottou and Vapnik <ce:cross-ref id=""""crf0033"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>, it is usually not easy to find a unique function which holds good predictability in the entire input feature space. Especially, very often a global hash projection for each view cannot accurately model the complex nonlinear semantic structure of large-scale datasets, in which the discriminative features vary from one neighborhood to the other. In <ce:cross-ref id=""""crf0034"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>, Vapnik further verified that local learning based approaches usually lead to lower empirical errors than global ones. This is due to the fact that nearby samples are more likely generated by the same data model, while far away samples tend to differ in it. Similarly, the discrete hash projections of neighboring samples maybe the same or similar, while for samples lying in different neighboring spaces their hash projections tend to vary significantly. As a consequence, it is preferable to learn local multiview hamming distance metric via a set of local multimodal hash functions (with local hash projections), which would sufficiently boost the modeling ability.</ce:para>""''"'		ANG	
cites	Introduction	M.M. Bronstein, A.M. Bronstein, F. Michel, N. Paragios, Data fusion through cross-modality metric learning using similarity-sensitive hashing , IEEE Conference on Computer Vision and Pattern Recognition (2010)	http://dx.doi.org/10.1016/j.patcog.2017.06.018	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-018/br/bib0005	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-018/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-018/ctx/ctx0011		39	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-018/itrp/0072	'For instance, Bronstein et al. proposed a cross-modal similar sensitive hashing (CMSSH) [5][[ refid=''bib0005'' ]] algorithm based on a standard boosting framework.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0011"""" view=""""all"""">In the literature, a few attempts have been made for cross-modal hashing <ce:cross-refs id=""""crfs0005"""" refid=""""bib0005 bib0014 bib0017 bib0025 bib0026 bib0034 bib0041 bib0046 bib0047 bib0051 bib0061"""">[5,14,17,25,26,34,41,46,47,51,61][[ refid=''''bib0005 bib0014 bib0017 bib0025 bib0026 bib0034 bib0041 bib0046 bib0047 bib0051 bib0061'''' ]]</ce:cross-refs>, which tried to learn some multi-view distance metric in the hamming space. For instance, Bronstein et al. proposed a cross-modal similar sensitive hashing (CMSSH) <ce:cross-ref id=""""crf0018"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> algorithm based on a standard boosting framework. Both cross-view hashing (CVH) <ce:cross-ref id=""""crf0019"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> and inter-media hashing (IMH) <ce:cross-ref id=""""crf0020"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> essentially extend spectral hashing <ce:cross-ref id=""""crf0021"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref> to the multi-view setting. Co-regularized hashing (CRH) <ce:cross-ref id=""""crf0022"""" refid=""""bib0061"""">[61][[ refid=''''bib0061'''' ]]</ce:cross-ref> and heterogeneous translated hashing (HTH) <ce:cross-ref id=""""crf0023"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref> further deal with multimodal data based on a boosted co-regularization framework. Predictable dual-view hashing (PDH) <ce:cross-ref id=""""crf0024"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref> aims to learn discriminative hash functions via a max-margin formulation. Collective matrix factorization hashing(CMFH) <ce:cross-ref id=""""crf0025"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> and its supervised extension SMFH <ce:cross-ref id=""""crf0026"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> formulate the objectives as a collective matrix factorization problem. Semantic correlation maximization hashing (SCMH) <ce:cross-ref id=""""crf0027"""" refid=""""bib0059"""">[59][[ refid=''''bib0059'''' ]]</ce:cross-ref> and semantic-preserving hashing (SepH) <ce:cross-ref id=""""crf0028"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> integrate fully observed semantic labels or affinities of all data examples to further improve the performances. Another line is to take a probabilistic generative model, including the work semantic topic multimodal hashing (STMH) <ce:cross-ref id=""""crf0029"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref>, multimodal latent binary embedding (MLBE) <ce:cross-ref id=""""crf0030"""" refid=""""bib0062"""">[62][[ refid=''''bib0062'''' ]]</ce:cross-ref> and cross-modal similarity learning via pairs and preferences (CSLP) <ce:cross-ref id=""""crf0031"""" refid=""""bib0063"""">[63][[ refid=''''bib0063'''' ]]</ce:cross-ref>.</ce:para>""''"'		ANG	
extends	Introduction	L. Zhou, W. Li, P. Ogunbona, Learning a pose lexicon for semantic action recognition , Proceedings of the IEEE International Conference on Multimedia and Expo (ICME) (2016)	http://dx.doi.org/10.1016/j.patcog.2017.06.035	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-035/br/bib0020	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-035/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-035/ctx/ctx0011		59	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-035/itrp/0085	'This paper is an extension of our previous work [20][[ refid=''bib0020'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0009"""" view=""""all"""">This paper is an extension of our previous work <ce:cross-ref id=""""crf0021"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>. The following are the additional contributions of this work compared to the earlier version.<ce:list id=""""celist0001""""><ce:list-item id=""""celistitem0005""""><ce:label>(1)</ce:label><ce:para id=""""para0010"""" view=""""all"""">For computational simplicity, salient frames are extracted rather than using all frames of action video. Two new methods of extracting salient frames are proposed and evaluated. In <ce:cross-ref id=""""crf0022"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>, salient frames are assumed to be frames in which human body reaches maximum or minimum extensions. Here, this assumption is extended to include frames in which motion reaches maximum or minimum speed.</ce:para></ce:list-item><ce:list-item id=""""celistitem0006""""><ce:label>(2)</ce:label><ce:para id=""""para0011"""" view=""""all"""">Unlike a separate process adopted in <ce:cross-ref id=""""crf0023"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>, we jointly generate visual pose sequences and align them to semantic pose sequences.</ce:para></ce:list-item><ce:list-item id=""""celistitem0007""""><ce:label>(3)</ce:label><ce:para id=""""para0012"""" view=""""all"""">Temporal constraint is incorporated to the pose lexicon model for capturing temporal characteristic of actions.</ce:para></ce:list-item><ce:list-item id=""""celistitem0008""""><ce:label>(4)</ce:label><ce:para id=""""para0013"""" view=""""all"""">The proposed model is evaluated on three more datasets: WorkoutUOW-18, Combined-15 and Combined-17. Comparisons are included with skeleton-based recognition methods, methods based on semantic learning. In addition, cross-dataset and zero-shot recognition were performed to verify the transferring knowledge of pose lexicon.</ce:para></ce:list-item></ce:list></ce:para>""''"'	extends	ANG	
cites	Related work	J. Porway, K. Wang, B. Yao, S.C. Zhu, A hierarchical and contextual model for aerial image understanding , Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on, IEEE (2008)	http://dx.doi.org/10.1016/j.patcog.2017.06.036	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/br/bib0037	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/ctx/ctx0023		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/itrp/0003	'Porway et al. [37][[ refid=''bib0037'' ]] combined color and edge features with object-level features in a hierarchical contextual model for geospatial image annotation.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0018"""" view=""""all"""">Geographic image annotation is usually carried out in feature space. Effective feature representation is very important to construct high-performance image annotation systems. Recently considerable efforts have been made to develop various feature representations to annotate different types of objects in satellite and aerial images such as color, Haar, SIFT, LBP, or HOG. Porway et al. <ce:cross-ref id=""""crf0035"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref> combined color and edge features with object-level features in a hierarchical contextual model for geospatial image annotation. Markususe et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> applied AdaBoost classifications based on Haar, and Textons features for semantic labelling on the ISPRS benchmark. Cheriyadat et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> used SIFT feature and graph sparse coding algorithm to annotate geospatial objects in aerial images. Kembhavi et al. <ce:cross-ref id=""""crf0038"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref> used multi-scale HOG features computed to annotate vehicles in San Francisco images from Google Earth, and showed HOG to outperform SIFT in complex city environments. Grabner et al. <ce:cross-ref id=""""crf0039"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> used boosting methods based on LBP and HOG to detect vehicles.</ce:para>""''"'		ANG	
cites	Related work	A. Kembhavi, D. Harwood, L.S. Davis, Vehicle detection using partial least squares , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 33 (2011), pp.1250-1265	http://dx.doi.org/10.1016/j.patcog.2017.06.036	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/br/bib0040	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/ctx/ctx0026		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/itrp/0009	'Kembhavi et al. [40][[ refid=''bib0040'' ]] used multi-scale HOG features computed to annotate vehicles in San Francisco images from Google Earth, and showed HOG to outperform SIFT in complex city environments.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0018"""" view=""""all"""">Geographic image annotation is usually carried out in feature space. Effective feature representation is very important to construct high-performance image annotation systems. Recently considerable efforts have been made to develop various feature representations to annotate different types of objects in satellite and aerial images such as color, Haar, SIFT, LBP, or HOG. Porway et al. <ce:cross-ref id=""""crf0035"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref> combined color and edge features with object-level features in a hierarchical contextual model for geospatial image annotation. Markususe et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> applied AdaBoost classifications based on Haar, and Textons features for semantic labelling on the ISPRS benchmark. Cheriyadat et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> used SIFT feature and graph sparse coding algorithm to annotate geospatial objects in aerial images. Kembhavi et al. <ce:cross-ref id=""""crf0038"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref> used multi-scale HOG features computed to annotate vehicles in San Francisco images from Google Earth, and showed HOG to outperform SIFT in complex city environments. Grabner et al. <ce:cross-ref id=""""crf0039"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> used boosting methods based on LBP and HOG to detect vehicles.</ce:para>""''"'		ANG	
cites	Related work	H. Grabner, T.T. Nguyen, B. Gruber, H. Bischof, On-line boosting-based car detection from aerial images , ISPRS J. Photogramm. Remote Sens. , vol. 63 (2008), pp.382-396	http://dx.doi.org/10.1016/j.patcog.2017.06.036	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/ctx/ctx0027		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/itrp/0010	'Grabner et al. [23][[ refid=''bib0023'' ]] used boosting methods based on LBP and HOG to detect vehicles.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0018"""" view=""""all"""">Geographic image annotation is usually carried out in feature space. Effective feature representation is very important to construct high-performance image annotation systems. Recently considerable efforts have been made to develop various feature representations to annotate different types of objects in satellite and aerial images such as color, Haar, SIFT, LBP, or HOG. Porway et al. <ce:cross-ref id=""""crf0035"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref> combined color and edge features with object-level features in a hierarchical contextual model for geospatial image annotation. Markususe et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> applied AdaBoost classifications based on Haar, and Textons features for semantic labelling on the ISPRS benchmark. Cheriyadat et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> used SIFT feature and graph sparse coding algorithm to annotate geospatial objects in aerial images. Kembhavi et al. <ce:cross-ref id=""""crf0038"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref> used multi-scale HOG features computed to annotate vehicles in San Francisco images from Google Earth, and showed HOG to outperform SIFT in complex city environments. Grabner et al. <ce:cross-ref id=""""crf0039"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> used boosting methods based on LBP and HOG to detect vehicles.</ce:para>""''"'		ANG	
cites	Related work	I. Markus Gerke, Use of the stair vision library within the isprs 2d semantic labeling benchmark (vaihingen).	http://dx.doi.org/10.1016/j.patcog.2017.06.036	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/br/bib0038	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/ctx/ctx0024		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/itrp/0011	'Markususe et al. [38][[ refid=''bib0038'' ]] applied AdaBoost classifications based on Haar, and Textons features for semantic labelling on the ISPRS benchmark.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0018"""" view=""""all"""">Geographic image annotation is usually carried out in feature space. Effective feature representation is very important to construct high-performance image annotation systems. Recently considerable efforts have been made to develop various feature representations to annotate different types of objects in satellite and aerial images such as color, Haar, SIFT, LBP, or HOG. Porway et al. <ce:cross-ref id=""""crf0035"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref> combined color and edge features with object-level features in a hierarchical contextual model for geospatial image annotation. Markususe et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> applied AdaBoost classifications based on Haar, and Textons features for semantic labelling on the ISPRS benchmark. Cheriyadat et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> used SIFT feature and graph sparse coding algorithm to annotate geospatial objects in aerial images. Kembhavi et al. <ce:cross-ref id=""""crf0038"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref> used multi-scale HOG features computed to annotate vehicles in San Francisco images from Google Earth, and showed HOG to outperform SIFT in complex city environments. Grabner et al. <ce:cross-ref id=""""crf0039"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> used boosting methods based on LBP and HOG to detect vehicles.</ce:para>""''"'		ANG	
cites	Related work	Y. Chen, Z. Lin, X. Zhao, G. Wang, Y. Gu, Deep learning-based classification of hyperspectral data , Sel. Top. Appl. Earth Obs. Remote Sens. , vol. 7 (2014), pp.2094-2107	http://dx.doi.org/10.1016/j.patcog.2017.06.036	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/br/bib0041	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/ctx/ctx0028		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/itrp/0013	'Chen et al. [41][[ refid=''bib0041'' ]] relied on stacked autoencoders, trained to reconstruct PCA-compressed hyperspectral signals.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0019"""" view=""""all"""">When only a small training set is available, using engineered shallow features and traditional classifiers is a reasonable approach. But if there are large numbers of samples for each class, learning the deep features from the training samples is more advisable. Deep Learning is currently fashionable for automatically learning robust features from the raw data. Chen et al. <ce:cross-ref id=""""crf0040"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> relied on stacked autoencoders, trained to reconstruct PCA-compressed hyperspectral signals. The network is then fine-tuned by backpropagating errors from a softmax loss on top of the stacked autoencoders. Both Castelluccio et al. <ce:cross-ref id=""""crf0041"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref> and Marmanis et al. <ce:cross-ref id=""""crf0042"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref> fine-tuned pre-trained CNNs to annotate geospatial images. Paisitkriangkrai et al. <ce:cross-ref id=""""crf0043"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> proposed a system based on CNNs trained on the Vaihingen challenge data set to perform semantic labeling. CNN potential is clearly shown by combining the features extracted from the CNN with random forest classifiers, standard appearance descriptors, and conditional random fields, performing structured prediction on the probabilities given by the classifier. Sherrah et al. <ce:cross-ref id=""""crf0044"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> using a deep FCN with no downsampling to annotate high-resolution aerial imagery on a Vaihingen challenge data set, eliminating the need for either deconvolution, or interpolation.</ce:para>""''"'		ANG	
cites	Multi-modal feature based image representation and image annotation	X. Wang, T.X. Han, S. Yan, An HOG-LBP human detector with partial occlusion handling , Proc. 12th International Conference on Computer Vision (2009)	http://dx.doi.org/10.1016/j.patcog.2017.06.036			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/br/bib0049	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/ctx/ctx0037		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/itrp/0050	'LBP has been found improving the detection performance considerably when it is combined with some other local image gradient based descriptors [49][[ refid=''bib0049'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0025"""" view=""""all""""><ce:bold>LBP Feature</ce:bold>: The LBP operator <ce:cross-ref id=""""crf0050"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> has been widely used in various applications. It has been proven to be highly discriminative and has the advantages of invariance w.r.t. monotonic gray-level changes and computational efficiency. LBP has been found improving the detection performance considerably when it is combined with some other local image gradient based descriptors <ce:cross-ref id=""""crf0051"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref>. This motivated us to combine LBP with the SIFT descriptor to construct the low-level local feature around points of interests. Similar with <ce:cross-ref id=""""crf0052"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>, we compare each pixel of the input image to each of its 8 neighbors along a clockwise circle and generate a 8-digit binary number, and then use this 8-digit binary number (corresponding to a decimal number within 0–255) as the low-level feature of each pixel.</ce:para>""''"'		ANG	
cites	Related work	J. Sherrah, Fully convolutional networks for dense semantic labelling of high-resolution aerial imagery,	http://dx.doi.org/10.1016/j.patcog.2017.06.036	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/br/bib0045	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/ctx/ctx0031		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/itrp/0052	'Sherrah et al. [45][[ refid=''bib0045'' ]] using a deep FCN with no downsampling to annotate high-resolution aerial imagery on a Vaihingen challenge data set, eliminating the need for either deconvolution, or interpolation.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0019"""" view=""""all"""">When only a small training set is available, using engineered shallow features and traditional classifiers is a reasonable approach. But if there are large numbers of samples for each class, learning the deep features from the training samples is more advisable. Deep Learning is currently fashionable for automatically learning robust features from the raw data. Chen et al. <ce:cross-ref id=""""crf0040"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> relied on stacked autoencoders, trained to reconstruct PCA-compressed hyperspectral signals. The network is then fine-tuned by backpropagating errors from a softmax loss on top of the stacked autoencoders. Both Castelluccio et al. <ce:cross-ref id=""""crf0041"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref> and Marmanis et al. <ce:cross-ref id=""""crf0042"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref> fine-tuned pre-trained CNNs to annotate geospatial images. Paisitkriangkrai et al. <ce:cross-ref id=""""crf0043"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> proposed a system based on CNNs trained on the Vaihingen challenge data set to perform semantic labeling. CNN potential is clearly shown by combining the features extracted from the CNN with random forest classifiers, standard appearance descriptors, and conditional random fields, performing structured prediction on the probabilities given by the classifier. Sherrah et al. <ce:cross-ref id=""""crf0044"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> using a deep FCN with no downsampling to annotate high-resolution aerial imagery on a Vaihingen challenge data set, eliminating the need for either deconvolution, or interpolation.</ce:para>""''"'		ANG	
cites	Related work	S. Paisitkriangkrai, J. Sherrah, P. Janney, V.-D. Hengel, Effective semantic pixel labelling with convolutional networks and conditional random fields , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (2015)	http://dx.doi.org/10.1016/j.patcog.2017.06.036	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/br/bib0044	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/ctx/ctx0030		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/itrp/0053	'Paisitkriangkrai et al. [44][[ refid=''bib0044'' ]] proposed a system based on CNNs trained on the Vaihingen challenge data set to perform semantic labeling.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0019"""" view=""""all"""">When only a small training set is available, using engineered shallow features and traditional classifiers is a reasonable approach. But if there are large numbers of samples for each class, learning the deep features from the training samples is more advisable. Deep Learning is currently fashionable for automatically learning robust features from the raw data. Chen et al. <ce:cross-ref id=""""crf0040"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> relied on stacked autoencoders, trained to reconstruct PCA-compressed hyperspectral signals. The network is then fine-tuned by backpropagating errors from a softmax loss on top of the stacked autoencoders. Both Castelluccio et al. <ce:cross-ref id=""""crf0041"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref> and Marmanis et al. <ce:cross-ref id=""""crf0042"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref> fine-tuned pre-trained CNNs to annotate geospatial images. Paisitkriangkrai et al. <ce:cross-ref id=""""crf0043"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> proposed a system based on CNNs trained on the Vaihingen challenge data set to perform semantic labeling. CNN potential is clearly shown by combining the features extracted from the CNN with random forest classifiers, standard appearance descriptors, and conditional random fields, performing structured prediction on the probabilities given by the classifier. Sherrah et al. <ce:cross-ref id=""""crf0044"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> using a deep FCN with no downsampling to annotate high-resolution aerial imagery on a Vaihingen challenge data set, eliminating the need for either deconvolution, or interpolation.</ce:para>""''"'		ANG	
uses_method_in	Multi-modal feature based image representation and image annotation	R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, S. Susstrunk, Slic superpixels compared to state-of-the-art superpixel methods , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 34 (2012), pp.2274-2282	http://dx.doi.org/10.1016/j.patcog.2017.06.036			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/br/bib0046	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/ctx/ctx0033		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/itrp/0054	'As illustrated in Fig. 2, for an input image I, we first use the linear iterative clustering (SLIC) algorithm [46][[ refid=''bib0046'' ]] to segment I into a set of superpixels S. For each superpixel Si∈S, we utilize a shallow modality channel and a deep modality channel to respectively extract shallow features VS and deep features VD.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0022"""" view=""""all"""">As illustrated in <ce:cross-ref id=""""crf0046"""" refid=""""fig0002"""">Fig. 2</ce:cross-ref>, for an input image <ce:italic>I</ce:italic>, we first use the linear iterative clustering (SLIC) algorithm <ce:cross-ref id=""""crf0047"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref> to segment <ce:italic>I</ce:italic> into a set of superpixels <mml:math altimg=""""si2.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""script"""">S</mml:mi></mml:math>. For each superpixel <mml:math altimg=""""si3.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant=""""script"""">S</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math> we utilize a shallow modality channel and a deep modality channel to respectively extract shallow features <mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mi mathvariant=""""bold"""">V</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math> and deep features <mml:math altimg=""""si5.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mi mathvariant=""""bold"""">V</mml:mi><mml:mi>D</mml:mi></mml:msub></mml:math>. We then employ a RBM model to generate the final representation of <ce:italic>S<ce:inf loc=""""post"""">i</ce:inf></ce:italic> by fusing <mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mi mathvariant=""""bold"""">V</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math> and <mml:math altimg=""""si5.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mi mathvariant=""""bold"""">V</mml:mi><mml:mi>D</mml:mi></mml:msub></mml:math>. In our framework both shallow features and deep features are achieved by a feature evolution process which is formed by three sequential modules for low-level, mid-level, and high-level feature extraction, respectively. The shallow features <mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mi mathvariant=""""bold"""">V</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:math> encode the extrinsic visual properties of a geographic image, whereas the deep features <mml:math altimg=""""si5.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mi mathvariant=""""bold"""">V</mml:mi><mml:mi>D</mml:mi></mml:msub></mml:math> encode the intrinsic semantic information. The two mutually complementary sets of features are fused together as the final representation <mml:math altimg=""""si6.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mi mathvariant=""""bold"""">V</mml:mi><mml:mi>J</mml:mi></mml:msub></mml:math> of <ce:italic>S<ce:inf loc=""""post"""">i</ce:inf></ce:italic>. We next describe individual modules of the proposed framework.</ce:para>""''"'		ANG	
uses_method_in	Multi-modal feature based image representation and image annotation	I.T. Jolliffe, Principal component analysis , None (2005)	http://dx.doi.org/10.1016/j.patcog.2017.06.036			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/br/bib0050	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/ctx/ctx0039		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/itrp/0056	'In our implementation, after obtaining the 256 dimensional initial vector, we adopt the principal components analysis algorithm (PCA) [50][[ refid=''bib0050'' ]] to reduce the initial 256 dimensional-vector to a more compact 80-dimensional feature vector.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0028"""" view=""""all"""">In <ce:cross-ref id=""""crf0053"""" refid=""""eq0001"""">Eq. (1)</ce:cross-ref>, <mml:math altimg=""""si14.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mi mathvariant=""""bold"""">F</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>s</mml:mi></mml:msubsup></mml:math> is computed by the <ce:italic>L</ce:italic><ce:inf loc=""""post"""">2</ce:inf> normalization of the average of the SIFT feature vectors of all the <mml:math altimg=""""si15.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mi>N</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub></mml:math> pixels within <ce:italic>S<ce:inf loc=""""post"""">i</ce:inf></ce:italic>, having the following formulation:<ce:display><ce:formula id=""""eq0002""""><ce:label>(2)</ce:label><mml:math altimg=""""si16.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msubsup><mml:mi mathvariant=""""bold"""">F</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>s</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>∥</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:munder><mml:msubsup><mml:mi mathvariant=""""bold"""">f</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi></mml:msubsup><mml:mo>/</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display><mml:math altimg=""""si14.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mi mathvariant=""""bold"""">F</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>s</mml:mi></mml:msubsup></mml:math> has the same number of dimensions as the low-level SIFT vector <mml:math altimg=""""si8.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mi mathvariant=""""bold"""">f</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi></mml:msubsup></mml:math> of pixel <ce:italic>p</ce:italic> (128D). The second feature component <mml:math altimg=""""si17.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mi mathvariant=""""bold"""">F</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>l</mml:mi></mml:msubsup></mml:math> is obtained by computing the histogram, over the super-pixel <ce:italic>S<ce:inf loc=""""post"""">i</ce:inf></ce:italic>, of the frequency of each number (8-digit binary number) in the low-level LBP features occurring. The initial vector of <mml:math altimg=""""si17.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mi mathvariant=""""bold"""">F</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>l</mml:mi></mml:msubsup></mml:math> created from the statistic histogram has 256 dimensions since there are 256 types of 8-digit binary numbers in total in the LBP features. In our implementation, after obtaining the 256 dimensional initial vector, we adopt the principal components analysis algorithm (PCA) <ce:cross-ref id=""""crf0054"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref> to reduce the initial 256 dimensional-vector to a more compact 80-dimensional feature vector. The final vector <mml:math altimg=""""si17.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mi mathvariant=""""bold"""">F</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>l</mml:mi></mml:msubsup></mml:math> is the <ce:italic>L</ce:italic><ce:inf loc=""""post"""">2</ce:inf> normalization of the 80 dimensional feature vector. The last feature component <mml:math altimg=""""si13.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mi mathvariant=""""bold"""">F</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>c</mml:mi></mml:msubsup></mml:math> is related to the statistic histogram, in terms of color channel, of the low-level color features of all the pixels within <ce:italic>S<ce:inf loc=""""post"""">i</ce:inf></ce:italic>. Specifically, for each channel of all the color features, we quantize the normalized values into 25 bins. We generate a 75 bin histogram by concatenating the histograms from three channels. The <ce:italic>L</ce:italic><ce:inf loc=""""post"""">2</ce:inf> normalization of this 75-dimensional vector forms the vector <mml:math altimg=""""si13.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mi mathvariant=""""bold"""">F</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mi>c</mml:mi></mml:msubsup></mml:math>.</ce:para>""''"'		ANG	
cites	Multi-modal feature based image representation and image annotation	T. Ojala, M. Pietikainen, D. Harwood, A comparative study of texture measures with classification based on featured distributions , Pattern Recognit. , vol. 29 (1996), pp.51-59	http://dx.doi.org/10.1016/j.patcog.2017.06.036			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/br/bib0048	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/ctx/ctx0038		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/itrp/0057	'Similar with [48][[ refid=''bib0048'' ]], we compare each pixel of the input image to each of its 8 neighbors along a clockwise circle and generate a 8-digit binary number, and then use this 8-digit binary number (corresponding to a decimal number within 0–255) as the low-level feature of each pixel.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0025"""" view=""""all""""><ce:bold>LBP Feature</ce:bold>: The LBP operator <ce:cross-ref id=""""crf0050"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> has been widely used in various applications. It has been proven to be highly discriminative and has the advantages of invariance w.r.t. monotonic gray-level changes and computational efficiency. LBP has been found improving the detection performance considerably when it is combined with some other local image gradient based descriptors <ce:cross-ref id=""""crf0051"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref>. This motivated us to combine LBP with the SIFT descriptor to construct the low-level local feature around points of interests. Similar with <ce:cross-ref id=""""crf0052"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>, we compare each pixel of the input image to each of its 8 neighbors along a clockwise circle and generate a 8-digit binary number, and then use this 8-digit binary number (corresponding to a decimal number within 0–255) as the low-level feature of each pixel.</ce:para>""''"'		ANG	
cites	Related work	X. Huang, L. Zhang, Comparison of vector stacking, multi-svms fuzzy output, and multi-svm+s voting methods for multiscale vhr urban mapping , Geosci. Remote Sens. Lett. , vol. 7 (2010), pp.261-265	http://dx.doi.org/10.1016/j.patcog.2017.06.036	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/br/bib0029	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/ctx/ctx0019		54	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-06-036/itrp/0058	'VS is simple to execute and has a potential to enhance the discrimination between similar geospatial objects [29][[ refid=''bib0029'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">There are also some other frameworks which combine/fuse several features to improve the performance of geographic image annotation. For example, Zhang et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref> and Tuia et al. <ce:cross-ref id=""""crf0032"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> concatenated multiple features by employing a vector-stacking (VS) strategy to provide the data required by the classifier for geospatial objects. VS is simple to execute and has a potential to enhance the discrimination between similar geospatial objects <ce:cross-ref id=""""crf0033"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref>. It does not mine deep correlations of various features very well. To overcome this limitation, research in <ce:cross-refs id=""""crfs0007"""" refid=""""bib0030 bib0031"""">[30,31][[ refid=''''bib0030 bib0031'''' ]]</ce:cross-refs> proposed using a framework based on a combination of deep Boltzmann machines (DBM) and RBM to learn an image representation over multiple modality features. It first employs DBM to learn multi-modal features from unlabeled data and then uses RBM to find a common space representation for different input modalities. In addition to the DBM+RBM framework, joint spare coding <ce:cross-refs id=""""crfs0008"""" refid=""""bib0032 bib0033"""">[32,33][[ refid=''''bib0032 bib0033'''' ]]</ce:cross-refs> and auto-encoder <ce:cross-ref id=""""crf0034"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> are also popular tools for multi-modal feature fusion.</ce:para>""''"'		ANG	
cites	Characteristics of MIL problems	W.J. Li, D.Y. Yeung, MILD: multiple-instance learning via disambiguation , IEEE Trans. Knowl. Data Eng. , vol. 22 (2010), pp.76-89	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0060	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0124		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0005	'A similar argument was made for APR [60][[ refid=''bib0060'' ]] for which a negative bag mislabeled as positive, would lead to a high FPR.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0072"""" view=""""all"""">Some MIL algorithms, especially those working under the standard MIL assumption, rely heavily on the correctness of bag labels. For instance, it was shown in <ce:cross-ref id=""""crf0165"""" refid=""""bib0057"""">[57][[ refid=''''bib0057'''' ]]</ce:cross-ref> that DD is not tolerant to noise in the sense that a single negative instance in the neighborhood of the positive concept can hinder performance. A similar argument was made for APR <ce:cross-ref id=""""crf0166"""" refid=""""bib0060"""">[60][[ refid=''''bib0060'''' ]]</ce:cross-ref> for which a negative bag mislabeled as positive, would lead to a high FPR.</ce:para>""''"'	cites	AGA	
cites	Characteristics of MIL problems	Z.-H. Zhou, J.-M. Xu, On the relation between multi-instance learning and semi-supervised learning , Proceedings of International Conference on Machine Learning, ICML (2007)	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0067	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0122		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0007	'In that case, MIL can be viewed as a special kind of semi-supervised problem [67][[ refid=''bib0067'' ]] where the labeled portion of the data belongs to only one class and the instance are structured in sets with label constraints.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0071"""" view=""""all"""">Label ambiguity is inherent to weak supervision. In MIL, this ambiguity can take different forms depending on the assumption under which the problem is formulated. Under the standard MIL assumption, there is no ambiguity on instance labels in negative bags. In that case, MIL can be viewed as a special kind of semi-supervised problem <ce:cross-ref id=""""crf0164"""" refid=""""bib0067"""">[67][[ refid=''''bib0067'''' ]]</ce:cross-ref> where the labeled portion of the data belongs to only one class and the instance are structured in sets with label constraints. Under more relaxed MIL assumptions, there are supplementary sources of ambiguity such as noise on labels and different label spaces for instances and bags.</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	T.G. Dietterich, R.H. Lathrop, T. Lozano-Pérez, Solving the multiple instance problem with axis-parallel rectangles , Artif. Intell. , vol. 89 (1997), pp.31-71	http://dx.doi.org/10.1016/j.patcog.2017.10.009	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0003	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0002		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0016	'For example, in the drug activity prediction problem [3][[ refid=''bib0003'' ]], the objective is to predict if a molecule induces a given effect.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">Weakly supervised methods, such as MIL, can alleviate this burden since weak supervision is generally obtained more efficiently. For example, object detectors can be trained with images collected from the web using their associated tags as weak supervision instead of locally-annotated data sets <ce:cross-refs id=""""crfs0001"""" refid=""""bib0001 bib0002"""">[1,2][[ refid=''''bib0001 bib0002'''' ]]</ce:cross-refs>. Computer-aided diagnosis algorithms can be trained with medical images for which only patient diagnoses are available instead of costly local annotations provided by an expert. Moreover, there are several types of problems that can naturally be formulated as MIL problems. For example, in the drug activity prediction problem <ce:cross-ref id=""""crf0016"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>, the objective is to predict if a molecule induces a given effect. A molecule can take many conformations which can either produce, or not, a desired effect. Observing the effect of individual conformations is unfeasible. Therefore, molecules must be observed as a group of conformations, hence the use of the MIL formulation. Because of these attractive properties, MIL has been increasingly used in many other application fields over the last 20 years, such as image and video classification <ce:cross-refs id=""""crfs0002"""" refid=""""bib0004 bib0005 bib0006 bib0007 bib0008 bib0009"""">[4–9][[ refid=''''bib0004 bib0005 bib0006 bib0007 bib0008 bib0009'''' ]]</ce:cross-refs>, document classification <ce:cross-refs id=""""crfs0003"""" refid=""""bib0010 bib0011"""">[10,11][[ refid=''''bib0010 bib0011'''' ]]</ce:cross-refs> and sound classification <ce:cross-ref id=""""crf0017"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Characteristics of MIL problems	F. Kang, R. Jin, R. Sukthankar, Correlated label propagation with application to multi-label learning , Proceedings of Conference on Computer Vision and Pattern Recognition, CVPR (2006)	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0092	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0091		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0052	'Thus, observing nature segments might help to decide if the image contains a cocktail or a bear [92][[ refid=''bib0092'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0059"""" view=""""all""""><ce:italic>Instance co-occurrence:</ce:italic> Instances co-occur in bags when they share a semantic relation. This type of correlation happens when the subject of a picture is more likely to be seen in some environment than in another, or when some objects are often found together (e.g. knife and fork). For example, the bear of <ce:cross-ref id=""""crf0129"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref> is more likely to be found in nature than in a nightclub. Thus, observing nature segments might help to decide if the image contains a cocktail or a bear <ce:cross-ref id=""""crf0130"""" refid=""""bib0092"""">[92][[ refid=''''bib0092'''' ]]</ce:cross-ref>. In <ce:cross-ref id=""""crf0131"""" refid=""""bib0093"""">[93][[ refid=''''bib0093'''' ]]</ce:cross-ref>, it is shown that different birds are often heard in the same audio fragment, so a “negative” bird song could help to correctly classify the bird of interest. In these examples, co-occurrence represents an opportunity for better accuracy, however, in some cases it is a necessary condition for successful classification. Consider the example given by Foulds and Frank <ce:cross-ref id=""""crf0132"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> where one must classify sea, desert and beach images. Both desert and beach images can contain sand instances, while water instances can be found in sea and beach images. However, both instances must co-occur in a beach image. Most methods working under the collective assumption <ce:cross-ref id=""""crf0133"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> naturally leverage co-occurrence. Many of these methods, like BoW <ce:cross-refs id=""""crfs0026"""" refid=""""bib0070 bib0094"""">[70,94][[ refid=''''bib0070 bib0094'''' ]]</ce:cross-refs>, miFV <ce:cross-ref id=""""crf0134"""" refid=""""bib0072"""">[72][[ refid=''''bib0072'''' ]]</ce:cross-ref>, FAMER <ce:cross-ref id=""""crf0135"""" refid=""""bib0095"""">[95][[ refid=''''bib0095'''' ]]</ce:cross-ref> or PPMM <ce:cross-ref id=""""crf0136"""" refid=""""bib0096"""">[96][[ refid=''''bib0096'''' ]]</ce:cross-ref> represent bags as instance distributions which indirectly account for co-occurrence. This has also been directly modeled in a tensor model <ce:cross-ref id=""""crf0137"""" refid=""""bib0097"""">[97][[ refid=''''bib0097'''' ]]</ce:cross-ref> and in a multi-label framework <ce:cross-ref id=""""crf0138"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Characteristics of MIL problems	D. Zhang, Y. Liu, L. Si, J. Zhang, R.D. Lawrence, Multiple instance learning on structured data , Proceedings of Conference on Neural Information Processing Systems, NIPS (2011)	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0077	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0099		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0066	'Alternatively, in web mining tasks [77][[ refid=''bib0077'' ]] where websites are bags and pages linked by the websites are instances, there exists a semantic relation between two bags representing websites linked together.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0061"""" view=""""all""""><ce:italic>Instance and bag structure:</ce:italic> In some problems, an underlying structure exists between instances of a same bag or even between bags <ce:cross-ref id=""""crf0139"""" refid=""""bib0077"""">[77][[ refid=''''bib0077'''' ]]</ce:cross-ref>. Structure is more complex than simple co-occurrence in the sense that instances follow a certain order, or are related in a meaningful way. Capturing this structure may lead to better classification performance <ce:cross-refs id=""""crfs0027"""" refid=""""bib0010 bib0080 bib0098"""">[10,80,98][[ refid=''''bib0010 bib0080 bib0098'''' ]]</ce:cross-refs>. The structure may be spatial, temporal, relational or even causal. For example, when a bag represents a video sequence, all frames or patches are temporally and spatially ordered. For example, it is difficult to differentiate between a person taking or leaving a package without taking this temporal order into account. Alternatively, in web mining tasks <ce:cross-ref id=""""crf0140"""" refid=""""bib0077"""">[77][[ refid=''''bib0077'''' ]]</ce:cross-ref> where websites are bags and pages linked by the websites are instances, there exists a semantic relation between two bags representing websites linked together.</ce:para>""''"'	cites	AGA	
cites	Studies on MIL	G. Vanwinckelen, V. Tragante do O, D. Fierens, Instance-level accuracy versus bag-level accuracy in multi-instance learning , Data Min. Knowl. Discov. , vol. 30 (2016), pp.313-341	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0020	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0035		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0070	'Recently, the differences between these two scenarios were rigorously investigated [20][[ refid=''bib0020'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0030"""" view=""""all"""">Some papers compare MIL to other learning settings to better understand when to use MIL. Ray and Craven <ce:cross-ref id=""""crf0049"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> compared the performance of MIL methods against supervised methods on MIL problems. They found that in many cases, supervised methods yield the most competitive results. They also noted that, while some methods systematically dominate others, the performance of the algorithms was application-dependent. In <ce:cross-ref id=""""crf0050"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref>, the relationship between MIL and other settings, such as group-based classification and set classification, is explored. They state that MIL is applicable in two scenarios: the classification of bags and the classification of instances. Recently, the differences between these two scenarios were rigorously investigated <ce:cross-ref id=""""crf0051"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>. It was shown analytically and experimentally that the correlation between classification performance at bag and instance level is relatively weak. Experiments showed that depending on the data set, the best algorithm for bag classification provides average, or even the worst performance for instance classification. They too observed that different MIL algorithms perform differently given the nature of the data.</ce:para>""''"'	cites	AGA	
cites	Studies on MIL	E. Alpaydin, V. Cheplygina, M. Loog, D.M. Tax, Single- vs. multiple-instance classification , Pattern Recognit. , vol. 48 (2015), pp.2831-2838	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0021	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0037		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0072	'Alpaydin et al. [21][[ refid=''bib0021'' ]] compared instance-space and bag-space classifiers on synthetic and real-world data.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0031"""" view=""""all"""">The classification of instances is a task in itself, but can also be an intermediate step toward bag classification for instance-space methods <ce:cross-ref id=""""crf0052"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>. Alpaydin et al. <ce:cross-ref id=""""crf0053"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> compared instance-space and bag-space classifiers on synthetic and real-world data. They concluded that for datasets with few bags, it is preferable to use an instance-space classifier. They also state, as in <ce:cross-ref id=""""crf0054"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>, that if the instances provide partial information about bag labels, it is preferable to use a bag-space representation. In <ce:cross-ref id=""""crf0055"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>, Cheplygina et al. explored the stability of the instance labels assigned by MIL algorithms. They found that algorithms yielding best bag classification performance were not the algorithms providing the most consistent instance labels. Carbonneau et al. <ce:cross-ref id=""""crf0056"""" refid=""""bib0053"""">[53][[ refid=''''bib0053'''' ]]</ce:cross-ref> studied the ability to identify witnesses of several MIL methods. They found that depending on the nature of the data, some algorithms perform well while others would have difficulty learning.</ce:para>""''"'	uses_data_from	AGA	
cites	Studies on MIL	V. Cheplygina, D.M.J. Tax, Characterizing multiple instance datasets , Proceedings of International Workshop on Similarity-Based Pattern Recognition, SIMBAD (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0032		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0077	'In [23][[ refid=''bib0023'' ]] the similarities between MIL benchmark data sets were studied.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0029"""" view=""""all"""">Some papers study specific topics of MIL. For instance, Foulds and Frank <ce:cross-ref id=""""crf0046"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> reviewed the assumptions made by MIL algorithms. They stated that these assumptions influence how algorithms perform on different types of data sets. They found that algorithms working under the collective assumption also perform well with data sets corresponding to the standard MIL assumption. Sabato and Tishby <ce:cross-ref id=""""crf0047"""" refid=""""bib0052"""">[52][[ refid=''''bib0052'''' ]]</ce:cross-ref> analyzed the sample complexity in MIL, and found that the statistical performance of MIL is only mildly dependent on the number of instances per bag. In <ce:cross-ref id=""""crf0048"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> the similarities between MIL benchmark data sets were studied. The data sets were represented in two ways: by meta-features describing numbers of bags, instances and so forth, and by features based on performances of MIL algorithms. Both representations were embedded in a 2-D space and found to be dissimilar to each other. In other words, data sets often considered similar due to the application or size of data did not behave similarly, which suggest that some unobserved properties influence MIL algorithms performance.</ce:para>""''"'	uses_data_from	AGA	
cites	Characteristics of MIL problems	J. Amores, Vocabulary-based approaches for multiple-instance data: a comparative study , Proceedings of International Conference on Pattern Recognition, ICPR (2010)	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0070	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0131		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0103	'Vocabulary-based methods [70][[ refid=''bib0070'' ]] are particularly well adapted for this situation.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0077"""" view=""""all"""">When instances cannot be assigned to a specific class, methods operating under the standard MIL assumption, which must identify positive instances, are inadequate. Therefore, in those cases, using the collective assumption is necessary. Vocabulary-based methods <ce:cross-ref id=""""crf0175"""" refid=""""bib0070"""">[70][[ refid=''''bib0070'''' ]]</ce:cross-ref> are particularly well adapted for this situation. They associate instances to words (e.g. prototypes or clusters) discovered from the instance distribution. Bags are represented by distributions over these words. Similarly, methods using embedding based on distance from selected prototype instances, such as MILES <ce:cross-ref id=""""crf0176"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref> and MILIS <ce:cross-ref id=""""crf0177"""" refid=""""bib0118"""">[118][[ refid=''''bib0118'''' ]]</ce:cross-ref>, can also deal with this type of problem.</ce:para>""''"'	cites	AGA	
cites	Discussion	L. Yuan, J. Liu, X. Tang, Combining example selection with instance selection to speed up multiple-instance learning , Neurocomputing , vol. 129 (2014), pp.504-515	http://dx.doi.org/10.1016/j.patcog.2017.10.009	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0186	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0233		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0107	'For example, [186][[ refid=''bib0186'' ]] uses instance selection algorithms inspired by the immune system to reduce the size of the data set before using MIL algorithms.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0160"""" view=""""all"""">While embedding methods decrease the computational cost, they generally do not allow for instance classification. In that case some methods have been proposed to reduce the size of the data set using instance selection. For example, <ce:cross-ref id=""""crf0317"""" refid=""""bib0186"""">[186][[ refid=''''bib0186'''' ]]</ce:cross-ref> uses instance selection algorithms inspired by the immune system to reduce the size of the data set before using MIL algorithms. MILIS <ce:cross-ref id=""""crf0318"""" refid=""""bib0118"""">[118][[ refid=''''bib0118'''' ]]</ce:cross-ref> has been proposed to reduce the complexity of MILES by selecting only one instance per bag instead of using a 1-norm SVM to perform the selection of prototypes.</ce:para>""''"'	uses_data_from	AGA	
cites	Characteristics of MIL problems	J. Wu, X. Zhu, C. Zhang, P.S. Yu, Bag constrained structure pattern mining for multi-graph classification , IEEE Trans. Knowl. Data Eng. , vol. 26 (2014), pp.2382-2396	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0078	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0080		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0124	'A similar approach is used in [78][[ refid=''bib0078'' ]] except bits are associated a pool of subgraphs patterns mined from the data set.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0055"""" view=""""all"""">Very few methods were proposed explicitly to address this problem. To deal with similar instances, miGraph <ce:cross-ref id=""""crf0115"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref> builds a graph per bag and groups similar instances together to adjust their relative importance based on the group size. CCE <ce:cross-ref id=""""crf0116"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref> performs a clustering of the instance space. Bags are represented by a binary vector in which each bit corresponds to a cluster. A bit is set to 1 if at least one instance in the bag has been assigned to the corresponding cluster. A similar approach is used in <ce:cross-ref id=""""crf0117"""" refid=""""bib0078"""">[78][[ refid=''''bib0078'''' ]]</ce:cross-ref> except bits are associated a pool of subgraphs patterns mined from the data set. Because features are binary, many instances can be assigned to the same cluster and the representation remains unaffected, which provides robustness to intra-bag similarity.</ce:para>""''"'	uses_data_from	AGA	
cites	Multiple instance learning	M.-L. Zhang, Z.-H. Zhou, Multi-instance clustering with applications to multi-instance prediction , Appl. Intell. , vol. 31 (2009), pp.47-68	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0048	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0023		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0142	'In some cases, clustering is performed in bag space using standard algorithms and set-based distance measures (e.g. k-Medoids and the Hausdorff distance [48][[ refid=''bib0048'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0025"""" view=""""all""""><ce:italic>Clustering:</ce:italic> This task consists in finding clusters or a structure among a set of unlabeled bags. The literature on the subject is limited. In some cases, clustering is performed in bag space using standard algorithms and set-based distance measures (e.g. <ce:italic>k</ce:italic>-Medoids and the Hausdorff distance <ce:cross-ref id=""""crf0038"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>). Alternatively, clustering can be performed at the instance-level. For example, in <ce:cross-ref id=""""crf0039"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref>, the algorithm identifies the most relevant instance of each bag, and performs maximum margin clustering on these instances.</ce:para>""''"'	cites	AGA	
cites_as_review	Studies on MIL	Z.-h. Zhou, Multi-Instance Learning: A Survey , Technical Report (2004)	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0013	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0025		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0150	'The first survey on MIL is a technical report written in 2004 [13][[ refid=''bib0013'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0028"""" view=""""all"""">The first survey on MIL is a technical report written in 2004 <ce:cross-ref id=""""crf0040"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>. It describes several MIL algorithms, some applications and discusses learnability under the MIL framework. In 2008, Babenko published a report <ce:cross-ref id=""""crf0041"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> containing an updated survey of the main families of MIL methods, and distinguished two types of ambiguity in MIL problems. The first type is polymorphism ambiguity, in which each instance is a distinct entity or a distinct version of an entity (e.g. conformations of a molecule). The second is part-whole ambiguity in which all instances are parts of the same object (e.g. segments of an image). In a more recent survey <ce:cross-ref id=""""crf0042"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>, Amores proposed a taxonomy in which MIL methods are divided in three broad categories following the representation space. Methods operating in the instance-space are grouped together, and the methods operating in bag-space are divided in two categories based on whether a bag embedding is performed or not. Several experiments were performed to compare bag classification accuracy in four application fields. Bag-space methods performed better in terms of bag classification accuracy, however, performance depends on the data and the distance function or the embedding method. Recently, a book on MIL has been published <ce:cross-ref id=""""crf0043"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref>. It discusses most of the tasks of <ce:cross-ref id=""""crf0044"""" refid=""""sec0004"""">Section 2.2</ce:cross-ref> along with associated methods, as well as data reduction and imbalanced data. Finally, Quellec et al. <ce:cross-ref id=""""crf0045"""" refid=""""bib0051"""">[51][[ refid=''''bib0051'''' ]]</ce:cross-ref> wrote a survey on MIL for medical imaging applications, for which MIL is a particularly attractive solution. They review how problems are formulated in this field of application and analyze results from various experiments. They conclude that, while being more convenient, MIL outperforms single instance learning because it can pick up on subtle global visual cues that cannot be properly segmented and used as single instances to train a classifier.</ce:para>""''"'	cites_as_review	AGA	
cites_as_review	Studies on MIL	G. Quellec, G. Cazuguel, B. Cochener, M. Lamard, Multiple-instance learning for medical image and video analysis , IEEE Rev. Biomed. Eng. , vol. PP (2017), pp.None	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0051	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0029		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0155	'Finally, Quellec et al. [51][[ refid=''bib0051'' ]] wrote a survey on MIL for medical imaging applications, for which MIL is a particularly attractive solution.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0028"""" view=""""all"""">The first survey on MIL is a technical report written in 2004 <ce:cross-ref id=""""crf0040"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>. It describes several MIL algorithms, some applications and discusses learnability under the MIL framework. In 2008, Babenko published a report <ce:cross-ref id=""""crf0041"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> containing an updated survey of the main families of MIL methods, and distinguished two types of ambiguity in MIL problems. The first type is polymorphism ambiguity, in which each instance is a distinct entity or a distinct version of an entity (e.g. conformations of a molecule). The second is part-whole ambiguity in which all instances are parts of the same object (e.g. segments of an image). In a more recent survey <ce:cross-ref id=""""crf0042"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>, Amores proposed a taxonomy in which MIL methods are divided in three broad categories following the representation space. Methods operating in the instance-space are grouped together, and the methods operating in bag-space are divided in two categories based on whether a bag embedding is performed or not. Several experiments were performed to compare bag classification accuracy in four application fields. Bag-space methods performed better in terms of bag classification accuracy, however, performance depends on the data and the distance function or the embedding method. Recently, a book on MIL has been published <ce:cross-ref id=""""crf0043"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref>. It discusses most of the tasks of <ce:cross-ref id=""""crf0044"""" refid=""""sec0004"""">Section 2.2</ce:cross-ref> along with associated methods, as well as data reduction and imbalanced data. Finally, Quellec et al. <ce:cross-ref id=""""crf0045"""" refid=""""bib0051"""">[51][[ refid=''''bib0051'''' ]]</ce:cross-ref> wrote a survey on MIL for medical imaging applications, for which MIL is a particularly attractive solution. They review how problems are formulated in this field of application and analyze results from various experiments. They conclude that, while being more convenient, MIL outperforms single instance learning because it can pick up on subtle global visual cues that cannot be properly segmented and used as single instances to train a classifier.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments	J. Amores, Multiple instance classification: review, taxonomy and comparative study , Artif. Intell. , vol. 201 (2013), pp.81-105	http://dx.doi.org/10.1016/j.patcog.2017.10.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0015	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0185		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0156	'The methods are grouped based on the representation space following a taxonomy similar to [15][[ refid=''bib0015'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0110"""" view=""""all"""">Next we describe the reference methods used in the experiments. The methods are grouped based on the representation space following a taxonomy similar to <ce:cross-ref id=""""crf0234"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>. Instance-space methods classify each instance individually and combine the instance labels to assign a bag to a class. Bag-space methods do not classify, explicitly at least, instances individually. Bag-space methods employ one of two strategies: either compare distance between bags using an appropriate distance measure for sets or distributions, or encode the content of the bags to obtain a summarizing representation used in a supervised learning setting.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experiments	D. Tax, V. Cheplygina, MIL, A Matlab Toolbox for Multiple Instance Learning, 2015, Version 1.1.0.	http://dx.doi.org/10.1016/j.patcog.2017.10.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0164	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0184		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0157	'All experiments have been conducted using Matlab and some implementations from the MIL toolbox [164][[ refid=''bib0164'' ]] and the LAMDA website.11http://lamda.nju.edu.cn/.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0109"""" view=""""all"""">In this section, 16 reference methods are compared using data sets that allow to shed light on some of the problem characteristics discussed in <ce:cross-ref id=""""crf0231"""" refid=""""sec0006"""">Section 4</ce:cross-ref>. These experiments are conducted to show how problem characteristics influence the behavior of MIL algorithms, and demonstrate that these characteristics cannot be neglected when designing or comparing MIL algorithms. Four characteristics were selected, each from a different category, to represent the spectrum of characteristics. Algorithms are compared on the instance classification task, under different WR, with an unobservable negative distribution and with different degrees of label noise. These characteristics were chosen because their effect can be isolated and easily parametrized. The reference methods used in the experiments were chosen because they represent most families of approaches and include most widely used reference methods. All experiments have been conducted using Matlab and some implementations from the MIL toolbox <ce:cross-ref id=""""crf0232"""" refid=""""bib0164"""">[164][[ refid=''''bib0164'''' ]]</ce:cross-ref> and the LAMDA website.<ce:cross-ref id=""""crf0233"""" refid=""""fn0001""""><ce:sup loc=""""post"""">1</ce:sup></ce:cross-ref><ce:footnote id=""""fn0001""""><ce:label>1</ce:label><ce:note-para id=""""cenotep0001"""" view=""""all""""><ce:inter-ref id=""""interref0002"""" xlink:href=""""http://lamda.nju.edu.cn/"""" xlink:type=""""simple"""">http://lamda.nju.edu.cn/</ce:inter-ref>.</ce:note-para></ce:footnote></ce:para>""''"'	uses_method_in	AGA	
cites	Experiments	S. Andrews, I. Tsochantaridis, T. Hofmann, Support vector machines for multiple-instance learning , Proceedings of Conference on Neural Information Processing Systems, NIPS (2002)	http://dx.doi.org/10.1016/j.patcog.2017.10.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0006	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0187		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0158	'MI-SVM and mi-SVM[6][[ refid=''bib0006'' ]]: These algorithms are transductive SVMs.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0112"""" view=""""all""""><ce:italic>MI-SVM and mi-SVM</ce:italic><ce:cross-ref id=""""crf0235"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>: These algorithms are transductive SVMs. Instances inherit their bag label. The SVM is trained and classifies each instance in the data set. It is then retrained using the new label assignments. This procedure is repeated until the labels remain stable. The resulting classifier is used to classify test instances. MI-SVM uses only the most positive instance of each bag for training, while mi-SVM uses all instances.</ce:para>""''"'	uses_method_in	AGA	
cites	Characteristics of MIL problems	Z. Li, G.-H. Geng, J. Feng, J.-y. Peng, C. Wen, J.-l. Liang, Multiple instance learning based on positive instance selection and bag structure construction , Pattern Recognit. Lett. , vol. 40 (2014), pp.19-26	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0107	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0109		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0176	'CKMIL [107][[ refid=''bib0107'' ]] locates the most positive instance in each bag based on its proximity to a single positive cluster center.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0065"""" view=""""all"""">Some MIL algorithms work under the assumption that the positive instances are located in a single cluster or region in feature space. This is the case for several early methods like APR <ce:cross-ref id=""""crf0146"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>, which searches for a hyper-rectangle that maximizes the inclusion of instances from positive bags while excluding instances from negative bags. Diverse Density (DD) <ce:cross-ref id=""""crf0147"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> methods follow a similar idea. These methods locate the point in feature space closest to instances in positive bags, but far from instances in negative bags. This point is considered to be the positive concept. Some more recent methods also follow the single cluster assumption. CKMIL <ce:cross-ref id=""""crf0148"""" refid=""""bib0107"""">[107][[ refid=''''bib0107'''' ]]</ce:cross-ref> locates the most positive instance in each bag based on its proximity to a single positive cluster center. In <ce:cross-ref id=""""crf0149"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>, the classifier is a sphere encompassing at least one positive instance from each positive bag while excluding instances from negative bags. The method in <ce:cross-ref id=""""crf0150"""" refid=""""bib0104"""">[104][[ refid=''''bib0104'''' ]]</ce:cross-ref> employs a similar strategy.</ce:para>""''"'	cites	AGA	
cites	Discussion	Z. Fu, A. Robles-Kelly, Fast multiple instance learning via L1,2 logistic regression , Proceedings of International Conference on Pattern Recognition, ICPR (2008)	http://dx.doi.org/10.1016/j.patcog.2017.10.009	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0184	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0226		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0207	'Alternatively, it has been proposed to use gradient descent with logistic regressions in a MILES like algorithm [184][[ refid=''bib0184'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0158"""" view=""""all"""">Many algorithms in literature do not scale well to big data sets. For example, the computational complexity of an SVM is between <mml:math altimg=""""si32.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi mathvariant=""""script"""">O</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:math> and <mml:math altimg=""""si33.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi mathvariant=""""script"""">O</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mn>3</mml:mn></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:math> when using traditional QP and LP solvers <ce:cross-ref id=""""crf0306"""" refid=""""bib0180"""">[180][[ refid=''''bib0180'''' ]]</ce:cross-ref>, where <ce:italic>n</ce:italic> is the number of instances. Thus, many methods using SVM and SVM-like algorithms <ce:cross-refs id=""""crfs0061"""" refid=""""bib0004 bib0006 bib0027 bib0179 bib0181 bib0182"""">[4,6,27,179,181,182][[ refid=''''bib0004 bib0006 bib0027 bib0179 bib0181 bib0182'''' ]]</ce:cross-refs> rapidly become impractical as the number of instances increases <ce:cross-ref id=""""crf0307"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref>. To address this problem, in <ce:cross-ref id=""""crf0308"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref>, a bundle algorithm <ce:cross-ref id=""""crf0309"""" refid=""""bib0183"""">[183][[ refid=''''bib0183'''' ]]</ce:cross-ref> is used to solve the SVM optimization problem in linear time (<mml:math altimg=""""si34.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi mathvariant=""""script"""">O</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>). Alternatively, it has been proposed to use gradient descent with logistic regressions in a MILES like algorithm <ce:cross-ref id=""""crf0310"""" refid=""""bib0184"""">[184][[ refid=''''bib0184'''' ]]</ce:cross-ref>. Gradient descent algorithms is more appropriate for large data sets than QP.</ce:para>""''"'	cites	AGA	
cites	Discussion	J. Amores, Multiple instance classification: review, taxonomy and comparative study , Artif. Intell. , vol. 201 (2013), pp.81-105	http://dx.doi.org/10.1016/j.patcog.2017.10.009	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0015	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0227		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0208	'Methods computing distance between bags also become impractical as the data set size increases [15][[ refid=''bib0015'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0159"""" view=""""all"""">Methods computing distance between bags also become impractical as the data set size increases <ce:cross-ref id=""""crf0311"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>. Obtaining the distance between two bags often means computing the distance between each pair of instances, which implies a classification cost of <mml:math altimg=""""si35.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi mathvariant=""""script"""">O</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>d</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math> where <ce:italic>b</ce:italic> is the number of bags, <ce:italic>m</ce:italic> is the average number of instances per bag and <ce:italic>d</ce:italic> the dimensionality of the data. This becomes to <mml:math altimg=""""si36.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi mathvariant=""""script"""">O</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msup><mml:mi>m</mml:mi><mml:mn>3</mml:mn></mml:msup><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math> when using the earth mover’s distance (EMD) to compare the distributions in the two bags. Moreover, these methods must store the entire data set in memory which can also be problematic. To avoid these costs when comparing bags, it is preferable to use bag embedding techniques <ce:cross-ref id=""""crf0312"""" refid=""""bib0072"""">[72][[ refid=''''bib0072'''' ]]</ce:cross-ref>. Representing bags as a single feature vector greatly reduces the number of training examples fed to the classifier, when compared to instance based methods. However, not all embedding methods possess the same scalability. For instance, methods representing bags as distance to instance prototypes (e.g. MILES <ce:cross-ref id=""""crf0313"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>) or other bags <ce:cross-ref id=""""crf0314"""" refid=""""bib0093"""">[93][[ refid=''''bib0093'''' ]]</ce:cross-ref> can produce very high dimensional representation with large data sets <ce:cross-ref id=""""crf0315"""" refid=""""bib0118"""">[118][[ refid=''''bib0118'''' ]]</ce:cross-ref>. This can be avoided altogether by representing bags using a vocabulary-like encoding as proposed in <ce:cross-refs id=""""crfs0062"""" refid=""""bib0070 bib0072"""">[70,72][[ refid=''''bib0070 bib0072'''' ]]</ce:cross-refs>. In <ce:cross-refs id=""""crfs0063"""" refid=""""bib0095 bib0185"""">[95,185][[ refid=''''bib0095 bib0185'''' ]]</ce:cross-refs>, hash functions have been used to accelerate the bag encoding process. Alternatively, bags can be represented by statistics on the instances as done in the Statistic Kernel (STK) <ce:cross-ref id=""""crf0316"""" refid=""""bib0073"""">[73][[ refid=''''bib0073'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA	
cites	Discussion	F. Briggs, X.Z. Fern, R. Raich, Rank-loss support instance machines for MIML instance annotation , Proceedings of Conference on Knowledge Discovery and Data Mining, KDD (2012)	http://dx.doi.org/10.1016/j.patcog.2017.10.009	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0012	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0216		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0209	'From these few data sets, to our knowledge, there is only one (Birds [12][[ refid=''bib0012'' ]]) that supplies instance labels and is non-artificial.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0150"""" view=""""all"""">In application fields other than computer vision, there are relatively few publicly available real-world data sets. From these few data sets, to our knowledge, there is only one (Birds <ce:cross-ref id=""""crf0291"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>) that supplies instance labels and is non-artificial. This is understandable since MIL is often used to avoid the labor-intensive instance labeling process. Nevertheless, real-world MIL data needs to be created to measure the instance labeling capability of different MIL methods, as it is an increasingly important task. Also, to our knowledge, there is no publicly available benchmark data set for MIL regression, which would surely stimulate research on this subject.</ce:para>""''"'	uses_data_from	AGA	
cites	Characteristics of MIL problems	Z.-H. Zhou, X.-B. Xue, Y. Jiang, Locating regions of interest in CBIR with multi-instance learning techniques , Proceedings of Australian Joint Conference on Artificial Intelligence, AUS-AI (2005)	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0066	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0057		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0213	'This is the rationale behind Citation-kNN-ROI [66][[ refid=''bib0066'' ]] which, however, does not perform well in practice (see Section 6.4).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0048"""" view=""""all"""">As explained above, using bag classification accuracy as a surrogate optimization objective is suboptimal. This is why it has been proposed to consider negative and positive bags separately in the classifier loss function <ce:cross-ref id=""""crf0082"""" refid=""""bib0064"""">[64][[ refid=''''bib0064'''' ]]</ce:cross-ref>. The accuracy on positive bags is taken at bag level, but for negative bags, all instances are treated individually. This optimization criterion was proposed to adjust the decision threshold of bag classifiers for instance classification and improve their accuracy in <ce:cross-ref id=""""crf0083"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref>. In <ce:cross-ref id=""""crf0084"""" refid=""""bib0065"""">[65][[ refid=''''bib0065'''' ]]</ce:cross-ref>, a different weight is assigned to FP and FN during the optimization of an SVM. Virtually any bag-level classifier can classify instances if they are seen as singleton bags. This is the rationale behind Citation-kNN-ROI <ce:cross-ref id=""""crf0085"""" refid=""""bib0066"""">[66][[ refid=''''bib0066'''' ]]</ce:cross-ref> which, however, does not perform well in practice (see <ce:cross-ref id=""""crf0086"""" refid=""""sec0029"""">Section 6.4</ce:cross-ref>). MILES <ce:cross-ref id=""""crf0087"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref> is a bag classification method based on prototype distance embedding and an SVM that can be used for instance classification. The method computes the contribution of each instance to the bag label assignation based on its distance to selected prototypes. Instances in positive bags for which the contribution is above a given threshold are identified as witnesses.</ce:para>""''"'	cites	AGA	
cites	Characteristics of MIL problems	J. Amores, Vocabulary-based approaches for multiple-instance data: a comparative study , Proceedings of International Conference on Pattern Recognition, ICPR (2010)	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0070	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0116		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0230	'Also, methods modeling instance distributions in bags such as vocabulary-based [70][[ refid=''bib0070'' ]] methods naturally deal with data sets containing multiple concepts/modes.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0067"""" view=""""all"""">Many MIL methods can learn multimodal positive concepts, however, only few representative approaches will be mentioned due to space constraints. First, non-parametric methods based on distance between bags like Citation-kNN <ce:cross-ref id=""""crf0152"""" refid=""""bib0108"""">[108][[ refid=''''bib0108'''' ]]</ce:cross-ref> and MInD <ce:cross-ref id=""""crf0153"""" refid=""""bib0093"""">[93][[ refid=''''bib0093'''' ]]</ce:cross-ref> naturally deal with all shapes of distributions. Simple non-parametric methods often lead to competitive results in MIL problems <ce:cross-ref id=""""crf0154"""" refid=""""bib0057"""">[57][[ refid=''''bib0057'''' ]]</ce:cross-ref>. Methods using distances to a set of prototypes as bag representation, like DD-SVM <ce:cross-ref id=""""crf0155"""" refid=""""bib0109"""">[109][[ refid=''''bib0109'''' ]]</ce:cross-ref> and MILES <ce:cross-ref id=""""crf0156"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>, can model many positive clusters, because each different cluster can be represented by a different prototype. Instance-space SVM-based methods like mi-SVM <ce:cross-ref id=""""crf0157"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref> can deal with disjoint regions of positive instances using a kernel. Also, methods modeling instance distributions in bags such as vocabulary-based <ce:cross-ref id=""""crf0158"""" refid=""""bib0070"""">[70][[ refid=''''bib0070'''' ]]</ce:cross-ref> methods naturally deal with data sets containing multiple concepts/modes. The mixture-model in <ce:cross-ref id=""""crf0159"""" refid=""""bib0110"""">[110][[ refid=''''bib0110'''' ]]</ce:cross-ref> naturally represents different positive clusters.</ce:para>""''"'	uses_data_from	AGA	
cites	Characteristics of MIL problems	S. Andrews, I. Tsochantaridis, T. Hofmann, Support vector machines for multiple-instance learning , Proceedings of Conference on Neural Information Processing Systems, NIPS (2002)	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0006	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0115		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0234	'Instance-space SVM-based methods like mi-SVM [6][[ refid=''bib0006'' ]] can deal with disjoint regions of positive instances using a kernel.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0067"""" view=""""all"""">Many MIL methods can learn multimodal positive concepts, however, only few representative approaches will be mentioned due to space constraints. First, non-parametric methods based on distance between bags like Citation-kNN <ce:cross-ref id=""""crf0152"""" refid=""""bib0108"""">[108][[ refid=''''bib0108'''' ]]</ce:cross-ref> and MInD <ce:cross-ref id=""""crf0153"""" refid=""""bib0093"""">[93][[ refid=''''bib0093'''' ]]</ce:cross-ref> naturally deal with all shapes of distributions. Simple non-parametric methods often lead to competitive results in MIL problems <ce:cross-ref id=""""crf0154"""" refid=""""bib0057"""">[57][[ refid=''''bib0057'''' ]]</ce:cross-ref>. Methods using distances to a set of prototypes as bag representation, like DD-SVM <ce:cross-ref id=""""crf0155"""" refid=""""bib0109"""">[109][[ refid=''''bib0109'''' ]]</ce:cross-ref> and MILES <ce:cross-ref id=""""crf0156"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>, can model many positive clusters, because each different cluster can be represented by a different prototype. Instance-space SVM-based methods like mi-SVM <ce:cross-ref id=""""crf0157"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref> can deal with disjoint regions of positive instances using a kernel. Also, methods modeling instance distributions in bags such as vocabulary-based <ce:cross-ref id=""""crf0158"""" refid=""""bib0070"""">[70][[ refid=''''bib0070'''' ]]</ce:cross-ref> methods naturally deal with data sets containing multiple concepts/modes. The mixture-model in <ce:cross-ref id=""""crf0159"""" refid=""""bib0110"""">[110][[ refid=''''bib0110'''' ]]</ce:cross-ref> naturally represents different positive clusters.</ce:para>""''"'	cites	AGA	
cites	Experiments	B. Frenay, M. Verleysen, Classification in the presence of label noise: a survey , IEEE Trans. Neural Networks Learn. Syst. , vol. 25 (2014), pp.845-869	http://dx.doi.org/10.1016/j.patcog.2017.10.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0172	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0211		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0266	'All methods in this experiment use an SVM which is known to be vulnerable to label noise [172][[ refid=''bib0172'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0144"""" view=""""all"""">All methods in this experiment use an SVM which is known to be vulnerable to label noise <ce:cross-ref id=""""crf0281"""" refid=""""bib0172"""">[172][[ refid=''''bib0172'''' ]]</ce:cross-ref>. Since all classifiers are SVMs, it is easier to compare embedding techniques. The performance curve shapes show which type of embedding is the most noise resistant. MInD and EMD-kernel both maintain their level of performance until there is 30% of mislabeled bags, while the performance of MILES, NSK-SVM and miGraph steadily decreases as the noise increases. MInD and EMD-kernel describe bags as distances between the other bags in a kernel. EMD-kernel computes the distance between distribution of instances, and MInD averages the minimal distance between all instances, which can also be seen as a distance between the two distributions. CCE also represents instance distributions in bags and exhibits a similar noise resistance in the experiments on SIVAL. Based on these observations, it would seem that <ce:italic>characterizing bags as instance distributions is a successful strategy to deal with label noise.</ce:italic></ce:para>""''"'	uses_method_in	AGA	
cites	Discussion	S. Andrews, I. Tsochantaridis, T. Hofmann, Support vector machines for multiple-instance learning , Proceedings of Conference on Neural Information Processing Systems, NIPS (2002)	http://dx.doi.org/10.1016/j.patcog.2017.10.009	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0006	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0213		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0269	'No further details are given on these features, except that this representation is sub-optimal and should be further investigated [6][[ refid=''bib0006'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0148"""" view=""""all"""">Several characteristics inherent to MIL problems were discussed in this paper. It has been established that algorithms perform differently depending on these characteristics. However, even to this day, many approaches are validated only with the Musk and Tiger/Elephant/Fox (TEF) data sets. There are several problems with these benchmark data sets. First, they pose only some of the challenges discussed earlier. For example, the WR of these data sets is high. Since the instance labels are not supplied, the real WR is unknown. However, it has been estimated in some papers <ce:cross-refs id=""""crfs0057"""" refid=""""bib0024 bib0028 bib0075"""">[24,28,75][[ refid=''''bib0024 bib0028 bib0075'''' ]]</ce:cross-refs> which reported 82–100% for Musk1, 23–90% for Musk2 and 38–100% for TEF. Moreover, in the Musk data sets, there is no explicit structure to be exploited. In the TEF data sets, the instances are represented by 230-dimensional feature vectors characterizing by color, texture and shape descriptors. No further details are given on these features, except that this representation is sub-optimal and should be further investigated <ce:cross-ref id=""""crf0288"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>. It is possible that the theoretical Bayesian error has already been reached for this feature representation and that better results are obtained on account of protocol related technicality, such as fold partitions. Also, since the annotations at instance level are not available, it is difficult to assess if the fox classifier really identifies foxes, or if it identifies background elements related to foxes such as forest segments. This would explain the high WR estimated in <ce:cross-refs id=""""crfs0058"""" refid=""""bib0024 bib0028 bib0075"""">[24,28,75][[ refid=''''bib0024 bib0028 bib0075'''' ]]</ce:cross-refs>. For all these reasons, in our opinion, while the Musk and TEF data sets are representative of some problems, using more diverse benchmarks would provide a more meaningful comparison of MIL algorithms.</ce:para>""''"'	cites	AGA	
cites_as_review	Studies on MIL	J. Amores, Multiple instance classification: review, taxonomy and comparative study , Artif. Intell. , vol. 201 (2013), pp.81-105	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0015	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0047		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0291	'For a more general survey on MIL methods, we refer the interested reader to [15][[ refid=''bib0015'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0041"""" view=""""all"""">All of these conclusions are related to one or more characteristics that are unique to MIL problems. <ce:italic>Identifying these characteristics and gaining a better understanding of their impact on MIL algorithms is an important step towards the advancement of MIL research.</ce:italic> This survey paper mainly focuses on these characteristics and their implications for methods and applications. For a more general survey on MIL methods, we refer the interested reader to <ce:cross-ref id=""""crf0065"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Studies on MIL	M.-A. Carbonneau, E. Granger, G. Gagnon, Witness identification in multiple instance learning using random subspaces , Proceedings of International Conference on Pattern Recognition, ICPR (2016)	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0053	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0040		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0292	'Carbonneau et al. [53][[ refid=''bib0053'' ]] studied the ability to identify witnesses of several MIL methods.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0031"""" view=""""all"""">The classification of instances is a task in itself, but can also be an intermediate step toward bag classification for instance-space methods <ce:cross-ref id=""""crf0052"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>. Alpaydin et al. <ce:cross-ref id=""""crf0053"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> compared instance-space and bag-space classifiers on synthetic and real-world data. They concluded that for datasets with few bags, it is preferable to use an instance-space classifier. They also state, as in <ce:cross-ref id=""""crf0054"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>, that if the instances provide partial information about bag labels, it is preferable to use a bag-space representation. In <ce:cross-ref id=""""crf0055"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>, Cheplygina et al. explored the stability of the instance labels assigned by MIL algorithms. They found that algorithms yielding best bag classification performance were not the algorithms providing the most consistent instance labels. Carbonneau et al. <ce:cross-ref id=""""crf0056"""" refid=""""bib0053"""">[53][[ refid=''''bib0053'''' ]]</ce:cross-ref> studied the ability to identify witnesses of several MIL methods. They found that depending on the nature of the data, some algorithms perform well while others would have difficulty learning.</ce:para>""''"'	cites	AGA	
cites	Applications	S. Ray, M. Craven, Supervised versus multiple instance learning: an empirical comparison , Proceedings of International Conference on Machine Learning, ICML (2005)	http://dx.doi.org/10.1016/j.patcog.2017.10.009	motivation		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0165		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0312	'In [18][[ refid=''bib0018'' ]], the task consists of identifying texts that contain a passage which links a protein to a particular component, process or function.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0098"""" view=""""all"""">Texts often contain several topics and are easily modeled as bags. Text classification problems can be formulated as MIL at different levels. At the lowest level, instances are words like in the BoW model. Alternatively, instances can be sentences <ce:cross-refs id=""""crfs0046"""" refid=""""bib0044 bib0147"""">[44,147][[ refid=''''bib0044 bib0147'''' ]]</ce:cross-refs>, passages <ce:cross-refs id=""""crfs0047"""" refid=""""bib0006 bib0148"""">[6,148][[ refid=''''bib0006 bib0148'''' ]]</ce:cross-refs> or paragraphs <ce:cross-ref id=""""crf0213"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. In <ce:cross-ref id=""""crf0214"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>, bags are text documents, which are divided in overlapping passages corresponding to instances. The passages are represented by a binary vector in which each element is a medical term. The task is to categorize the texts. In <ce:cross-ref id=""""crf0215"""" refid=""""bib0149"""">[149][[ refid=''''bib0149'''' ]]</ce:cross-ref>, instances are short posts from different newsgroups. A bag is a collection of posts and the task is to determine if a group of posts contains a reference to a subject of interest. In <ce:cross-ref id=""""crf0216"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>, the task consists of identifying texts that contain a passage which links a protein to a particular component, process or function. In this case, paragraphs are instances while entire texts are bags. The paragraphs are represented by a BoW alongside distances from protein names and key terms. In <ce:cross-ref id=""""crf0217"""" refid=""""bib0150"""">[150][[ refid=''''bib0150'''' ]]</ce:cross-ref>, the content of emails is analyzed to detect spam. A common approach to elude spam filters is to include words that are not associated with spam in the message. Representing emails as bags of passages proved to be an efficient way to deal with these attacks. In <ce:cross-refs id=""""crfs0048"""" refid=""""bib0044 bib0147 bib0151 bib0152"""">[44,147,151,152][[ refid=''''bib0044 bib0147 bib0151 bib0152'''' ]]</ce:cross-refs>, MIL was used to infer the sentiment expressed in individual sentences based on labels provided for entire user reviews. MIL has also been used to discover relations between named entities <ce:cross-ref id=""""crf0218"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>. In this case, bags are collections of sentences containing two words that may or may not express a target relation (e.g. “Rick Astley” lives in “Montreal”). If the two words are related in the specified way, some of the sentences in the bag will express this relation. If that is not the case, none of the sentences will indicate the relation, hence the MIL formulation.</ce:para>""''"'	cites	AGA	
cites	Experiments	Y. Chen, J. Bi, J.Z. Wang, MILES: multiple-instance learning via embedded instance selection , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 28 (2006), pp.1931-1947	http://dx.doi.org/10.1016/j.patcog.2017.10.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0196		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0321	'MILES[4][[ refid=''bib0004'' ]]: In Multiple Instance Learning via Embedded instance Selection (MILES) an SVM classifies bags represented by feature vectors containing maximal similarities to selected prototypes.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0119"""" view=""""all""""><ce:italic>MILES</ce:italic><ce:cross-ref id=""""crf0247"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>: In Multiple Instance Learning via Embedded instance Selection (MILES) an SVM classifies bags represented by feature vectors containing maximal similarities to selected prototypes. The prototypes are instances from the training data selected by a 1-norm SVM. Instance classification relies on a score representing the instance contribution to the bag label.</ce:para>""''"'	cites	AGA	
cites	Experiments	V. Cheplygina, D.M. Tax, M. Loog, Multiple instance learning with bag dissimilarities , Pattern Recognit. , vol. 48 (2015), pp.264-275	http://dx.doi.org/10.1016/j.patcog.2017.10.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0093	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0194		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0323	'MInD[93][[ refid=''bib0093'' ]]: With this method, each bag is encoded by a vector whose fields are dissimilarities to the other bags in the training data set.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0117"""" view=""""all""""><ce:italic>MInD</ce:italic><ce:cross-ref id=""""crf0245"""" refid=""""bib0093"""">[93][[ refid=''''bib0093'''' ]]</ce:cross-ref>: With this method, each bag is encoded by a vector whose fields are dissimilarities to the other bags in the training data set. A regular supervised classifier, an SVM in this case, classifies these feature vectors. Many dissimilarity measures are proposed in the paper, but the <ce:italic>meanmin</ce:italic> offered the best overall performance and will be used in this paper.</ce:para>""''"'	uses_data_from	AGA	
cites	Experiments	Z.-H. Zhou, M.-L. Zhang, Solving multi-instance problems with classifier ensemble based on constructive clustering , Knowl. Inf. Syst. , vol. 11 (2007), pp.155-170	http://dx.doi.org/10.1016/j.patcog.2017.10.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0036	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0195		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0324	'CCE[36][[ refid=''bib0036'' ]]: This algorithm is based on clustering and classifier ensembles.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0118"""" view=""""all""""><ce:italic>CCE</ce:italic><ce:cross-ref id=""""crf0246"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref>: This algorithm is based on clustering and classifier ensembles. At first, the feature space is clustered using a fixed number of clusters. The bags are represented as binary vectors in which each bit corresponds to a cluster. A bit is set to 1 when at least one instance in a bag is assigned to its cluster. The binary codes are used to train one of the classifiers in the ensemble. Diversity is created in the ensemble by using a different number of clusters each time.</ce:para>""''"'	uses_method_in	AGA	
cites	Experiments	J.H. Friedman, Greedy function approximation: a gradient boosting machine , Ann. Stat. , vol. 29 (2001), pp.1189-1232	http://dx.doi.org/10.1016/j.patcog.2017.10.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0165	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0191		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0329	'The method is essentially the same as gradient boosting [165][[ refid=''bib0165'' ]] except that the loss function is based on bag classification error.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0115"""" view=""""all""""><ce:italic>MIL-Boost</ce:italic><ce:cross-ref id=""""crf0240"""" refid=""""bib0059"""">[59][[ refid=''''bib0059'''' ]]</ce:cross-ref>: The MIL-Boost algorithm used in this paper is a generalization of the algorithm presented in <ce:cross-ref id=""""crf0241"""" refid=""""bib0062"""">[62][[ refid=''''bib0062'''' ]]</ce:cross-ref>. The method is essentially the same as gradient boosting <ce:cross-ref id=""""crf0242"""" refid=""""bib0165"""">[165][[ refid=''''bib0165'''' ]]</ce:cross-ref> except that the loss function is based on bag classification error. The instances are classified individually, and their labels are combined to obtain bag labels.</ce:para>""''"'	uses_method_in	AGA	
cites	Applications	A. Mcgovern, D. Jensen, Identifying predictive structures in relational data using multiple instance learning , Proceedings of International Conference on Machine Learning, ICML (2003)	http://dx.doi.org/10.1016/j.patcog.2017.10.009	motivation		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0099	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0183		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0331	'In [99][[ refid=''bib0099'' ]], a method learning relational structure in data predicts which movies will be nominated for an award.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0108"""" view=""""all"""">In <ce:cross-ref id=""""crf0230"""" refid=""""bib0099"""">[99][[ refid=''''bib0099'''' ]]</ce:cross-ref>, a method learning relational structure in data predicts which movies will be nominated for an award. A movie is represented by a graph that models its relations to actors, studios, genre, release date, etc. The MIL algorithm identifies which sub-graph explains the nomination to infer the success of test cases. This type of structural relation between bags and instance is akin to web page classification problems.</ce:para>""''"'	uses_data_from	AGA	
cites	Experiments	Z.-H. Zhou, Y.-Y. Sun, Y.-F. Li, Multi-instance learning by treating instances as non-I.I.D. samples , Proceedings of International Conference on Machine Learning, ICML (2009)	http://dx.doi.org/10.1016/j.patcog.2017.10.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0198		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0332	'miGraph[10][[ refid=''bib0010'' ]]: This method represents each bag by a graph in which instances correspond to nodes.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0121"""" view=""""all""""><ce:italic>miGraph</ce:italic><ce:cross-ref id=""""crf0249"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>: This method represents each bag by a graph in which instances correspond to nodes. Cliques are identified in the graph to adjust the instance weights. Instances belonging to large cliques have lower weights so each concept present in the bag is equally represented when instances are averaged. A graph kernel captures similarity between bags and is used in an SVM.</ce:para>""''"'	uses_method_in	AGA	
cites	Experiments	Z.-H. Zhou, X.-B. Xue, Y. Jiang, Locating regions of interest in CBIR with multi-instance learning techniques , Proceedings of Australian Joint Conference on Artificial Intelligence, AUS-AI (2005)	http://dx.doi.org/10.1016/j.patcog.2017.10.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0066	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0193		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0333	'The algorithm was adapted in [66][[ refid=''bib0066'' ]] to perform instance classification.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0116"""" view=""""all""""><ce:italic>C-kNN</ce:italic><ce:cross-ref id=""""crf0243"""" refid=""""bib0108"""">[108][[ refid=''''bib0108'''' ]]</ce:cross-ref>: This is an adaptation of kNN to MIL problems. The distance between two bags is measured using the minimal Hausdorff distance. C-kNN relies on a two-level voting scheme inspired from the notion of citations and references in research papers. The algorithm was adapted in <ce:cross-ref id=""""crf0244"""" refid=""""bib0066"""">[66][[ refid=''''bib0066'''' ]]</ce:cross-ref> to perform instance classification.</ce:para>""''"'	uses_method_in	AGA	
cites	Experiments	F. Briggs, X.Z. Fern, R. Raich, Rank-loss support instance machines for MIML instance annotation , Proceedings of Conference on Knowledge Discovery and Data Mining, KDD (2012)	http://dx.doi.org/10.1016/j.patcog.2017.10.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0012	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0202		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0338	'Birds[12][[ refid=''bib0012'' ]]: The bags of this data set correspond to 10 s recordings of bird songs from one or more species.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0125"""" view=""""all""""><ce:italic>Birds</ce:italic><ce:cross-ref id=""""crf0254"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>: The bags of this data set correspond to 10 s recordings of bird songs from one or more species. The recording is segmented temporally to create instances, which belong to a particular bird or to background noise. These 10,232 instances are represented by 38-dimensional feature vectors. Readers should refer to the original paper for details on the features. There are 13 types of bird in the data set, each in turn considered as the positive class. Therefore 13 problems can be generated from this data set. In this data set, low WR poses a challenge, especially since it is not constant across bags. Moreover, bag classes are sometimes severely imbalanced.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experiments	M. Stone, Cross-validatory choice and assessment of statistical predictions , J. R. Stat. Soc. Ser. B (Methodol.) , vol. 36 (1974), pp.111-147	http://dx.doi.org/10.1016/j.patcog.2017.10.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0170	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0207		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0346	'The experiments were conducted using a nested cross-fold validation protocol [170][[ refid=''bib0170'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0131"""" view=""""all"""">The experiments were conducted using a nested cross-fold validation protocol <ce:cross-ref id=""""crf0261"""" refid=""""bib0170"""">[170][[ refid=''''bib0170'''' ]]</ce:cross-ref>. It consists of two cross-validation loops. An outer loop assesses the performance of the algorithm in test, and an inner loop is used to optimize the algorithm hyper-parameters. This means that for each test fold of the outer loop, hyper-parameters optimization is performed via grid-search. Average performance is reported on results for the outer loop test folds.</ce:para>""''"'	uses_method_in	AGA	
uses_data_from	Experiments	P. Baldi, K. Cranmer, T. Faucett, P. Sadowski, D. Whiteson, Parameterized machine learning for high-energy physics, (2016) 1−6, doi:	http://dx.doi.org/10.1016/j.patcog.2017.10.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0168	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0204		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0347	'HEPMASS[168][[ refid=''bib0168'' ]]: The instances of this data set come from the HEPMASS Data Set (http://archive.ics.uci.edu/ml/datasets/HEPMASS).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0127"""" view=""""all""""><ce:italic>HEPMASS</ce:italic><ce:cross-ref id=""""crf0257"""" refid=""""bib0168"""">[168][[ refid=''''bib0168'''' ]]</ce:cross-ref>: The instances of this data set come from the HEPMASS Data Set.<ce:cross-ref id=""""crf0258"""" refid=""""fn0002""""><ce:sup loc=""""post"""">2</ce:sup></ce:cross-ref><ce:footnote id=""""fn0002""""><ce:label>2</ce:label><ce:note-para id=""""cenotep0002"""" view=""""all""""><ce:inter-ref id=""""interref0003"""" xlink:href=""""http://archive.ics.uci.edu/ml/datasets/HEPMASS"""" xlink:type=""""simple"""">http://archive.ics.uci.edu/ml/datasets/HEPMASS</ce:inter-ref>.</ce:note-para></ce:footnote> It contains more than 10M instances which are simulation of particle collisions. The positive class corresponds to collisions that produce exotic particles, while the negative class is background noise. Each instance is represented by a 27-dimensional feature vector containing low-level kinematic measurements and their combination to create higher level mass features (see original paper for more details). For each WR value, 10 versions of the MIL data are randomly generated. For each version, the training and a test sets contain 50 positive bags and 50 negative bags composed of 100 instances.</ce:para>""''"'	uses_data_from	AGA	
uses_data_from	Experiments	P.W. Frey, D.J. Slate, Letter recognition using holland-style adaptive classifiers , Mach. Learn. , vol. 6 (1991), pp.161-182	http://dx.doi.org/10.1016/j.patcog.2017.10.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0169	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0205		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0348	'Letters[169][[ refid=''bib0169'' ]]: This semi-synthetic MIL data set uses instances from the Letter Recognition data set (https://archive.ics.uci.edu/ml/datasets/Letter+Recognition).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0128"""" view=""""all""""><ce:italic>Letters</ce:italic><ce:cross-ref id=""""crf0259"""" refid=""""bib0169"""">[169][[ refid=''''bib0169'''' ]]</ce:cross-ref>: This semi-synthetic MIL data set uses instances from the Letter Recognition data set.<ce:cross-ref id=""""crf0260"""" refid=""""fn0003""""><ce:sup loc=""""post"""">3</ce:sup></ce:cross-ref><ce:footnote id=""""fn0003""""><ce:label>3</ce:label><ce:note-para id=""""cenotep0003"""" view=""""all""""><ce:inter-ref id=""""interref0004"""" xlink:href=""""https://archive.ics.uci.edu/ml/datasets/Letter+Recognition"""" xlink:type=""""simple"""">https://archive.ics.uci.edu/ml/datasets/Letter+Recognition</ce:inter-ref>.</ce:note-para></ce:footnote> It contains a total of 20k instances representing each of the 26 letters in the English alphabet. Each of these letters can be seen as a concept and used to create different positive and negative distributions. Each letter is encoded by a 16-dimensional feature vector that has been standardized. The reader is referred to the original paper for more details. In WR experiments, for each WR value, 10 versions of the MIL data sets are randomly generated. Each version has a training and a test set. Both sets contain 50 positive bags and 50 negative bags each containing 20 instances. In the positive bags, witness are sampled from 3 letters randomly selected to represent positive concepts. All other letters are considered as negative concepts. For the experiments on negative class modeling, the data set is divided in train and test partitions each containing 200 bags. Each bag contains 20 instances. The bag classes are equally proportioned and the WR is 20%. Like before, the positive instances are samples from 3 randomly selected letters. Half of the remaining letters constitute the initial negative distribution and the other half constitutes the unknown negative distribution.</ce:para>""''"'	uses_data_from	AGA	
cites	Characteristics of MIL problems	S. Yan, X. Zhu, G. Liu, Sparse multiple instance learning as document classification , Multimed. Tools Appl. , vol. 76 (2017), pp.4553-4570	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0026	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0073		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0354	'In miDoc [26][[ refid=''bib0026'' ]], a graph represents the entire MIL problem, where bags are compared based on the connecting edges.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0051"""" view=""""all"""">Several authors studied low WR problems in recent years. For example, sparse transductive MIL (stMIL) <ce:cross-ref id=""""crf0099"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> is an SVM formulation similar to NSK-SVM <ce:cross-ref id=""""crf0100"""" refid=""""bib0073"""">[73][[ refid=''''bib0073'''' ]]</ce:cross-ref>. However, to better deal with low WR bags, the optimization constraints of the SVM are modified to be satisfied when at least one witness is found in positive bags. This method performs well at low WR but is less efficient when it is higher. Sparse balanced MIL (sbMIL) <ce:cross-ref id=""""crf0101"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> incorporates an estimation of the WR as a parameter in the optimization objective to solve this problem. WR estimation has also been successfully used in low WR problems by ALP-SVM <ce:cross-ref id=""""crf0102"""" refid=""""bib0075"""">[75][[ refid=''''bib0075'''' ]]</ce:cross-ref>, SVR-SVM <ce:cross-ref id=""""crf0103"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref> and the <ce:italic>γ</ce:italic>-rule <ce:cross-ref id=""""crf0104"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. One drawback of using the WR as a parameter is that the WR is assumed to be constant across all bags. Other methods, like CR-MILBoost <ce:cross-ref id=""""crf0105"""" refid=""""bib0076"""">[76][[ refid=''''bib0076'''' ]]</ce:cross-ref> and RSIS <ce:cross-ref id=""""crf0106"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, estimate the probability that each instance is positive before training an ensemble of classifiers. During training, the classifiers give more importance to the instances that are more likely to be witnesses. In miGraph <ce:cross-ref id=""""crf0107"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>, similar instances in a bag are grouped in cliques. The importance of each instance is inversely proportional to the size of its clique. Assuming positive and negative instances belong to different cliques, the WR has little impact. In miDoc <ce:cross-ref id=""""crf0108"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>, a graph represents the entire MIL problem, where bags are compared based on the connecting edges. Experiments show that the method performs well on very low WR problems.</ce:para>""''"'	cites	AGA	
cites	Characteristics of MIL problems	Z.-H. Zhou, M.-L. Zhang, Solving multi-instance problems with classifier ensemble based on constructive clustering , Knowl. Inf. Syst. , vol. 11 (2007), pp.155-170	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0036	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0079		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0362	'CCE [36][[ refid=''bib0036'' ]] performs a clustering of the instance space.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0055"""" view=""""all"""">Very few methods were proposed explicitly to address this problem. To deal with similar instances, miGraph <ce:cross-ref id=""""crf0115"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref> builds a graph per bag and groups similar instances together to adjust their relative importance based on the group size. CCE <ce:cross-ref id=""""crf0116"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref> performs a clustering of the instance space. Bags are represented by a binary vector in which each bit corresponds to a cluster. A bit is set to 1 if at least one instance in the bag has been assigned to the corresponding cluster. A similar approach is used in <ce:cross-ref id=""""crf0117"""" refid=""""bib0078"""">[78][[ refid=''''bib0078'''' ]]</ce:cross-ref> except bits are associated a pool of subgraphs patterns mined from the data set. Because features are binary, many instances can be assigned to the same cluster and the representation remains unaffected, which provides robustness to intra-bag similarity.</ce:para>""''"'	cites	AGA	
cites	Applications	S. Andrews, I. Tsochantaridis, T. Hofmann, Support vector machines for multiple-instance learning , Proceedings of Conference on Neural Information Processing Systems, NIPS (2002)	http://dx.doi.org/10.1016/j.patcog.2017.10.009	motivation		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0006	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0171		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0364	'When texts are represented by word frequency features (e.g. BoW) the data is very sparse and high-dimensional [6][[ refid=''bib0006'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0100"""" view=""""all"""">Text data poses particular challenges for MIL. Most of the time, instances are non-i.i.d. Words may have different meanings depending on the context and thus, co-occurrence is important in this type of application. While BoW methods are successful to some degree, structure is an important component of sentences which convey important semantic information. Often, only small passages or specific words indicate the class of the document, which means WR can be quite low. Depending on the task and the formulation of the problem, bag and instance classification can be performed. In addition, text classification can present an additional difficulty compared to other applications. When texts are represented by word frequency features (e.g. BoW) the data is very sparse and high-dimensional <ce:cross-ref id=""""crf0220"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>. This type of data is often difficult to handle by classifiers using Euclidean-like distance measures. These distributions are highly multimodal and it is difficult to adequately represent the distribution of negative data.</ce:para>""''"'	uses_data_from	AGA	
cites	Applications	M.I. Mandel, D.P.W. Ellis, Multiple-Instance Learning for Music information Retrieval, 2008.	http://dx.doi.org/10.1016/j.patcog.2017.10.009	motivation		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0155	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0173		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0365	'In [155][[ refid=''bib0155'' ]], the objective is to automatically determine the genre of musical excerpts.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0103"""" view=""""all"""">Just like for images, some sound classification tasks can be cast as MIL. In <ce:cross-ref id=""""crf0222"""" refid=""""bib0155"""">[155][[ refid=''''bib0155'''' ]]</ce:cross-ref>, the objective is to automatically determine the genre of musical excerpts. In training, labels are provided for entire albums or artists, but not for each excerpt. The bags are collections of excerpts from the same artist or album. It is possible to find different genres of music on the same album or from the same artist, therefore the bags may contain positive and negative instances. In <ce:cross-ref id=""""crf0223"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>, MIL is used to identify bird songs in recordings made by unattended microphones in the wild. Sound sequences contain several types of birds and other noises. The objective is to identify each birdsong individually while training only on weakly labeled sound files.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments	J. Amores, Multiple instance classification: review, taxonomy and comparative study , Artif. Intell. , vol. 201 (2013), pp.81-105	http://dx.doi.org/10.1016/j.patcog.2017.10.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0015	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0199		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0370	'This is achieved with BoW-SVM by performing k-means clustering on all the training instances [15][[ refid=''bib0015'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0122"""" view=""""all""""><ce:italic>BoW-SVM:</ce:italic> Creating a dictionary of representative words is the first step when using a BoW method. This is achieved with BoW-SVM by performing k-means clustering on all the training instances <ce:cross-ref id=""""crf0250"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>. Next, instances are represented by the most similar word contained in the dictionary. Bags are represented by frequency histograms of the words. Histograms are classified by an SVM using a kernel suitable for histogram comparison (exponential <ce:italic>χ</ce:italic><ce:sup loc=""""post"""">2</ce:sup> in this case).</ce:para>""''"'	uses_method_in	AGA	
cites	Applications	J. Wang, B. Li, W. Hu, O. Wu, Horror video scene recognition via multiple-instance learning , Proceedings of International Conference on Acoustics, Speech and Signal Processing, ICASSP (2011)	http://dx.doi.org/10.1016/j.patcog.2017.10.009	motivation		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0137	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0144		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0374	'This problem formulation is also used in [137][[ refid=''bib0137'' ]] to recognize scenes that are inappropriate for children.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0089"""" view=""""all"""">Instance classification has also been applied in videos. It has been used to recognize complex events such as “attempting a board trick” or “birthday party” <ce:cross-refs id=""""crfs0040"""" refid=""""bib0008 bib0136"""">[8,136][[ refid=''''bib0008 bib0136'''' ]]</ce:cross-refs>. Several concepts compose these complex events. Evidences of these concepts sometimes last only for a short time, and can be difficult to observe in the total amount of information presented in the video. To deal with this problem, video sequences are divided in shorter sequences (instances) that are later classified individually. This problem formulation is also used in <ce:cross-ref id=""""crf0194"""" refid=""""bib0137"""">[137][[ refid=''''bib0137'''' ]]</ce:cross-ref> to recognize scenes that are inappropriate for children. Also in videos, MIL methods were proposed to perform object tracking <ce:cross-refs id=""""crfs0041"""" refid=""""bib0061 bib0138 bib0139"""">[61,138,139][[ refid=''''bib0061 bib0138 bib0139'''' ]]</ce:cross-refs>. For example, in <ce:cross-ref id=""""crf0195"""" refid=""""bib0061"""">[61][[ refid=''''bib0061'''' ]]</ce:cross-ref> a classifier is trained online to recognize and track an object of interest in a frame sequence. The tracker proposes candidate windows which compose a bag and are used to train the MIL classifier.</ce:para>""''"'	cites	AGA	
cites	Characteristics of MIL problems	W.J. Li, D.Y. Yeung, MILD: multiple-instance learning via disambiguation , IEEE Trans. Knowl. Data Eng. , vol. 22 (2010), pp.76-89	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0060	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0062		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0404	'MILD [60][[ refid=''bib0060'' ]] discovers a set of true positive instances.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0049"""" view=""""all"""">Some methods try to uncover the true label of the instances to train an instance classifier. One of the most well-known methods is mi-SVM <ce:cross-ref id=""""crf0088"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>. After instance labels have been initialized, an SVM classifier is trained and used to update the label assignation. These two steps are performed iteratively until the label assignation remains unchanged. The resulting SVM classifier is used to predict the label of test instances. MissSVM <ce:cross-ref id=""""crf0089"""" refid=""""bib0067"""">[67][[ refid=''''bib0067'''' ]]</ce:cross-ref> views the problem as semi-supervised learning where instances in positive bags are unlabeled. The algorithm is similar to mi-SVM except that it enforces the constraint that every positive bags contain a positive instance. KI-SVM <ce:cross-ref id=""""crf0090"""" refid=""""bib0068"""">[68][[ refid=''''bib0068'''' ]]</ce:cross-ref> uses a multiple kernel approach in which a kernel encodes possible label assignations in the SVM constraints. In this method, it is assumed that there is the same number of positive instances in all positive bags. MILD <ce:cross-ref id=""""crf0091"""" refid=""""bib0060"""">[60][[ refid=''''bib0060'''' ]]</ce:cross-ref> discovers a set of <ce:italic>true positive</ce:italic> instances. The probability that an instance is positive depends on the bag labels in its vicinity defined by a Gaussian kernel. The discovered true positive instances are used to train an SVM classifier. A similar idea is proposed in RSIS-EoSVM <ce:cross-ref id=""""crf0092"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> where instances are projected in random subspaces and vicinity depends on cluster assignations. In that case, label assignation is probabilistic. Several training sets are sampled based on these probabilistic assignations to train an ensemble of SVM classifiers.</ce:para>""''"'	cites	AGA	
cites	Discussion	B. Zhang, W. Zuo, Learning from positive and unlabeled examples: a survey , Proceedings of International Symposiums on Information Processing, ISIP (2008)	http://dx.doi.org/10.1016/j.patcog.2017.10.009	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0188	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0238		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0408	'This type of problem is well studied in single instance learning [188][[ refid=''bib0188'' ]], but requires more exploration in the MIL context.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0165"""" view=""""all"""">In some applications, the training data contains only positive and unlabeled data. For example, in recommender systems, the history of a user contains a list of consulted products that can be modeled as bags. If the user bought a product, it is considered as a positive bag. The other consulted products may or may not be interesting to the customer and therefore remain unlabeled. This type of problem is well studied in single instance learning <ce:cross-ref id=""""crf0324"""" refid=""""bib0188"""">[188][[ refid=''''bib0188'''' ]]</ce:cross-ref>, but requires more exploration in the MIL context. As explained before, and observed in the experiments, many MIL methods depend on the characterization of the negative distribution and the correctness of bag labels to identify positive concepts. In this case, learning from positive and unlabeled bags becomes a difficult problem for MIL. So far, only a handful of papers are dedicated to this subject <ce:cross-refs id=""""crfs0065"""" refid=""""bib0189 bib0190 bib0191"""">[189–191][[ refid=''''bib0189 bib0190 bib0191'''' ]]</ce:cross-refs>.</ce:para>""''"'	cites	AGA	
cites	Discussion	P. Branco, L. Torgo, R.P. Ribeiro, A survey of predictive modeling on imbalanced domains , ACM Comput. Surv. , vol. 49 (2016), pp.31:1-31:50	http://dx.doi.org/10.1016/j.patcog.2017.10.009	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0192	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0241		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0417	'There exist many methods to deal with imbalanced data [192][[ refid=''bib0192'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0168"""" view=""""all"""">In many problems, the numbers of negative and positive instances are severely imbalanced, and yet, the existing learning methods for imbalanced data set have not studied extensively in MIL. There exist many methods to deal with imbalanced data <ce:cross-ref id=""""crf0325"""" refid=""""bib0192"""">[192][[ refid=''''bib0192'''' ]]</ce:cross-ref>. There are external methods like SMOTE <ce:cross-ref id=""""crf0326"""" refid=""""bib0193"""">[193][[ refid=''''bib0193'''' ]]</ce:cross-ref> and RUSBoost <ce:cross-ref id=""""crf0327"""" refid=""""bib0194"""">[194][[ refid=''''bib0194'''' ]]</ce:cross-ref> that necessitate accurate labels to perform over or under sampling. To be adapted to MIL these methods could use some kind of probabilistic label function. Internal methods <ce:cross-refs id=""""crfs0067"""" refid=""""bib0195 bib0196"""">[195,196][[ refid=''''bib0195 bib0196'''' ]]</ce:cross-refs> adjust the misclassification cost independently for each class. These schemes could be used in algorithms such as mi-SVM which require the training of an SVM with high class imbalance when the WR is low. Class imbalance has also been identified in <ce:cross-ref id=""""crf0328"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref> as an important topic for future research.</ce:para>""''"'	uses_data_from	AGA	
cites	Applications	J. Melendez, A novel multiple-instance learning-based approach to computer-aided detection of tuberculosis on chest x-rays , Trans. Med. Imaging , vol. 31 (2014), pp.179-192	http://dx.doi.org/10.1016/j.patcog.2017.10.009	motivation		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0144	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0152		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0419	'For example, in [144][[ refid=''bib0144'' ]], a MIL classifier trained only with X-ray images labeled as healthy or as containing tuberculosis, outperforms its supervised version, trained on outlines of tuberculosis lesions.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0094"""" view=""""all"""">When the focus is on classifying bags, MIL classifiers benefit from using information about co-occurrence and structure of instances. For example, in <ce:cross-ref id=""""crf0203"""" refid=""""bib0144"""">[144][[ refid=''''bib0144'''' ]]</ce:cross-ref>, a MIL classifier trained only with X-ray images labeled as healthy or as containing tuberculosis, outperforms its supervised version, trained on outlines of tuberculosis lesions. Similar results are observed on the task of classification of chronic obstructive pulmonary disease (COPD) from chest computed tomography images <ce:cross-ref id=""""crf0204"""" refid=""""bib0145"""">[145][[ refid=''''bib0145'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Applications	V. Cheplygina, L. Sørensen, D.M.J. Tax, J.H. Pedersen, M. Loog, M. de Bruijne, Classification of COPD with multiple instance learning , Proceedings of International Conference on Pattern Recognition, ICPR (2014)	http://dx.doi.org/10.1016/j.patcog.2017.10.009	motivation		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0145	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0159		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0438	'For example, the chronic lung disease COPD has 4 different stages, but [145][[ refid=''bib0145'' ]] treats them all as the positive class.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0096"""" view=""""all"""">CAD shares many key challenges with other less constrained computer vision tasks. Depending on the sampling – which can be done on a dense grid <ce:cross-refs id=""""crfs0045"""" refid=""""bib0058 bib0144"""">[58,144][[ refid=''''bib0058 bib0144'''' ]]</ce:cross-refs>, randomly <ce:cross-ref id=""""crf0208"""" refid=""""bib0145"""">[145][[ refid=''''bib0145'''' ]]</ce:cross-ref> or according to constraints <ce:cross-ref id=""""crf0209"""" refid=""""bib0143"""">[143][[ refid=''''bib0143'''' ]]</ce:cross-ref> – the instances can display varying degrees of similarity. In many pathologies, abnormalities are likely to include different subtypes, which have different appearance resulting in multimodal concept distributions. Moreover, differences between patients, such as age, sex and weight, as well as differences in acquisition of the images can also lead to large intra-class variability. On the other hand, the negative distribution (healthy tissue) is more constrained than in computer vision applications. This means that it is reasonable to attempt to capture and model the negative distribution, which is very difficult in unconstrained image recognition problems. Another particularity of CAD problems is that they are naturally suitable to have real-valued outputs, because diseases can have different stages, although this is often not considered when off-the-shelf algorithms are applied. For example, the chronic lung disease COPD has 4 different stages, but <ce:cross-ref id=""""crf0210"""" refid=""""bib0145"""">[145][[ refid=''''bib0145'''' ]]</ce:cross-ref> treats them all as the positive class. During evaluation, the mild stage is most often misclassified as healthy. Tong et al. <ce:cross-ref id=""""crf0211"""" refid=""""bib0143"""">[143][[ refid=''''bib0143'''' ]]</ce:cross-ref> considers binary classification tasks out of four possible classes (healthy, two types of mild cognitive impairment, and Alzheimer’s), while these could be considered as a continuous scale. Lastly, CAD can be formulated as an instance and a bag classification task.</ce:para>""''"'	cites	AGA	
cites	Multiple instance learning	N. Weidmann, E. Frank, B. Pfahringer, A two-level learning method for generalized multi-instance problems , Proceedings of European Conference on Machine Learning, ECML (2003)	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0032	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0013		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0450	'There are different levels of generality for multiple concept assumptions of this type [32][[ refid=''bib0032'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0019"""" view=""""all"""">A more general case for the collective assumption is when the class of a bag is defined by instances belonging to more than one concept. Foulds and Frank <ce:cross-ref id=""""crf0027"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> give a simple and representative example of this assumption by classifying images of desert, sea and beach. Images of deserts contain sand segments, while images of the sea contain water segments. However, images of beaches must contain both types of segments. To correctly classify beach images, the model must verify the presence of both types of witnesses, and thus, methods working under the standard MIL assumption would fail in this case. Some methods assign instances to a set of defined concepts (<mml:math altimg=""""si8.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""script"""">C</mml:mi></mml:math>), and some of these concepts belong to the positive class (<mml:math altimg=""""si9.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msup><mml:mi mathvariant=""""script"""">C</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo>⊂</mml:mo><mml:mi mathvariant=""""script"""">C</mml:mi></mml:mrow></mml:math>). In that case, the bag classifier <ce:italic>g</ce:italic>(<ce:italic>X</ce:italic>) is defined by:<ce:display><ce:formula id=""""eq0003""""><ce:label>(3)</ce:label><mml:math altimg=""""si10.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy=""""true"""">{</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign=""""left""""><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign=""""left""""><mml:mrow><mml:mtext>if</mml:mtext><mml:mspace width=""""4.pt""""/><mml:mo>∀</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant=""""script"""">C</mml:mi><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo>:</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>∈</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign=""""left""""><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign=""""left""""><mml:mrow><mml:mtext>otherwise</mml:mtext><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></ce:formula></ce:display>where <mml:math altimg=""""si11.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is a process that outputs 1 if <mml:math altimg=""""si12.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""bold"""">x</mml:mi></mml:math> belongs to concept <ce:italic>c</ce:italic> and <ce:italic>θ<ce:inf loc=""""post"""">c</ce:inf></ce:italic> is the number of instances belonging to <ce:italic>c</ce:italic> required to observe a positive bag. There are different levels of generality for multiple concept assumptions of this type <ce:cross-ref id=""""crf0028"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>. Alternatively, bags can be seen as distributions of instances. In <ce:cross-ref id=""""crf0029"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref>, the bag space <mml:math altimg=""""si13.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""script"""">B</mml:mi></mml:math> is defined as the set of all probability distributions on the instance space (<mml:math altimg=""""si14.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi mathvariant=""""script"""">P</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant=""""script"""">X</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>). Each bag <ce:italic>X</ce:italic> is a probability distribution over instances <mml:math altimg=""""si15.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>|</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>. In that case, a bag classifier is a process that maps a probability distribution to a label: <mml:math altimg=""""si16.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>g</mml:mi><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>)</mml:mo><mml:mo>:</mml:mo><mml:mi mathvariant=""""script"""">P</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant=""""script"""">X</mml:mi><mml:mo>)</mml:mo><mml:mo>→</mml:mo><mml:mo>{</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math>.</ce:para>""''"'	cites	AGA	
cites_as_review	Multiple instance learning	J. Foulds, E. Frank, A review of multi-instance learning assumptions , Knowl. Eng. Rev. , vol. 25 (2010), pp.1-25	http://dx.doi.org/10.1016/j.patcog.2017.10.009			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0017	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0010		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0457	'For a more detailed review on the subject, the reader is referred to [17][[ refid=''bib0017'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all"""">In this paper, we consider two broad assumptions: the standard and the collective assumption. For a more detailed review on the subject, the reader is referred to <ce:cross-ref id=""""crf0025"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites_as_review	AGA	
cites	Applications	A. Kumar, B. Raj, Weakly supervised scalable audio content analysis , 2016 IEEE International Conference on Multimedia and Expo (ICME), Seattle, WA (2016)	http://dx.doi.org/10.1016/j.patcog.2017.10.009	motivation		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/br/bib0159	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/ctx/ctx0178		253	7	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-009/itrp/0463	'The BoW framework has been used in a similar fashion in [159][[ refid=''bib0159'' ]], however, in that case instances are cepstrum feature vectors representing 1 s-long audio segments.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0104"""" view=""""all"""">Some methods represent audio signals as spectrograms and use image recognition techniques to perform recognition <ce:cross-ref id=""""crf0224"""" refid=""""bib0156"""">[156][[ refid=''''bib0156'''' ]]</ce:cross-ref>. This idea has been used for bird song recognition <ce:cross-ref id=""""crf0225"""" refid=""""bib0157"""">[157][[ refid=''''bib0157'''' ]]</ce:cross-ref> with histograms of gradients. In <ce:cross-ref id=""""crf0226"""" refid=""""bib0158"""">[158][[ refid=''''bib0158'''' ]]</ce:cross-ref>, personality traits are inferred from speech signals represented as spectrograms in a BoW framework. In that case, entire speech signals are bags and small parts of the spectrogram are instances. The BoW framework has been used in a similar fashion in <ce:cross-ref id=""""crf0227"""" refid=""""bib0159"""">[159][[ refid=''''bib0159'''' ]]</ce:cross-ref>, however, in that case instances are cepstrum feature vectors representing 1 s-long audio segments. Audio classification poses different challenges depending on how sounds are represented. For example, when a sound signal is represented as a time series, capturing structure is important. However, in a BoW framework, the co-occurrence of different markers will be more important. In many cases, the background noise related to capture conditions leads to high intra-bag similarity.</ce:para>""''"'	cites	AGA	
cites	Related work	E.P. Xing, M.I. Jordan, S. Russell, A.Y. Ng, Distance metric learning with application to clustering with side-information , Proceedings of the Advances in Neural Information Processing Systems (NIPS) (2002)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0036	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0022		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0001	'Metric learning has been a hot research topic, influenced by the pioneering work of Xing et al. [36][[ refid=''bib0036'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">Metric learning has been a hot research topic, influenced by the pioneering work of Xing et al. <ce:cross-ref id=""""crf0047"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref>. Metric-learning approaches usually focus on the linear metric Mahalanobis distance <mml:math altimg=""""si9.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi mathvariant=""""bold"""">M</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> where <ce:bold>x</ce:bold> and <ce:bold>y</ce:bold> are feature vectors of images <ce:italic>x</ce:italic> and <ce:italic>y</ce:italic>, respectively, and <ce:bold>M</ce:bold> is a PSD matrix. One of the most widely used Mahalanobis-distance learning methods is Large-Margin Nearest Neighbours (LMNN), introduced by Weinberger et al. <ce:cross-ref id=""""crf0048"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref>, which defines the constraints in a local way and has many extensions. Information-Theoretic Metric Learning (ITML) is another important work, proposed by Davis et al. <ce:cross-ref id=""""crf0049"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, which uses LogDet divergence regularization to learn Mahalanobis distance. Qi et al. <ce:cross-ref id=""""crf0050"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> exploited the sparse nature of the high-dimensional feature space and considered the case of high-dimensional data together with few training samples, for which they used LogDet divergence and <ce:italic>L</ce:italic><ce:inf loc=""""post"""">1</ce:inf> regularization together. Mirror-Descent Metric Learning (MDML), proposed by Kunapuli et al. <ce:cross-ref id=""""crf0051"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref>, is a general online Mahalanobis-distance learning framework. Non-Mahalanobis based metric-learning methods have also been proposed, such as kernelizations of the linear method <ce:cross-ref id=""""crf0052"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> and the nonlinear method <ce:cross-ref id=""""crf0053"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>. Deep CNN has already made impressive progress on many computer vision problems, and recently, several deep-CNN based models have been explored for metric learning. Deep Ranking, proposed by Wang et al. <ce:cross-ref id=""""crf0054"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref>, learns fine-grained image similarity; and FPNN, proposed by Li et al. <ce:cross-ref id=""""crf0055"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>, handles misalignment and photometric and geometric transforms via deep networks. Our deep model is partially motivated by these works but differs from them.</ce:para>""''"'	cites	AGA	
cites	Related work	K.Q. Weinberger, L.K. Saul, Distance metric learning for large margin nearest neighbor classification , J. Mach. Learn. Res. , vol. 10 (2009), pp.207-244	http://dx.doi.org/10.1016/j.patcog.2017.10.015	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0037	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0023		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0002	'One of the most widely used Mahalanobis-distance learning methods is Large-Margin Nearest Neighbours (LMNN), introduced by Weinberger et al. [37][[ refid=''bib0037'' ]], which defines the constraints in a local way and has many extensions.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">Metric learning has been a hot research topic, influenced by the pioneering work of Xing et al. <ce:cross-ref id=""""crf0047"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref>. Metric-learning approaches usually focus on the linear metric Mahalanobis distance <mml:math altimg=""""si9.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi mathvariant=""""bold"""">M</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> where <ce:bold>x</ce:bold> and <ce:bold>y</ce:bold> are feature vectors of images <ce:italic>x</ce:italic> and <ce:italic>y</ce:italic>, respectively, and <ce:bold>M</ce:bold> is a PSD matrix. One of the most widely used Mahalanobis-distance learning methods is Large-Margin Nearest Neighbours (LMNN), introduced by Weinberger et al. <ce:cross-ref id=""""crf0048"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref>, which defines the constraints in a local way and has many extensions. Information-Theoretic Metric Learning (ITML) is another important work, proposed by Davis et al. <ce:cross-ref id=""""crf0049"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, which uses LogDet divergence regularization to learn Mahalanobis distance. Qi et al. <ce:cross-ref id=""""crf0050"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> exploited the sparse nature of the high-dimensional feature space and considered the case of high-dimensional data together with few training samples, for which they used LogDet divergence and <ce:italic>L</ce:italic><ce:inf loc=""""post"""">1</ce:inf> regularization together. Mirror-Descent Metric Learning (MDML), proposed by Kunapuli et al. <ce:cross-ref id=""""crf0051"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref>, is a general online Mahalanobis-distance learning framework. Non-Mahalanobis based metric-learning methods have also been proposed, such as kernelizations of the linear method <ce:cross-ref id=""""crf0052"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> and the nonlinear method <ce:cross-ref id=""""crf0053"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>. Deep CNN has already made impressive progress on many computer vision problems, and recently, several deep-CNN based models have been explored for metric learning. Deep Ranking, proposed by Wang et al. <ce:cross-ref id=""""crf0054"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref>, learns fine-grained image similarity; and FPNN, proposed by Li et al. <ce:cross-ref id=""""crf0055"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>, handles misalignment and photometric and geometric transforms via deep networks. Our deep model is partially motivated by these works but differs from them.</ce:para>""''"'	cites	AGA	
cites	Related work	G. Kunapuli, J. Shavlik, Mirror descent for metric learning: A unified approach , Proceedings of the Joint European Conference on Machine Learning and Knowledge Discovery in Databases, Springer (2012)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0040	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0026		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0009	'Mirror-Descent Metric Learning (MDML), proposed by Kunapuli et al. [40][[ refid=''bib0040'' ]], is a general online Mahalanobis-distance learning framework.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">Metric learning has been a hot research topic, influenced by the pioneering work of Xing et al. <ce:cross-ref id=""""crf0047"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref>. Metric-learning approaches usually focus on the linear metric Mahalanobis distance <mml:math altimg=""""si9.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi mathvariant=""""bold"""">M</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> where <ce:bold>x</ce:bold> and <ce:bold>y</ce:bold> are feature vectors of images <ce:italic>x</ce:italic> and <ce:italic>y</ce:italic>, respectively, and <ce:bold>M</ce:bold> is a PSD matrix. One of the most widely used Mahalanobis-distance learning methods is Large-Margin Nearest Neighbours (LMNN), introduced by Weinberger et al. <ce:cross-ref id=""""crf0048"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref>, which defines the constraints in a local way and has many extensions. Information-Theoretic Metric Learning (ITML) is another important work, proposed by Davis et al. <ce:cross-ref id=""""crf0049"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, which uses LogDet divergence regularization to learn Mahalanobis distance. Qi et al. <ce:cross-ref id=""""crf0050"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> exploited the sparse nature of the high-dimensional feature space and considered the case of high-dimensional data together with few training samples, for which they used LogDet divergence and <ce:italic>L</ce:italic><ce:inf loc=""""post"""">1</ce:inf> regularization together. Mirror-Descent Metric Learning (MDML), proposed by Kunapuli et al. <ce:cross-ref id=""""crf0051"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref>, is a general online Mahalanobis-distance learning framework. Non-Mahalanobis based metric-learning methods have also been proposed, such as kernelizations of the linear method <ce:cross-ref id=""""crf0052"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> and the nonlinear method <ce:cross-ref id=""""crf0053"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>. Deep CNN has already made impressive progress on many computer vision problems, and recently, several deep-CNN based models have been explored for metric learning. Deep Ranking, proposed by Wang et al. <ce:cross-ref id=""""crf0054"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref>, learns fine-grained image similarity; and FPNN, proposed by Li et al. <ce:cross-ref id=""""crf0055"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>, handles misalignment and photometric and geometric transforms via deep networks. Our deep model is partially motivated by these works but differs from them.</ce:para>""''"'	cites	AGA	
cites	Related work	G.-J. Qi, J. Tang, Z.-J. Zha, T.-S. Chua, H.-J. Zhang, An efficient sparse metric learning in high-dimensional space via l 1-penalized log-determinant regularization , Proceedings of the International Conference on Machine Learning (ICML), ACM (2009)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0025		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0013	'Qi et al. [39][[ refid=''bib0039'' ]] exploited the sparse nature of the high-dimensional feature space and considered the case of high-dimensional data together with few training samples, for which they used LogDet divergence and L1 regularization together.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">Metric learning has been a hot research topic, influenced by the pioneering work of Xing et al. <ce:cross-ref id=""""crf0047"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref>. Metric-learning approaches usually focus on the linear metric Mahalanobis distance <mml:math altimg=""""si9.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi mathvariant=""""bold"""">M</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>−</mml:mo><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> where <ce:bold>x</ce:bold> and <ce:bold>y</ce:bold> are feature vectors of images <ce:italic>x</ce:italic> and <ce:italic>y</ce:italic>, respectively, and <ce:bold>M</ce:bold> is a PSD matrix. One of the most widely used Mahalanobis-distance learning methods is Large-Margin Nearest Neighbours (LMNN), introduced by Weinberger et al. <ce:cross-ref id=""""crf0048"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref>, which defines the constraints in a local way and has many extensions. Information-Theoretic Metric Learning (ITML) is another important work, proposed by Davis et al. <ce:cross-ref id=""""crf0049"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, which uses LogDet divergence regularization to learn Mahalanobis distance. Qi et al. <ce:cross-ref id=""""crf0050"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> exploited the sparse nature of the high-dimensional feature space and considered the case of high-dimensional data together with few training samples, for which they used LogDet divergence and <ce:italic>L</ce:italic><ce:inf loc=""""post"""">1</ce:inf> regularization together. Mirror-Descent Metric Learning (MDML), proposed by Kunapuli et al. <ce:cross-ref id=""""crf0051"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref>, is a general online Mahalanobis-distance learning framework. Non-Mahalanobis based metric-learning methods have also been proposed, such as kernelizations of the linear method <ce:cross-ref id=""""crf0052"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> and the nonlinear method <ce:cross-ref id=""""crf0053"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>. Deep CNN has already made impressive progress on many computer vision problems, and recently, several deep-CNN based models have been explored for metric learning. Deep Ranking, proposed by Wang et al. <ce:cross-ref id=""""crf0054"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref>, learns fine-grained image similarity; and FPNN, proposed by Li et al. <ce:cross-ref id=""""crf0055"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>, handles misalignment and photometric and geometric transforms via deep networks. Our deep model is partially motivated by these works but differs from them.</ce:para>""''"'	uses_data_from	AGA	
uses_data_from	Experiment	K. Ricanek, T. Tesafaye, MORPH: a longitudinal image database of normal adult age-progression , Proceedings of the International Conference on Automatic Face and Gesture Recognition (FGR), IEEE (2006)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0043	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0029		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0016	'database [43][[ refid=''bib0043'' ]], the CACD (http://bcsiriuschen.github.io/CARC/).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0039"""" view=""""all"""">We evaluate the performance of our approach on three different databases, they are the MORPH-II<ce:cross-ref id=""""crf0073"""" refid=""""fn0001""""><ce:sup loc=""""post"""">1</ce:sup></ce:cross-ref><ce:footnote id=""""fn0001""""><ce:label>1</ce:label><ce:note-para id=""""cenotep0001"""" view=""""all""""><ce:inter-ref id=""""interref0001"""" xlink:href=""""http://www.faceaginggroup.com/morph/"""" xlink:type=""""simple"""">http://www.faceaginggroup.com/morph/</ce:inter-ref>.</ce:note-para></ce:footnote> database <ce:cross-ref id=""""crf0074"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref>, the CACD<ce:cross-ref id=""""crf0075"""" refid=""""fn0002""""><ce:sup loc=""""post"""">2</ce:sup></ce:cross-ref><ce:footnote id=""""fn0002""""><ce:label>2</ce:label><ce:note-para id=""""cenotep0002"""" view=""""all""""><ce:inter-ref id=""""interref0002"""" xlink:href=""""http://bcsiriuschen.github.io/CARC/"""" xlink:type=""""simple"""">http://bcsiriuschen.github.io/CARC/</ce:inter-ref>.</ce:note-para></ce:footnote> database <ce:cross-ref id=""""crf0076"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> and the FG-NET database <ce:cross-ref id=""""crf0077"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	Y. Li, G. Wang, L. Lin, H. Chang, A deep joint learning approach for age invariant face verification , Proceedings of the Computer Vision CCF Chinese Conference (CCCV) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0008		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0017	'Furthermore, we have tried different network structures, and the experimental results show that our method is also applicable in deeper network; while the work [1][[ refid=''bib0001'' ]] have not demonstrated accuracy gains with increased depth.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">Different from our work, paper <ce:cross-ref id=""""crf0032"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> models the similarity limited to the thresholds. The fluctuation of the thresholds definitely affects the judgement of whether two faces are from the same person. On the contrary, our formulation learns a more general distance metrics, which is not be influenced by the thresholds. In addition, the similarity function of the newly proposed method can be modelled as the weights of fully connected layer, therefore, feature learning and metric learning are integrated together in an end-to-end way. Furthermore, we have tried different network structures, and the experimental results show that our method is also applicable in deeper network; while the work <ce:cross-ref id=""""crf0033"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> have not demonstrated accuracy gains with increased depth. Finally, we evaluate the generalization ability of our approach on more databases than <ce:cross-ref id=""""crf0034"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Introduction	Y. Li, G. Wang, L. Lin, H. Chang, A deep joint learning approach for age invariant face verification , Proceedings of the Computer Vision CCF Chinese Conference (CCCV) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0009		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0018	'Finally, we evaluate the generalization ability of our approach on more databases than [1][[ refid=''bib0001'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">Different from our work, paper <ce:cross-ref id=""""crf0032"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> models the similarity limited to the thresholds. The fluctuation of the thresholds definitely affects the judgement of whether two faces are from the same person. On the contrary, our formulation learns a more general distance metrics, which is not be influenced by the thresholds. In addition, the similarity function of the newly proposed method can be modelled as the weights of fully connected layer, therefore, feature learning and metric learning are integrated together in an end-to-end way. Furthermore, we have tried different network structures, and the experimental results show that our method is also applicable in deeper network; while the work <ce:cross-ref id=""""crf0033"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> have not demonstrated accuracy gains with increased depth. Finally, we evaluate the generalization ability of our approach on more databases than <ce:cross-ref id=""""crf0034"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experiment	A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks , Proceedings of the Advances in Neural Information Processing Systems (NIPS) (2012)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0046	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0040		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0019	'However considering the sufficient pairs in a mini-batch is crucial to our model and deeper network also requires more memory, we use the Alexnet [46][[ refid=''bib0046'' ]] to train a new deeper model to investigate the performance improvement bring by deeper network.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0053"""" view=""""all""""><ce:italic>Influence from the depth of network.</ce:italic> Deeper neural networks have been shown in previous work are beneficial to the performance. However, it isn’t the deeper always better, the accuracy is stagnant or even reduced in some very deep attempts <ce:cross-ref id=""""crf0106"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref>. The CACD database is large enough to be trained by a deeper network. However considering the sufficient pairs in a mini-batch is crucial to our model and deeper network also requires more memory, we use the Alexnet <ce:cross-ref id=""""crf0107"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref> to train a new deeper model to investigate the performance improvement bring by deeper network. The results are reported in <ce:cross-ref id=""""crf0108"""" refid=""""fig0006"""">Fig. 6</ce:cross-ref>, where the blue and red lines present the comparison of different depth. The blue line denotes the result of the deeper model (Ours-3) with same training set as Ours-2. We can observe that on “2004–2006” fold the MAP of deeper model Ours-3 is significantly improved from 0.61 to 0.65, while on “2007–2009” fold the improvement is not obvious. Further, it is obvious that the performance of every method is improve as the age gap is made smaller, which also indicates the undoubted influence of age variation on the retrieval results.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experiment	K.Q. Weinberger, L.K. Saul, Distance metric learning for large margin nearest neighbor classification , J. Mach. Learn. Res. , vol. 10 (2009), pp.207-244	http://dx.doi.org/10.1016/j.patcog.2017.10.015	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0037	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0041		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0020	'Using the identity information as the supervised signal, we first learn the feature with softmax loss, and then adopt LMNN [37][[ refid=''bib0037'' ]] to learn Mahalanobis distance.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0054"""" view=""""all""""><ce:italic>The effectiveness of joint learning.</ce:italic> Our approach integrates feature leaning and distance metric learning via a deep CNN in an end-to-end way. We also investigate the effectiveness of our similarity metric learning. We implement a model with the feature learning and distance metric learning stages performed separately. Using the identity information as the supervised signal, we first learn the feature with softmax loss, and then adopt LMNN <ce:cross-ref id=""""crf0109"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref> to learn Mahalanobis distance. We compare our joint model with the separated model and the experiment result illustrates the better performance of our proposed joint model. In <ce:cross-ref id=""""crf0110"""" refid=""""fig0006"""">Fig. 6</ce:cross-ref>, the green line denotes the separated model, where the MAPs are all lower than 0.4 on three folders, especially, on “2004-2006” fold the MAP is only 0.364. We also show some retrieval examples in <ce:cross-ref id=""""crf0111"""" refid=""""fig0007"""">Fig. 7</ce:cross-ref><ce:float-anchor refid=""""fig0007""""/>. The leftmost column shows the probe images. The right fifteen columns correspond to top-15 retrieval results, and the number on top of each column indicates the rank. The incorrect retrieval results are highlighted by red rectangles. We can see that it is completely correct for the top-15 retrieval results of probe images 4, 5, 7, 9, 10 and 14, in which the expression, hairstyle, head pose, presence of moustache and illumination are varied. For probe-3 and probe-8, the retrieval results include image with make-up changes, and for probe-2 and probe-12, the results include images in which the individual is wearing glasses. These visualized results demonstrate that our method has amazing robustness to expression, hairstyle, head pose, moustache, illumination, make-up and wearing glasses.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experiment	I. Kemelmacher-Shlizerman, S.M. Seitz, D. Miller, E. Brossard, The megaface benchmark: 1 million faces for recognition at scale , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2016)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0047	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0043		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0024	'The experimental setting is the same as that used in [47][[ refid=''bib0047'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0056"""" view=""""all"""">The evaluation of generalization ability of our approach are performed on FG-NET due to its large age span for each person. We use the model trained on CACD directly for the task of identification on FG-NET, and the CACD-VS dataset is used as our gallery of distractors. Given a probe image, the gallery contains one image of the same person and distractors. The algorithm rank orders of all images in the gallery based on similarity to the probe. Specifically, the probe set includes <ce:italic>N</ce:italic> people, and for each person there are <ce:italic>M</ce:italic> images. We test each of the <ce:italic>M</ce:italic> images per individual by adding it into the gallery of distractors and use each of the other <mml:math altimg=""""si59.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math> images as a probe. The experimental setting is the same as that used in <ce:cross-ref id=""""crf0119"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref>. Results are presented using CMC curves. As shown in <ce:cross-ref id=""""crf0120"""" refid=""""fig0009"""">Fig. 9</ce:cross-ref><ce:float-anchor refid=""""fig0009""""/>, the rank-1 accuracy is 33.95%. It does make sense because we only train our model on CACD, while the best result presented in <ce:cross-ref id=""""crf0121"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref> is 38.2%, which is trained on 672 K identities, much more face data than our training samples.</ce:para>""''"'	uses_method_in	AGA	
cites	Introduction	Y. Li, G. Wang, L. Lin, H. Chang, A deep joint learning approach for age invariant face verification , Proceedings of the Computer Vision CCF Chinese Conference (CCCV) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0001		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0025	'The challenges include large intra-subject variation and great inter-subject similarity [1][[ refid=''bib0001'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">Despite the great advances in face-related works in recent years, face recognition across age remains a challenging problem. The challenges include large intra-subject variation and great inter-subject similarity <ce:cross-ref id=""""crf0016"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. The human facial appearance changes greatly with the aging process. From birth to adulthood, the greatest change is craniofacial growth, which involves a change in shape; while from adulthood to old age, the most perceptible change turns skin aging, which involves texture change <ce:cross-ref id=""""crf0017"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>. The changes of the same person are the intra-subject variations. Meanwhile, different persons in same age period may look similar, which is the inter-subject similarity. <ce:cross-ref id=""""crf0018"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref><ce:float-anchor refid=""""fig0001""""/> illustrates the intra-subject variations and inter-subject similarity.</ce:para>""''"'	cites	AGA	
cites	Introduction	Y. Fu, G. Guo, T.S. Huang, Age synthesis and estimation via faces: a survey , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 32 (2010), pp.1955-1976	http://dx.doi.org/10.1016/j.patcog.2017.10.015	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0002	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0002		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0026	'From birth to adulthood, the greatest change is craniofacial growth, which involves a change in shape; while from adulthood to old age, the most perceptible change turns skin aging, which involves texture change [2][[ refid=''bib0002'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">Despite the great advances in face-related works in recent years, face recognition across age remains a challenging problem. The challenges include large intra-subject variation and great inter-subject similarity <ce:cross-ref id=""""crf0016"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. The human facial appearance changes greatly with the aging process. From birth to adulthood, the greatest change is craniofacial growth, which involves a change in shape; while from adulthood to old age, the most perceptible change turns skin aging, which involves texture change <ce:cross-ref id=""""crf0017"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>. The changes of the same person are the intra-subject variations. Meanwhile, different persons in same age period may look similar, which is the inter-subject similarity. <ce:cross-ref id=""""crf0018"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref><ce:float-anchor refid=""""fig0001""""/> illustrates the intra-subject variations and inter-subject similarity.</ce:para>""''"'	cites	AGA	
cites	Introduction	Y. Li, G. Wang, L. Lin, H. Chang, A deep joint learning approach for age invariant face verification , Proceedings of the Computer Vision CCF Chinese Conference (CCCV) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0007		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0040	'Different from our work, paper [1][[ refid=''bib0001'' ]] models the similarity limited to the thresholds.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">Different from our work, paper <ce:cross-ref id=""""crf0032"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> models the similarity limited to the thresholds. The fluctuation of the thresholds definitely affects the judgement of whether two faces are from the same person. On the contrary, our formulation learns a more general distance metrics, which is not be influenced by the thresholds. In addition, the similarity function of the newly proposed method can be modelled as the weights of fully connected layer, therefore, feature learning and metric learning are integrated together in an end-to-end way. Furthermore, we have tried different network structures, and the experimental results show that our method is also applicable in deeper network; while the work <ce:cross-ref id=""""crf0033"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> have not demonstrated accuracy gains with increased depth. Finally, we evaluate the generalization ability of our approach on more databases than <ce:cross-ref id=""""crf0034"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiment	Y. Sun, X. Wang, X. Tang, Deep convolutional network cascade for facial point detection , Proceedings of the Computer Vision and Pattern Recognition (CVPR), IEEE (2013)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0044	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0034		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0046	'We first detect the faces using the method proposed in paper [44][[ refid=''bib0044'' ]] and resize the faces to a uniform size.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0044"""" view=""""all"""">In our architecture, the initial parameters of the convolutional and fully connected layers are set according to two zero-mean Gaussian distributions with standard deviations of 0.01 and 0.001. We first detect the faces using the method proposed in paper <ce:cross-ref id=""""crf0082"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> and resize the faces to a uniform size. We set learning rate <ce:italic>α</ce:italic> and weight decay <ce:italic>λ</ce:italic> to 0.001 and 0.0005 respectively. How to set them is present in <ce:cross-ref id=""""crf0083"""" refid=""""sec0016"""">Section 4.3</ce:cross-ref>.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experiment	B.-C. Chen, C.-S. Chen, W.H. Hsu, Cross-age reference coding for age-invariant face recognition and retrieval , Proceedings of the European Conference on Computer Vision (ECCV), Springer (2014)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0030	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0037		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0047	'The experimental setting is the same as in [30][[ refid=''bib0030'' ]], and we divide the rest of the images into three folders: images taken in 2004–2006, in 2007–2009 and in 2010–2012.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0050"""" view=""""all"""">Age-invariant face retrieval means finding those images that are matched to the probe image in gallery, where the age gap between the probe image and the matched images in gallery is large. We use images taken in 2013 as query images and find the same person’s images from among the rest of the images; that is, images taken in 2013 are probe images, and the rest of the images are gallery images. The experimental setting is the same as in <ce:cross-ref id=""""crf0100"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, and we divide the rest of the images into three folders: images taken in 2004–2006, in 2007–2009 and in 2010–2012. We compare our deep-CNN model with several state-of-the-art methods, including CARC <ce:cross-ref id=""""crf0101"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> and HFA <ce:cross-ref id=""""crf0102"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_method_in	AGA	
cites	Experiment	Y. Wen, Z. Li, Y. Qiao, Latent factor guided convolutional neural networks for age-invariant face recognition , Proceedings of the Computer Vision and Pattern Recognition (CVPR) (2016)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0035	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0036		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0048	'Note that we train our model only on the MORPH dataset for fair comparison, while the newest deep model on age invariant face recognition proposed in [35][[ refid=''bib0035'' ]] is pretrained on several other face datasets.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0049"""" view=""""all"""">We compare our deep CNN model with several state-of-the-art methods for age-invariant face recognition on MORPH-II, including MFDA <ce:cross-ref id=""""crf0088"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>, HFA <ce:cross-ref id=""""crf0089"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>, CARC <ce:cross-ref id=""""crf0090"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, LPS+HFA <ce:cross-ref id=""""crf0091"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> and the method proposed in paper <ce:cross-ref id=""""crf0092"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>. The comparison of the results is reported in <ce:cross-ref id=""""crf0093"""" refid=""""tbl0002"""">Table 2</ce:cross-ref><ce:float-anchor refid=""""tbl0002""""/>. Note that we train our model only on the MORPH dataset for fair comparison, while the newest deep model on age invariant face recognition proposed in <ce:cross-ref id=""""crf0094"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> is pretrained on several other face datasets. It is difficult to distinguish the performance improvement comes from the method itself or the large-scale training data with different scale of training set. So we do not compare our results with it. It is encouraging to see that our approach achieves very competitive results compared to other state-of-the-art methods trained only on MORPH. For the top-10 and top-20 cases, our model achieves recognition accuracies of 98.8% and 99.34%, respectively. The CMC curve is shown in <ce:cross-ref id=""""crf0095"""" refid=""""fig0005"""">Fig. 5</ce:cross-ref><ce:float-anchor refid=""""fig0005""""/>. It should be noted that the result is better than the results in <ce:cross-ref id=""""crf0096"""" refid=""""fig0003"""">Figs. 3</ce:cross-ref> and<ce:cross-ref id=""""crf0097"""" refid=""""fig0004"""">4</ce:cross-ref> because the recognition accuracies in <ce:cross-ref id=""""crf0098"""" refid=""""fig0003"""">Figs. 3</ce:cross-ref> and<ce:cross-ref id=""""crf0099"""" refid=""""fig0004"""">4</ce:cross-ref> are obtained after the same number of iterations for each different strategy in mini-batch selection.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experiment	B.-C. Chen, C.-S. Chen, W.H. Hsu, Cross-age reference coding for age-invariant face recognition and retrieval , Proceedings of the European Conference on Computer Vision (ECCV), Springer (2014)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0030>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0036>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0051	'The experimental setting is the same as in [30][[ refid=''bib0030'' ]], and we divide the rest of the images into three folders: images taken in 2004–2006, in 2007–2009 and in 2010–2012.'			FDY+AGA	infered_pred1
cites	Experiment	B.-C. Chen, C.-S. Chen, W. Hsu, Face recognition and retrieval using cross-age reference coding with cross-age celebrity dataset , IEEE Trans. Multimedia , vol. 17 (2015), pp.804-815	http://dx.doi.org/10.1016/j.patcog.2017.10.015	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0031	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0033		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0053	'Based on the CACD database, Chen et al. [31][[ refid=''bib0031'' ]] developed a verification subset called CACD-VS, which contains 2000 positive pairs and 2000 negative pairs.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0041"""" view=""""all"""">The CACD database is a large-scale database, released in 2014, which contains more than 160,000 images of 2000 celebrities. The images in CACD are challenging because they vary in age, pose, illumination and occlusion. However, images of only 200 celebrities were manually checked originally. The studies using this dataset are based on these previously manually checked images. We extend the set of manually checked images to 500 celebrities. To make the results comparable with those of previous works, we adopt the original 200 individuals and along with 500 new individuals. We use the mean average precision (MAP) to measure the performance (see <ce:cross-ref id=""""crf0080"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> for the MAP calculation). Based on the CACD database, Chen et al. <ce:cross-ref id=""""crf0081"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> developed a verification subset called CACD-VS, which contains 2000 positive pairs and 2000 negative pairs. Two images of each positive pair come from the same person but with a large age interval. CACD-VS is used to evaluate the performance of face verification across age, which differs from the famous LFW database. We report verification results with receiver-operating characteristic (ROC) curves, which explores the trade off between falsely accepting unmatched pairs and falsely rejecting matched pairs.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experiment	B.-C. Chen, C.-S. Chen, W. Hsu, Face recognition and retrieval using cross-age reference coding with cross-age celebrity dataset , IEEE Trans. Multimedia , vol. 17 (2015), pp.804-815	http://dx.doi.org/10.1016/j.patcog.2017.10.015	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0031	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0032		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0054	'We use the mean average precision (MAP) to measure the performance (see [31][[ refid=''bib0031'' ]] for the MAP calculation).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0041"""" view=""""all"""">The CACD database is a large-scale database, released in 2014, which contains more than 160,000 images of 2000 celebrities. The images in CACD are challenging because they vary in age, pose, illumination and occlusion. However, images of only 200 celebrities were manually checked originally. The studies using this dataset are based on these previously manually checked images. We extend the set of manually checked images to 500 celebrities. To make the results comparable with those of previous works, we adopt the original 200 individuals and along with 500 new individuals. We use the mean average precision (MAP) to measure the performance (see <ce:cross-ref id=""""crf0080"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> for the MAP calculation). Based on the CACD database, Chen et al. <ce:cross-ref id=""""crf0081"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> developed a verification subset called CACD-VS, which contains 2000 positive pairs and 2000 negative pairs. Two images of each positive pair come from the same person but with a large age interval. CACD-VS is used to evaluate the performance of face verification across age, which differs from the famous LFW database. We report verification results with receiver-operating characteristic (ROC) curves, which explores the trade off between falsely accepting unmatched pairs and falsely rejecting matched pairs.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experiment	A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks , Proceedings of the Advances in Neural Information Processing Systems (NIPS) (2012)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0046>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0039>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0057	'However considering the sufficient pairs in a mini-batch is crucial to our model and deeper network also requires more memory, we use the Alexnet [46][[ refid=''bib0046'' ]] to train a new deeper model to investigate the performance improvement bring by deeper network.'			FDY+AGA	infered_pred1
cites	Related work	Z. Li, D. Gong, X. Li, D. Tao, Aging face recognition: a hierarchical learning model based on local patterns selection , IEEE Trans. Image Process. , vol. 25 (2016), pp.2146-2154	http://dx.doi.org/10.1016/j.patcog.2017.10.015	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0033	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0019		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0058	'Li et al. [33][[ refid=''bib0033'' ]] proposed a two-level hierarchical-learning model with a new feature descriptor called local pattern selection (LPS) to address this problem.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">In the past, most age-related works focused on age estimation <ce:cross-refs id=""""crfs0002"""" refid=""""bib0003 bib0016 bib0017 bib0018 bib0019 bib0020 bib0021 bib0022 bib0023"""">[3,16–23][[ refid=''''bib0003 bib0016 bib0017 bib0018 bib0019 bib0020 bib0021 bib0022 bib0023'''' ]]</ce:cross-refs>, including exact-age estimation and age-group estimation. In recent years, many works focused on age-invariant recognition. In <ce:cross-ref id=""""crf0035"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, Park et al. proposed a 3D facial-aging model and simulation method, which used a generative approach and tried to compensate for the lack of age information for the 3D facial-images before recognition. Li et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> proposed a multi-feature discriminant-analysis (MFDA) method, in which each face was represented by patch-based SIFT and LBP descriptors and faces were recognized using a variation of random-subspace LDA. Sungatullina et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> also used the multi-feature descriptor and further proposed a multi-view discriminative-learning (MDL) method. Bereta et al. <ce:cross-ref id=""""crf0038"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> quantified abilities of local descriptors commonly used in face recognition, and gave a comparison among them in the context of age discrimination. Gong et al. <ce:cross-ref id=""""crf0039"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> proposed a hidden-factor analysis (HFA) method, in which they supposed that there are two hidden factors, age and identity, that influence facial appearance. They further proposed a maximum-entropy feature descriptor (MEFD) using the identity-factor analysis (IFA) matching method in <ce:cross-ref id=""""crf0040"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> to improve the HFA. It is worth noting that in 2014, Chen et al. <ce:cross-refs id=""""crfs0003"""" refid=""""bib0030 bib0031"""">[30,31][[ refid=''''bib0030 bib0031'''' ]]</ce:cross-refs> released a new age-related face dataset named CACD; since then, almost all the works on age-invariant face recognition have performed their experiments using it. Bouchaffra <ce:cross-ref id=""""crf0041"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> introduced a novel formalism that performed dimensionality reduction and captured topological features to conduct pattern classification. More recently, several works have applied the hierarchical and deep models for age-invariant face recognition. Li et al. <ce:cross-ref id=""""crf0042"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> proposed a two-level hierarchical-learning model with a new feature descriptor called local pattern selection (LPS) to address this problem. Two newer works <ce:cross-refs id=""""crfs0004"""" refid=""""bib0034 bib0035"""">[34,35][[ refid=''''bib0034 bib0035'''' ]]</ce:cross-refs> adopting deep models both represented the face images using three components as <ce:cross-ref id=""""crf0043"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>; paper <ce:cross-ref id=""""crf0044"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> used a coupled auto-encoder networks (CAN); and paper <ce:cross-ref id=""""crf0045"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> used CNNs to obtain identity features for face recognition. Although the work in <ce:cross-ref id=""""crf0046"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> used CNN, the parameters in the convolutional unit and in the fully connected layer were updated separately; to some extent, the CNN was only used to extract features. Our work is different from this in an essential aspect: in our model, feature learning and distance-metric learning are integrated seamlessly in an end-to-end way and the parameters are updated jointly via SGD.</ce:para>""''"'	cites	AGA	
cites	Related work	D. Bouchaffra, Nonlinear topological component analysis: application to age-invariant face recognition , IEEE Trans. Neural Netw. Learn. Syst. , vol. 26 (2015), pp.1375-1387	http://dx.doi.org/10.1016/j.patcog.2017.10.015	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0032	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0018		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0059	'Bouchaffra [32][[ refid=''bib0032'' ]] introduced a novel formalism that performed dimensionality reduction and captured topological features to conduct pattern classification.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">In the past, most age-related works focused on age estimation <ce:cross-refs id=""""crfs0002"""" refid=""""bib0003 bib0016 bib0017 bib0018 bib0019 bib0020 bib0021 bib0022 bib0023"""">[3,16–23][[ refid=''''bib0003 bib0016 bib0017 bib0018 bib0019 bib0020 bib0021 bib0022 bib0023'''' ]]</ce:cross-refs>, including exact-age estimation and age-group estimation. In recent years, many works focused on age-invariant recognition. In <ce:cross-ref id=""""crf0035"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, Park et al. proposed a 3D facial-aging model and simulation method, which used a generative approach and tried to compensate for the lack of age information for the 3D facial-images before recognition. Li et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> proposed a multi-feature discriminant-analysis (MFDA) method, in which each face was represented by patch-based SIFT and LBP descriptors and faces were recognized using a variation of random-subspace LDA. Sungatullina et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> also used the multi-feature descriptor and further proposed a multi-view discriminative-learning (MDL) method. Bereta et al. <ce:cross-ref id=""""crf0038"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> quantified abilities of local descriptors commonly used in face recognition, and gave a comparison among them in the context of age discrimination. Gong et al. <ce:cross-ref id=""""crf0039"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> proposed a hidden-factor analysis (HFA) method, in which they supposed that there are two hidden factors, age and identity, that influence facial appearance. They further proposed a maximum-entropy feature descriptor (MEFD) using the identity-factor analysis (IFA) matching method in <ce:cross-ref id=""""crf0040"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> to improve the HFA. It is worth noting that in 2014, Chen et al. <ce:cross-refs id=""""crfs0003"""" refid=""""bib0030 bib0031"""">[30,31][[ refid=''''bib0030 bib0031'''' ]]</ce:cross-refs> released a new age-related face dataset named CACD; since then, almost all the works on age-invariant face recognition have performed their experiments using it. Bouchaffra <ce:cross-ref id=""""crf0041"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> introduced a novel formalism that performed dimensionality reduction and captured topological features to conduct pattern classification. More recently, several works have applied the hierarchical and deep models for age-invariant face recognition. Li et al. <ce:cross-ref id=""""crf0042"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> proposed a two-level hierarchical-learning model with a new feature descriptor called local pattern selection (LPS) to address this problem. Two newer works <ce:cross-refs id=""""crfs0004"""" refid=""""bib0034 bib0035"""">[34,35][[ refid=''''bib0034 bib0035'''' ]]</ce:cross-refs> adopting deep models both represented the face images using three components as <ce:cross-ref id=""""crf0043"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>; paper <ce:cross-ref id=""""crf0044"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> used a coupled auto-encoder networks (CAN); and paper <ce:cross-ref id=""""crf0045"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> used CNNs to obtain identity features for face recognition. Although the work in <ce:cross-ref id=""""crf0046"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> used CNN, the parameters in the convolutional unit and in the fully connected layer were updated separately; to some extent, the CNN was only used to extract features. Our work is different from this in an essential aspect: in our model, feature learning and distance-metric learning are integrated seamlessly in an end-to-end way and the parameters are updated jointly via SGD.</ce:para>""''"'	cites	AGA	
cites	Related work	D. Sungatullina, J. Lu, G. Wang, P. Moulin, Multiview discriminative learning for age-invariant face recognition , Proceedings of the International Conference and Workshops on Automatic Face and Gesture Recognition (FG), IEEE (2013)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0026	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0013		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0060	'Sungatullina et al. [26][[ refid=''bib0026'' ]] also used the multi-feature descriptor and further proposed a multi-view discriminative-learning (MDL) method.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">In the past, most age-related works focused on age estimation <ce:cross-refs id=""""crfs0002"""" refid=""""bib0003 bib0016 bib0017 bib0018 bib0019 bib0020 bib0021 bib0022 bib0023"""">[3,16–23][[ refid=''''bib0003 bib0016 bib0017 bib0018 bib0019 bib0020 bib0021 bib0022 bib0023'''' ]]</ce:cross-refs>, including exact-age estimation and age-group estimation. In recent years, many works focused on age-invariant recognition. In <ce:cross-ref id=""""crf0035"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, Park et al. proposed a 3D facial-aging model and simulation method, which used a generative approach and tried to compensate for the lack of age information for the 3D facial-images before recognition. Li et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> proposed a multi-feature discriminant-analysis (MFDA) method, in which each face was represented by patch-based SIFT and LBP descriptors and faces were recognized using a variation of random-subspace LDA. Sungatullina et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> also used the multi-feature descriptor and further proposed a multi-view discriminative-learning (MDL) method. Bereta et al. <ce:cross-ref id=""""crf0038"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> quantified abilities of local descriptors commonly used in face recognition, and gave a comparison among them in the context of age discrimination. Gong et al. <ce:cross-ref id=""""crf0039"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> proposed a hidden-factor analysis (HFA) method, in which they supposed that there are two hidden factors, age and identity, that influence facial appearance. They further proposed a maximum-entropy feature descriptor (MEFD) using the identity-factor analysis (IFA) matching method in <ce:cross-ref id=""""crf0040"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> to improve the HFA. It is worth noting that in 2014, Chen et al. <ce:cross-refs id=""""crfs0003"""" refid=""""bib0030 bib0031"""">[30,31][[ refid=''''bib0030 bib0031'''' ]]</ce:cross-refs> released a new age-related face dataset named CACD; since then, almost all the works on age-invariant face recognition have performed their experiments using it. Bouchaffra <ce:cross-ref id=""""crf0041"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> introduced a novel formalism that performed dimensionality reduction and captured topological features to conduct pattern classification. More recently, several works have applied the hierarchical and deep models for age-invariant face recognition. Li et al. <ce:cross-ref id=""""crf0042"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> proposed a two-level hierarchical-learning model with a new feature descriptor called local pattern selection (LPS) to address this problem. Two newer works <ce:cross-refs id=""""crfs0004"""" refid=""""bib0034 bib0035"""">[34,35][[ refid=''''bib0034 bib0035'''' ]]</ce:cross-refs> adopting deep models both represented the face images using three components as <ce:cross-ref id=""""crf0043"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>; paper <ce:cross-ref id=""""crf0044"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> used a coupled auto-encoder networks (CAN); and paper <ce:cross-ref id=""""crf0045"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> used CNNs to obtain identity features for face recognition. Although the work in <ce:cross-ref id=""""crf0046"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> used CNN, the parameters in the convolutional unit and in the fully connected layer were updated separately; to some extent, the CNN was only used to extract features. Our work is different from this in an essential aspect: in our model, feature learning and distance-metric learning are integrated seamlessly in an end-to-end way and the parameters are updated jointly via SGD.</ce:para>""''"'	cites	AGA	
cites	Related work	Z. Li, U. Park, A.K. Jain, A discriminative model for age invariant face recognition , IEEE Trans. Inf. Forensics Secur. , vol. 6 (2011), pp.1028-1037	http://dx.doi.org/10.1016/j.patcog.2017.10.015	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0025	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0012		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0061	'Li et al. [25][[ refid=''bib0025'' ]] proposed a multi-feature discriminant-analysis (MFDA) method, in which each face was represented by patch-based SIFT and LBP descriptors and faces were recognized using a variation of random-subspace LDA.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">In the past, most age-related works focused on age estimation <ce:cross-refs id=""""crfs0002"""" refid=""""bib0003 bib0016 bib0017 bib0018 bib0019 bib0020 bib0021 bib0022 bib0023"""">[3,16–23][[ refid=''''bib0003 bib0016 bib0017 bib0018 bib0019 bib0020 bib0021 bib0022 bib0023'''' ]]</ce:cross-refs>, including exact-age estimation and age-group estimation. In recent years, many works focused on age-invariant recognition. In <ce:cross-ref id=""""crf0035"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, Park et al. proposed a 3D facial-aging model and simulation method, which used a generative approach and tried to compensate for the lack of age information for the 3D facial-images before recognition. Li et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> proposed a multi-feature discriminant-analysis (MFDA) method, in which each face was represented by patch-based SIFT and LBP descriptors and faces were recognized using a variation of random-subspace LDA. Sungatullina et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> also used the multi-feature descriptor and further proposed a multi-view discriminative-learning (MDL) method. Bereta et al. <ce:cross-ref id=""""crf0038"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> quantified abilities of local descriptors commonly used in face recognition, and gave a comparison among them in the context of age discrimination. Gong et al. <ce:cross-ref id=""""crf0039"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> proposed a hidden-factor analysis (HFA) method, in which they supposed that there are two hidden factors, age and identity, that influence facial appearance. They further proposed a maximum-entropy feature descriptor (MEFD) using the identity-factor analysis (IFA) matching method in <ce:cross-ref id=""""crf0040"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> to improve the HFA. It is worth noting that in 2014, Chen et al. <ce:cross-refs id=""""crfs0003"""" refid=""""bib0030 bib0031"""">[30,31][[ refid=''''bib0030 bib0031'''' ]]</ce:cross-refs> released a new age-related face dataset named CACD; since then, almost all the works on age-invariant face recognition have performed their experiments using it. Bouchaffra <ce:cross-ref id=""""crf0041"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> introduced a novel formalism that performed dimensionality reduction and captured topological features to conduct pattern classification. More recently, several works have applied the hierarchical and deep models for age-invariant face recognition. Li et al. <ce:cross-ref id=""""crf0042"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> proposed a two-level hierarchical-learning model with a new feature descriptor called local pattern selection (LPS) to address this problem. Two newer works <ce:cross-refs id=""""crfs0004"""" refid=""""bib0034 bib0035"""">[34,35][[ refid=''''bib0034 bib0035'''' ]]</ce:cross-refs> adopting deep models both represented the face images using three components as <ce:cross-ref id=""""crf0043"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>; paper <ce:cross-ref id=""""crf0044"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> used a coupled auto-encoder networks (CAN); and paper <ce:cross-ref id=""""crf0045"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> used CNNs to obtain identity features for face recognition. Although the work in <ce:cross-ref id=""""crf0046"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> used CNN, the parameters in the convolutional unit and in the fully connected layer were updated separately; to some extent, the CNN was only used to extract features. Our work is different from this in an essential aspect: in our model, feature learning and distance-metric learning are integrated seamlessly in an end-to-end way and the parameters are updated jointly via SGD.</ce:para>""''"'	cites	AGA	
cites	Related work	D. Gong, Z. Li, D. Lin, J. Liu, X. Tang, Hidden factor analysis for age invariant face recognition , Proceedings of the International Conference on Computer Vision (ICCV), IEEE (2013)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0028	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0015		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0075	'Gong et al. [28][[ refid=''bib0028'' ]] proposed a hidden-factor analysis (HFA) method, in which they supposed that there are two hidden factors, age and identity, that influence facial appearance.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">In the past, most age-related works focused on age estimation <ce:cross-refs id=""""crfs0002"""" refid=""""bib0003 bib0016 bib0017 bib0018 bib0019 bib0020 bib0021 bib0022 bib0023"""">[3,16–23][[ refid=''''bib0003 bib0016 bib0017 bib0018 bib0019 bib0020 bib0021 bib0022 bib0023'''' ]]</ce:cross-refs>, including exact-age estimation and age-group estimation. In recent years, many works focused on age-invariant recognition. In <ce:cross-ref id=""""crf0035"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, Park et al. proposed a 3D facial-aging model and simulation method, which used a generative approach and tried to compensate for the lack of age information for the 3D facial-images before recognition. Li et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> proposed a multi-feature discriminant-analysis (MFDA) method, in which each face was represented by patch-based SIFT and LBP descriptors and faces were recognized using a variation of random-subspace LDA. Sungatullina et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> also used the multi-feature descriptor and further proposed a multi-view discriminative-learning (MDL) method. Bereta et al. <ce:cross-ref id=""""crf0038"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> quantified abilities of local descriptors commonly used in face recognition, and gave a comparison among them in the context of age discrimination. Gong et al. <ce:cross-ref id=""""crf0039"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> proposed a hidden-factor analysis (HFA) method, in which they supposed that there are two hidden factors, age and identity, that influence facial appearance. They further proposed a maximum-entropy feature descriptor (MEFD) using the identity-factor analysis (IFA) matching method in <ce:cross-ref id=""""crf0040"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> to improve the HFA. It is worth noting that in 2014, Chen et al. <ce:cross-refs id=""""crfs0003"""" refid=""""bib0030 bib0031"""">[30,31][[ refid=''''bib0030 bib0031'''' ]]</ce:cross-refs> released a new age-related face dataset named CACD; since then, almost all the works on age-invariant face recognition have performed their experiments using it. Bouchaffra <ce:cross-ref id=""""crf0041"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> introduced a novel formalism that performed dimensionality reduction and captured topological features to conduct pattern classification. More recently, several works have applied the hierarchical and deep models for age-invariant face recognition. Li et al. <ce:cross-ref id=""""crf0042"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> proposed a two-level hierarchical-learning model with a new feature descriptor called local pattern selection (LPS) to address this problem. Two newer works <ce:cross-refs id=""""crfs0004"""" refid=""""bib0034 bib0035"""">[34,35][[ refid=''''bib0034 bib0035'''' ]]</ce:cross-refs> adopting deep models both represented the face images using three components as <ce:cross-ref id=""""crf0043"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>; paper <ce:cross-ref id=""""crf0044"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> used a coupled auto-encoder networks (CAN); and paper <ce:cross-ref id=""""crf0045"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> used CNNs to obtain identity features for face recognition. Although the work in <ce:cross-ref id=""""crf0046"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> used CNN, the parameters in the convolutional unit and in the fully connected layer were updated separately; to some extent, the CNN was only used to extract features. Our work is different from this in an essential aspect: in our model, feature learning and distance-metric learning are integrated seamlessly in an end-to-end way and the parameters are updated jointly via SGD.</ce:para>""''"'	cites	AGA	
cites	Experiment	I. Kemelmacher-Shlizerman, S.M. Seitz, D. Miller, E. Brossard, The megaface benchmark: 1 million faces for recognition at scale , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2016)	http://dx.doi.org/10.1016/j.patcog.2017.10.015	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/br/bib0047	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/ctx/ctx0044		44	3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-015/itrp/0077	'It does make sense because we only train our model on CACD, while the best result presented in [47][[ refid=''bib0047'' ]] is 38.2%, which is trained on 672 K identities, much more face data than our training samples.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0056"""" view=""""all"""">The evaluation of generalization ability of our approach are performed on FG-NET due to its large age span for each person. We use the model trained on CACD directly for the task of identification on FG-NET, and the CACD-VS dataset is used as our gallery of distractors. Given a probe image, the gallery contains one image of the same person and distractors. The algorithm rank orders of all images in the gallery based on similarity to the probe. Specifically, the probe set includes <ce:italic>N</ce:italic> people, and for each person there are <ce:italic>M</ce:italic> images. We test each of the <ce:italic>M</ce:italic> images per individual by adding it into the gallery of distractors and use each of the other <mml:math altimg=""""si59.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>M</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math> images as a probe. The experimental setting is the same as that used in <ce:cross-ref id=""""crf0119"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref>. Results are presented using CMC curves. As shown in <ce:cross-ref id=""""crf0120"""" refid=""""fig0009"""">Fig. 9</ce:cross-ref><ce:float-anchor refid=""""fig0009""""/>, the rank-1 accuracy is 33.95%. It does make sense because we only train our model on CACD, while the best result presented in <ce:cross-ref id=""""crf0121"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref> is 38.2%, which is trained on 672 K identities, much more face data than our training samples.</ce:para>""''"'	uses_data_from	AGA	
cites	Method	Y. Bengio, N.L. Roux, P. Vincent, O. Delalleau, P. Marcotte, Convex neural networks , Advances in Neural Information Processing Systems (2005)	http://dx.doi.org/10.1016/j.patcog.2017.10.017	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0056	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0022		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0001	'Autoencoder loss is the Euclidean loss between input and output tensors given by ∥x¯−x¯o∥2 whereas −∑jyjlog(eoj∑keok) is the softmax loss from the predictor [56][[ refid=''bib0056'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0021"""" view=""""all""""><ce:cross-ref id=""""crf0038"""" refid=""""eq0001"""">Eq. (1)</ce:cross-ref> defines semi-supervised learner loss by combining the loss terms from predictor and autoencoder neural networks. Here <ce:italic>y<ce:inf loc=""""post"""">j</ce:inf></ce:italic> refers to the input labels to represent each facial expression uniquely while <ce:italic>o<ce:inf loc=""""post"""">k</ce:inf></ce:italic> are the outputs from the final layer of predictor neural net. Also <mml:math altimg=""""si8.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mover accent=""""true""""><mml:mi>x</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math> is the input tensor (<mml:math altimg=""""si9.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant=""""double-struck"""">R</mml:mi><mml:mrow><mml:mn>145</mml:mn><mml:mo>×</mml:mo><mml:mn>145</mml:mn><mml:mo>×</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math>) and <mml:math altimg=""""si10.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msub><mml:mover accent=""""true""""><mml:mi>x</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>o</mml:mi></mml:msub></mml:math> is the corresponding output from autoencoder. Autoencoder loss is the Euclidean loss between input and output tensors given by <mml:math altimg=""""si11.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mover accent=""""true""""><mml:mi>x</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:msub><mml:mover accent=""""true""""><mml:mi>x</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>o</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math> whereas <mml:math altimg=""""si12.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:msub><mml:mi>o</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:msup><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:msup><mml:mi>e</mml:mi><mml:msub><mml:mi>o</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msup></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math> is the softmax loss from the predictor <ce:cross-ref id=""""crf0039"""" refid=""""bib0056"""">[56][[ refid=''''bib0056'''' ]]</ce:cross-ref>. Each step of stochastic gradient descent is performed over a batch of 22 inputs and loss is obtained by adding loss terms for the entire batch. At the commencement of training of the predictor layers, we select values of <ce:italic>β</ce:italic> which make softmax loss term an order of magnitude higher than the Euclidean loss term (see <ce:cross-ref id=""""crf0040"""" refid=""""eq0001"""">Eq. (1)</ce:cross-ref>). We continue training predictor layers by gradually decreasing loss coefficient <ce:italic>α</ce:italic> alongside of softmax loss to prevent overfitting of autoencoder. Amalgamation of predictor and autoencoder architectures is depicted in <ce:cross-ref id=""""crf0041"""" refid=""""fig0003"""">Fig. 3</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
uses_method_in	Datasets and implementation	A. Asthana, S. Zafeiriou, S. Cheng, M. Pantic, Incremental face alignment in the wild , Proceedings of Conference on Computer Vision and Pattern Recognition, IEEE (2014)	http://dx.doi.org/10.1016/j.patcog.2017.10.017	data	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0057	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0023		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0002	'As an additional step we obtained the facial pose information by using active appearance models and generating facial landmarks [57][[ refid=''bib0057'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0027"""" view=""""all"""">As an additional step we obtained the facial pose information by using active appearance models and generating facial landmarks <ce:cross-ref id=""""crf0049"""" refid=""""bib0057"""">[57][[ refid=''''bib0057'''' ]]</ce:cross-ref>. We fitted the facial landmarks to a 3<ce:italic>D</ce:italic> deformable model and restricted our dataset to clips containing less than 30 degrees of yaw, pitch or roll, thereby eliminating faces looking sideways. For data generation, we relied on daily feeds from news sources such as CNN, MSNBC, FOX and CSPAN. Collection of this dataset required development of an automated system to mine video clips, segment faces and filter meaningful data and it took us more than 6 months to collect the entire dataset. To our knowledge this is the largest dataset containing facial video clips and we plan to share it with scientific community by making it public.</ce:para>""''"'	cites	AGA	
uses_method_in	Method	A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks , Advances in Neural Information Processing Systems (2012)	http://dx.doi.org/10.1016/j.patcog.2017.10.017	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0015>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0020>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0003	'The autoencoder topology is inspired by ImageNet [15][[ refid=''bib0015'' ]] and comprises of convolutional layers gradually reducing data dimensionality until we reach a fully connected layer.'			FDY+AGA	infered_pred1
cites	Datasets and implementation	M. Valstar, M. Pantic, Induced disgust, happiness and surprise: an addition to the MMI facial expression database , Workshop on EMOTION: Corpora for Research on Emotion and Affect (2010)	http://dx.doi.org/10.1016/j.patcog.2017.10.017	data	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0060	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0026		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0005	'MMI which originally contained only posed facial expressions, was recently extended to include natural versions of happiness, disgust and surprise [60][[ refid=''bib0060'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0029"""" view=""""all"""">MMI facial expression dataset <ce:cross-ref id=""""crf0051"""" refid=""""bib0059"""">[59][[ refid=''''bib0059'''' ]]</ce:cross-ref> involves an ongoing effort for representing both enacted and induced facial expressions. The dataset comprises of 2894 video samples out of which around 200 video clips are labeled for six basic emotions. The clips contain faces going from blank expression to the peak emotion and then back to neutral facial expression. MMI which originally contained only posed facial expressions, was recently extended to include natural versions of happiness, disgust and surprise <ce:cross-ref id=""""crf0052"""" refid=""""bib0060"""">[60][[ refid=''''bib0060'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Datasets and implementation	O. Gupta, D. Raviv, R. Raskar, Multi-velocity neural networks for facial expression recognition in videos , IEEE Trans. Affect. Comput. , vol. pp (2017), pp.1-99	http://dx.doi.org/10.1016/j.patcog.2017.10.017	data	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0054	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0027		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0006	'We developed specialized video recording and annotation tools to collect and label facial expressions (first presented in [54][[ refid=''bib0054'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0030"""" view=""""all"""">We developed specialized video recording and annotation tools to collect and label facial expressions (first presented in <ce:cross-ref id=""""crf0053"""" refid=""""bib0054"""">[54][[ refid=''''bib0054'''' ]]</ce:cross-ref>). The application was developed in Python programming language and we used well known libraries such as OpenCV for video capture and annotation. The database contains facial clips from 160 subjects (both male and female), where expressions were artificially generated according to a specific request, or genuinely given due to a shown stimulus. We captured 1032 clips for posed expressions and 1745 clips for induced facial expressions amounting to a total of 2777 video clips. Genuine facial expressions were induced in subjects using visual stimuli, i.e. videos selected randomly from a bank of Youtube videos to generate a specific emotion. Please refer to <ce:cross-ref id=""""crf0054"""" refid=""""tbl0003"""">Table 3</ce:cross-ref> to see the distribution of database, where posed clips refers to the artificially generated expressions and non-posed refers to the stimulus activation procedure.</ce:para>""''"'	cites	AGA	
cites	Datasets and implementation	P. Lucey, J.F. Cohn, T. Kanade, J. Saragih, Z. Ambadar, I. Matthews, The extended Cohn-Kanade dataset (CK+): a complete dataset for action unit and emotion-specified expression , Proceedings of IEEE Computer Vision and Pattern Recognition Workshops (2010)	http://dx.doi.org/10.1016/j.patcog.2017.10.017	data	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0058	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0024		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0007	'The Cohn Kanade dataset [58][[ refid=''bib0058'' ]] is one of the oldest and well known dataset containing facial expression video clips.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0028"""" view=""""all"""">The Cohn Kanade dataset <ce:cross-ref id=""""crf0050"""" refid=""""bib0058"""">[58][[ refid=''''bib0058'''' ]]</ce:cross-ref> is one of the oldest and well known dataset containing facial expression video clips. It contains a total of 593 video clip sequences from which 327 clips are labeled for seven basic emotions (most of these are <ce:italic>posed</ce:italic>). Clips contain the frontal view of face performing facial expression varying from neutral expression to maximum intensity of emotion. While the dataset contains a lot of natural smile expressions it lacks diversity of induced samples for other facial expressions.</ce:para>""''"'	uses_data_from	AGA	
cites	Datasets and implementation	M. Pantic, M. Valstar, R. Rademaker, L. Maat, Web-based database for facial expression analysis , International Conference on Multimedia and Expo, IEEE (2005)	http://dx.doi.org/10.1016/j.patcog.2017.10.017	data	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0059	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0025		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0008	'MMI facial expression dataset [59][[ refid=''bib0059'' ]] involves an ongoing effort for representing both enacted and induced facial expressions.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0029"""" view=""""all"""">MMI facial expression dataset <ce:cross-ref id=""""crf0051"""" refid=""""bib0059"""">[59][[ refid=''''bib0059'''' ]]</ce:cross-ref> involves an ongoing effort for representing both enacted and induced facial expressions. The dataset comprises of 2894 video samples out of which around 200 video clips are labeled for six basic emotions. The clips contain faces going from blank expression to the peak emotion and then back to neutral facial expression. MMI which originally contained only posed facial expressions, was recently extended to include natural versions of happiness, disgust and surprise <ce:cross-ref id=""""crf0052"""" refid=""""bib0060"""">[60][[ refid=''''bib0060'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experiments and results	Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, T. Darrell, Caffe: convolutional architecture for fast feature embedding , Proceedings of the 22nd ACM International Conference on Multimedia, ACM (2014)	http://dx.doi.org/10.1016/j.patcog.2017.10.017	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0062>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0029>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0011	'Our neural network was implemented using the Caffe framework [62][[ refid=''bib0062'' ]] and trained using NVIDIA Tesla K40 GPUs.'			FDY+AGA	infered_pred1
cites	Introduction	C. Frith, Role of facial expressions in social interactions , Philos. Trans. R. Soc. B , vol. 364 (2009), pp.3453-3458	http://dx.doi.org/10.1016/j.patcog.2017.10.017	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0001		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0021	'In fact, studies have shown that non-verbal communication accounts for more than half of all societal interactions [1][[ refid=''bib0001'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0004"""" view=""""all"""">Human beings, as social animals, rely on a vast array of methods to communicate with each other in the society. Non-verbal communication, that includes body language and expressions, is an essential aspect of interpersonal communication. In fact, studies have shown that non-verbal communication accounts for more than half of all societal interactions <ce:cross-ref id=""""crf0020"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. Studying facial expressions is therefore of vital importance in fields like sociology, psychology and automated recognition of expressions can be applied towards creating more user affable software and user agents in these fields.</ce:para>""''"'	cites	AGA	
cites	Introduction	M. Liu, S. Li, S. Shan, R. Wang, X. Chen, Deeply learning deformable facial action parts model for dynamic expression analysis , Asian Conference on Computer Vision, Springer (2014)	http://dx.doi.org/10.1016/j.patcog.2017.10.017	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0007	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0004		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0027	'Modeling and parameterizing human faces is one of the most fundamental problems in computer graphics [7][[ refid=''bib0007'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">Modeling and parameterizing human faces is one of the most fundamental problems in computer graphics <ce:cross-ref id=""""crf0021"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>. Understanding and classification of expressions from videos can have applications towards better modeling of human faces in computer graphics and human computer interaction. Accurate characterization of face geometry and muscle motion can be used for both expression identification and synthesis <ce:cross-refs id=""""crfs0003"""" refid=""""bib0008 bib0009"""">[8,9][[ refid=''''bib0008 bib0009'''' ]]</ce:cross-refs> with applications towards computer animation <ce:cross-ref id=""""crf0022"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. Such approaches combine very high dimensional facial features from facial topology and compress them to lower dimensions using a series of parameters or transformations <ce:cross-refs id=""""crfs0004"""" refid=""""bib0011 bib0012"""">[11,12][[ refid=''''bib0011 bib0012'''' ]]</ce:cross-refs>. This paper demonstrates how to use deep neural networks to reduce dimensionality of high information facial videos and recover the embedded temporal and spatial information by utilizing a series of stacked autoencoders.</ce:para>""''"'	cites	AGA	
uses_data_from	Experiments and results	Sources, Visual information processing and learning, [Online; accessed 10-July-2015].	http://dx.doi.org/10.1016/j.patcog.2017.10.017	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0063	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0031		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0037	'We utilize sources downloaded from Visual data transforming and taking in Resources[63][[ refid=''bib0063'' ]] as a reference to contrast with our strategies.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0036"""" view=""""all"""">For quantitative analysis we compare our results against expression-lets base approaches <ce:cross-ref id=""""crf0061"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> and multiple kernel methods <ce:cross-ref id=""""crf0062"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. We utilize sources downloaded from <ce:italic>Visual data transforming and taking in Resources</ce:italic><ce:cross-ref id=""""crf0063"""" refid=""""bib0063"""">[63][[ refid=''''bib0063'''' ]]</ce:cross-ref> as a reference to contrast with our strategies. For reasonable comparison we use same partitioning techniques while comparing our techniques with external methods. While we cannot compare against methods such as <ce:cross-ref id=""""crf0064"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> because of absence of publicly available code our method still wins on MMI dataset.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experiments and results	Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, T. Darrell, Caffe: convolutional architecture for fast feature embedding , Proceedings of the 22nd ACM International Conference on Multimedia, ACM (2014)	http://dx.doi.org/10.1016/j.patcog.2017.10.017	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0062>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0033>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0040	'Both autoencoder and predictor network topologies are implemented as Caffe prototxt files [62][[ refid=''bib0062'' ]] and they will be made available for public usage.'			FDY+AGA	infered_pred1
cites	Experiments and results	M. Liu, S. Li, S. Shan, R. Wang, X. Chen, Deeply learning deformable facial action parts model for dynamic expression analysis , Asian Conference on Computer Vision, Springer (2014)	http://dx.doi.org/10.1016/j.patcog.2017.10.017	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0007	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0032		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0041	'While we cannot compare against methods such as [7][[ refid=''bib0007'' ]] because of absence of publicly available code our method still wins on MMI dataset.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0036"""" view=""""all"""">For quantitative analysis we compare our results against expression-lets base approaches <ce:cross-ref id=""""crf0061"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> and multiple kernel methods <ce:cross-ref id=""""crf0062"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. We utilize sources downloaded from <ce:italic>Visual data transforming and taking in Resources</ce:italic><ce:cross-ref id=""""crf0063"""" refid=""""bib0063"""">[63][[ refid=''''bib0063'''' ]]</ce:cross-ref> as a reference to contrast with our strategies. For reasonable comparison we use same partitioning techniques while comparing our techniques with external methods. While we cannot compare against methods such as <ce:cross-ref id=""""crf0064"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> because of absence of publicly available code our method still wins on MMI dataset.</ce:para>""''"'	uses_data_from	AGA	
cites	Method	G.E. Hinton, R.R. Salakhutdinov, Reducing the dimensionality of data with neural networks , Science , vol. 313 (2006), pp.504-507	http://dx.doi.org/10.1016/j.patcog.2017.10.017	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0055	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0019		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0042	'Stacked autoencoders can be used to convert high dimensional data into lower dimensional space which can be useful for classification, visualization or retrieval [55][[ refid=''bib0055'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0017"""" view=""""all"""">Stacked autoencoders can be used to convert high dimensional data into lower dimensional space which can be useful for classification, visualization or retrieval <ce:cross-ref id=""""crf0031"""" refid=""""bib0055"""">[55][[ refid=''''bib0055'''' ]]</ce:cross-ref>. Since video data is extremely high dimensional we rely on a deep convolutional autoencoder to extract meaningful features from this data by embedding it into <mml:math altimg=""""si2.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msup><mml:mi mathvariant=""""double-struck"""">R</mml:mi><mml:mn>4096</mml:mn></mml:msup></mml:math>. The autoencoder topology is inspired by ImageNet <ce:cross-ref id=""""crf0032"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> and comprises of convolutional layers gradually reducing data dimensionality until we reach a fully connected layer. Central fully connected layers are followed by a cascade of deconvolutional layers which essentially invert the convolutional layers thereby reconstructing the input tensor (<mml:math altimg=""""si3.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msup><mml:mi mathvariant=""""double-struck"""">R</mml:mi><mml:mrow><mml:mn>145</mml:mn><mml:mo>×</mml:mo><mml:mn>145</mml:mn><mml:mo>×</mml:mo><mml:mn>9</mml:mn></mml:mrow></mml:msup></mml:math>). The complete autoencoder architecture can be described in following shorthand <mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>C</mml:mi><mml:mo>(</mml:mo><mml:mn>96</mml:mn><mml:mo>,</mml:mo><mml:mn>11</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>C</mml:mi><mml:mo>(</mml:mo><mml:mn>256</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>C</mml:mi><mml:mo>(</mml:mo><mml:mn>384</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>F</mml:mi><mml:mi>C</mml:mi><mml:mo>(</mml:mo><mml:mn>4096</mml:mn><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>F</mml:mi><mml:mi>C</mml:mi><mml:mo>(</mml:mo><mml:mn>4096</mml:mn><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mi>C</mml:mi><mml:mo>(</mml:mo><mml:mn>96</mml:mn><mml:mo>,</mml:mo><mml:mn>11</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mi>C</mml:mi><mml:mo>(</mml:mo><mml:mn>256</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mi>C</mml:mi><mml:mo>(</mml:mo><mml:mn>384</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:math>. Here <ce:italic>C</ce:italic>(96, 11, 3) is a convolutional layer containing 96 filters of size 11 × 11 in spatial domain and spanning 3 frames in temporal domain. <ce:italic>N</ce:italic> stands for local response normalization layers, <ce:italic>DC</ce:italic> stands for deconvolutional layers and <ce:italic>FC</ce:italic>(4096) stands for fully connected layers containing 4096 neurons.</ce:para>""''"'	uses_data_from	AGA	
cites	Related work	O. Gupta, D. Raviv, R. Raskar, Multi-velocity neural networks for facial expression recognition in videos , IEEE Trans. Affect. Comput. , vol. pp (2017), pp.1-99	http://dx.doi.org/10.1016/j.patcog.2017.10.017	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0054	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0018		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0043	'In [54][[ refid=''bib0054'' ]], the author considered velocity changes in videos as well as a semi-supervised learning approach.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">Introducing invariants in neural networks is an area of active research, some examples include illumination invariant face recognition techniques <ce:cross-refs id=""""crfs0017"""" refid=""""bib0051 bib0052"""">[51,52][[ refid=''''bib0051 bib0052'''' ]]</ce:cross-refs> and deep Lambertian networks <ce:cross-refs id=""""crfs0018"""" refid=""""bib0014 bib0053"""">[14,53][[ refid=''''bib0014 bib0053'''' ]]</ce:cross-refs>. Our method tries to introduce similar invariants for video neural networks by introducing <ce:italic>temporal</ce:italic> invariants to illumination. While we test our techniques on facial expression datasets, in principal they can be extended to any neural network taking videos as input. In <ce:cross-ref id=""""crf0030"""" refid=""""bib0054"""">[54][[ refid=''''bib0054'''' ]]</ce:cross-ref>, the author considered velocity changes in videos as well as a semi-supervised learning approach. Here we focus on a different neural network topology and parameter calibration, and report better results on similar databases using new invariant layers.</ce:para>""''"'	cites	AGA	
cites	Related work	P. Vincent, H. Larochelle, Y. Bengio, P.-A. Manzagol, Extracting and composing robust features with denoising auto-encoders , Proceedings of the 25th International Conference on Machine learning, ACM (2008)	http://dx.doi.org/10.1016/j.patcog.2017.10.017	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/br/bib0044	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/ctx/ctx0014		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-017/itrp/0077	'A way around this is to use autoencoders for feature extraction or weights initialization [44][[ refid=''bib0044'' ]], followed by fine tuning over a smaller labeled dataset.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all"""">While deep neural nets are notorious for stellar results, training a neural net can be challenging because of huge data requirements. A way around this is to use autoencoders for feature extraction or weights initialization <ce:cross-ref id=""""crf0027"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref>, followed by fine tuning over a smaller labeled dataset. This issue can also be solved using embeddings in lower dimensional manifold <ce:cross-refs id=""""crfs0015"""" refid=""""bib0045 bib0046"""">[45,46][[ refid=''''bib0045 bib0046'''' ]]</ce:cross-refs> or pre-train using pseudo labels <ce:cross-ref id=""""crf0028"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref> thereby requiring fewer number of labeled samples. Approaches based on semi supervised learning have shown to work for smaller labeled datasets <ce:cross-ref id=""""crf0029"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> and techniques using deep neural nets to combine labels and unlabeled data in the same architecture <ce:cross-refs id=""""crfs0016"""" refid=""""bib0049 bib0050"""">[49,50][[ refid=''''bib0049 bib0050'''' ]]</ce:cross-refs> have emerged victorious. In this paper we propose similar hybrid approaches incorporating deep autoencoders for unlabeled data and additive loss function for the classification tasks.</ce:para>""''"'	uses_data_from	AGA	
cites	Consistent Inference of Latent Representations Based Learning	Y. Bengio, P. Lamblin, D. Popovici, H. Larochelle, Greedy layer-wise training of deep networks , Adv. Neural Inf. Process. Syst. , vol. 19 (2007), pp.153	http://dx.doi.org/10.1016/j.patcog.2017.10.022			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0025	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0023		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0002	'Similar to the autoencoder [25][[ refid=''bib0025'' ]], some variants of CILR can be obtained by applying frequently-used constraint, such as regularization constraint and sparsity constraint.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0022"""" view=""""all"""">Similar to the autoencoder <ce:cross-ref id=""""crf0107"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>, some variants of CILR can be obtained by applying frequently-used constraint, such as regularization constraint and sparsity constraint.</ce:para>""''"'	cites	AGA	
cites	Related work	H. Valpola, From neural PCA to deep unsupervised learning , Adv. Indep. Compon. Anal. Learn. Mach. (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0044	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0020		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0003	'Inspired by principal component analysis, Valpola et al. [44][[ refid=''bib0044'' ]] proposed a semi-supervised method to train deep neural networks by including the lateral shortcut connections from the encoder part to decoder part at each layer.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">Recently, most unsupervised or semi-supervised methods have been presented to improve the capability of DNNs when labeled data is limited. Inspired by principal component analysis, Valpola et al. <ce:cross-ref id=""""crf0095"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> proposed a semi-supervised method to train deep neural networks by including the lateral shortcut connections from the encoder part to decoder part at each layer. Furthermore, Pezeshki et al. <ce:cross-ref id=""""crf0096"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> adjusted connections between individual parts of deep models to enhance performance by learning their relationships. Experimentally, they have demonstrated the promising results on the MNIST classification task. Zhao et al. <ce:cross-ref id=""""crf0097"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref> presented an architecture which provides an uniform strategy to supervised, semi-supervised and unsupervised learning. Specifically, this model consists of convolutional and deconvolutional network parts to encode inputs and produce reconstruction, respectively. While the performance has been significantly improved, these methods have to learn superfluous auxiliary parameters that may degrade the pre-training efficiency and effectiveness.</ce:para>""''"'	cites	AGA	
cites	Related work	M. Pezeshki, L. Fan, P. Brakel, A. Courville, Y. Bengio, Deconstructing the ladder network architecture , None (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0045	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0021		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0004	'Furthermore, Pezeshki et al. [45][[ refid=''bib0045'' ]] adjusted connections between individual parts of deep models to enhance performance by learning their relationships.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">Recently, most unsupervised or semi-supervised methods have been presented to improve the capability of DNNs when labeled data is limited. Inspired by principal component analysis, Valpola et al. <ce:cross-ref id=""""crf0095"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> proposed a semi-supervised method to train deep neural networks by including the lateral shortcut connections from the encoder part to decoder part at each layer. Furthermore, Pezeshki et al. <ce:cross-ref id=""""crf0096"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> adjusted connections between individual parts of deep models to enhance performance by learning their relationships. Experimentally, they have demonstrated the promising results on the MNIST classification task. Zhao et al. <ce:cross-ref id=""""crf0097"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref> presented an architecture which provides an uniform strategy to supervised, semi-supervised and unsupervised learning. Specifically, this model consists of convolutional and deconvolutional network parts to encode inputs and produce reconstruction, respectively. While the performance has been significantly improved, these methods have to learn superfluous auxiliary parameters that may degrade the pre-training efficiency and effectiveness.</ce:para>""''"'	cites	AGA	
cites	Consistent Inference of Latent Representations Based Learning	M. Ranzato, F.J. Huang, Y. Boureau, Y. Lecun, Unsupervised learning of invariant feature hierarchies with applications to object recognition , Computer Vision and Pattern Recognition (2007)	http://dx.doi.org/10.1016/j.patcog.2017.10.022			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0043	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0026		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0005	'The sparsity can be utilized to discover interesting structure in data and to learn the more robust feature representations of data points [43][[ refid=''bib0043'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0025"""" view=""""all"""">The sparsity can be utilized to discover interesting structure in data and to learn the more robust feature representations of data points <ce:cross-ref id=""""crf0111"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref>. Inspired by Ng <ce:cross-ref id=""""crf0112"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>, we develop an variant of CILR termed sparse CILR which attempts to learn sparse feature representations by adding a sparse penalty term in loss function. More formally, the objective function of the sparse CILR is formulated as:<ce:display><ce:formula id=""""eq0006""""><ce:label>(6)</ce:label><mml:math altimg=""""si16.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd columnalign=""""right""""><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign=""""left""""><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>ɛ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msub><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mi>K</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ρ</mml:mi><mml:mo>∥</mml:mo><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign=""""left""""><mml:mrow><mml:mo>≤</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>ɛ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign=""""left""""><mml:mrow><mml:mspace width=""""1em""""/><mml:mo>+</mml:mo><mml:mspace width=""""0.16em""""/><mml:mi>β</mml:mi><mml:msub><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mi>K</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ρ</mml:mi><mml:mo>∥</mml:mo><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where <ce:italic>ρ</ce:italic> is a sparsity parameter, and <ce:italic>β</ce:italic> is a regularization parameter to control the weight of the sparsity. The average activation of the output unit <ce:italic>j</ce:italic> can be calculated by:<ce:display><ce:formula id=""""eq0007""""><ce:label>(7)</ce:label><mml:math altimg=""""si17.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd/><mml:mtd columnalign=""""left""""><mml:mrow><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>M</mml:mi><mml:mi>E</mml:mi><mml:mi>A</mml:mi><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:msubsup><mml:mi mathvariant=""""bold"""">a</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where <mml:math altimg=""""si18.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msup><mml:mi mathvariant=""""bold"""">a</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>ɛ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math><mml:math altimg=""""si19.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mi mathvariant=""""bold"""">a</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup></mml:math> is the <ce:italic>j</ce:italic>th component of <ce:bold>a</ce:bold><ce:sup loc=""""post""""><ce:italic>k</ce:italic></ce:sup>, and <ce:italic>MEAN</ce:italic>( · ) is a mean function. In addition, <mml:math altimg=""""si20.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi><mml:mo>(</mml:mo><mml:mi>ρ</mml:mi><mml:mo>∥</mml:mo><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> represents the Kullback–Leibler divergence between a Bernoulli random variable with mean <ce:italic>ρ</ce:italic> and a Bernoulli random variable with mean <mml:math altimg=""""si21.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math> and can be formulated as:<ce:display><ce:formula id=""""eq0008""""><ce:label>(8)</ce:label><mml:math altimg=""""si22.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd/><mml:mtd columnalign=""""left""""><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ρ</mml:mi><mml:mo>∥</mml:mo><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mi>log</mml:mi><mml:mfrac><mml:mi>ρ</mml:mi><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>log</mml:mi><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display></ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Consistent Inference of Latent Representations Based Learning	A. Ng, Sparse autoencoder, CS294A Lecture notes 72(2011) 1–19.	http://dx.doi.org/10.1016/j.patcog.2017.10.022			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0027		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0006	'Inspired by Ng [39][[ refid=''bib0039'' ]], we develop an variant of CILR termed sparse CILR which attempts to learn sparse feature representations by adding a sparse penalty term in loss function.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0025"""" view=""""all"""">The sparsity can be utilized to discover interesting structure in data and to learn the more robust feature representations of data points <ce:cross-ref id=""""crf0111"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref>. Inspired by Ng <ce:cross-ref id=""""crf0112"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>, we develop an variant of CILR termed sparse CILR which attempts to learn sparse feature representations by adding a sparse penalty term in loss function. More formally, the objective function of the sparse CILR is formulated as:<ce:display><ce:formula id=""""eq0006""""><ce:label>(6)</ce:label><mml:math altimg=""""si16.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd columnalign=""""right""""><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign=""""left""""><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>ɛ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msub><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mi>K</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ρ</mml:mi><mml:mo>∥</mml:mo><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign=""""left""""><mml:mrow><mml:mo>≤</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>ɛ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign=""""left""""><mml:mrow><mml:mspace width=""""1em""""/><mml:mo>+</mml:mo><mml:mspace width=""""0.16em""""/><mml:mi>β</mml:mi><mml:msub><mml:mo>∑</mml:mo><mml:mi>j</mml:mi></mml:msub><mml:mi>K</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ρ</mml:mi><mml:mo>∥</mml:mo><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where <ce:italic>ρ</ce:italic> is a sparsity parameter, and <ce:italic>β</ce:italic> is a regularization parameter to control the weight of the sparsity. The average activation of the output unit <ce:italic>j</ce:italic> can be calculated by:<ce:display><ce:formula id=""""eq0007""""><ce:label>(7)</ce:label><mml:math altimg=""""si17.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd/><mml:mtd columnalign=""""left""""><mml:mrow><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>M</mml:mi><mml:mi>E</mml:mi><mml:mi>A</mml:mi><mml:mi>N</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:msubsup><mml:mi mathvariant=""""bold"""">a</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where <mml:math altimg=""""si18.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msup><mml:mi mathvariant=""""bold"""">a</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>ɛ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math><mml:math altimg=""""si19.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mi mathvariant=""""bold"""">a</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mi>k</mml:mi></mml:msubsup></mml:math> is the <ce:italic>j</ce:italic>th component of <ce:bold>a</ce:bold><ce:sup loc=""""post""""><ce:italic>k</ce:italic></ce:sup>, and <ce:italic>MEAN</ce:italic>( · ) is a mean function. In addition, <mml:math altimg=""""si20.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi><mml:mo>(</mml:mo><mml:mi>ρ</mml:mi><mml:mo>∥</mml:mo><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> represents the Kullback–Leibler divergence between a Bernoulli random variable with mean <ce:italic>ρ</ce:italic> and a Bernoulli random variable with mean <mml:math altimg=""""si21.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math> and can be formulated as:<ce:display><ce:formula id=""""eq0008""""><ce:label>(8)</ce:label><mml:math altimg=""""si22.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd/><mml:mtd columnalign=""""left""""><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ρ</mml:mi><mml:mo>∥</mml:mo><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mi>log</mml:mi><mml:mfrac><mml:mi>ρ</mml:mi><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>log</mml:mi><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mover accent=""""true""""><mml:mi>ρ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display></ce:para>""''"'	cites	AGA	
cites	Consistent Inference of Latent Representations Based Learning	N. Lange, , None, MIT Press (1993)	http://dx.doi.org/10.1016/j.patcog.2017.10.022			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0046	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0024		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0007	'Theoretically, in the supervised learning tasks, reducing the structural error can improve the generalization capability of models [46][[ refid=''bib0046'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0023"""" view=""""all"""">Theoretically, in the supervised learning tasks, reducing the structural error can improve the generalization capability of models <ce:cross-ref id=""""crf0108"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref>. Empirically, Krizhevsky et al. <ce:cross-ref id=""""crf0109"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> have found that the weight decay utilized in the AlexNet is not merely a regularizer, it can reduce the training error of models. Inspired by such observations, for training better models, the weight decay is added in the objective function of CILR to assist pre-training. We name it regularized CILR that the loss function is formulated as:<ce:display><ce:formula id=""""eq0004""""><ce:label>(4)</ce:label><mml:math altimg=""""si11.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd columnalign=""""right""""><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign=""""left""""><mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>ɛ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mo>∥</mml:mo><mml:mi mathvariant=""""bold"""">w</mml:mi><mml:msubsup><mml:mo>∥</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign=""""left""""><mml:mrow><mml:mo>≤</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>ɛ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mo>∥</mml:mo><mml:mi mathvariant=""""bold"""">w</mml:mi><mml:msubsup><mml:mo>∥</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where <ce:bold>w</ce:bold> represents the model parameter vector inside the function <ce:italic>f</ce:italic>, and <ce:bold>w</ce:bold><ce:inf loc=""""post""""><ce:italic>i</ce:italic></ce:inf> stands for the <ce:italic>i<ce:sup loc=""""post"""">th</ce:sup></ce:italic> entity of <ce:bold>w</ce:bold><ce:cross-ref id=""""crf0110"""" refid=""""fn0001""""><ce:sup loc=""""post"""">1</ce:sup></ce:cross-ref><ce:footnote id=""""fn0001""""><ce:label>1</ce:label><ce:note-para id=""""cenotep0001"""" view=""""all""""><ce:bold>w</ce:bold><ce:inf loc=""""post""""><ce:italic>i</ce:italic></ce:inf> corresponds to the weight of a pair of connected nodes in neural networks.</ce:note-para></ce:footnote>. <mml:math altimg=""""si12.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mo>∥</mml:mo><mml:mo>·</mml:mo><mml:msubsup><mml:mo>∥</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math> represents <ce:italic>l</ce:italic><ce:inf loc=""""post"""">2</ce:inf>-norm of vectors, and <ce:italic>λ</ce:italic> is a regularization parameter to control the weight of the weight decay.</ce:para>""''"'	cites	AGA	
cites	Consistent Inference of Latent Representations Based Learning	A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks , Advances in Neural Information Processing Systems (2012)	http://dx.doi.org/10.1016/j.patcog.2017.10.022			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0025		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0008	'Empirically, Krizhevsky et al. [1][[ refid=''bib0001'' ]] have found that the weight decay utilized in the AlexNet is not merely a regularizer, it can reduce the training error of models.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0023"""" view=""""all"""">Theoretically, in the supervised learning tasks, reducing the structural error can improve the generalization capability of models <ce:cross-ref id=""""crf0108"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref>. Empirically, Krizhevsky et al. <ce:cross-ref id=""""crf0109"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> have found that the weight decay utilized in the AlexNet is not merely a regularizer, it can reduce the training error of models. Inspired by such observations, for training better models, the weight decay is added in the objective function of CILR to assist pre-training. We name it regularized CILR that the loss function is formulated as:<ce:display><ce:formula id=""""eq0004""""><ce:label>(4)</ce:label><mml:math altimg=""""si11.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd columnalign=""""right""""><mml:mrow><mml:msub><mml:mi>ℓ</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign=""""left""""><mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>ɛ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mo>∥</mml:mo><mml:mi mathvariant=""""bold"""">w</mml:mi><mml:msubsup><mml:mo>∥</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign=""""left""""><mml:mrow><mml:mo>≤</mml:mo><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>ɛ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mo>∥</mml:mo><mml:mi mathvariant=""""bold"""">w</mml:mi><mml:msubsup><mml:mo>∥</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where <ce:bold>w</ce:bold> represents the model parameter vector inside the function <ce:italic>f</ce:italic>, and <ce:bold>w</ce:bold><ce:inf loc=""""post""""><ce:italic>i</ce:italic></ce:inf> stands for the <ce:italic>i<ce:sup loc=""""post"""">th</ce:sup></ce:italic> entity of <ce:bold>w</ce:bold><ce:cross-ref id=""""crf0110"""" refid=""""fn0001""""><ce:sup loc=""""post"""">1</ce:sup></ce:cross-ref><ce:footnote id=""""fn0001""""><ce:label>1</ce:label><ce:note-para id=""""cenotep0001"""" view=""""all""""><ce:bold>w</ce:bold><ce:inf loc=""""post""""><ce:italic>i</ce:italic></ce:inf> corresponds to the weight of a pair of connected nodes in neural networks.</ce:note-para></ce:footnote>. <mml:math altimg=""""si12.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mo>∥</mml:mo><mml:mo>·</mml:mo><mml:msubsup><mml:mo>∥</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math> represents <ce:italic>l</ce:italic><ce:inf loc=""""post"""">2</ce:inf>-norm of vectors, and <ce:italic>λ</ce:italic> is a regularization parameter to control the weight of the weight decay.</ce:para>""''"'	cites	AGA	
cites	Convergence analyses	T.K. Moon, The expectation-maximization algorithm , IEEE Signal Process. Mag. , vol. 13 (1996), pp.47-60	http://dx.doi.org/10.1016/j.patcog.2017.10.022			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0047	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0029		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0010	'Similar to the expectation maximization algorithm [47][[ refid=''bib0047'' ]], the Theorem 1 does not quite imply that the proposed method converges to a global optimal value, because it is indeterminate whether the result of optimizing ∑kd(ft(xk),yk)+d(yk,ft(Tɛ(xk))) is the global minimum at each iteration.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0041"""" view=""""all"""">Similar to the expectation maximization algorithm <ce:cross-ref id=""""crf0131"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref>, the <ce:cross-ref id=""""crf0132"""" refid=""""enun0001"""">Theorem 1</ce:cross-ref> does not quite imply that the proposed method converges to a global optimal value, because it is indeterminate whether the result of optimizing <mml:math altimg=""""si52.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mo>∑</mml:mo><mml:mi>k</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>ɛ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mi>k</mml:mi></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> is the global minimum at each iteration.</ce:para>""''"'	cites	AGA	
cites	Introduction	P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, P.A. Manzagol, Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion , J. Mach. Learn. Res. , vol. 11 (2010), pp.3371-3408	http://dx.doi.org/10.1016/j.patcog.2017.10.022	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0040	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0008		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0011	'Different from adding regularization to loss function, a denoising function will be learned by reconstructing the original clean data from the corrupted input data [40][[ refid=''bib0040'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">Most unsupervised methods aim to pre-train DNNs by reconstructing inputs, such as the restricted Boltzmann machine <ce:cross-ref id=""""crf0073"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref>, the autoencoder <ce:cross-ref id=""""crf0074"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>, and so on. Technically, what the entire network learns is a non-linear mapping that is able to transform data points identically to be themselves. DNNs trained by these methods consist of two different parts: encoding and decoding. The encoding part is designed to learn a function to map data points into a latent space and yields feature representations for inputs. Meanwhile, the decoding part can be treated as an inverse operator of encoding, with which the inputs could be reconstructed by using the learned feature representations. The encode-decode architecture is a typically unsupervised way to train the DNNs. Furthermore, these methods can be assisted to learn more robust representations by associating with some frequently-used regularization terms, including the Frobenius norm <ce:cross-ref id=""""crf0075"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, sparsity <ce:cross-ref id=""""crf0076"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>, and so on. Different from adding regularization to loss function, a denoising function will be learned by reconstructing the original clean data from the corrupted input data <ce:cross-ref id=""""crf0077"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA	
uses_data_from	Experiments	J. Deng, W. Dong, R. Socher, L. Li, K. Li, F. Li, Imagenet: a large-scale hierarchical image database , CVPR (2009)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0053>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0046>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0015	'We conduct experiments on the ILSVRC2012 1K dataset [53][[ refid=''bib0053'' ]] to evaluate the performance of the proposed method.'			FDY+AGA	infered_pred1
uses_method_in	Experiments	K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale image recognition , None (2014)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0073	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0047		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0016	'Specifically, the VGG-16 and VGG-19 networks proposed in [73][[ refid=''bib0073'' ]] are employed as the based models.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0069"""" view=""""all"""">We conduct experiments on the ILSVRC2012 1K dataset <ce:cross-ref id=""""crf0160"""" refid=""""bib0053"""">[53][[ refid=''''bib0053'''' ]]</ce:cross-ref> to evaluate the performance of the proposed method. Specifically, the VGG-16 and VGG-19 networks proposed in <ce:cross-ref id=""""crf0161"""" refid=""""bib0073"""">[73][[ refid=''''bib0073'''' ]]</ce:cross-ref> are employed as the based models. From <ce:cross-ref id=""""crf0162"""" refid=""""tbl0009"""">Table 9</ce:cross-ref><ce:float-anchor refid=""""tbl0009""""/>, we observe that our method can improve the baselines marginally. This indicates that the proposed approaches are useful in practical applications.</ce:para>""''"'	cites	AGA	
cites	Experiments	Y. LeCun, L. Bottou, Y. Bengio, P. Haffner, Gradient-based learning applied to document recognition , Proc. IEEE , vol. 86 (1998), pp.2278-2324	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0049	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0042		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0020	'The convolutional neural network is an extension of the LeNet-5 [49][[ refid=''bib0049'' ]], but it has more filters in convolutional layers.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0064"""" view=""""all"""">We optionally devise a fully connected neural network and a convolutional neural network to compare the performance of the proposed approaches with some traditional pre-training methods on MNIST. The structure of the molded network is illustrated in <ce:cross-ref id=""""crf0150"""" refid=""""tbl0001"""">Table 1</ce:cross-ref><ce:float-anchor refid=""""tbl0001""""/>. The convolutional neural network is an extension of the LeNet-5 <ce:cross-ref id=""""crf0151"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref>, but it has more filters in convolutional layers. In the pre-training stage, the whole images in MNIST are utilized to pre-training the deep networks. In the fine-tuning stage, we randomly select labeled samples to fine-tune the networks. The sizes of labeled subset are respectively 300, 600, 1000, 3000, 5000, 10,000 and 60,000 (full). Additionally, in this paper, the autoencoder and its variants are employed to compare with the proposed method. For more comprehensive compare, we also collect the previously reports to demonstrate the effectiveness of the proposed method and its variants.</ce:para>""''"'	cites	AGA	
cites	Introduction	C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich, Going deeper with convolutions , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0021	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0002		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0043	'A straightforward way to train excellent DNNs is increasing the number of labeled training data [21][[ refid=''bib0021'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0005"""" view=""""all"""">A straightforward way to train excellent DNNs is increasing the number of labeled training data <ce:cross-ref id=""""crf0069"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>. However, it is laborious and expensive to obtain a large amount of labeled data. Since training DNNs can be considered as an optimal problem with a group of parameters <ce:cross-ref id=""""crf0070"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>, it is reasonable to learn deep models by pre-training these models with a mass of unlabeled data and fine-tuning the models for the specific classification task with labeled data. Along this line, in the literature, several unsupervised methods have been presented, such as the deep belief networks <ce:cross-refs id=""""crfs0006"""" refid=""""bib0023 bib0024"""">[23,24][[ refid=''''bib0023 bib0024'''' ]]</ce:cross-refs>, the autoencoders <ce:cross-refs id=""""crfs0007"""" refid=""""bib0025 bib0026 bib0027"""">[25–27][[ refid=''''bib0025 bib0026 bib0027'''' ]]</ce:cross-refs>, the deep Boltzmann machine <ce:cross-ref id=""""crf0071"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>, the convolutional autoencoder <ce:cross-ref id=""""crf0072"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref>, and so on. The results achieved by these methods have demonstrated that significant improvements can be obtained in various tasks, such as classification <ce:cross-refs id=""""crfs0008"""" refid=""""bib0025 bib0027 bib0028"""">[25,27,28][[ refid=''''bib0025 bib0027 bib0028'''' ]]</ce:cross-refs>, recognition <ce:cross-refs id=""""crfs0009"""" refid=""""bib0030 bib0031 bib0032"""">[30–32][[ refid=''''bib0030 bib0031 bib0032'''' ]]</ce:cross-refs>, retrieval <ce:cross-refs id=""""crfs0010"""" refid=""""bib0033 bib0034 bib0035 bib0036"""">[33–36][[ refid=''''bib0033 bib0034 bib0035 bib0036'''' ]]</ce:cross-refs>, and so on.</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	W. Ouyang, X. Wang, X. Zeng, S. Qiu, P. Luo, Y. Tian, H. Li, S. Yang, Z. Wang, C.-C. Loy, Deepid-net: deformable deep convolutional neural networks for object detection , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0022	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0003		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0044	'Since training DNNs can be considered as an optimal problem with a group of parameters [22][[ refid=''bib0022'' ]], it is reasonable to learn deep models by pre-training these models with a mass of unlabeled data and fine-tuning the models for the specific classification task with labeled data.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0005"""" view=""""all"""">A straightforward way to train excellent DNNs is increasing the number of labeled training data <ce:cross-ref id=""""crf0069"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>. However, it is laborious and expensive to obtain a large amount of labeled data. Since training DNNs can be considered as an optimal problem with a group of parameters <ce:cross-ref id=""""crf0070"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>, it is reasonable to learn deep models by pre-training these models with a mass of unlabeled data and fine-tuning the models for the specific classification task with labeled data. Along this line, in the literature, several unsupervised methods have been presented, such as the deep belief networks <ce:cross-refs id=""""crfs0006"""" refid=""""bib0023 bib0024"""">[23,24][[ refid=''''bib0023 bib0024'''' ]]</ce:cross-refs>, the autoencoders <ce:cross-refs id=""""crfs0007"""" refid=""""bib0025 bib0026 bib0027"""">[25–27][[ refid=''''bib0025 bib0026 bib0027'''' ]]</ce:cross-refs>, the deep Boltzmann machine <ce:cross-ref id=""""crf0071"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>, the convolutional autoencoder <ce:cross-ref id=""""crf0072"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref>, and so on. The results achieved by these methods have demonstrated that significant improvements can be obtained in various tasks, such as classification <ce:cross-refs id=""""crfs0008"""" refid=""""bib0025 bib0027 bib0028"""">[25,27,28][[ refid=''''bib0025 bib0027 bib0028'''' ]]</ce:cross-refs>, recognition <ce:cross-refs id=""""crfs0009"""" refid=""""bib0030 bib0031 bib0032"""">[30–32][[ refid=''''bib0030 bib0031 bib0032'''' ]]</ce:cross-refs>, retrieval <ce:cross-refs id=""""crfs0010"""" refid=""""bib0033 bib0034 bib0035 bib0036"""">[33–36][[ refid=''''bib0033 bib0034 bib0035 bib0036'''' ]]</ce:cross-refs>, and so on.</ce:para>""''"'	uses_data_from	AGA	
cites	Experiments	R. Hadsell, S. Chopra, Y. LeCun, Dimensionality reduction by learning an invariant mapping , Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, IEEE , vol. 2 (2006), pp.1735-1742	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0059	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0048		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0066	'Thirdly, although the siamese networks [59][[ refid=''bib0059'' ]] consider pair-wise samples as CILR to pre-train deep models, the contribution of the siamese networks is limited.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0070"""" view=""""all"""">Furthermore, in terms of the pre-training task, several tendencies can be observed from the results on the aforementioned six datasets. First, the regularized CILR can effectively improve the performance of CILR. This indicates that more generalization capability can be obtained by applying the weight decay during pre-training phase. Secondly, we found that the sparse CILR may degrade the performance of CILR. One possible reason is that the sparsity constraint weakens the original objective which attempts to map similar data points to one point. This observation in turn indicates that the original objective is important to pre-training deep neural networks. Thirdly, although the siamese networks <ce:cross-ref id=""""crf0163"""" refid=""""bib0059"""">[59][[ refid=''''bib0059'''' ]]</ce:cross-ref> consider pair-wise samples as CILR to pre-train deep models, the contribution of the siamese networks is limited. Further analysis, the siamese networks treat the whole seed data points as dissimilar samples. This may introduce a mass of noisy samples during the pre-training stage and degrade the performance of the pre-training.</ce:para>""''"'	uses_method_in	AGA	
uses_data_from	Experiments	J. Deng, W. Dong, R. Socher, L. Li, K. Li, F. Li, Imagenet: a large-scale hierarchical image database , CVPR (2009)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0053>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0035>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0070	'There are 5000 training samples, 8000 test samples and 100000 unlabeled samples.ILSVRC2012 1K[53][[ refid=''bib0053'' ]]: ILSVRC2012 1K image dataset consists of 1000 categories.'			FDY+AGA	infered_pred1
uses_data_from	Experiments	A. Coates, A.Y. Ng, H. Lee, An analysis of single-layer networks in unsupervised feature learning , J. Mach. Learn. Res. , vol. 15 (2011), pp.215-223	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0052	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0034		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0071	'Except it has 100 classes, and only 500 training images, 100 testing images per class.STL-10[52][[ refid=''bib0052'' ]]: The STL-10 dataset consists of 96 × 96 color images and relatively less labeled data.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0045"""" view=""""all"""">We evaluate the proposed approaches on six popular image datasets:<ce:list id=""""celist0003""""><ce:list-item id=""""celistitem0007""""><ce:para id=""""para0046"""" view=""""all""""><ce:bold>MNIST</ce:bold><ce:cross-ref id=""""crf0138"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref>: A dataset of 28 × 28 gray handwritten digit images in 10 classes, has a training set of 60000 examples, and a test set of 10000 examples.</ce:para></ce:list-item><ce:list-item id=""""celistitem0008""""><ce:para id=""""para0047"""" view=""""all""""><ce:bold>SVHN</ce:bold><ce:cross-ref id=""""crf0139"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref>: SVHN is a real-world digit image dataset, which consists of 32 × 32 color images in 10 classes. It contains 73257 digit samples for training, 26032 digit samples for testing.</ce:para></ce:list-item><ce:list-item id=""""celistitem0009""""><ce:para id=""""para0048"""" view=""""all""""><ce:bold>CIFAR-10</ce:bold><ce:cross-ref id=""""crf0140"""" refid=""""bib0051"""">[51][[ refid=''''bib0051'''' ]]</ce:cross-ref>: A dataset of 32 × 32 colour images in 10 classes, with 5000 examples each. There are 50000 training images and 10000 test images.</ce:para></ce:list-item><ce:list-item id=""""celistitem0010""""><ce:para id=""""para0049"""" view=""""all""""><ce:bold>CIFAR-100</ce:bold><ce:cross-ref id=""""crf0141"""" refid=""""bib0051"""">[51][[ refid=''''bib0051'''' ]]</ce:cross-ref>: This dataset is just like the CIFAR-10. Except it has 100 classes, and only 500 training images, 100 testing images per class.</ce:para></ce:list-item><ce:list-item id=""""celistitem0011""""><ce:para id=""""para0050"""" view=""""all""""><ce:bold>STL-10</ce:bold><ce:cross-ref id=""""crf0142"""" refid=""""bib0052"""">[52][[ refid=''''bib0052'''' ]]</ce:cross-ref>: The STL-10 dataset consists of 96 × 96 color images and relatively less labeled data. There are 5000 training samples, 8000 test samples and 100000 unlabeled samples.</ce:para></ce:list-item><ce:list-item id=""""celistitem0012""""><ce:para id=""""para0051"""" view=""""all""""><ce:bold>ILSVRC2012 1K</ce:bold><ce:cross-ref id=""""crf0143"""" refid=""""bib0053"""">[53][[ refid=''''bib0053'''' ]]</ce:cross-ref>: ILSVRC2012 1K image dataset consists of 1000 categories. The dataset has 1.28 million training and 50k validation images, respectively.</ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_data_from	AGA	
cites	Experiments	F. Chollet, Keras, 2015, (	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0054	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0037		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0072	'The deep learning library Keras [54][[ refid=''bib0054'' ]] is employed to actualize deep models.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0062"""" view=""""all"""">The deep learning library Keras <ce:cross-ref id=""""crf0144"""" refid=""""bib0054"""">[54][[ refid=''''bib0054'''' ]]</ce:cross-ref> is employed to actualize deep models. The RMSProp optimizer <ce:cross-ref id=""""crf0145"""" refid=""""bib0055"""">[55][[ refid=''''bib0055'''' ]]</ce:cross-ref> is utilized to optimize objective functions in this paper. The learning rate is 0.001 for the initial phase of learning. Batch size is 256 in the pre-training procedure. In the fine-tuning phase, batch size is 100. For each deep neural network, the Gaussian initialization strategy described in <ce:cross-ref id=""""crf0146"""" refid=""""bib0056"""">[56][[ refid=''''bib0056'''' ]]</ce:cross-ref> is used to initialize the parameters. The ReLU activation function <ce:cross-ref id=""""crf0147"""" refid=""""bib0057"""">[57][[ refid=''''bib0057'''' ]]</ce:cross-ref> is employed to improve the efficiency of training, as analysed in <ce:cross-ref id=""""crf0148"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. And the batch normalization described in <ce:cross-ref id=""""crf0149"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> is utilized to normalize the inputs of each layer in the modeled deep neural networks.</ce:para>""''"'	cites	AGA	
uses_method_in	Reducing overfitting	S. Ioffe, C. Szegedy, Batch normalization: accelerating deep network training by reducing internal covariate shift , None (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.022			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0048	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0030		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0077	'Inspired by Ioffe and Szegedy [48][[ refid=''bib0048'' ]], we combat the overfitting by normalizing the inputs of each layer.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0043"""" view=""""all"""">Similar to supervised learning methods, overfitting also exists in the proposed method. For an arbitrary constant vector <ce:bold>c</ce:bold>, there is a function <mml:math altimg=""""si54.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant=""""bold"""">c</mml:mi></mml:mrow></mml:math> that can hit the minimum of <ce:cross-ref id=""""crf0133"""" refid=""""eq0002"""">Eq. (2)</ce:cross-ref>. However, it is noneffective for pre-training DNNs or learning valuable feature representations. Inspired by Ioffe and Szegedy <ce:cross-ref id=""""crf0134"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>, we combat the overfitting by normalizing the inputs of each layer. Experiments turn out that the batch normalization operation can alleviate the overfitting and improve the performance in practice.</ce:para>""''"'	cites	AGA	
uses_data_from	Experiments	A. Krizhevsky, Learning multiple layers of features from tiny images , None (2012)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0051	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0033		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0078	'There are 50000 training images and 10000 test images.CIFAR-100[51][[ refid=''bib0051'' ]]: This dataset is just like the CIFAR-10.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0045"""" view=""""all"""">We evaluate the proposed approaches on six popular image datasets:<ce:list id=""""celist0003""""><ce:list-item id=""""celistitem0007""""><ce:para id=""""para0046"""" view=""""all""""><ce:bold>MNIST</ce:bold><ce:cross-ref id=""""crf0138"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref>: A dataset of 28 × 28 gray handwritten digit images in 10 classes, has a training set of 60000 examples, and a test set of 10000 examples.</ce:para></ce:list-item><ce:list-item id=""""celistitem0008""""><ce:para id=""""para0047"""" view=""""all""""><ce:bold>SVHN</ce:bold><ce:cross-ref id=""""crf0139"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref>: SVHN is a real-world digit image dataset, which consists of 32 × 32 color images in 10 classes. It contains 73257 digit samples for training, 26032 digit samples for testing.</ce:para></ce:list-item><ce:list-item id=""""celistitem0009""""><ce:para id=""""para0048"""" view=""""all""""><ce:bold>CIFAR-10</ce:bold><ce:cross-ref id=""""crf0140"""" refid=""""bib0051"""">[51][[ refid=''''bib0051'''' ]]</ce:cross-ref>: A dataset of 32 × 32 colour images in 10 classes, with 5000 examples each. There are 50000 training images and 10000 test images.</ce:para></ce:list-item><ce:list-item id=""""celistitem0010""""><ce:para id=""""para0049"""" view=""""all""""><ce:bold>CIFAR-100</ce:bold><ce:cross-ref id=""""crf0141"""" refid=""""bib0051"""">[51][[ refid=''''bib0051'''' ]]</ce:cross-ref>: This dataset is just like the CIFAR-10. Except it has 100 classes, and only 500 training images, 100 testing images per class.</ce:para></ce:list-item><ce:list-item id=""""celistitem0011""""><ce:para id=""""para0050"""" view=""""all""""><ce:bold>STL-10</ce:bold><ce:cross-ref id=""""crf0142"""" refid=""""bib0052"""">[52][[ refid=''''bib0052'''' ]]</ce:cross-ref>: The STL-10 dataset consists of 96 × 96 color images and relatively less labeled data. There are 5000 training samples, 8000 test samples and 100000 unlabeled samples.</ce:para></ce:list-item><ce:list-item id=""""celistitem0012""""><ce:para id=""""para0051"""" view=""""all""""><ce:bold>ILSVRC2012 1K</ce:bold><ce:cross-ref id=""""crf0143"""" refid=""""bib0053"""">[53][[ refid=''''bib0053'''' ]]</ce:cross-ref>: ILSVRC2012 1K image dataset consists of 1000 categories. The dataset has 1.28 million training and 50k validation images, respectively.</ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_data_from	AGA	
uses_data_from	Experiments	A. Krizhevsky, Learning multiple layers of features from tiny images , None (2012)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0051	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0032		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0079	'It contains 73257 digit samples for training, 26032 digit samples for testing.CIFAR-10[51][[ refid=''bib0051'' ]]: A dataset of 32 × 32 colour images in 10 classes, with 5000 examples each.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0045"""" view=""""all"""">We evaluate the proposed approaches on six popular image datasets:<ce:list id=""""celist0003""""><ce:list-item id=""""celistitem0007""""><ce:para id=""""para0046"""" view=""""all""""><ce:bold>MNIST</ce:bold><ce:cross-ref id=""""crf0138"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref>: A dataset of 28 × 28 gray handwritten digit images in 10 classes, has a training set of 60000 examples, and a test set of 10000 examples.</ce:para></ce:list-item><ce:list-item id=""""celistitem0008""""><ce:para id=""""para0047"""" view=""""all""""><ce:bold>SVHN</ce:bold><ce:cross-ref id=""""crf0139"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref>: SVHN is a real-world digit image dataset, which consists of 32 × 32 color images in 10 classes. It contains 73257 digit samples for training, 26032 digit samples for testing.</ce:para></ce:list-item><ce:list-item id=""""celistitem0009""""><ce:para id=""""para0048"""" view=""""all""""><ce:bold>CIFAR-10</ce:bold><ce:cross-ref id=""""crf0140"""" refid=""""bib0051"""">[51][[ refid=''''bib0051'''' ]]</ce:cross-ref>: A dataset of 32 × 32 colour images in 10 classes, with 5000 examples each. There are 50000 training images and 10000 test images.</ce:para></ce:list-item><ce:list-item id=""""celistitem0010""""><ce:para id=""""para0049"""" view=""""all""""><ce:bold>CIFAR-100</ce:bold><ce:cross-ref id=""""crf0141"""" refid=""""bib0051"""">[51][[ refid=''''bib0051'''' ]]</ce:cross-ref>: This dataset is just like the CIFAR-10. Except it has 100 classes, and only 500 training images, 100 testing images per class.</ce:para></ce:list-item><ce:list-item id=""""celistitem0011""""><ce:para id=""""para0050"""" view=""""all""""><ce:bold>STL-10</ce:bold><ce:cross-ref id=""""crf0142"""" refid=""""bib0052"""">[52][[ refid=''''bib0052'''' ]]</ce:cross-ref>: The STL-10 dataset consists of 96 × 96 color images and relatively less labeled data. There are 5000 training samples, 8000 test samples and 100000 unlabeled samples.</ce:para></ce:list-item><ce:list-item id=""""celistitem0012""""><ce:para id=""""para0051"""" view=""""all""""><ce:bold>ILSVRC2012 1K</ce:bold><ce:cross-ref id=""""crf0143"""" refid=""""bib0053"""">[53][[ refid=''''bib0053'''' ]]</ce:cross-ref>: ILSVRC2012 1K image dataset consists of 1000 categories. The dataset has 1.28 million training and 50k validation images, respectively.</ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experiments	X. Glorot, Y. Bengio, Understanding the difficulty of training deep feedforward neural networks , J. Mach. Learn. Res. , vol. 9 (2010), pp.249-256	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0056	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0039		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0080	'For each deep neural network, the Gaussian initialization strategy described in [56][[ refid=''bib0056'' ]] is used to initialize the parameters.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0062"""" view=""""all"""">The deep learning library Keras <ce:cross-ref id=""""crf0144"""" refid=""""bib0054"""">[54][[ refid=''''bib0054'''' ]]</ce:cross-ref> is employed to actualize deep models. The RMSProp optimizer <ce:cross-ref id=""""crf0145"""" refid=""""bib0055"""">[55][[ refid=''''bib0055'''' ]]</ce:cross-ref> is utilized to optimize objective functions in this paper. The learning rate is 0.001 for the initial phase of learning. Batch size is 256 in the pre-training procedure. In the fine-tuning phase, batch size is 100. For each deep neural network, the Gaussian initialization strategy described in <ce:cross-ref id=""""crf0146"""" refid=""""bib0056"""">[56][[ refid=''''bib0056'''' ]]</ce:cross-ref> is used to initialize the parameters. The ReLU activation function <ce:cross-ref id=""""crf0147"""" refid=""""bib0057"""">[57][[ refid=''''bib0057'''' ]]</ce:cross-ref> is employed to improve the efficiency of training, as analysed in <ce:cross-ref id=""""crf0148"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. And the batch normalization described in <ce:cross-ref id=""""crf0149"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> is utilized to normalize the inputs of each layer in the modeled deep neural networks.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experiments	T. Tieleman, G. Hinton, Lecture 6.5—RmsProp: divide the gradient by a running average of its recent magnitude, 2012, (COURSERA: Neural Networks for Machine Learning).	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0055	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0038		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0081	'The RMSProp optimizer [55][[ refid=''bib0055'' ]] is utilized to optimize objective functions in this paper.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0062"""" view=""""all"""">The deep learning library Keras <ce:cross-ref id=""""crf0144"""" refid=""""bib0054"""">[54][[ refid=''''bib0054'''' ]]</ce:cross-ref> is employed to actualize deep models. The RMSProp optimizer <ce:cross-ref id=""""crf0145"""" refid=""""bib0055"""">[55][[ refid=''''bib0055'''' ]]</ce:cross-ref> is utilized to optimize objective functions in this paper. The learning rate is 0.001 for the initial phase of learning. Batch size is 256 in the pre-training procedure. In the fine-tuning phase, batch size is 100. For each deep neural network, the Gaussian initialization strategy described in <ce:cross-ref id=""""crf0146"""" refid=""""bib0056"""">[56][[ refid=''''bib0056'''' ]]</ce:cross-ref> is used to initialize the parameters. The ReLU activation function <ce:cross-ref id=""""crf0147"""" refid=""""bib0057"""">[57][[ refid=''''bib0057'''' ]]</ce:cross-ref> is employed to improve the efficiency of training, as analysed in <ce:cross-ref id=""""crf0148"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. And the batch normalization described in <ce:cross-ref id=""""crf0149"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> is utilized to normalize the inputs of each layer in the modeled deep neural networks.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments	K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition , None (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0056		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0082	'Following the protocols in [4][[ refid=''bib0004'' ]], the resnet-32 network is used in the experiments.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0084"""" view=""""all"""">We also perform experiment to study the performance of CILR on the residual networks <ce:cross-ref id=""""crf0187"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>. Following the protocols in <ce:cross-ref id=""""crf0188"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>, the resnet-32 network is used in the experiments. For the CIFAR-10 and CIFAR-100 datasets, the whole images are utilized to pre-train and fine-tune resnet-32 orderly. As for STL-10, the unlabeled and the labeled images are employed to pre-train and fine-tune resnet-32, respectively.</ce:para>""''"'	uses_method_in	AGA	
cites	Related work	K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition , None (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0019		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0083	'To pre-train more deeper CNNs (e.g., residual networks [4][[ refid=''bib0004'' ]]), an end-to-end approach is desiderated.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">As a natural framework to process images and videos, some previous works have been proposed to pre-train convolutional neural networks (CNNs). By applying the up-pooling operator, the convolutional autoencoder <ce:cross-ref id=""""crf0090"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> has been developed to pre-train CNNs by reconstructing input images. Similar to the autoencoder <ce:cross-ref id=""""crf0091"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>, a variety of regularization terms like Frobenius norm and sparse constraint can be employed to learn more robust and meaningful feature representations. In addition, the deconvolutional network <ce:cross-ref id=""""crf0092"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> pre-trains CNNs based on the decomposition under a sparse constraint with unlabeled data only. As a result, CNNs are pre-trained in an unsupervised learning way. Inspired by the sparse coding algorithm, Ranzato et al. <ce:cross-ref id=""""crf0093"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref> presented an unsupervised method to learn a group of sparse feature detectors that are invariant to small shifts and distortions. By initializing these detectors to convolutional kernels, more robust feature representations can be yielded. However, these methods mainly focus on shallow CNNs. To pre-train more deeper CNNs (<ce:italic>e.g.</ce:italic>, residual networks <ce:cross-ref id=""""crf0094"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>), an end-to-end approach is desiderated.</ce:para>""''"'	cites	AGA	
cites	Related work	M. Ranzato, F.J. Huang, Y. Boureau, Y. Lecun, Unsupervised learning of invariant feature hierarchies with applications to object recognition , Computer Vision and Pattern Recognition (2007)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0043	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0018		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0084	'Inspired by the sparse coding algorithm, Ranzato et al. [43][[ refid=''bib0043'' ]] presented an unsupervised method to learn a group of sparse feature detectors that are invariant to small shifts and distortions.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">As a natural framework to process images and videos, some previous works have been proposed to pre-train convolutional neural networks (CNNs). By applying the up-pooling operator, the convolutional autoencoder <ce:cross-ref id=""""crf0090"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> has been developed to pre-train CNNs by reconstructing input images. Similar to the autoencoder <ce:cross-ref id=""""crf0091"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>, a variety of regularization terms like Frobenius norm and sparse constraint can be employed to learn more robust and meaningful feature representations. In addition, the deconvolutional network <ce:cross-ref id=""""crf0092"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> pre-trains CNNs based on the decomposition under a sparse constraint with unlabeled data only. As a result, CNNs are pre-trained in an unsupervised learning way. Inspired by the sparse coding algorithm, Ranzato et al. <ce:cross-ref id=""""crf0093"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref> presented an unsupervised method to learn a group of sparse feature detectors that are invariant to small shifts and distortions. By initializing these detectors to convolutional kernels, more robust feature representations can be yielded. However, these methods mainly focus on shallow CNNs. To pre-train more deeper CNNs (<ce:italic>e.g.</ce:italic>, residual networks <ce:cross-ref id=""""crf0094"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>), an end-to-end approach is desiderated.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments	R.K. Srivastava, K. Greff, J. Schmidhuber, Training very deep networks , None (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0069	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0053		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0085	'The fully connected network (“plain network” described in [69][[ refid=''bib0069'' ]]) is employed to model deeper networks to investigate the capacities of different pre-training methods.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0081"""" view=""""all"""">The fully connected network (“plain network” described in <ce:cross-ref id=""""crf0181"""" refid=""""bib0069"""">[69][[ refid=''''bib0069'''' ]]</ce:cross-ref>) is employed to model deeper networks to investigate the capacities of different pre-training methods. The details of network are illustrated in <ce:cross-ref id=""""crf0182"""" refid=""""tbl0012"""">Table 12</ce:cross-ref><ce:float-anchor refid=""""tbl0012""""/>, where <ce:italic>n</ce:italic> represents the number of fully connected layers added in the networks and these two models are used for MNIST and CIFAR-10 classification, respectively. For data preparation, we follow the aforementioned settings in <ce:cross-ref id=""""crf0183"""" refid=""""sec0014"""">Section 6.3</ce:cross-ref>. The sizes of labeled subset are respectively 300, 600, 1000, 3000, 5000, 10,000, 60,000 (full) on MNIST. For CIFAR-10, the number of fine-tuned images are respectively 300, 1000, 5000, 10,000, 30,000, 50,000 (full).</ce:para>""''"'	uses_method_in	AGA	
cites	Experiments	G.E. Hinton, R.R. Salakhutdinov, Reducing the dimensionality of data with neural networks , Science , vol. 313 (2006), pp.504-507	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0037	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0051		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0088	'For example, principle component analysis can minimize the mean squared error of training data, but the performance for image classification is worse than the autoencoder with larger mean squared error [37][[ refid=''bib0037'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0076"""" view=""""all"""">The main reason is the information utilized in these traditional methods only comes from a single sample, but CILR mines the valuable information from a group of samples. Further analyse, the feature representations obtained by these traditional methods can perfectly reconstruct the input data. However, it is dubious that the learned features benefit to supervised tasks (such as classification). For example, principle component analysis can minimize the mean squared error of training data, but the performance for image classification is worse than the autoencoder with larger mean squared error <ce:cross-ref id=""""crf0173"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref>. Compared with these traditional methods, CILR and its variants utilize much latent labeled information and stronger constraint which the feature representations of similarly samples are consistent. The results verify that this regulation is valid and practicable.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experiments	J. Wang, J. Wang, J. Song, X. Xu, H. Shen, S. Li, Optimized cartesian k-means , IEEE Trans. Knowl. Data Eng. , vol. 27 (2015), pp.180-192	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0080	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0050		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0089	'In experiments, the K-means [80][[ refid=''bib0080'' ]] method is employed as the postprocessing to cluster images.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0071"""" view=""""all"""">In this section, we evaluate the availability of the learned latent representations by performing the clustering task on MNIST, CIFAR-10 and STL-10. For each dataset, specifically, the networks modeled in <ce:cross-ref id=""""crf0164"""" refid=""""sec0014"""">Section 6.3</ce:cross-ref> are utilized in the clustering task directly. To a roundly comparison, three popular measures in the literature are employed to evaluate the performance of the aforementioned clustering methods, including Accuracy (ACC) <ce:cross-ref id=""""crf0165"""" refid=""""bib0077"""">[77][[ refid=''''bib0077'''' ]]</ce:cross-ref>, Normalized Mutual Information (NMI)<ce:cross-ref id=""""crf0166"""" refid=""""bib0078"""">[78][[ refid=''''bib0078'''' ]]</ce:cross-ref> and Adjusted Rand Index (ARI) <ce:cross-ref id=""""crf0167"""" refid=""""bib0079"""">[79][[ refid=''''bib0079'''' ]]</ce:cross-ref>. Specifically, these measures range in [0, 1], and higher scores imply more accurate clustering results. In experiments, the K-means <ce:cross-ref id=""""crf0168"""" refid=""""bib0080"""">[80][[ refid=''''bib0080'''' ]]</ce:cross-ref> method is employed as the postprocessing to cluster images.</ce:para>""''"'	uses_method_in	AGA	
cites	Related work	S. Rifai, P. Vincent, X. Muller, X. Glorot, Y. Bengio, Contractive auto-encoders: explicit invariance during feature extraction , Proceedings of the 28th International Conference on Machine Learning (2011)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0038	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0013		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0090	'Similar to the sparse autoencoder, the contractive autoencoder [38][[ refid=''bib0038'' ]] attempts to learn the invariant feature representations of the inputs by introducing the Frobenius norm to encoding layers.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all"""">Various deep unsupervised learning methods with different structures have been presented in the literature. Traditional pre-training algorithms pre-train fully connected neural networks via layer-wise pre-training strategy, such as the deep belief network <ce:cross-ref id=""""crf0085"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> and the autoencoder <ce:cross-ref id=""""crf0086"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. Specifically, the fully connected layers are pre-trained by reconstructing inputs in these methods. Furthermore, by imposing the sparse constraints to encoding layers, more robust feature representations can be learned in the sparse autoencoder <ce:cross-ref id=""""crf0087"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>. Similar to the sparse autoencoder, the contractive autoencoder <ce:cross-ref id=""""crf0088"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> attempts to learn the invariant feature representations of the inputs by introducing the Frobenius norm to encoding layers. The denoising autoencoder <ce:cross-ref id=""""crf0089"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref> successfully learns a denoising function by reconstructing the original clean data from the corrupted inputs. Although it is feasible to pre-train very deep fully connected networks via these methods, the pre-training procedures are cumbersome. Compared with these methods, in this paper, we attempt to develop an end-to-end pre-training strategy, which can simplify the pre-training procedure and achieve the promising performance.</ce:para>""''"'	cites	AGA	
cites	Related work	A. Ng, Sparse autoencoder, CS294A Lecture notes 72(2011) 1–19.	http://dx.doi.org/10.1016/j.patcog.2017.10.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0012		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0091	'Furthermore, by imposing the sparse constraints to encoding layers, more robust feature representations can be learned in the sparse autoencoder [39][[ refid=''bib0039'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all"""">Various deep unsupervised learning methods with different structures have been presented in the literature. Traditional pre-training algorithms pre-train fully connected neural networks via layer-wise pre-training strategy, such as the deep belief network <ce:cross-ref id=""""crf0085"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> and the autoencoder <ce:cross-ref id=""""crf0086"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. Specifically, the fully connected layers are pre-trained by reconstructing inputs in these methods. Furthermore, by imposing the sparse constraints to encoding layers, more robust feature representations can be learned in the sparse autoencoder <ce:cross-ref id=""""crf0087"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>. Similar to the sparse autoencoder, the contractive autoencoder <ce:cross-ref id=""""crf0088"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> attempts to learn the invariant feature representations of the inputs by introducing the Frobenius norm to encoding layers. The denoising autoencoder <ce:cross-ref id=""""crf0089"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref> successfully learns a denoising function by reconstructing the original clean data from the corrupted inputs. Although it is feasible to pre-train very deep fully connected networks via these methods, the pre-training procedures are cumbersome. Compared with these methods, in this paper, we attempt to develop an end-to-end pre-training strategy, which can simplify the pre-training procedure and achieve the promising performance.</ce:para>""''"'	cites	AGA	
cites	Introduction	K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition , None (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0010		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0094	'However, a universal method for training very deep networks is under the way of exploring [4][[ refid=''bib0004'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">Although significant performances have been achieved over the past few years, there are two crucial problems that still need to be tackled. First, it is difficult to pre-train DNNs with a large number of layers. An essential reason is that decoding layers may deepen the depth of the networks during pre-training phase <ce:cross-refs id=""""crfs0011"""" refid=""""bib0029 bib0041 bib0042"""">[29,41,42][[ refid=''''bib0029 bib0041 bib0042'''' ]]</ce:cross-refs>. However, a universal method for training very deep networks is under the way of exploring <ce:cross-ref id=""""crf0078"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>. Second, the traditional pre-training methods are model-specified, which means that different strategies are required to pre-train various DNNs. Generally, more general method is desired for facilitating the usage of unsupervised deep feature learning.</ce:para>""''"'	cites	AGA	
cites	Related work	M.D. Zeiler, D. Krishnan, G.W. Taylor, R. Fergus, Deconvolutional networks , Computer Vision and Pattern Recognition, 2010 IEEE Conference on, IEEE (2010)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0041	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0017		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0095	'In addition, the deconvolutional network [41][[ refid=''bib0041'' ]] pre-trains CNNs based on the decomposition under a sparse constraint with unlabeled data only.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">As a natural framework to process images and videos, some previous works have been proposed to pre-train convolutional neural networks (CNNs). By applying the up-pooling operator, the convolutional autoencoder <ce:cross-ref id=""""crf0090"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> has been developed to pre-train CNNs by reconstructing input images. Similar to the autoencoder <ce:cross-ref id=""""crf0091"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>, a variety of regularization terms like Frobenius norm and sparse constraint can be employed to learn more robust and meaningful feature representations. In addition, the deconvolutional network <ce:cross-ref id=""""crf0092"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> pre-trains CNNs based on the decomposition under a sparse constraint with unlabeled data only. As a result, CNNs are pre-trained in an unsupervised learning way. Inspired by the sparse coding algorithm, Ranzato et al. <ce:cross-ref id=""""crf0093"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref> presented an unsupervised method to learn a group of sparse feature detectors that are invariant to small shifts and distortions. By initializing these detectors to convolutional kernels, more robust feature representations can be yielded. However, these methods mainly focus on shallow CNNs. To pre-train more deeper CNNs (<ce:italic>e.g.</ce:italic>, residual networks <ce:cross-ref id=""""crf0094"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>), an end-to-end approach is desiderated.</ce:para>""''"'	uses_data_from	AGA	
cites	Related work	J. Masci, U. Meier, D. Cireşan, J. Schmidhuber, Stacked convolutional auto-encoders for hierarchical feature extraction , International Conference on Artificial Neural Networks, Springer (2011)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0029	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0015		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0097	'By applying the up-pooling operator, the convolutional autoencoder [29][[ refid=''bib0029'' ]] has been developed to pre-train CNNs by reconstructing input images.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">As a natural framework to process images and videos, some previous works have been proposed to pre-train convolutional neural networks (CNNs). By applying the up-pooling operator, the convolutional autoencoder <ce:cross-ref id=""""crf0090"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> has been developed to pre-train CNNs by reconstructing input images. Similar to the autoencoder <ce:cross-ref id=""""crf0091"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>, a variety of regularization terms like Frobenius norm and sparse constraint can be employed to learn more robust and meaningful feature representations. In addition, the deconvolutional network <ce:cross-ref id=""""crf0092"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> pre-trains CNNs based on the decomposition under a sparse constraint with unlabeled data only. As a result, CNNs are pre-trained in an unsupervised learning way. Inspired by the sparse coding algorithm, Ranzato et al. <ce:cross-ref id=""""crf0093"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref> presented an unsupervised method to learn a group of sparse feature detectors that are invariant to small shifts and distortions. By initializing these detectors to convolutional kernels, more robust feature representations can be yielded. However, these methods mainly focus on shallow CNNs. To pre-train more deeper CNNs (<ce:italic>e.g.</ce:italic>, residual networks <ce:cross-ref id=""""crf0094"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>), an end-to-end approach is desiderated.</ce:para>""''"'	cites	AGA	
cites	Related work	P. Vincent, H. Larochelle, I. Lajoie, Y. Bengio, P.A. Manzagol, Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion , J. Mach. Learn. Res. , vol. 11 (2010), pp.3371-3408	http://dx.doi.org/10.1016/j.patcog.2017.10.022	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0040	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0014		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0098	'The denoising autoencoder [40][[ refid=''bib0040'' ]] successfully learns a denoising function by reconstructing the original clean data from the corrupted inputs.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all"""">Various deep unsupervised learning methods with different structures have been presented in the literature. Traditional pre-training algorithms pre-train fully connected neural networks via layer-wise pre-training strategy, such as the deep belief network <ce:cross-ref id=""""crf0085"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> and the autoencoder <ce:cross-ref id=""""crf0086"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. Specifically, the fully connected layers are pre-trained by reconstructing inputs in these methods. Furthermore, by imposing the sparse constraints to encoding layers, more robust feature representations can be learned in the sparse autoencoder <ce:cross-ref id=""""crf0087"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>. Similar to the sparse autoencoder, the contractive autoencoder <ce:cross-ref id=""""crf0088"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> attempts to learn the invariant feature representations of the inputs by introducing the Frobenius norm to encoding layers. The denoising autoencoder <ce:cross-ref id=""""crf0089"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref> successfully learns a denoising function by reconstructing the original clean data from the corrupted inputs. Although it is feasible to pre-train very deep fully connected networks via these methods, the pre-training procedures are cumbersome. Compared with these methods, in this paper, we attempt to develop an end-to-end pre-training strategy, which can simplify the pre-training procedure and achieve the promising performance.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experiments	J. Zhao, M. Mathieu, R. Goroshin, Y. Lecun, Stacked what-where auto-encoders , None (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0042	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0044		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0099	'For data preparation, we follow the previous work as described in [42][[ refid=''bib0042'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0066"""" view=""""all"""">Since the samples in CIFAR-10, CIFAR-100 and SVHN have the same size, the similar deep neural network illustrated in <ce:cross-ref id=""""crf0153"""" refid=""""tbl0003"""">Table 3</ce:cross-ref><ce:float-anchor refid=""""tbl0003""""/> are devised in this subsection. The structure is inspired by Conv-Large network described in <ce:cross-refs id=""""crfs0013"""" refid=""""bib0063 bib0064"""">[63,64][[ refid=''''bib0063 bib0064'''' ]]</ce:cross-refs>. Contrary to the Conv-Large, the ReLU activation function is utilized and the Gaussian noise is added in the input of each layer. For data preparation, we follow the previous work as described in <ce:cross-ref id=""""crf0154"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>. For CIFAR-10 and CIFAR-100, we resize the unlabeled images in STL-10 from 96 × 96 pixels to 32 × 32 pixels and utilize they to pre-train the networks. Specifically, the sizes of labeled subset used in CIFAR-10 are respectively 300, 1000, 4000, 5000, 10000 and 50000 (full). And the whole training data on CIFAR-100 are utilized in fine-tuning phase as the limited samples obtained in per class. When testing on SVHN, the whole images are employed to pre-training the deep networks first. Then, we utilize the whole labeled samples to fine-tune the networks. Because the traditional pre-training methods cannot pre-train the devised convolutional neural network, we compare the validity of CILR and its variants with recently proposed methods only.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experiments	K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale image recognition , None (2014)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0073	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0045		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0100	'We carry out CILR and its variants with a VGG-style network [73][[ refid=''bib0073'' ]] as illustrated in Table 7.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0068"""" view=""""all"""">STL-10 is particularly primly suited for deep unsupervised learning as it contains a large set of 100,000 unlabeled images. We carry out CILR and its variants with a VGG-style network <ce:cross-ref id=""""crf0157"""" refid=""""bib0073"""">[73][[ refid=''''bib0073'''' ]]</ce:cross-ref> as illustrated in <ce:cross-ref id=""""crf0158"""" refid=""""tbl0007"""">Table 7</ce:cross-ref><ce:float-anchor refid=""""tbl0007""""/>. And the unlabeled samples are used to pre-train the deep model. Similar to CIFAR-100, the pre-trained network is fine-tuned with whole labeled samples from STL-10. The classification results of STL-10 are shown in <ce:cross-ref id=""""crf0159"""" refid=""""tbl0008"""">Table 8</ce:cross-ref><ce:float-anchor refid=""""tbl0008""""/>. It also demonstrates that the proposed method is available for pre-training deep convolutional neural networks.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments	K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition , None (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.022	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/ctx/ctx0055		56	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-022/itrp/0101	'We also perform experiment to study the performance of CILR on the residual networks [4][[ refid=''bib0004'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0084"""" view=""""all"""">We also perform experiment to study the performance of CILR on the residual networks <ce:cross-ref id=""""crf0187"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>. Following the protocols in <ce:cross-ref id=""""crf0188"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>, the resnet-32 network is used in the experiments. For the CIFAR-10 and CIFAR-100 datasets, the whole images are utilized to pre-train and fine-tune resnet-32 orderly. As for STL-10, the unlabeled and the labeled images are employed to pre-train and fine-tune resnet-32, respectively.</ce:para>""''"'	uses_method_in	AGA	
cites	MMPC-GAC model based image segmentation with four-color labeling	L. Liu, W. Tao, Image segmentation by iterative optimization of multiphase multiple piecewise constant model and four-color relabeling , Pattern Recognit. , vol. 44 (2011), pp.2819-2833	http://dx.doi.org/10.1016/j.patcog.2017.10.023	model		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/ctx/ctx0021		45	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/itrp/0006	'In [1][[ refid=''bib0001'' ]], we adopt them to achieve the approximate optimization of Eq. (8) by minimizing the following formula [[ formulaid=''id7_pos0'' ]] with assuming g(x)=|x|.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0018"""" view=""""all"""">Actually, <ce:cross-ref id=""""crf0054"""" refid=""""eq0008"""">Eq. (8)</ce:cross-ref> formulates a multilabel Potts model, which cannot be exactly optimized with multiple layer graph methods <ce:cross-refs id=""""crfs0013"""" refid=""""bib0039 bib0040"""">[39,40][[ refid=''''bib0039 bib0040'''' ]]</ce:cross-refs>. In <ce:cross-ref id=""""crf0055"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>, we adopt them to achieve the approximate optimization of <ce:cross-ref id=""""crf0056"""" refid=""""eq0008"""">Eq. (8)</ce:cross-ref> by minimizing the following formula<ce:display><ce:formula id=""""eq0009""""><ce:label>(9)</ce:label><mml:math altimg=""""si18.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd columnalign=""""right""""><mml:mrow><mml:msup><mml:mi>E</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mi>G</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>φ</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign=""""left""""><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>⋯</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:munder><mml:mtext>min</mml:mtext><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>⋯</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi>ψ</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>l</mml:mi></mml:mrow><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign=""""left""""><mml:mrow><mml:mo>+</mml:mo><mml:mspace width=""""0.28em""""/><mml:mi>v</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>∈</mml:mo><mml:mi>P</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>∈</mml:mo><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy=""""true"""">|</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>φ</mml:mi><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo stretchy=""""true"""">|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display> with assuming <mml:math altimg=""""si19.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>g</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>|</mml:mo><mml:mi>x</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:math>. Approximation error between <ce:cross-ref id=""""crf0057"""" refid=""""eq0008"""">Eqs. (8)</ce:cross-ref> and<ce:cross-ref id=""""crf0058"""" refid=""""eq0009"""">(9)</ce:cross-ref> is also estimated in <ce:cross-ref id=""""crf0059"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>, which shows that it is positive correlated with the number of graph layers. According to the formulation described in <ce:cross-ref id=""""crf0060"""" refid=""""eq0009"""">Eq. (9)</ce:cross-ref>, an iterative segmentation scheme can be organized as iteratively solving <ce:italic>m</ce:italic>-phase optimization problem with MLG method. Obviously, such strategy will become very time-consuming when <ce:italic>m</ce:italic> is relatively large. Considering both approximation error and computing efficiency, four-color theorem <ce:cross-ref id=""""crf0061"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> is introduced into <ce:cross-ref id=""""crf0062"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> to limit the number of graph layers.</ce:para>""''"'	cites	AGA	
cites	Feature driven heuristic four-color labeling for robust and fast image segmentation	L. Liu, W. Tao, Image segmentation by iterative optimization of multiphase multiple piecewise constant model and four-color relabeling , Pattern Recognit. , vol. 44 (2011), pp.2819-2833	http://dx.doi.org/10.1016/j.patcog.2017.10.023			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/ctx/ctx0025		45	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/itrp/0011	'In [1][[ refid=''bib0001'' ]], four-color labeling is implemented as coloring the regions one by one.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0020"""" view=""""all"""">In <ce:cross-ref id=""""crf0064"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>, four-color labeling is implemented as coloring the regions one by one. The color of each region is randomly assigned by choosing an admissible color, which should satisfy the rule that the adjacent regions should have different colors. It was noting that a 2D map is only theoretical colorable with four colors, actually it could be time-consuming when the map structure is extremely complicated. Complicated map often makes the coloring procedure has to step back to re-color the previous regions if the current one has no admissible color to use.</ce:para>""''"'	cites	AGA	
uses_method_in	Feature driven heuristic four-color labeling for robust and fast image segmentation	B.J. Frey, D. Dueck, Clustering by passing messages between data points , Science , vol. 315 (2007), pp.972-976	http://dx.doi.org/10.1016/j.patcog.2017.10.023			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/br/bib0042	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/ctx/ctx0028		45	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/itrp/0012	'Specifically, in grouping step, we define a similarity matrix S={Si,j},i,j≤Rn on the initial local region set ℜ={ri},i=1,2,…,Rn, and then apply Affinity Propagation (AP) clustering [42][[ refid=''bib0042'' ]] with S. AP clustering only takes the similarity between pairs of data as input, and there is no need to specify the initial centers or the number of them beforehand.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0026"""" view=""""all"""">Specifically, in grouping step, we define a similarity matrix <mml:math altimg=""""si25.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math> on the initial local region set <mml:math altimg=""""si26.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>ℜ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math> and then apply Affinity Propagation (AP) clustering <ce:cross-ref id=""""crf0072"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref> with <ce:italic>S</ce:italic>. AP clustering only takes the similarity between pairs of data as input, and there is no need to specify the initial centers or the number of them beforehand. All the elements are viewed as potential centers at first, and then the messages are exchanged between the elements until a high-quality set of centers and corresponding clusters gradually emerge. In our implementation, the similarity of two regions is defined as the negative Euclidean squared distance of their average color.</ce:para>""''"'	uses_data_from	AGA	
cites	Feature driven heuristic four-color labeling for robust and fast image segmentation	B.J. Frey, D. Dueck, Clustering by passing messages between data points , Science , vol. 315 (2007), pp.972-976	http://dx.doi.org/10.1016/j.patcog.2017.10.023			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/br/bib0042	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/ctx/ctx0029		45	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/itrp/0013	'As suggested by Frey and Dueck [42][[ refid=''bib0042'' ]], the minimum similarity or the median similarity of similarity matrix S will be good initial choice for the preference.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0027"""" view=""""all"""">In AP clustering, the number of clusters is automatically determined by the diagonal elements of similarity matrix, which is also named as the “preference” (the priori suitability of an element to be a center). The diagonal elements are usually set to a shared value, and a larger preference will lead to more clusters. As suggested by Frey and Dueck <ce:cross-ref id=""""crf0073"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>, the minimum similarity or the median similarity of similarity matrix <ce:italic>S</ce:italic> will be good initial choice for the preference. Considering that the adjacency cracking operation requires the regions to be close in feature space, a relatively larger preference (such as the median similarity) is a safer choice. But for some cases, a relatively smaller preference (such as the minimum similarity) may even lead to a smoother and more reasonable color map. We will give a more detailed discussion about the “preference” setting in <ce:cross-ref id=""""crf0074"""" refid=""""sec0014"""">Section 5.4</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Experiments	P.F. Felzenszwalb, D.P. Huttenlocher, Efficient graph-based image segmentation , Int. J. Comput. Vis. , vol. 59 (2004), pp.167-181	http://dx.doi.org/10.1016/j.patcog.2017.10.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/br/bib0022	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/ctx/ctx0041		45	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/itrp/0027	'As to GBIS [22][[ refid=''bib0022'' ]], it only uses local similarity criterion, but our method utilizes MLG for global approximate solution and global grouping based heuristic four-color labeling strategy for smooth coloring.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0043"""" view=""""all"""">In general, the proposed method performs better than SC <ce:cross-ref id=""""crf0121"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, MSNC <ce:cross-ref id=""""crf0122"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref> and IGP <ce:cross-ref id=""""crf0123"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref>, and it mainly because our method can obtain a good approximate solution for MMPC-GAC model since the four-color labeling limits the approximate error of MLG-based optimization. However, SC, MSNC and IGP need to perform two approximation steps since spectral relaxation is used. These two approximation steps include transformations from discrete values to continuous values and continuous solutions to discrete solutions. As to GBIS <ce:cross-ref id=""""crf0124"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>, it only uses local similarity criterion, but our method utilizes MLG for global approximate solution and global grouping based heuristic four-color labeling strategy for smooth coloring. In terms of PRI and GCE, our performance is slightly worse than several graph partition methods <ce:cross-ref id=""""crf0125"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> and random walk methods <ce:cross-refs id=""""crfs0015"""" refid=""""bib0029 bib0030"""">[29,30][[ refid=''''bib0029 bib0030'''' ]]</ce:cross-refs>. This is mainly because graph partition methods <ce:cross-ref id=""""crf0126"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> are mainly based on superpixels and delicate partitioning criterions are introduced, but our method is pixel-wise labeling method in the optimization step which may result in some non-smooth labels; the random walk methods <ce:cross-refs id=""""crfs0016"""" refid=""""bib0029 bib0030"""">[29,30][[ refid=''''bib0029 bib0030'''' ]]</ce:cross-refs> apply carefully designed post-refinement but in our method we only remove those very tiny isolated regions after segmentation. However, thanks to the four-color labeling assisted MLG global optimization and the proposed new coloring strategy, our method still achieves competitive results under PRI and GCE metrics, and even performs better under VoI and BDE metrics. Especially when we integrate the measurements of RFCL on R_Better subgroup with that of HFCL on H_Better subgroup, we find that it almost outperforms all the compared methods under PRI, VoI and BDE metrics. Again, it demonstrates that our method is a good alternative strategy for RFCL strategy, especially when RFCL performs badly on images with complex scenes.</ce:para>""''"'	uses_method_in	AGA	
cites	Introduction	L. Liu, W. Tao, Image segmentation by iterative optimization of multiphase multiple piecewise constant model and four-color relabeling , Pattern Recognit. , vol. 44 (2011), pp.2819-2833	http://dx.doi.org/10.1016/j.patcog.2017.10.023	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/ctx/ctx0001		45	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/itrp/0034	'In our previous work [1][[ refid=''bib0001'' ]], an unsupervised image segmentation method based on Multiphase Multiple Piecewise Constant and Geodesic Active Contour (MMPC-GAC) model is proposed.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0009"""" view=""""all"""">In our previous work <ce:cross-ref id=""""crf0027"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>, an unsupervised image segmentation method based on Multiphase Multiple Piecewise Constant and Geodesic Active Contour (MMPC-GAC) model is proposed. To provide an efficient approximate optimization with Multiple Layer Graph (MLG) and reduce the approximate error of optimization, four-color labeling is introduced into the optimization iteration to limit MLG within three layers (representing four phases). But for those images with clutters and complicated structures, the randomness of original four-color labeling process usually produces chaotic color maps, which may lead to slow convergence and unsatisfactory segmentation. To solve these problems, we introduce a region adjacency cracking method to adaptively loosen the color labeling constraints. Moreover, a heuristic four-color labeling algorithm is proposed to establish global consistency for those regions of homogeneous appearance. We report both qualitative and quantitative results over public image datasets. The results with comparisons show that the proposed labeling method is a good substitute and improvement for random coloring method, especially for those images with clutters and complicated structures.</ce:para>""''"'	cites	AGA	
cites_as_review	Related works	H. Zhu, F. Meng, J. Cai, S. Lu, Beyond pixels: a comprehensive survey from bottom-up to semantic image segmentation and cosegmentation , J. Vis. Commun. Image Represent. , vol. 34 (2016), pp.12-27	http://dx.doi.org/10.1016/j.patcog.2017.10.023	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/br/bib0002	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/ctx/ctx0006		45	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/itrp/0048	'A more comprehensive review of image segmentation works can be found in [2][[ refid=''bib0002'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0011"""" view=""""all"""">Image segmentation algorithms can be roughly divided into three categories according to the role of user-provide prior knowledge in the approach <ce:cross-ref id=""""crf0033"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>, i.e., unsupervised methods, semi-supervised methods and supervised methods. Actually, all these three kinds of methods are correlated with each other and the border lines are not very clear. The unsupervised methods segment images without any human intervention <ce:cross-refs id=""""crfs0001"""" refid=""""bib0003 bib0004 bib0005 bib0006"""">[3–6][[ refid=''''bib0003 bib0004 bib0005 bib0006'''' ]]</ce:cross-refs>. Methods processing images with coarse priors, such as casual captions <ce:cross-refs id=""""crfs0002"""" refid=""""bib0007 bib0008 bib0009"""">[7–9][[ refid=''''bib0007 bib0008 bib0009'''' ]]</ce:cross-refs>, user scribbles and annotations <ce:cross-refs id=""""crfs0003"""" refid=""""bib0010 bib0011 bib0012"""">[10–12][[ refid=''''bib0010 bib0011 bib0012'''' ]]</ce:cross-refs> can be viewed as semi-supervised methods. And more recently, with the advent of large annotation dataset, supervised methods receive great development <ce:cross-refs id=""""crfs0004"""" refid=""""bib0013 bib0014"""">[13,14][[ refid=''''bib0013 bib0014'''' ]]</ce:cross-refs>. These methods achieve good performance since they learn superior target-specified models with those carefully annotated datasets. Since we focus on unsupervised segmentation in this paper, we only give a review of unsupervised methods in this section. A more comprehensive review of image segmentation works can be found in <ce:cross-ref id=""""crf0034"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites_as_review	AGA	
cites	Experiments	P. Arbelaez, M. Maire, C. Fowlkes, J. Malik, Contour detection and hierarchical image segmentation , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 33 (2011), pp.898-916	http://dx.doi.org/10.1016/j.patcog.2017.10.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/br/bib0044	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/ctx/ctx0035		45	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/itrp/0057	'To test the performance of the proposed Heuristic Four-Color Labeling (HFCL) method, especially on those complex natural images, we first give a comprehensive comparison with the Random Four-Color Labeling (RFCL) strategy on the BSDS500 dataset [44][[ refid=''bib0044'' ]], which contains 500 images from a broad range of scenarios.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0034"""" view=""""all"""">To test the performance of the proposed Heuristic Four-Color Labeling (HFCL) method, especially on those complex natural images, we first give a comprehensive comparison with the Random Four-Color Labeling (RFCL) strategy on the BSDS500 dataset <ce:cross-ref id=""""crf0092"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref>, which contains 500 images from a broad range of scenarios.</ce:para>""''"'	uses_data_from	AGA	
uses_data_from	Experiments	L. Liu, W. Tao, Image segmentation by iterative optimization of multiphase multiple piecewise constant model and four-color relabeling , Pattern Recognit. , vol. 44 (2011), pp.2819-2833	http://dx.doi.org/10.1016/j.patcog.2017.10.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/ctx/ctx0034		45	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/itrp/0058	'The parameters of MLG share the same values with [1][[ refid=''bib0001'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0033"""" view=""""all"""">Even though some key parameters have been given in the place where they are mentioned, here we still provide a summary about the parameter setting for clarity. In our experiment, we use the images from BSDS300 <ce:cross-ref id=""""crf0086"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref> and its extended version BSDS500 <ce:cross-ref id=""""crf0087"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref>. The image size is fixed to 481 × 321 (321 × 481). Mean shift <ce:cross-ref id=""""crf0088"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref> is served as the over-segmentation method for initialization, whose bandwidth parameter is <mml:math altimg=""""si36.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi mathvariant=""""bold"""">h</mml:mi><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mi>s</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mn>10</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:math> and minimum region area is <mml:math altimg=""""si37.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>200</mml:mn></mml:mrow></mml:math>. The similarities of the local regions are defined on the RGB color space. The preference of AP clustering is set to a shared value, and if not specified, it is fixed to the median of the similar matrix. A detailed discussion about the preference is given in <ce:cross-ref id=""""crf0089"""" refid=""""sec0014"""">Section 5.4</ce:cross-ref>. The parameters of MLG share the same values with <ce:cross-ref id=""""crf0090"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. The <ce:italic>v</ce:italic> and <ce:italic>β</ce:italic> in <ce:cross-ref id=""""crf0091"""" refid=""""eq0008"""">Eq. (8)</ce:cross-ref> are fixed to 12,000 and 0.03, respectively. For MLG construction, <ce:italic>n<ce:inf loc=""""post"""">l</ce:inf></ce:italic> is fixed to 25. The maximum number of iterations is set to 8. We test our algorithm on a PC with a 3.0 Ghz CPU and 4 GB memory. Each iteration for MLG based optimization costs about 3–4 s.</ce:para>""''"'	uses_method_in	AGA	
uses_data_from	Experiments	D. Martin, C. Fowlkes, D. Tal, J. Malik, A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics , Proceedings of the International Conference on Computer Vision , vol. 2 (2001), pp.416-423	http://dx.doi.org/10.1016/j.patcog.2017.10.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/br/bib0043	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/ctx/ctx0037		45	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/itrp/0059	'Like most other approaches, we take BSDS300 [43][[ refid=''bib0043'' ]] for the comparison.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0040"""" view=""""all"""">In <ce:cross-ref id=""""crf0108"""" refid=""""sec0012"""">Section 5.2</ce:cross-ref>, we give a comprehensive comparison between RFCL strategy and the proposed HFCL strategy. In this section, we will compare our method with the state-of-art methods. Like most other approaches, we take BSDS300 <ce:cross-ref id=""""crf0109"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref> for the comparison. The value of AP clustering preference for the proposed method is fixed to the median of the similarity matrix.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments	D. Comaniciu, P. Meer, Mean shift: a robust approach toward feature space analysis , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 24 (2002), pp.603-619	http://dx.doi.org/10.1016/j.patcog.2017.10.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/br/bib0003	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/ctx/ctx0033		45	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/itrp/0067	'Mean shift [3][[ refid=''bib0003'' ]] is served as the over-segmentation method for initialization, whose bandwidth parameter is h=(hr,hs)=(8,10) and minimum region area is M=200.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0033"""" view=""""all"""">Even though some key parameters have been given in the place where they are mentioned, here we still provide a summary about the parameter setting for clarity. In our experiment, we use the images from BSDS300 <ce:cross-ref id=""""crf0086"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref> and its extended version BSDS500 <ce:cross-ref id=""""crf0087"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref>. The image size is fixed to 481 × 321 (321 × 481). Mean shift <ce:cross-ref id=""""crf0088"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref> is served as the over-segmentation method for initialization, whose bandwidth parameter is <mml:math altimg=""""si36.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi mathvariant=""""bold"""">h</mml:mi><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi><mml:mi>s</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mn>10</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:math> and minimum region area is <mml:math altimg=""""si37.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>200</mml:mn></mml:mrow></mml:math>. The similarities of the local regions are defined on the RGB color space. The preference of AP clustering is set to a shared value, and if not specified, it is fixed to the median of the similar matrix. A detailed discussion about the preference is given in <ce:cross-ref id=""""crf0089"""" refid=""""sec0014"""">Section 5.4</ce:cross-ref>. The parameters of MLG share the same values with <ce:cross-ref id=""""crf0090"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. The <ce:italic>v</ce:italic> and <ce:italic>β</ce:italic> in <ce:cross-ref id=""""crf0091"""" refid=""""eq0008"""">Eq. (8)</ce:cross-ref> are fixed to 12,000 and 0.03, respectively. For MLG construction, <ce:italic>n<ce:inf loc=""""post"""">l</ce:inf></ce:italic> is fixed to 25. The maximum number of iterations is set to 8. We test our algorithm on a PC with a 3.0 Ghz CPU and 4 GB memory. Each iteration for MLG based optimization costs about 3–4 s.</ce:para>""''"'	uses_method_in	AGA	
cites	Related works	J. Wang, H. Jiang, Y. Jia, X.S. Hua, C. Zhang, L. Quan, Regularized tree partitioning and its application to unsupervised image segmentation , IEEE Trans. Image Process. , vol. 23 (2014), pp.1909-1922	http://dx.doi.org/10.1016/j.patcog.2017.10.023	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/ctx/ctx0010		45	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/itrp/0094	'More recently, Wang et al. [27][[ refid=''bib0027'' ]] introduced normalized and average tree partitioning methods to perform normalized and average cut over a tree.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">Segmentation problems are essentially clustering problems, which aim to group the pixels into local homogenous regions. K-means, mean-shift <ce:cross-ref id=""""crf0035"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref> region merging <ce:cross-refs id=""""crfs0005"""" refid=""""bib0015 bib0016"""">[15,16][[ refid=''''bib0015 bib0016'''' ]]</ce:cross-refs>, region splitting <ce:cross-refs id=""""crfs0006"""" refid=""""bib0017 bib0018"""">[17,18][[ refid=''''bib0017 bib0018'''' ]]</ce:cross-refs> and more recent works <ce:cross-refs id=""""crfs0007"""" refid=""""bib0019 bib0020 bib0021"""">[19–21][[ refid=''''bib0019 bib0020 bib0021'''' ]]</ce:cross-refs> are all typical examples for clustering based methods. Specifically, K-means is a parametric approach which requires a prior knowledge of the number of clustering centers. While mean-shift, region merging, splitting methods and <ce:cross-refs id=""""crfs0008"""" refid=""""bib0019 bib0020 bib0021"""">[19–21][[ refid=''''bib0019 bib0020 bib0021'''' ]]</ce:cross-refs> are all non-parametric approaches, which need no assumptions about the number of centers or feature distributions. Besides clustering based methods, graph based methods also receive great attention, such as graph-based image segmentation <ce:cross-refs id=""""crfs0009"""" refid=""""bib0004 bib0005 bib0022"""">[4,5,22][[ refid=''''bib0004 bib0005 bib0022'''' ]]</ce:cross-refs>, ratio cut <ce:cross-ref id=""""crf0036"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>, normalized cut <ce:cross-ref id=""""crf0037"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, average cut <ce:cross-ref id=""""crf0038"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>, segmentation with spanning tree presentation <ce:cross-ref id=""""crf0039"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>, etc. More recently, Wang et al. <ce:cross-ref id=""""crf0040"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> introduced normalized and average tree partitioning methods to perform normalized and average cut over a tree. Saglam and Baykan <ce:cross-ref id=""""crf0041"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> used Prim’s sequential representation of minimum spanning tree and presented a new cutting criterion for image segmentation. Besides, some approaches based on random walk model <ce:cross-refs id=""""crfs0010"""" refid=""""bib0029 bib0030"""">[29,30][[ refid=''''bib0029 bib0030'''' ]]</ce:cross-refs> also receive good performance.</ce:para>""''"'	cites	AGA	
cites	Related works	D. Mumford, J. Shah, Optimal approximations by piecewise smooth functions and associated variational problems , Commun. Pure Appl. Math. , vol. 42 (1989), pp.577-685	http://dx.doi.org/10.1016/j.patcog.2017.10.023	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/br/bib0031	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/ctx/ctx0014		45	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/itrp/0103	'Mumford–Shah model [31][[ refid=''bib0031'' ]] for segmentation aims to seek piece-wise smooth approximation and minimal edge cost.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">The aforementioned methods are all defined in discrete domain. Actually, continuous models <ce:cross-refs id=""""crfs0011"""" refid=""""bib0001 bib0031 bib0032 bib0033 bib0034 bib0035 bib0036"""">[1,31–36][[ refid=''''bib0001 bib0031 bib0032 bib0033 bib0034 bib0035 bib0036'''' ]]</ce:cross-refs> are also widely used in image segmentation society. Mumford–Shah model <ce:cross-ref id=""""crf0042"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> for segmentation aims to seek piece-wise smooth approximation and minimal edge cost. By assuming the local regions are piecewise constant, Chan–Vese model <ce:cross-ref id=""""crf0043"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> introduces level set representation to bridge the gap between the theoretic formulation of <ce:cross-ref id=""""crf0044"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> and optimization difficulty in practice, which further simplifies Mumford–Shah model. In <ce:cross-ref id=""""crf0045"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> and <ce:cross-ref id=""""crf0046"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>, the piecewise constant model is further extended to Multiple Piecewise Constant model (MPC) <ce:cross-ref id=""""crf0047"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> and Multiphase Multiple Piecewise Constant model (MMPC) <ce:cross-ref id=""""crf0048"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> to adapt to more complex situations. We will give more detailed description about this model in the following section.</ce:para>""''"'	cites	AGA	
cites	Experiments	L. Liu, W. Tao, Image segmentation by iterative optimization of multiphase multiple piecewise constant model and four-color relabeling , Pattern Recognit. , vol. 44 (2011), pp.2819-2833	http://dx.doi.org/10.1016/j.patcog.2017.10.023	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/ctx/ctx0045		45	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-023/itrp/0105	'We have shown in [1][[ refid=''bib0001'' ]] that the four-color setting can significantly increase the efficiency while achieving equivalent level of performance.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0047"""" view=""""all""""><ce:italic>The number of used colors:</ce:italic> As we discussed in <ce:cross-ref id=""""crf0135"""" refid=""""sec0005"""">Section 3.2</ce:cross-ref>, the number of used colors determines the number of layers in MLG and more layers lead to more computational cost and larger approximation error. We have shown in <ce:cross-ref id=""""crf0136"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> that the four-color setting can significantly increase the efficiency while achieving equivalent level of performance. Four colors are only theoretically enough to color the whole image. But for some more complex images, it seems a little bit inappropriate. On the one hand, if only four colors are allowed, the color labeling process may be time-consuming since there may be a lot of stepping back during the coloring. On the other hand, the final segmentation is limited within four classes according to the colors, which sometimes cannot be directly corresponded to the real classes in human conception.</ce:para>""''"'	uses_method_in	AGA	
cites	Related work	Y. Yin, G. Yang, J. Xu, H. Man, Small group human activity recognition , Proceeding of International Conference on Image Processing (2012)	http://dx.doi.org/10.1016/j.patcog.2017.10.037	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/br/bib0020	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/ctx/ctx0022		47	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/itrp/0001	'Yin et al. [20][[ refid=''bib0020'' ]] proposed a conditional Gaussian process dynamic model (CGPDM) for capturing both the spatial and temporal dynamics of group activities.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all""""><ce:italic>Group Activity Recognition:</ce:italic> Some studies <ce:cross-refs id=""""crfs0008"""" refid=""""bib0017 bib0030 bib0033 bib0034"""">[17,30,33,34][[ refid=''''bib0017 bib0030 bib0033 bib0034'''' ]]</ce:cross-refs> used a layered model for group activity recognition by enabling the analysis of different person-level information. Cheng et al. <ce:cross-ref id=""""crf0024"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> proposed a unified model with three layers or levels of representations for jointly considering the different granularities of activity patterns: individual actions, pairwise interactions, and overall motion pattern of a group. They presented the statistical properties of activity patterns in each layer to recognize the group activity. Choi and Silvio <ce:cross-refs id=""""crf0025"""" refid=""""bib0030 bib0033"""">[30,33][[ refid=''''bib0030 bib0033'''' ]]</ce:cross-refs> inferred individual activity labels at a low level and used these labels to describe the human interaction at the middle level. The acquired interaction labels were used to infer the collective activity. An accurate inference of individual activity is a crucial factor for the overall recognition. Therefore, this model was dependent on the correctness of the acquired labels. Similarly, Chang et al. <ce:cross-ref id=""""crf0027"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> considered human interaction as an important cue for collective activity recognition. They proposed an interaction matrix (IM) that measures the connection between individual activities. Scott and Fisher <ce:cross-ref id=""""crf0028"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> used a hidden Markov model (HMM) for the temporal analysis of group activities. Cho et al. <ce:cross-ref id=""""crf0029"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> proposed a group interaction zone (GIZ) for suppressing the noise caused by non-group members. Zhang et al. <ce:cross-ref id=""""crf0030"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref> measured the causalities between people for group activity recognition. Lan et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> modeled social roles between people. These roles are used as a context information for group activity recognition. Noceti and Odone <ce:cross-ref id=""""crf0032"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref> represented human group with graphs encoding the information of mutual positions and orientations. They devised a spectral method-based kernel function for graph matching. Brendel and Todorovic <ce:cross-ref id=""""crf0033"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref> described videos by spatio-temporal graphs. The model learned the complex activities in terms of relevant sub-activities and their hierarchical, temporal, and spatial relations. Sun et al. <ce:cross-ref id=""""crf0034"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> presented the contextual relations between people as a latent relational graph. The graph hierarchically encodes the association potentials between trajectories, intra-group interactions, correlations, and inter-group compatibilities. Stephens and Bors <ce:cross-ref id=""""crf0035"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref> proposed a model describing the group interdependencies in both motion flows and locations of moving regions. The regions are modeled using kernel density estimation (KDE). Shu et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> used an and-or graph to jointly infer groups, events, and social roles, with Markov chain Monte Carlo (MCMC) and dynamic programming. Moreover, they presented templates for characterizing latent sub-events. Yin et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> proposed a conditional Gaussian process dynamic model (CGPDM) for capturing both the spatial and temporal dynamics of group activities. Group activities are represented as a set of Gaussian processes with different means and covariance matrices. Although these previous studies modeled the overall group relationship in a scene, similar local motions of sub-groups were ignored. However, if similar local motions are not considered, there would be limitations in the representation. We thus propose a descriptor that handles the influences of these motions.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments	N.-G. Cho, Y.-J. Kim, U. Park, J.-S. Park, S.-W. Lee, Group activity recognition with group interaction zone based on relative distance between human objects , Int. J. Pattern Recognit. Artif. Intell. , vol. 29 (2015), pp.1555007	http://dx.doi.org/10.1016/j.patcog.2017.10.037	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/ctx/ctx0040		47	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/itrp/0030	'Some classes contained only few samples, therefore, we ignored those classes in our tasks and we conducted an experiment on six class classifications following a previous work [18][[ refid=''bib0018'' ]]: Approach, Fight, InGroup, RunTogether, Split, and WalkTogether.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0031"""" view=""""all"""">The BEHAVE dataset <ce:cross-ref id=""""crf0062"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> was recorded from a surveillance system, and it consists of 10 group activities: <ce:italic>InGroup, Approach, WalkTogether, Meet, Split, Ignore, Chase, Fight, RunTogether, and Following</ce:italic>. These activities are performed by two to five people in the scenes. Each activity is described in <ce:cross-ref id=""""crf0063"""" refid=""""tbl0001"""">Table 1</ce:cross-ref><ce:float-anchor refid=""""tbl0001""""/>. Some classes contained only few samples, therefore, we ignored those classes in our tasks and we conducted an experiment on six class classifications following a previous work <ce:cross-ref id=""""crf0064"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>: <ce:italic>Approach, Fight, InGroup, RunTogether, Split, and WalkTogether</ce:italic>. We evaluated the proposed descriptor by comparison with the methods used in previous studies <ce:cross-refs id=""""crfs0010"""" refid=""""bib0018 bib0020 bib0021 bib0022"""">[18,20–22][[ refid=''''bib0018 bib0020 bib0021 bib0022'''' ]]</ce:cross-refs>. Several previous approaches consisted of an individual descriptor and a pairwise descriptor instead of a sub-event descriptor. We focused on the composition of the descriptor and conducted a comparison. In this experiment, we performed the 3-fold cross validation strategy as implemented in previous works <ce:cross-refs id=""""crfs0011"""" refid=""""bib0018 bib0020 bib0021 bib0022"""">[18,20–22][[ refid=''''bib0018 bib0020 bib0021 bib0022'''' ]]</ce:cross-refs>. We randomly selected 82 clips for training and 41 clips for testing. Each training and testing data are augmented to 2050 clips and 1025 clips, respectively.</ce:para>""''"'	uses_method_in	AGA	
cites	Introduction	J.C. Nascimento, J.S. Marques, J.M. Lemos, Modeling and classifying human activities from trajectories using a class of space-varying parametric motion fields , IEEE Trans. Image Process. , vol. 22 (2013), pp.2066-2080	http://dx.doi.org/10.1016/j.patcog.2017.10.037	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/br/bib0025	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/ctx/ctx0002		47	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/itrp/0067	'It is also ineffective when the region of a person occupies less than 5% of a scene [25][[ refid=''bib0025'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0008"""" view=""""all"""">For understanding human activities in surveillance videos, two types of features are representatively used: shape-based features and trajectory-based features. The shape-based feature is used to describe the appearance information of a human and is meaningful for capturing the relationship between the local motions from body parts. Human activity can also be represented as a combination of local motions. For example, in the case of people hugging, the activity can be described as a combination of “stepping forward” and “embracing arms.” Although the shape-based feature can elaborately represent human activity, it is vulnerable to low resolution and occlusion of body parts. It is also ineffective when the region of a person occupies less than 5% of a scene <ce:cross-ref id=""""crf0014"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. On the other hand, the trajectory-based feature captures the motion of an object with a semantic-level interpretation of the movements in a scene. This feature can represent a human activity (<ce:italic>e.g., standing, walking, running, etc</ce:italic>.) according to the degree of location changes. Furthermore, by considering the relationships and properties between people, this feature can describe a group activity. For example, the moving directions of individuals and the distances between people are meaningful for determining whether people are approaching or splitting up. We focus on the analysis of relations among people in videos using trajectories in this work. We do not detect the human objects and track them in the videos. We assume that the trajectories are given in advance. It means that we use the ground truth location of objects. If we can successfully detect the objects with any available detector, the problems of low-resolution and occluded objects will be not critical.</ce:para>""''"'	cites	AGA	
cites	Related work	F. Visin, K. Kastner, K. Cho, M. Matteucci, A. Courville, Y. Bengio, Renet: a recurrent neural network based alternative to convolutional networks, (2015).	http://dx.doi.org/10.1016/j.patcog.2017.10.037	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/br/bib0045	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/ctx/ctx0031		47	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/itrp/0082	'Visin et al. [45][[ refid=''bib0045'' ]] proposed a model that replaced convolution and pooling layer of convolutional neural network (CNN) with GRU for object recognition.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">The GRU model has been widely applied to several tasks, such as question detection <ce:cross-ref id=""""crf0042"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>, rumor detection <ce:cross-ref id=""""crf0043"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref>, social media encoding <ce:cross-ref id=""""crf0044"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref>, and object recognition <ce:cross-ref id=""""crf0045"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref>. Tang et al. <ce:cross-ref id=""""crf0046"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref> proposed models for capturing the context information of a speech question at the segment and utterance level from acoustic features. Ma et al. <ce:cross-ref id=""""crf0047"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref> presented a model for debunking rumors. The hidden representations of the model capture the context of relevant posts over time. Dhingra et al. <ce:cross-ref id=""""crf0048"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> proposed a character encoder from social media posts by learning the non-local dependencies of characters in a sentence. Visin et al. <ce:cross-ref id=""""crf0049"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> proposed a model that replaced convolution and pooling layer of convolutional neural network (CNN) with GRU for object recognition.</ce:para>""''"'	cites	AGA	
cites	Experiments	B. Scott, R. Fisher, The behave video dataset: ground truthed video for multi-person behavior classification , Proceeding of British Machine Vision Conference , vol. 4 (2010), pp.1-12	http://dx.doi.org/10.1016/j.patcog.2017.10.037	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/br/bib0031	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/ctx/ctx0039		47	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/itrp/0086	'The BEHAVE dataset [31][[ refid=''bib0031'' ]] was recorded from a surveillance system, and it consists of 10 group activities: InGroup, Approach, WalkTogether, Meet, Split, Ignore, Chase, Fight, RunTogether, and Following.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0031"""" view=""""all"""">The BEHAVE dataset <ce:cross-ref id=""""crf0062"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> was recorded from a surveillance system, and it consists of 10 group activities: <ce:italic>InGroup, Approach, WalkTogether, Meet, Split, Ignore, Chase, Fight, RunTogether, and Following</ce:italic>. These activities are performed by two to five people in the scenes. Each activity is described in <ce:cross-ref id=""""crf0063"""" refid=""""tbl0001"""">Table 1</ce:cross-ref><ce:float-anchor refid=""""tbl0001""""/>. Some classes contained only few samples, therefore, we ignored those classes in our tasks and we conducted an experiment on six class classifications following a previous work <ce:cross-ref id=""""crf0064"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>: <ce:italic>Approach, Fight, InGroup, RunTogether, Split, and WalkTogether</ce:italic>. We evaluated the proposed descriptor by comparison with the methods used in previous studies <ce:cross-refs id=""""crfs0010"""" refid=""""bib0018 bib0020 bib0021 bib0022"""">[18,20–22][[ refid=''''bib0018 bib0020 bib0021 bib0022'''' ]]</ce:cross-refs>. Several previous approaches consisted of an individual descriptor and a pairwise descriptor instead of a sub-event descriptor. We focused on the composition of the descriptor and conducted a comparison. In this experiment, we performed the 3-fold cross validation strategy as implemented in previous works <ce:cross-refs id=""""crfs0011"""" refid=""""bib0018 bib0020 bib0021 bib0022"""">[18,20–22][[ refid=''''bib0018 bib0020 bib0021 bib0022'''' ]]</ce:cross-refs>. We randomly selected 82 clips for training and 41 clips for testing. Each training and testing data are augmented to 2050 clips and 1025 clips, respectively.</ce:para>""''"'	uses_data_from	AGA	
cites	Related work	C. Zhang, X. Yang, W. Lin, J. Zhu, Recognizing human group behaviors with multi-group causalities , Proceeding of IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology Workshops (2012)	http://dx.doi.org/10.1016/j.patcog.2017.10.037	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/br/bib0022	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/ctx/ctx0015		47	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/itrp/0098	'Zhang et al. [22][[ refid=''bib0022'' ]] measured the causalities between people for group activity recognition.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all""""><ce:italic>Group Activity Recognition:</ce:italic> Some studies <ce:cross-refs id=""""crfs0008"""" refid=""""bib0017 bib0030 bib0033 bib0034"""">[17,30,33,34][[ refid=''''bib0017 bib0030 bib0033 bib0034'''' ]]</ce:cross-refs> used a layered model for group activity recognition by enabling the analysis of different person-level information. Cheng et al. <ce:cross-ref id=""""crf0024"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> proposed a unified model with three layers or levels of representations for jointly considering the different granularities of activity patterns: individual actions, pairwise interactions, and overall motion pattern of a group. They presented the statistical properties of activity patterns in each layer to recognize the group activity. Choi and Silvio <ce:cross-refs id=""""crf0025"""" refid=""""bib0030 bib0033"""">[30,33][[ refid=''''bib0030 bib0033'''' ]]</ce:cross-refs> inferred individual activity labels at a low level and used these labels to describe the human interaction at the middle level. The acquired interaction labels were used to infer the collective activity. An accurate inference of individual activity is a crucial factor for the overall recognition. Therefore, this model was dependent on the correctness of the acquired labels. Similarly, Chang et al. <ce:cross-ref id=""""crf0027"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> considered human interaction as an important cue for collective activity recognition. They proposed an interaction matrix (IM) that measures the connection between individual activities. Scott and Fisher <ce:cross-ref id=""""crf0028"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> used a hidden Markov model (HMM) for the temporal analysis of group activities. Cho et al. <ce:cross-ref id=""""crf0029"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> proposed a group interaction zone (GIZ) for suppressing the noise caused by non-group members. Zhang et al. <ce:cross-ref id=""""crf0030"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref> measured the causalities between people for group activity recognition. Lan et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> modeled social roles between people. These roles are used as a context information for group activity recognition. Noceti and Odone <ce:cross-ref id=""""crf0032"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref> represented human group with graphs encoding the information of mutual positions and orientations. They devised a spectral method-based kernel function for graph matching. Brendel and Todorovic <ce:cross-ref id=""""crf0033"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref> described videos by spatio-temporal graphs. The model learned the complex activities in terms of relevant sub-activities and their hierarchical, temporal, and spatial relations. Sun et al. <ce:cross-ref id=""""crf0034"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> presented the contextual relations between people as a latent relational graph. The graph hierarchically encodes the association potentials between trajectories, intra-group interactions, correlations, and inter-group compatibilities. Stephens and Bors <ce:cross-ref id=""""crf0035"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref> proposed a model describing the group interdependencies in both motion flows and locations of moving regions. The regions are modeled using kernel density estimation (KDE). Shu et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> used an and-or graph to jointly infer groups, events, and social roles, with Markov chain Monte Carlo (MCMC) and dynamic programming. Moreover, they presented templates for characterizing latent sub-events. Yin et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> proposed a conditional Gaussian process dynamic model (CGPDM) for capturing both the spatial and temporal dynamics of group activities. Group activities are represented as a set of Gaussian processes with different means and covariance matrices. Although these previous studies modeled the overall group relationship in a scene, similar local motions of sub-groups were ignored. However, if similar local motions are not considered, there would be limitations in the representation. We thus propose a descriptor that handles the influences of these motions.</ce:para>""''"'	cites	AGA	
cites	Experiments	N.-G. Cho, Y.-J. Kim, U. Park, J.-S. Park, S.-W. Lee, Group activity recognition with group interaction zone based on relative distance between human objects , Int. J. Pattern Recognit. Artif. Intell. , vol. 29 (2015), pp.1555007	http://dx.doi.org/10.1016/j.patcog.2017.10.037	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/ctx/ctx0044		47	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/itrp/0100	'Our method achieved 4.99% higher recognition accuracy than the state-of-the-art method, GIZ [18][[ refid=''bib0018'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0033"""" view=""""all""""><ce:cross-ref id=""""crf0072"""" refid=""""tbl0002"""">Table 2</ce:cross-ref><ce:float-anchor refid=""""tbl0002""""/> and <ce:cross-ref id=""""crf0073"""" refid=""""fig0006"""">Fig. 6</ce:cross-ref><ce:float-anchor refid=""""fig0006""""/> show the results of the experiments on the BEHAVE dataset. The proposed DGCF + GRU outperformed the other competing approaches <ce:cross-refs id=""""crfs0012"""" refid=""""bib0018 bib0020 bib0021 bib0022"""">[18,20–22][[ refid=''''bib0018 bib0020 bib0021 bib0022'''' ]]</ce:cross-refs> on average. Our method achieved 4.99% higher recognition accuracy than the state-of-the-art method, GIZ <ce:cross-ref id=""""crf0074"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. To validate the effectiveness of the DGCF descriptor, we also measured the classification performance by using only individual + pairwise feature in the same experimental setup. The constructed individual + pairwise descriptor only combined the features for behavioral patterns of individuals and all pairs in a scene. The results showed that the individual + pairwise + GRU slightly outperformed the competing methods. It means that GRU effectively handles the temporal variability. However, the proposed DGCF + GRU improved the accuracy of 4.01% by considering sub-group relationships rather than simply combining all pairs.</ce:para>""''"'	uses_method_in	AGA	
cites	Experiments	W. Choi, S. Silvio, A unified framework for multi-target tracking and collective activity recognition , Proceeding of European Conference on Computer Vision (2012)	http://dx.doi.org/10.1016/j.patcog.2017.10.037	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/br/bib0033	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/ctx/ctx0045		47	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-037/itrp/0101	'New Collective Activity dataset [33][[ refid=''bib0033'' ]] consists of six classes: Gathering, Talking, Dismissal, Walking, Chasing, and Queuing.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0037"""" view=""""all"""">New Collective Activity dataset <ce:cross-ref id=""""crf0078"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> consists of six classes: <ce:italic>Gathering, Talking, Dismissal, Walking, Chasing, and Queuing</ce:italic>. The videos are recorded from a hand-held camera at a low angle of view. <ce:cross-ref id=""""crf0079"""" refid=""""fig0009"""">Fig. 9</ce:cross-ref><ce:float-anchor refid=""""fig0009""""/> shows the example of the dataset. We aimed to analyze the relations among people for representation of group’s behavioral property. Therefore, we used the annotations of the trajectories provided with the dataset. In this experiment, we performed a 3-fold cross-validation as implemented in previous works <ce:cross-refs id=""""crfs0013"""" refid=""""bib0023 bib0024 bib0030 bib0034"""">[23,24,30,34][[ refid=''''bib0023 bib0024 bib0030 bib0034'''' ]]</ce:cross-refs> for the quantitative comparison. Thus, we divided into three subsets and augmented the number of samples in the dataset to 1100. The augmented data must belong to a subset of the origin data. The 29 clips were augmented to 725 clips for training, and the 15 clips were also augmented to 375 clips for testing.</ce:para>""''"'	uses_data_from	AGA	
cites	The proposed LSO-VLADNet	J. Nchez, F. Perronnin, T. Mensink, J. Verbeek, Image classification with the fisher vector: theory and practice , Int. J. Comput. Vis. , vol. 105 (2013), pp.222-245	http://dx.doi.org/10.1016/j.patcog.2017.10.039			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0026	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0022		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0001	'Fisher Vector (FV [26][[ refid=''bib0026'' ]]) coding is a widely-used second-order feature coding method.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0031"""" view=""""all"""">From <ce:cross-ref id=""""crf0096"""" refid=""""fig0002"""">Figs. 2</ce:cross-ref> and <ce:cross-ref id=""""crf0097"""" refid=""""fig0003"""">3</ce:cross-ref>, compared with the original NetVLAD model, LSAC layer, <mml:math altimg=""""si42.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math> activation function layer and affine subspace layer are three newly designed layers. The LSO-VLADNet is an end-to-end deep network. The feed-forward operation first updates the loss of the deep network, then the gradients of the loss with respect to each trainable parameter will back propagate to the input to update each parameter. The end-to-end training procedure of the proposed network is represented as the blue and the red arrows in <ce:cross-ref id=""""crf0098"""" refid=""""fig0003"""">Fig. 3</ce:cross-ref>. The end-to-end LSAC layer is not researched in the existing deep learning model, our network first propose this new structure end-to-end layer. Fisher Vector (FV <ce:cross-ref id=""""crf0099"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>) coding is a widely-used second-order feature coding method. The original FV only has the forward operation, yet our second-order statistic layer is trained by the end-to-end manner. The original affine subspace method <ce:cross-ref id=""""crf0100"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> only has the forward operation, yet our affine subspace layer is viewed as the 1 × 1 convolutional layer and can be trained by the end-to-end pattern. These new structure layers can efficiently improve the classification performances of the proposed network.</ce:para>""''"'	cites	AGA	
cites	The proposed LSO-VLADNet	P. Li, X. Lu, Q. Wang, From dictionary of visual words to subspaces: locality-constrained affine subspace coding , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.039			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0028	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0023		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0002	'The original affine subspace method [28][[ refid=''bib0028'' ]] only has the forward operation, yet our affine subspace layer is viewed as the 1 × 1 convolutional layer and can be trained by the end-to-end pattern.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0031"""" view=""""all"""">From <ce:cross-ref id=""""crf0096"""" refid=""""fig0002"""">Figs. 2</ce:cross-ref> and <ce:cross-ref id=""""crf0097"""" refid=""""fig0003"""">3</ce:cross-ref>, compared with the original NetVLAD model, LSAC layer, <mml:math altimg=""""si42.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math> activation function layer and affine subspace layer are three newly designed layers. The LSO-VLADNet is an end-to-end deep network. The feed-forward operation first updates the loss of the deep network, then the gradients of the loss with respect to each trainable parameter will back propagate to the input to update each parameter. The end-to-end training procedure of the proposed network is represented as the blue and the red arrows in <ce:cross-ref id=""""crf0098"""" refid=""""fig0003"""">Fig. 3</ce:cross-ref>. The end-to-end LSAC layer is not researched in the existing deep learning model, our network first propose this new structure end-to-end layer. Fisher Vector (FV <ce:cross-ref id=""""crf0099"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>) coding is a widely-used second-order feature coding method. The original FV only has the forward operation, yet our second-order statistic layer is trained by the end-to-end manner. The original affine subspace method <ce:cross-ref id=""""crf0100"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> only has the forward operation, yet our affine subspace layer is viewed as the 1 × 1 convolutional layer and can be trained by the end-to-end pattern. These new structure layers can efficiently improve the classification performances of the proposed network.</ce:para>""''"'	cites	AGA	
cites	The proposed LSO-VLADNet	P. Li, X. Lu, Q. Wang, From dictionary of visual words to subspaces: locality-constrained affine subspace coding , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.039			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0028	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0020		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0003	'In the proposed model, the affine subspace method in [28][[ refid=''bib0028'' ]] is used to reduce the dimension.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0026"""" view=""""all"""">The second factor to promote the discrimination is the dimension reduction method. The original NetVLAD method used the PCA algorithm to reduce the dimension. In the proposed model, the affine subspace method in <ce:cross-ref id=""""crf0079"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> is used to reduce the dimension. Compared with the PCA algorithm, the affine subspace method is a more discriminative dimension reduction method. In order to reduce the dimension in <ce:cross-ref id=""""crf0080"""" refid=""""eq0003"""">(3)</ce:cross-ref>, the affine subspace method can be written as<ce:display><ce:formula id=""""eq0016""""><ce:label>(16)</ce:label><mml:math altimg=""""si35.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd columnalign=""""right""""><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where <mml:math altimg=""""si36.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math><ce:italic>U<ce:inf loc=""""post"""">k</ce:inf></ce:italic> ∈ <ce:italic>R</ce:italic><ce:sup loc=""""post""""><ce:italic>P</ce:italic> × <ce:italic>D</ce:italic></ce:sup> (<mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math>) is the projective matrix in the affine subspace method, and <ce:italic>P</ce:italic> is the subspace dimension. Since <mml:math altimg=""""si37.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>U</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math> in <ce:cross-ref id=""""crf0081"""" refid=""""eq0016"""">(16)</ce:cross-ref> can be viewed as the 1 × 1 convolution layer with the weight {<ce:italic>U<ce:inf loc=""""post"""">k</ce:inf></ce:italic>} and the bias <mml:math altimg=""""si38.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mo>{</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math> the affine subspace layer can be easily embedded into the deep neural network.</ce:para>""''"'	cites	AGA	
cites	Experimental results	M. Cimpoi, S. Maji, I. Kokkinos, S. Mohamed, A. Vedaldi, Describing textures in the wild , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2013)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0034	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0027		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0008	'Describing textures database (DTD)[34][[ refid=''bib0034'' ]] is a texture database, consisting of 5640 images, organized according to a list of 47 classes inspired from human perception.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0035"""" view=""""all""""><ce:italic>Describing textures database (DTD)</ce:italic><ce:cross-ref id=""""crf0108"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> is a texture database, consisting of 5640 images, organized according to a list of 47 classes inspired from human perception. We use the suggested training/test split in <ce:cross-ref id=""""crf0109"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> to get the experimental results.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experimental results	K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale image recognition , Proceedings of the International Conference on Learning Representation (ICLR) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0038	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0025		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0013	'In our experiments, the feature maps from the last convolutional layer of the VGG-VD [38][[ refid=''bib0038'' ]] network are used as the CNN features, all the images are resized to 448 × 448 pixels, and the images are augmented by random crop and random mirror.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0033"""" view=""""all"""">In our experiments, the feature maps from the last convolutional layer of the VGG-VD <ce:cross-ref id=""""crf0105"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> network are used as the CNN features, all the images are resized to 448 × 448 pixels, and the images are augmented by random crop and random mirror. The deep CNN feature extraction and the end-to-end training of the deep network are implemented by the deep learning library Mxnet <ce:cross-ref id=""""crf0106"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>, and the Adam <ce:cross-ref id=""""crf0107"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref> optimization algorithm is used to minimize the loss of the deep network. All the experiments are carried out on a desktop PC with one Intel I7 3.4GHz CPU and two NVIDIA TitanX GPUs.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experimental results	M. Cimpoi, S. Maji, I. Kokkinos, S. Mohamed, A. Vedaldi, Describing textures in the wild , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2013)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0034	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0028		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0014	'We use the suggested training/test split in [34][[ refid=''bib0034'' ]] to get the experimental results.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0035"""" view=""""all""""><ce:italic>Describing textures database (DTD)</ce:italic><ce:cross-ref id=""""crf0108"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> is a texture database, consisting of 5640 images, organized according to a list of 47 classes inspired from human perception. We use the suggested training/test split in <ce:cross-ref id=""""crf0109"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> to get the experimental results.</ce:para>""''"'	uses_method_in	AGA	
cites	Experimental results	A. Quattoni, A. Torralba, Recognizing indoor scenes , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2009)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0035	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0029		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0015	'MIT indoors (MIT)[35][[ refid=''bib0035'' ]] dataset is a difficult indoor scene benchmark which contains 15,620 images of 67 indoor scenes.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0036"""" view=""""all""""><ce:italic>MIT indoors (MIT)</ce:italic><ce:cross-ref id=""""crf0110"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> dataset is a difficult indoor scene benchmark which contains 15,620 images of 67 indoor scenes. We use the standard training/test split in <ce:cross-ref id=""""crf0111"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> to report the classification results.</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	Y. Huang, Z. Wu, L. Wang, T. Tan, Feature coding in image classification: a comprehensive study , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 36 (2014), pp.493-506	http://dx.doi.org/10.1016/j.patcog.2017.10.039	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0020	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0008		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0016	'In image classification, feature coding [20][[ refid=''bib0020'' ]] is an important model and has been widely studied over the past several years.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">In image classification, feature coding <ce:cross-ref id=""""crf0038"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> is an important model and has been widely studied over the past several years. The core idea of the feature coding method is to obtain the representation codings of the feature descriptors via a trained dictionary. The popular feature coding methods include hard coding <ce:cross-ref id=""""crf0039"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>, soft coding <ce:cross-ref id=""""crf0040"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, sparse coding <ce:cross-ref id=""""crf0041"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>, Low-rank sparse coding <ce:cross-ref id=""""crf0042"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>, locality constrained coding (LLC) <ce:cross-ref id=""""crf0043"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, Vector of Locally Aggregated Descriptor (VLAD) coding <ce:cross-ref id=""""crf0044"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> and Fisher Vector (FV) coding <ce:cross-ref id=""""crf0045"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>. The traditional feature coding methods are unsupervised; thus, the trained dictionary may not be optimal for image recognition, and the SIFT <ce:cross-ref id=""""crf0046"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> feature used in the feature coding method doesn’t have a strong representation ability. Inspired by the great advantages of the deep learning model, Arandjelovic et al. <ce:cross-ref id=""""crf0047"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> extended the traditional VLAD coding model to an end-to-end model called NetVLAD. They chose the outputs of the last convolutional layer of a deep CNN to feed the VLAD layer. The entire network trained all the parameters by the back propagation algorithm.</ce:para>""''"'	cites	AGA	
cites	Experimental results	A. Quattoni, A. Torralba, Recognizing indoor scenes , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2009)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0035	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0046		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0024	'In the MIT-indoor [35][[ refid=''bib0035'' ]] database, T is set as 7.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0055"""" view=""""all"""">In the MIT-indoor <ce:cross-ref id=""""crf0146"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> database, <ce:italic>T</ce:italic> is set as 7. The competing methods include FC-CNN <ce:cross-ref id=""""crf0147"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, FV-CNN <ce:cross-ref id=""""crf0148"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, Task driven pooling (TDP) <ce:cross-ref id=""""crf0149"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref>, directed acyclic graph CNN (DAG-CNN) <ce:cross-ref id=""""crf0150"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref>, B-CNN <ce:cross-ref id=""""crf0151"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> and NetVLAD <ce:cross-ref id=""""crf0152"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>. <ce:cross-ref id=""""crf0153"""" refid=""""tbl0004"""">Table 4</ce:cross-ref><ce:float-anchor refid=""""tbl0004""""/> presents the accuracies of the LSO-VLADNet and other competing methods. As <ce:cross-ref id=""""crf0154"""" refid=""""tbl0004"""">Table 4</ce:cross-ref> shows, the LSO-VLAD is much better than the FV-CNN method which is a state-of-art feature coding method in this dataset. This demonstrates the effectiveness of our newly-designed feature coding method. The LSO-VLADNet has obvious advantages than the B-CNN <ce:cross-ref id=""""crf0155"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> and the NetVLAD which are end-to-end methods, this demonstrates the superiority of our end-to-end model.</ce:para>""''"'	uses_data_from	AGA	
cites	Experimental results	R. Arandjelovic, P. Gronat, A. Torii, T. Pajdla, J. Sivic, Netvlad: CNN architecture for weakly supervised place recognition , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0040		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0031	'Since the proposed LSO-VLADNet is very relative to the NetVLAD [27][[ refid=''bib0027'' ]], a detailed classification comparison of NetVLAD and LSO-VLADNet is given.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0051"""" view=""""all"""">Since the proposed LSO-VLADNet is very relative to the NetVLAD <ce:cross-ref id=""""crf0130"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>, a detailed classification comparison of NetVLAD and LSO-VLADNet is given. <ce:cross-ref id=""""crf0131"""" refid=""""tbl0002"""">Table 2</ce:cross-ref><ce:float-anchor refid=""""tbl0002""""/> shows the means and stds of accuracies of NetVLAD and LSO-VLADNet on 10 different data replications.</ce:para>""''"'	cites	AGA	
cites	Experimental results	K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale image recognition , Proceedings of the International Conference on Learning Representation (ICLR) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0038	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0041		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0032	'Since the structure of the CNN will significantly impact the classification result, for a fair comparison, we only compare those CNN methods which are based on the VGG-VD [38][[ refid=''bib0038'' ]] network.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0053"""" view=""""all"""">In this subsection, we will compare the LSO-VLADNet model with other state-of-art methods on each dataset. All the competing methods are based on CNN model. Since the structure of the CNN will significantly impact the classification result, for a fair comparison, we only compare those CNN methods which are based on the VGG-VD <ce:cross-ref id=""""crf0133"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> network.</ce:para>""''"'	uses_method_in	AGA	
cites	Experimental results	M. Cimpoi, S. Maji, I. Kokkinos, S. Mohamed, A. Vedaldi, Describing textures in the wild , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2013)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0034	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0042		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0033	'In the DTD [34][[ refid=''bib0034'' ]] dataset, T is set as 6.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0054"""" view=""""all"""">In the DTD <ce:cross-ref id=""""crf0134"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> dataset, <ce:italic>T</ce:italic> is set as 6. The competing methods include FC-CNN <ce:cross-ref id=""""crf0135"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, FV-CNN <ce:cross-ref id=""""crf0136"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, bilinear CNN (B-CNN) <ce:cross-ref id=""""crf0137"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref>, compact bilinear pooling with Tensor sketch (CBP-TS) <ce:cross-ref id=""""crf0138"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref>, compact bilinear pooling with Random Maclaurin (CBP-RM) <ce:cross-ref id=""""crf0139"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> and the NetVLAD <ce:cross-ref id=""""crf0140"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>. Since the FV-CNN exploited the second order statistic to obtain the Fisher Vector (FV) coding, there is an intimate relationship between the FV coding and the LSO-VLAD model. The original FV-CNN method used the multi-scale images to get the FV codings, yet the proposed model utilizes the single-scale images with 448 × 448 pixels to compute the codings. For a fair comparison, the FV-CNN method uses 448 × 448 pixels images to compute the FV codings in our experiments. The classification results on DTD dataset are shown in <ce:cross-ref id=""""crf0141"""" refid=""""tbl0003"""">Table 3</ce:cross-ref><ce:float-anchor refid=""""tbl0003""""/>. As <ce:cross-ref id=""""crf0142"""" refid=""""tbl0003"""">Table 3</ce:cross-ref> shows, LSO-VLADNet is better than the LSO-VLAD and NetVLAD <ce:cross-ref id=""""crf0143"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. Besides, LSO-VLADNet outperforms the B-CNN <ce:cross-ref id=""""crf0144"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> and the CBP-TS <ce:cross-ref id=""""crf0145"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> which are state-of-art methods in DTD database. The experimental results in DTD dataset demonstrate the effectiveness of the LSO-VLADNet in texture classification.</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	S. Zheng, S. Jayasumana, B. Romeraparedes, V. Vineet, Z. Su, D. Du, C. Huang, P.H.S. Torr, Conditional random fields as recurrent neural networks , Proceedings of the IEEE International Conference on Computer Vision (ICCV) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0016	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0004		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0055	'Zheng et al. [16][[ refid=''bib0016'' ]] treated the mean field algorithm as a recurrent neural network (RNN), and then they jointly train the new structure RNN and a deep CNN to obtain the excellent image segmentation results.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">More recently, inspired by the advantages of the end-to-end model and the deep feature, some works extend the traditional machine learning methods to the end-to-end models and embed the new structure layers into the convolutional neural network (CNN). These new structure CNNs can inherit the advantages of the original machine learning methods and have better performances than the original CNNs. The representative works include: He et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> combined the spatial pyramid matching method <ce:cross-ref id=""""crf0032"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> and a CNN to design a state-of-art image classification and detection model. Zheng et al. <ce:cross-ref id=""""crf0033"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref> treated the mean field algorithm as a recurrent neural network (RNN), and then they jointly train the new structure RNN and a deep CNN to obtain the excellent image segmentation results. Wang et al. <ce:cross-ref id=""""crf0034"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> developed an end-to-end learning algorithm for optimizing the dictionary pairs classifier <ce:cross-ref id=""""crf0035"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> and the CNN simultaneously. Wang et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> combined the domain expertise of the sparse coding and the merits of the deep learning to achieve the state-of-art image super resolution results. Wang et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> introduced a one-step sparse inference module to remove artifacts of JPEG compressed images. The optimization and the computation procedures of some traditional machine learning models can bring inspirations for designing new structure deep networks, and these new layers make the deep learning model has interpretability.</ce:para>""''"'	cites	AGA	
cites	Introduction	Z. Wang, D. Liu, J. Yang, W. Han, T. Huang, Deep networks for image super-resolution with sparse prior , Proceedings of the IEEE International Conference on Computer Vision (ICCV) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0005	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0006		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0058	'Wang et al. [5][[ refid=''bib0005'' ]] combined the domain expertise of the sparse coding and the merits of the deep learning to achieve the state-of-art image super resolution results.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">More recently, inspired by the advantages of the end-to-end model and the deep feature, some works extend the traditional machine learning methods to the end-to-end models and embed the new structure layers into the convolutional neural network (CNN). These new structure CNNs can inherit the advantages of the original machine learning methods and have better performances than the original CNNs. The representative works include: He et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> combined the spatial pyramid matching method <ce:cross-ref id=""""crf0032"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> and a CNN to design a state-of-art image classification and detection model. Zheng et al. <ce:cross-ref id=""""crf0033"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref> treated the mean field algorithm as a recurrent neural network (RNN), and then they jointly train the new structure RNN and a deep CNN to obtain the excellent image segmentation results. Wang et al. <ce:cross-ref id=""""crf0034"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> developed an end-to-end learning algorithm for optimizing the dictionary pairs classifier <ce:cross-ref id=""""crf0035"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> and the CNN simultaneously. Wang et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> combined the domain expertise of the sparse coding and the merits of the deep learning to achieve the state-of-art image super resolution results. Wang et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> introduced a one-step sparse inference module to remove artifacts of JPEG compressed images. The optimization and the computation procedures of some traditional machine learning models can bring inspirations for designing new structure deep networks, and these new layers make the deep learning model has interpretability.</ce:para>""''"'	cites	AGA	
cites	Introduction	Z. Wang, D. Liu, S. Chang, Q. Ling, Y. Yang, T.S. Huang, D3: deep dual-domain based fast restoration of JPEG-compressed images , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0019	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0007		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0059	'Wang et al. [19][[ refid=''bib0019'' ]] introduced a one-step sparse inference module to remove artifacts of JPEG compressed images.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">More recently, inspired by the advantages of the end-to-end model and the deep feature, some works extend the traditional machine learning methods to the end-to-end models and embed the new structure layers into the convolutional neural network (CNN). These new structure CNNs can inherit the advantages of the original machine learning methods and have better performances than the original CNNs. The representative works include: He et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> combined the spatial pyramid matching method <ce:cross-ref id=""""crf0032"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> and a CNN to design a state-of-art image classification and detection model. Zheng et al. <ce:cross-ref id=""""crf0033"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref> treated the mean field algorithm as a recurrent neural network (RNN), and then they jointly train the new structure RNN and a deep CNN to obtain the excellent image segmentation results. Wang et al. <ce:cross-ref id=""""crf0034"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> developed an end-to-end learning algorithm for optimizing the dictionary pairs classifier <ce:cross-ref id=""""crf0035"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> and the CNN simultaneously. Wang et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> combined the domain expertise of the sparse coding and the merits of the deep learning to achieve the state-of-art image super resolution results. Wang et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> introduced a one-step sparse inference module to remove artifacts of JPEG compressed images. The optimization and the computation procedures of some traditional machine learning models can bring inspirations for designing new structure deep networks, and these new layers make the deep learning model has interpretability.</ce:para>""''"'	cites	AGA	
cites	Experimental results	T.-Y. Lin, A. RoyChowdhury, S. Maji, Bilinear CNN models for fine-grained visual recognition , Proceedings of the IEEE International Conference on Computer Vision (ICCV) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0044	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0048		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0060	'The LSO-VLADNet has obvious advantages than the B-CNN [44][[ refid=''bib0044'' ]] and the NetVLAD which are end-to-end methods, this demonstrates the superiority of our end-to-end model.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0055"""" view=""""all"""">In the MIT-indoor <ce:cross-ref id=""""crf0146"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> database, <ce:italic>T</ce:italic> is set as 7. The competing methods include FC-CNN <ce:cross-ref id=""""crf0147"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, FV-CNN <ce:cross-ref id=""""crf0148"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, Task driven pooling (TDP) <ce:cross-ref id=""""crf0149"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref>, directed acyclic graph CNN (DAG-CNN) <ce:cross-ref id=""""crf0150"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref>, B-CNN <ce:cross-ref id=""""crf0151"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> and NetVLAD <ce:cross-ref id=""""crf0152"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>. <ce:cross-ref id=""""crf0153"""" refid=""""tbl0004"""">Table 4</ce:cross-ref><ce:float-anchor refid=""""tbl0004""""/> presents the accuracies of the LSO-VLADNet and other competing methods. As <ce:cross-ref id=""""crf0154"""" refid=""""tbl0004"""">Table 4</ce:cross-ref> shows, the LSO-VLAD is much better than the FV-CNN method which is a state-of-art feature coding method in this dataset. This demonstrates the effectiveness of our newly-designed feature coding method. The LSO-VLADNet has obvious advantages than the B-CNN <ce:cross-ref id=""""crf0155"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> and the NetVLAD which are end-to-end methods, this demonstrates the superiority of our end-to-end model.</ce:para>""''"'	uses_method_in	AGA	
cites	Experimental results	C. Wah, S. Branson, P. Welinder, P. Perona, S. Belongie, The Caltech-UCSD Birds200–2011 Dataset , None, California Institute of Technology (2011)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0036	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0049		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0061	'In the CUB200 [36][[ refid=''bib0036'' ]] database, T is set as 5.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0056"""" view=""""all"""">In the CUB200 <ce:cross-ref id=""""crf0156"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref> database, <ce:italic>T</ce:italic> is set as 5. In this database, we only use the category label without any part or bounding box annotation. <ce:cross-ref id=""""crf0157"""" refid=""""tbl0005"""">Table 5</ce:cross-ref><ce:float-anchor refid=""""tbl0005""""/> shows the classification results from FV-CNN <ce:cross-ref id=""""crf0158"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, NetVLAD <ce:cross-ref id=""""crf0159"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>, Neural Activation Constellations (NAC) <ce:cross-ref id=""""crf0160"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>, Multiple Granularity Descriptors (Multi-grained) <ce:cross-ref id=""""crf0161"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref>, Local Parts to Global Discrimination CNN (LG-CNN) <ce:cross-ref id=""""crf0162"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref>, without part annotations (WPA) <ce:cross-ref id=""""crf0163"""" refid=""""bib0051"""">[51][[ refid=''''bib0051'''' ]]</ce:cross-ref> and the proposed method. In this benchmark, the LSO-VLADNet achieves 7.1% improvement over the LSO-VLAD, this demonstrates the great advantage of the end-to-end training in our model. Besides, the LSO-VLADNet achieves 2.6% improvement over the NetVLAD, this demonstrates the effectiveness of the newly designed layers. NAC <ce:cross-ref id=""""crf0164"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>, Multi-grained <ce:cross-ref id=""""crf0165"""" refid=""""bib0049"""">[49][[ refid=''''bib0049'''' ]]</ce:cross-ref>, LG-CNN <ce:cross-ref id=""""crf0166"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref> and WPA <ce:cross-ref id=""""crf0167"""" refid=""""bib0051"""">[51][[ refid=''''bib0051'''' ]]</ce:cross-ref> are state-of-art methods in CUB200 dataset, and our LSO-VLADNet has advantages over these state-of-art methods. The experiments in CUB200 dataset validate the proposed LSO-VLADNet is very competitive in birds categorization.</ce:para>""''"'	uses_data_from	AGA	
uses_data_from	Experimental results	J. Xiao, J. Hays, K. Ehinger, K. Oliva, A. Torralba, Sun database: large-scale scene recognition from abbey to zoo , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2010)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0054	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0058		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0062	'In order to demonstrate the effectiveness of this scheme, we make some experiments on SUN397 [54][[ refid=''bib0054'' ]] dataset which contains more than 100K scene images from 397 scene categories and is a relatively big dataset.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0060"""" view=""""all"""">The initial dictionary is obtained by the <ce:italic>K</ce:italic>-means algorithm. The time complexity seems to be very huge when training on big dataset. Since the running time of the <ce:italic>K</ce:italic>-means algorithm mainly depends on the number of clustering samples, it is possible to reduce the time complexity with little performance loss by using only part of the total samples to initialize the dictionary. In order to demonstrate the effectiveness of this scheme, we make some experiments on SUN397 <ce:cross-ref id=""""crf0186"""" refid=""""bib0054"""">[54][[ refid=''''bib0054'''' ]]</ce:cross-ref> dataset which contains more than 100K scene images from 397 scene categories and is a relatively big dataset.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experimental results	A. Vedaldi, B. Fulkerson, Vlfeat: an open and portable library of computer vision algorithms , Proceedings of the International Conference on Multimedea (2010)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0041	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0035		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0063	'Then, the features of the last convolutional layer are used to train the initialized dictionary {ck}k=1K, and the initialized dictionary is obtained by the K-means algorithm which is implemented by the VLFeat library [41][[ refid=''bib0041'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0039"""" view=""""all"""">In the proposed LSO-VLADNet, the parameters in the Deep CNN are initialized by the weights and biases in the pre-trained VGG-VD <ce:cross-ref id=""""crf0115"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> network. Then, the features of the last convolutional layer are used to train the initialized dictionary <mml:math altimg=""""si51.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math> and the initialized dictionary is obtained by the <ce:italic>K</ce:italic>-means algorithm which is implemented by the VLFeat library <ce:cross-ref id=""""crf0116"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref>. The projective matrixes <ce:italic>U<ce:inf loc=""""post"""">k</ce:inf></ce:italic> (<mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math>) are initialized by the affine subspace method in <ce:cross-ref id=""""crf0117"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. <ce:italic>w<ce:inf loc=""""post"""">k</ce:inf>, b<ce:inf loc=""""post"""">k</ce:inf></ce:italic> and <ce:italic>µ<ce:inf loc=""""post"""">k</ce:inf></ce:italic> are initialized by 2<ce:italic>βc<ce:inf loc=""""post"""">k</ce:inf></ce:italic>, <mml:math altimg=""""si52.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math> and <ce:italic>U<ce:inf loc=""""post"""">k</ce:inf>c<ce:inf loc=""""post"""">k</ce:inf></ce:italic>, respectively. Based on the above initialized parameters, the LSO–VLAD codings can be obtained by <ce:cross-ref id=""""crf0118"""" refid=""""eq0020"""">(20)</ce:cross-ref>. At last, we train a softmax classifier by the LSO-VLAD codings to get the initialization parameters of the last fully connected layer.</ce:para>""''"'	uses_method_in	AGA	
cites	Experimental results	K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale image recognition , Proceedings of the International Conference on Learning Representation (ICLR) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0038	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0034		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0064	'In the proposed LSO-VLADNet, the parameters in the Deep CNN are initialized by the weights and biases in the pre-trained VGG-VD [38][[ refid=''bib0038'' ]] network.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0039"""" view=""""all"""">In the proposed LSO-VLADNet, the parameters in the Deep CNN are initialized by the weights and biases in the pre-trained VGG-VD <ce:cross-ref id=""""crf0115"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> network. Then, the features of the last convolutional layer are used to train the initialized dictionary <mml:math altimg=""""si51.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math> and the initialized dictionary is obtained by the <ce:italic>K</ce:italic>-means algorithm which is implemented by the VLFeat library <ce:cross-ref id=""""crf0116"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref>. The projective matrixes <ce:italic>U<ce:inf loc=""""post"""">k</ce:inf></ce:italic> (<mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math>) are initialized by the affine subspace method in <ce:cross-ref id=""""crf0117"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. <ce:italic>w<ce:inf loc=""""post"""">k</ce:inf>, b<ce:inf loc=""""post"""">k</ce:inf></ce:italic> and <ce:italic>µ<ce:inf loc=""""post"""">k</ce:inf></ce:italic> are initialized by 2<ce:italic>βc<ce:inf loc=""""post"""">k</ce:inf></ce:italic>, <mml:math altimg=""""si52.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math> and <ce:italic>U<ce:inf loc=""""post"""">k</ce:inf>c<ce:inf loc=""""post"""">k</ce:inf></ce:italic>, respectively. Based on the above initialized parameters, the LSO–VLAD codings can be obtained by <ce:cross-ref id=""""crf0118"""" refid=""""eq0020"""">(20)</ce:cross-ref>. At last, we train a softmax classifier by the LSO-VLAD codings to get the initialization parameters of the last fully connected layer.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experimental results	P. Li, X. Lu, Q. Wang, From dictionary of visual words to subspaces: locality-constrained affine subspace coding , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	methods	results	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0028>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0036>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0067	'The projective matrixes Uk (k=1,2,…,K) are initialized by the affine subspace method in [28][[ refid=''bib0028'' ]].'			FDY+AGA	infered_pred1
cites	Experimental results	C. Wah, S. Branson, P. Welinder, P. Perona, S. Belongie, The Caltech-UCSD Birds200–2011 Dataset , None, California Institute of Technology (2011)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0036	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0031		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0068	'Caltech-UCSD Birds (CUB200)[36][[ refid=''bib0036'' ]] dataset is a widely used fine-grained image benchmark.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0037"""" view=""""all""""><ce:italic>Caltech-UCSD Birds (CUB200)</ce:italic><ce:cross-ref id=""""crf0112"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref> dataset is a widely used fine-grained image benchmark. This database contains 11,788 images from 200 bird classes, each class has around 30 training samples. We use the split setting in <ce:cross-ref id=""""crf0113"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref> to obtain the experimental results.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experimental results	A. Quattoni, A. Torralba, Recognizing indoor scenes , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2009)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0035	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0030		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0069	'We use the standard training/test split in [35][[ refid=''bib0035'' ]] to report the classification results.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0036"""" view=""""all""""><ce:italic>MIT indoors (MIT)</ce:italic><ce:cross-ref id=""""crf0110"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> dataset is a difficult indoor scene benchmark which contains 15,620 images of 67 indoor scenes. We use the standard training/test split in <ce:cross-ref id=""""crf0111"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> to report the classification results.</ce:para>""''"'	cites	AGA	
cites	Experimental results	G. Griffin, A. Holub, P. Perona, Caltech-256 Object Category Dataset , None, California Institute of Technology (2007)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0037	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0033		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0070	'Caltech 256[37][[ refid=''bib0037'' ]] database is a large-scale object image benchmark which has 256 object classes with at least 80 images per category.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0038"""" view=""""all""""><ce:italic>Caltech 256</ce:italic><ce:cross-ref id=""""crf0114"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref> database is a large-scale object image benchmark which has 256 object classes with at least 80 images per category. This database has a total number of 30,608 object images. Following the common experimental settings, 60 images per class are randomly selected for training, and the remaining images are used for testing.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experimental results	C. Wah, S. Branson, P. Welinder, P. Perona, S. Belongie, The Caltech-UCSD Birds200–2011 Dataset , None, California Institute of Technology (2011)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0036	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0032		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0071	'We use the split setting in [36][[ refid=''bib0036'' ]] to obtain the experimental results.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0037"""" view=""""all""""><ce:italic>Caltech-UCSD Birds (CUB200)</ce:italic><ce:cross-ref id=""""crf0112"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref> dataset is a widely used fine-grained image benchmark. This database contains 11,788 images from 200 bird classes, each class has around 30 training samples. We use the split setting in <ce:cross-ref id=""""crf0113"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref> to obtain the experimental results.</ce:para>""''"'	uses_method_in	AGA	
cites	Experimental results	D.P. Kingma, J. Ba, Adam: a method for stochastic optimization , Proceedings of the International Conference on Learning Representation (ICLR) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0040	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0039		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0072	'Besides, the Adam [40][[ refid=''bib0040'' ]] algorithm can avoid some local minima and obtain relatively low loss.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0042"""" view=""""all"""">Since the deep neural network is not convex, it is very hard to find a global optimal solution, and many recent deep learning works <ce:cross-refs id=""""crfs0010"""" refid=""""bib0042 bib0043"""">[42,43][[ refid=''''bib0042 bib0043'''' ]]</ce:cross-refs> try to find a point in parameter space that has low but not minimal cost. In our LSO-VLADNet, we first use <ce:italic>K</ce:italic>-means algorithm to initialize the dictionary and train the last softmax classifier by the initialized codings. This initialization scheme can get a relatively low initialization loss value. Next, we use Adam <ce:cross-ref id=""""crf0119"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref> algorithm which is an adaptively stochastic optimization method to reduce the cost function until the convergence. When the cost function curve tends to be flat, we reduce the learning rate so that the cost function value can be further reduced. Besides, the Adam <ce:cross-ref id=""""crf0120"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref> algorithm can avoid some local minima and obtain relatively low loss. Although the final parameters may not be the true global minimum, the final loss is very low and the trained model can get the satisfactory classification results.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experimental results	D.P. Kingma, J. Ba, Adam: a method for stochastic optimization , Proceedings of the International Conference on Learning Representation (ICLR) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0040	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0038		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0073	'Next, we use Adam [40][[ refid=''bib0040'' ]] algorithm which is an adaptively stochastic optimization method to reduce the cost function until the convergence.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0042"""" view=""""all"""">Since the deep neural network is not convex, it is very hard to find a global optimal solution, and many recent deep learning works <ce:cross-refs id=""""crfs0010"""" refid=""""bib0042 bib0043"""">[42,43][[ refid=''''bib0042 bib0043'''' ]]</ce:cross-refs> try to find a point in parameter space that has low but not minimal cost. In our LSO-VLADNet, we first use <ce:italic>K</ce:italic>-means algorithm to initialize the dictionary and train the last softmax classifier by the initialized codings. This initialization scheme can get a relatively low initialization loss value. Next, we use Adam <ce:cross-ref id=""""crf0119"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref> algorithm which is an adaptively stochastic optimization method to reduce the cost function until the convergence. When the cost function curve tends to be flat, we reduce the learning rate so that the cost function value can be further reduced. Besides, the Adam <ce:cross-ref id=""""crf0120"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref> algorithm can avoid some local minima and obtain relatively low loss. Although the final parameters may not be the true global minimum, the final loss is very low and the trained model can get the satisfactory classification results.</ce:para>""''"'	uses_method_in	AGA	
cites	Experimental results	R. Arandjelovic, P. Gronat, A. Torii, T. Pajdla, J. Sivic, Netvlad: CNN architecture for weakly supervised place recognition , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0056		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0076	'In the training stage, LSO-VLADNet which utilizes the combination of the first-order and the second-order statistics is more time-consuming than the NetVLAD [27][[ refid=''bib0027'' ]] which only uses first-order statistical information.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0058"""" view=""""all""""><ce:cross-ref id=""""crf0182"""" refid=""""tbl0007"""">Table 7</ce:cross-ref><ce:float-anchor refid=""""tbl0007""""/> gives the training and test times of the proposed LSO-VLADNet and other related methods in one epoch. In the training stage, LSO-VLADNet which utilizes the combination of the first-order and the second-order statistics is more time-consuming than the NetVLAD <ce:cross-ref id=""""crf0183"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> which only uses first-order statistical information. Besides, LSO-VLADNet is faster than the VGG-VD <ce:cross-ref id=""""crf0184"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> which has multiple high-dimensional fully connected layers and the B-CNN <ce:cross-ref id=""""crf0185"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> which needs to compute the time-consuming outer product operation. In the test stage, the proposed LSO-VLADNet is slightly slower than the NetVLAD and faster than the VGG-VD and the B-CNN. Although the LSO-VLADNet is slower than the NetVLAD, considering the superior recognition performance of the LSO-VLADNet, the proposed network is still very effective.</ce:para>""''"'	cites	AGA	
cites	Related work	R. Arandjelovic, A. Zisserman, All about vlad , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2013)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0033	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0019		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0077	'At last, intra-normalization [33][[ refid=''bib0033'' ]] and L2-normalization are used to produce the final VLAD vector for image classification.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0019"""" view=""""all"""">At last, intra-normalization <ce:cross-ref id=""""crf0061"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> and L2-normalization are used to produce the final VLAD vector for image classification. Since all the layers in the NetVLAD model are differentiable, the NetVLAD model can be trained by an end-to-end manner. The complete NetVLAD model is illustrated in <ce:cross-ref id=""""crf0062"""" refid=""""fig0002"""">Fig. 2</ce:cross-ref><ce:float-anchor refid=""""fig0002""""/>.</ce:para>""''"'	cites	AGA	
cites	Experimental results	G. Griffin, A. Holub, P. Perona, Caltech-256 Object Category Dataset , None, California Institute of Technology (2007)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0037	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0052		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0085	'In the Caltech256 [37][[ refid=''bib0037'' ]] database, T is set as 7.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0057"""" view=""""all"""">In the Caltech256 <ce:cross-ref id=""""crf0168"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref> database, <ce:italic>T</ce:italic> is set as 7. <ce:cross-ref id=""""crf0169"""" refid=""""tbl0006"""">Table 6</ce:cross-ref><ce:float-anchor refid=""""tbl0006""""/> shows the average classification accuracies (over 10 runs) of FV-CNN <ce:cross-ref id=""""crf0170"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, Fine-tuned FC-CNN <ce:cross-ref id=""""crf0171"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, Multiple Scale Deep Spatial Pyramid (MS-DSP) <ce:cross-ref id=""""crf0172"""" refid=""""bib0052"""">[52][[ refid=''''bib0052'''' ]]</ce:cross-ref>, NetVLAD <ce:cross-ref id=""""crf0173"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>, Probabilistic Collaborative Representation classification (ProCRC) <ce:cross-ref id=""""crf0174"""" refid=""""bib0053"""">[53][[ refid=''''bib0053'''' ]]</ce:cross-ref>, NAC <ce:cross-ref id=""""crf0175"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> and the proposed model. As <ce:cross-ref id=""""crf0176"""" refid=""""tbl0006"""">Table 6</ce:cross-ref> shows, LSO-VLADNet is better than FT-FC-CNN <ce:cross-ref id=""""crf0177"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, MS-DSP <ce:cross-ref id=""""crf0178"""" refid=""""bib0052"""">[52][[ refid=''''bib0052'''' ]]</ce:cross-ref>, NAC <ce:cross-ref id=""""crf0179"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> and ProCRC <ce:cross-ref id=""""crf0180"""" refid=""""bib0053"""">[53][[ refid=''''bib0053'''' ]]</ce:cross-ref> which are state-of-art methods in Caltech256 dataset. Compared with the non-end-to-end LSO-VLAD and the end-to-end NetVLAD <ce:cross-ref id=""""crf0181"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>, LSO-VLADNet improves 4.3% and 1.8%, respectively. The large-scale object classification experiment demonstrates the superiorities of the newly designed layers and the end-to-end training in our network.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Introduction	P. Li, X. Lu, Q. Wang, From dictionary of visual words to subspaces: locality-constrained affine subspace coding , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0028>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0012>				http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0098	'In the proposed network, we use the affine subspace method in [28][[ refid=''bib0028'' ]] for dimension reduction.'			FDY+AGA	infered_pred1
cites	Introduction	R. Arandjelovic, P. Gronat, A. Torii, T. Pajdla, J. Sivic, Netvlad: CNN architecture for weakly supervised place recognition , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0011		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0099	'Inspired by the great advantages of the deep learning model, Arandjelovic et al. [27][[ refid=''bib0027'' ]] extended the traditional VLAD coding model to an end-to-end model called NetVLAD.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">In image classification, feature coding <ce:cross-ref id=""""crf0038"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> is an important model and has been widely studied over the past several years. The core idea of the feature coding method is to obtain the representation codings of the feature descriptors via a trained dictionary. The popular feature coding methods include hard coding <ce:cross-ref id=""""crf0039"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>, soft coding <ce:cross-ref id=""""crf0040"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, sparse coding <ce:cross-ref id=""""crf0041"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>, Low-rank sparse coding <ce:cross-ref id=""""crf0042"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>, locality constrained coding (LLC) <ce:cross-ref id=""""crf0043"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, Vector of Locally Aggregated Descriptor (VLAD) coding <ce:cross-ref id=""""crf0044"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> and Fisher Vector (FV) coding <ce:cross-ref id=""""crf0045"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>. The traditional feature coding methods are unsupervised; thus, the trained dictionary may not be optimal for image recognition, and the SIFT <ce:cross-ref id=""""crf0046"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> feature used in the feature coding method doesn’t have a strong representation ability. Inspired by the great advantages of the deep learning model, Arandjelovic et al. <ce:cross-ref id=""""crf0047"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> extended the traditional VLAD coding model to an end-to-end model called NetVLAD. They chose the outputs of the last convolutional layer of a deep CNN to feed the VLAD layer. The entire network trained all the parameters by the back propagation algorithm.</ce:para>""''"'	cites	AGA	
cites	Introduction	D.G. Lowe, Distinctive image features from scale-invariant keypoints , Int. J. Comput. Vis. , vol. 60 (2004), pp.91-110	http://dx.doi.org/10.1016/j.patcog.2017.10.039	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0012	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0010		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0100	'The traditional feature coding methods are unsupervised; thus, the trained dictionary may not be optimal for image recognition, and the SIFT [12][[ refid=''bib0012'' ]] feature used in the feature coding method doesn’t have a strong representation ability.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">In image classification, feature coding <ce:cross-ref id=""""crf0038"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> is an important model and has been widely studied over the past several years. The core idea of the feature coding method is to obtain the representation codings of the feature descriptors via a trained dictionary. The popular feature coding methods include hard coding <ce:cross-ref id=""""crf0039"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>, soft coding <ce:cross-ref id=""""crf0040"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, sparse coding <ce:cross-ref id=""""crf0041"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>, Low-rank sparse coding <ce:cross-ref id=""""crf0042"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>, locality constrained coding (LLC) <ce:cross-ref id=""""crf0043"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, Vector of Locally Aggregated Descriptor (VLAD) coding <ce:cross-ref id=""""crf0044"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> and Fisher Vector (FV) coding <ce:cross-ref id=""""crf0045"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>. The traditional feature coding methods are unsupervised; thus, the trained dictionary may not be optimal for image recognition, and the SIFT <ce:cross-ref id=""""crf0046"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> feature used in the feature coding method doesn’t have a strong representation ability. Inspired by the great advantages of the deep learning model, Arandjelovic et al. <ce:cross-ref id=""""crf0047"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> extended the traditional VLAD coding model to an end-to-end model called NetVLAD. They chose the outputs of the last convolutional layer of a deep CNN to feed the VLAD layer. The entire network trained all the parameters by the back propagation algorithm.</ce:para>""''"'	cites	AGA	
cites	Related work	M. Cimpoi, S. Maji, A. Vedaldi, Deep filter banks for texture recognition and segmentation , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0030	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0017		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0101	'The most useful features of a pre-trained CNN are the feature of the last convolutional layer and the feature of the last fully connected layer [30][[ refid=''bib0030'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">The image feature in <ce:cross-ref id=""""crf0051"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref> can be the SIFT <ce:cross-ref id=""""crf0052"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> or the CNN feature. Since the CNN feature is the excellent representation of the image, most popular algorithms use the CNN feature to represent the image. The CNN model utilized deep structure which consists of multiple convolutional layers, pooling layers and nonlinear activation functions to obtain more abstract and descriptive feature representation from the large-scale ImageNet <ce:cross-ref id=""""crf0053"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> dateset. Other small image datasets can also obtain the most representative features by the CNN which is pre-trained from the ImageNet. The most useful features of a pre-trained CNN are the feature of the last convolutional layer and the feature of the last fully connected layer <ce:cross-ref id=""""crf0054"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. For the feature coding network, the CNN features are extracted from the last convolutional layer of a pre-trained deep CNN.</ce:para>""''"'	cites	AGA	
cites	Related work	J. Deng, W. Dong, R. Socher, L.J. Li, Imagenet: a large-scale hierarchical image database , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2009)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0031	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0016		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0102	'The CNN model utilized deep structure which consists of multiple convolutional layers, pooling layers and nonlinear activation functions to obtain more abstract and descriptive feature representation from the large-scale ImageNet [31][[ refid=''bib0031'' ]] dateset.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">The image feature in <ce:cross-ref id=""""crf0051"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref> can be the SIFT <ce:cross-ref id=""""crf0052"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> or the CNN feature. Since the CNN feature is the excellent representation of the image, most popular algorithms use the CNN feature to represent the image. The CNN model utilized deep structure which consists of multiple convolutional layers, pooling layers and nonlinear activation functions to obtain more abstract and descriptive feature representation from the large-scale ImageNet <ce:cross-ref id=""""crf0053"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> dateset. Other small image datasets can also obtain the most representative features by the CNN which is pre-trained from the ImageNet. The most useful features of a pre-trained CNN are the feature of the last convolutional layer and the feature of the last fully connected layer <ce:cross-ref id=""""crf0054"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. For the feature coding network, the CNN features are extracted from the last convolutional layer of a pre-trained deep CNN.</ce:para>""''"'	cites	AGA	
cites	Related work	D.G. Lowe, Distinctive image features from scale-invariant keypoints , Int. J. Comput. Vis. , vol. 60 (2004), pp.91-110	http://dx.doi.org/10.1016/j.patcog.2017.10.039	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0012	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0015		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0103	'The image feature in Fig. 1 can be the SIFT [12][[ refid=''bib0012'' ]] or the CNN feature.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">The image feature in <ce:cross-ref id=""""crf0051"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref> can be the SIFT <ce:cross-ref id=""""crf0052"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> or the CNN feature. Since the CNN feature is the excellent representation of the image, most popular algorithms use the CNN feature to represent the image. The CNN model utilized deep structure which consists of multiple convolutional layers, pooling layers and nonlinear activation functions to obtain more abstract and descriptive feature representation from the large-scale ImageNet <ce:cross-ref id=""""crf0053"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> dateset. Other small image datasets can also obtain the most representative features by the CNN which is pre-trained from the ImageNet. The most useful features of a pre-trained CNN are the feature of the last convolutional layer and the feature of the last fully connected layer <ce:cross-ref id=""""crf0054"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. For the feature coding network, the CNN features are extracted from the last convolutional layer of a pre-trained deep CNN.</ce:para>""''"'	cites	AGA	
cites	Introduction	M. Cimpoi, S. Maji, A. Vedaldi, Deep filter banks for texture recognition and segmentation , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2015)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0030	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0014		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0104	'It is worth noting that the LSO-VLAD has the better performance than the FV-CNN [30][[ refid=''bib0030'' ]] which is a state-of-art non-end-to-end feature coding method in visual recognition.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0011"""" view=""""all"""">In the image recognition experiments, the excellent classification performances will demonstrate the advantages of the newly designed LSAC layer and the second order statistic layer. Besides, some image classification experiments show that the LSO-VLADNet is obviously superior than the LSO-VLAD, this demonstrates the advantage of the end-to-end training. It is worth noting that the LSO-VLAD has the better performance than the FV-CNN <ce:cross-ref id=""""crf0049"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> which is a state-of-art non-end-to-end feature coding method in visual recognition. This implies that our newly designed feature coding method is very competitive in visual recognition. Various comparisons between the proposed model and other state-of-art methods will also be given to demonstrate the effectiveness of the proposed method.</ce:para>""''"'	cites	AGA	
cites	Experimental results	H. Jegou, M. Douze, C. Schmid, P. Perez, Aggregating local descriptors into a compact image representation , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2010)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0025	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0044		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0105	'As Table 3 shows, LSO-VLADNet is better than the LSO-VLAD and NetVLAD [25][[ refid=''bib0025'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0054"""" view=""""all"""">In the DTD <ce:cross-ref id=""""crf0134"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> dataset, <ce:italic>T</ce:italic> is set as 6. The competing methods include FC-CNN <ce:cross-ref id=""""crf0135"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, FV-CNN <ce:cross-ref id=""""crf0136"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, bilinear CNN (B-CNN) <ce:cross-ref id=""""crf0137"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref>, compact bilinear pooling with Tensor sketch (CBP-TS) <ce:cross-ref id=""""crf0138"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref>, compact bilinear pooling with Random Maclaurin (CBP-RM) <ce:cross-ref id=""""crf0139"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> and the NetVLAD <ce:cross-ref id=""""crf0140"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>. Since the FV-CNN exploited the second order statistic to obtain the Fisher Vector (FV) coding, there is an intimate relationship between the FV coding and the LSO-VLAD model. The original FV-CNN method used the multi-scale images to get the FV codings, yet the proposed model utilizes the single-scale images with 448 × 448 pixels to compute the codings. For a fair comparison, the FV-CNN method uses 448 × 448 pixels images to compute the FV codings in our experiments. The classification results on DTD dataset are shown in <ce:cross-ref id=""""crf0141"""" refid=""""tbl0003"""">Table 3</ce:cross-ref><ce:float-anchor refid=""""tbl0003""""/>. As <ce:cross-ref id=""""crf0142"""" refid=""""tbl0003"""">Table 3</ce:cross-ref> shows, LSO-VLADNet is better than the LSO-VLAD and NetVLAD <ce:cross-ref id=""""crf0143"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. Besides, LSO-VLADNet outperforms the B-CNN <ce:cross-ref id=""""crf0144"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> and the CBP-TS <ce:cross-ref id=""""crf0145"""" refid=""""bib0045"""">[45][[ refid=''''bib0045'''' ]]</ce:cross-ref> which are state-of-art methods in DTD database. The experimental results in DTD dataset demonstrate the effectiveness of the LSO-VLADNet in texture classification.</ce:para>""''"'	cites	AGA	
cites	Experimental results	R. Arandjelovic, P. Gronat, A. Torii, T. Pajdla, J. Sivic, Netvlad: CNN architecture for weakly supervised place recognition , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016)	http://dx.doi.org/10.1016/j.patcog.2017.10.039	results	methods	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/ctx/ctx0055		58	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-10-039/itrp/0108	'Compared with the non-end-to-end LSO-VLAD and the end-to-end NetVLAD [27][[ refid=''bib0027'' ]], LSO-VLADNet improves 4.3% and 1.8%, respectively.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0057"""" view=""""all"""">In the Caltech256 <ce:cross-ref id=""""crf0168"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref> database, <ce:italic>T</ce:italic> is set as 7. <ce:cross-ref id=""""crf0169"""" refid=""""tbl0006"""">Table 6</ce:cross-ref><ce:float-anchor refid=""""tbl0006""""/> shows the average classification accuracies (over 10 runs) of FV-CNN <ce:cross-ref id=""""crf0170"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, Fine-tuned FC-CNN <ce:cross-ref id=""""crf0171"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, Multiple Scale Deep Spatial Pyramid (MS-DSP) <ce:cross-ref id=""""crf0172"""" refid=""""bib0052"""">[52][[ refid=''''bib0052'''' ]]</ce:cross-ref>, NetVLAD <ce:cross-ref id=""""crf0173"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>, Probabilistic Collaborative Representation classification (ProCRC) <ce:cross-ref id=""""crf0174"""" refid=""""bib0053"""">[53][[ refid=''''bib0053'''' ]]</ce:cross-ref>, NAC <ce:cross-ref id=""""crf0175"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> and the proposed model. As <ce:cross-ref id=""""crf0176"""" refid=""""tbl0006"""">Table 6</ce:cross-ref> shows, LSO-VLADNet is better than FT-FC-CNN <ce:cross-ref id=""""crf0177"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, MS-DSP <ce:cross-ref id=""""crf0178"""" refid=""""bib0052"""">[52][[ refid=''''bib0052'''' ]]</ce:cross-ref>, NAC <ce:cross-ref id=""""crf0179"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> and ProCRC <ce:cross-ref id=""""crf0180"""" refid=""""bib0053"""">[53][[ refid=''''bib0053'''' ]]</ce:cross-ref> which are state-of-art methods in Caltech256 dataset. Compared with the non-end-to-end LSO-VLAD and the end-to-end NetVLAD <ce:cross-ref id=""""crf0181"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>, LSO-VLADNet improves 4.3% and 1.8%, respectively. The large-scale object classification experiment demonstrates the superiorities of the newly designed layers and the end-to-end training in our network.</ce:para>""''"'	cites	AGA	
cites	Related work	K. Kersting, M. Wahabzada, C. Thurau, C. Bauckhage, Hierarchical convex NMF for clustering massive data , Proceedings of the 2nd Asian Conference on Machine Learning (2010)	http://dx.doi.org/10.1016/j.patcog.2017.11.002	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0022	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0023		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0002	'To overcome the drawbacks of convex NMF, in [22][[ refid=''bib0022'' ]], a hierarchical convex NMF that can automatically adapt to the internal structures of a data set is proposed, which hence yields meaningful and interpretable clusters for non-convex data sets.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0024"""" view=""""all"""">Hierarchical matrix factorization based topic models are also proposed by many researchers <ce:cross-refs id=""""crf0049"""" refid=""""bib0021 bib0022 bib0023"""">[21–23][[ refid=''''bib0021 bib0022 bib0023'''' ]]</ce:cross-refs>. In <ce:cross-ref id=""""crf0051"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, a tree-structured sparse regularization is presented to learn dictionaries embedded in a topic hierarchy, which can be computed by a finite number of proximal operators. To overcome the drawbacks of convex NMF, in <ce:cross-ref id=""""crf0052"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>, a hierarchical convex NMF that can automatically adapt to the internal structures of a data set is proposed, which hence yields meaningful and interpretable clusters for non-convex data sets. In <ce:cross-ref id=""""crf0053"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>, an efficient hierarchical document clustering method is presented to reveal the hierarchical relations between the documents, which is based on a new algorithm for rank-2 NMF.</ce:para>""''"'	uses_data_from	AGA	
cites	Hierarchical online NMF for topic detecting	J. Mairal, F. Bach, J. Ponce, G. Sapiro, Online learning for matrix factorization and sparse coding , J. Mach. Learn. Res. , vol. 11 (2010), pp.19-60	http://dx.doi.org/10.1016/j.patcog.2017.11.002			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0003	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0027		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0008	'Eq. (3) can be solved by using the optimizing rules in [3][[ refid=''bib0003'' ]], which are presented in Table 1.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0031"""" view=""""all""""><ce:cross-ref id=""""crf0056"""" refid=""""eqn0003"""">Eq. (3)</ce:cross-ref> can be solved by using the optimizing rules in <ce:cross-ref id=""""crf0057"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>, which are presented in <ce:cross-ref id=""""crf0058"""" refid=""""tbl0001"""">Table 1</ce:cross-ref><ce:float-anchor refid=""""tbl0001""""/>. After the optimizing process of <ce:bold><ce:italic>W</ce:italic></ce:bold><ce:italic><ce:sup loc=""""post"""">t</ce:sup></ce:italic>, <ce:bold><ce:italic>H</ce:italic></ce:bold><ce:italic><ce:sup loc=""""post"""">t</ce:sup></ce:italic> can be got using LARS-Lasso <ce:cross-ref id=""""crf0059"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>. The detailed convergence proof of the algorithm can be found in <ce:cross-ref id=""""crf0060"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>. Two auxiliary matrices are used to store the intermediate results of ONMF. The auxiliary matrix <ce:bold><ce:italic>A</ce:italic></ce:bold> stores the information related to the document-specific topic distribution vectors in the past time slots, and the auxiliary matrix <ce:bold><ce:italic>B</ce:italic></ce:bold> stores the information related to the documents and the document-specific topic distribution vectors in the past time slots, which can be found in line 4 of Algorithm 1. <ce:italic>β</ce:italic> is used to replace the time scaling function, which has a value between 0 and 1. When a new document arrives, the weights of all past documents would be scaled by <ce:italic>β</ce:italic>. In ONMF, <ce:bold><ce:italic>W</ce:italic></ce:bold><ce:sup loc=""""post"""">0</ce:sup> is randomly initialized and <ce:bold><ce:italic>A</ce:italic></ce:bold><ce:sup loc=""""post"""">0</ce:sup>, <ce:bold><ce:italic>B</ce:italic></ce:bold><ce:sup loc=""""post"""">0</ce:sup> are initialized with <ce:bold><ce:italic>A</ce:italic></ce:bold><ce:sup loc=""""post"""">0</ce:sup> = <ce:italic>ε</ce:italic><ce:bold><ce:italic>I, B</ce:italic></ce:bold><ce:sup loc=""""post"""">0</ce:sup> = <ce:italic>ε</ce:italic><ce:bold><ce:italic>W</ce:italic></ce:bold><ce:sup loc=""""post"""">0</ce:sup>, where <ce:italic>ε</ce:italic> is a very small value and <ce:bold><ce:italic>I</ce:italic></ce:bold> is a <ce:italic>k</ce:italic> × <ce:italic>k</ce:italic> identity matrix.</ce:para>""''"'	cites	AGA	
cites	Related work	D. Kuang, H. Park, Fast rank-2 nonnegative matrix factorization for hierarchical document clustering , Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (2013)	http://dx.doi.org/10.1016/j.patcog.2017.11.002	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0024		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0009	'In [23][[ refid=''bib0023'' ]], an efficient hierarchical document clustering method is presented to reveal the hierarchical relations between the documents, which is based on a new algorithm for rank-2 NMF.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0024"""" view=""""all"""">Hierarchical matrix factorization based topic models are also proposed by many researchers <ce:cross-refs id=""""crf0049"""" refid=""""bib0021 bib0022 bib0023"""">[21–23][[ refid=''''bib0021 bib0022 bib0023'''' ]]</ce:cross-refs>. In <ce:cross-ref id=""""crf0051"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, a tree-structured sparse regularization is presented to learn dictionaries embedded in a topic hierarchy, which can be computed by a finite number of proximal operators. To overcome the drawbacks of convex NMF, in <ce:cross-ref id=""""crf0052"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>, a hierarchical convex NMF that can automatically adapt to the internal structures of a data set is proposed, which hence yields meaningful and interpretable clusters for non-convex data sets. In <ce:cross-ref id=""""crf0053"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>, an efficient hierarchical document clustering method is presented to reveal the hierarchical relations between the documents, which is based on a new algorithm for rank-2 NMF.</ce:para>""''"'	cites	AGA	
cites	Related work	M.D. Hoffman, D.M. Blei, F.R. Bach, Online learning for latent Dirichlet allocation , Proceedings of the 24th Annual Conference on Neural Information Processing Systems (2010)	http://dx.doi.org/10.1016/j.patcog.2017.11.002	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0009		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0014	'In [1][[ refid=''bib0001'' ]], an online variation of Bayes algorithm is proposed for LDA, which is based on online stochastic optimization with a natural gradient step.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0020"""" view=""""all"""">The first category of methods uses probabilistic models, e.g., LDA <ce:cross-ref id=""""crf0028"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref> and HDP <ce:cross-ref id=""""crf0029"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>, as their base models. For example, TOT (topic over time) model <ce:cross-ref id=""""crf0030"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> captures how a topic changes over time, where each topic is associated with a continuous distribution, and the distribution over a topic is influenced by the timestamp of documents. In <ce:cross-ref id=""""crf0031"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>, a continuous dynamic topic model is proposed by using Brownian motion to model topic evolution through time with arbitrary granularity. In <ce:cross-ref id=""""crf0032"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>, an online variation of Bayes algorithm is proposed for LDA, which is based on online stochastic optimization with a natural gradient step. In <ce:cross-ref id=""""crf0033"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>, an online variation of HDP with a new coordinate-ascent variational inference algorithm is presented. In <ce:cross-refs id=""""crf0034"""" refid=""""bib0028 bib0029 bib0030"""">[28–30][[ refid=''''bib0028 bib0029 bib0030'''' ]]</ce:cross-refs>, HDP is used to discover topics for each time slot, and the evolving of the topics are modeled by exploiting the similarity between the topics of adjacent time slots. Compared to LDA, HDP does not need to predefine topic number. However, these methods organize topics in flat structures.</ce:para>""''"'	cites	AGA	
cites	Experiments	D.M. Blei, T.L. Griffiths, M.I. Jordan, The nested Chinese restaurant process and Bayesian nonparametric inference of topic hierarchies , J. ACM , vol. 55 (2010), pp.1-30	http://dx.doi.org/10.1016/j.patcog.2017.11.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0041		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0017	'The reason can be two-fold: 1) HLDA uses the whole document set to train a model iteratively while OLDA does not; 2) HLDA generates more topics than OLDA, and the two methods have better performance with more topics [18][[ refid=''bib0018'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0085"""" view=""""all"""">Among the probabilistic methods, HLDA performs better than OLDA. The reason can be two-fold: 1) HLDA uses the whole document set to train a model iteratively while OLDA does not; 2) HLDA generates more topics than OLDA, and the two methods have better performance with more topics <ce:cross-ref id=""""crf0087"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. The reason HLDA generates more topics is that HLDA does not provide a parameter to control topic number directly, and it tends to produce many small topics.</ce:para>""''"'	uses_method_in	AGA	
cites	Experiments	S.P. Kasiviswanathan, P. Melville, A. Banerjee, V. Sindhwani, Emerging topic detection using dictionary learning , Proceedings of the 20th ACM Conference on Information and Knowledge Management (2011)	http://dx.doi.org/10.1016/j.patcog.2017.11.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0026	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0042		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0018	'The result of our method is also better than the result in [26][[ refid=''bib0026'' ]] (0.54), despite the influence of document partition strategy.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0091"""" view=""""all""""><ce:cross-ref id=""""crf0097"""" refid=""""tbl0006"""">Table 6</ce:cross-ref><ce:float-anchor refid=""""tbl0006""""/> is the MicroF1 scores of all the compared methods. It can be seen that our method outperforms all baseline methods. OLDA seems to be not sensitive to the ground truth emerging topics. JPP has better ability at finding the ground truth emerging topics than ONMF. The result of our method is also better than the result in <ce:cross-ref id=""""crf0098"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> (0.54), despite the influence of document partition strategy. The reason HONMF performs well might be that the topics found in the last time slot have high accuracy, and the accuracy of novel document detection is relatively high.</ce:para>""''"'	uses_method_in	AGA	
cites	Related work	X. Wang, A. McCallum, Topics over time: a non-Markov continuous-time model of topical trends , Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (2006)	http://dx.doi.org/10.1016/j.patcog.2017.11.002	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0015	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0007		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0043	'For example, TOT (topic over time) model [15][[ refid=''bib0015'' ]] captures how a topic changes over time, where each topic is associated with a continuous distribution, and the distribution over a topic is influenced by the timestamp of documents.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0020"""" view=""""all"""">The first category of methods uses probabilistic models, e.g., LDA <ce:cross-ref id=""""crf0028"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref> and HDP <ce:cross-ref id=""""crf0029"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>, as their base models. For example, TOT (topic over time) model <ce:cross-ref id=""""crf0030"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> captures how a topic changes over time, where each topic is associated with a continuous distribution, and the distribution over a topic is influenced by the timestamp of documents. In <ce:cross-ref id=""""crf0031"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>, a continuous dynamic topic model is proposed by using Brownian motion to model topic evolution through time with arbitrary granularity. In <ce:cross-ref id=""""crf0032"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>, an online variation of Bayes algorithm is proposed for LDA, which is based on online stochastic optimization with a natural gradient step. In <ce:cross-ref id=""""crf0033"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>, an online variation of HDP with a new coordinate-ascent variational inference algorithm is presented. In <ce:cross-refs id=""""crf0034"""" refid=""""bib0028 bib0029 bib0030"""">[28–30][[ refid=''''bib0028 bib0029 bib0030'''' ]]</ce:cross-refs>, HDP is used to discover topics for each time slot, and the evolving of the topics are modeled by exploiting the similarity between the topics of adjacent time slots. Compared to LDA, HDP does not need to predefine topic number. However, these methods organize topics in flat structures.</ce:para>""''"'	cites	AGA	
uses_data_from	Experiments	D. Cai, X. He, J. Han, Locally consistent concept factorization for document clustering , IEEE Trans. Knowl. Data Eng. , vol. 23 (2011), pp.902-913	http://dx.doi.org/10.1016/j.patcog.2017.11.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0034		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0045	'The first dataset is a subset of the Nist Topic Detection and Tracking corpus (TDT2) [27][[ refid=''bib0027'' ]], which consists of data collected during the first half of 1998 and taken from 6 sources, including 2 newswires (APW, NYT), 2 radio programs (VOA, PRI), and 2 television programs (CNN, ABC).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0063"""" view=""""all"""">Two datasets are used in our experiments. The first dataset is a subset of the Nist Topic Detection and Tracking corpus (TDT2) <ce:cross-ref id=""""crf0074"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>, which consists of data collected during the first half of 1998 and taken from 6 sources, including 2 newswires (APW, NYT), 2 radio programs (VOA, PRI), and 2 television programs (CNN, ABC). In this subset, those documents appearing in two or more categories are removed, and only the largest 30 categories are kept. Finally, 10,212 documents and about 26,000 distinct words are left in total. The second dataset is the 20 Newsgroup dataset, which has 20 classes and about 20,000 documents. A resampling procedure has been conducted to the original dataset. After that, 16 classes are selected in our experiment by reducing some broad topics (e.g., talk.politics.misc), and 3000 documents are left.</ce:para>""''"'	uses_data_from	AGA	
cites	Experiments	D. Kuang, H. Park, Fast rank-2 nonnegative matrix factorization for hierarchical document clustering , Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (2013)	http://dx.doi.org/10.1016/j.patcog.2017.11.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0037		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0046	'The difference between t-NMF-l1 and fix-NMF-l1 is that in every time slot, t-NMF-l1 generates a new topic matrix and initializes with Wt-1.Hie-NMF-l1: Hie-Rank2 can cluster documents into hierarchies by repeatedly performing rank2-NMF [23][[ refid=''bib0023'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0071"""" view=""""all"""">In order to evaluate our method, seven baseline methods are compared in the experiments:<ce:list id=""""celist0003""""><ce:list-item id=""""celistitem0008""""><ce:para id=""""para0072"""" view=""""all""""><ce:bold>fix-NMF-l1</ce:bold>: fix-NMF-l1 only performs NMF on the data of the first time slot and does not change the topic distribution in the latter time slots. The NMF algorithm is implemented with multiplicative-updates rules and l1-norm regularization <ce:cross-ref id=""""crf0077"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0009""""><ce:para id=""""para0073"""" view=""""all""""><ce:bold>t-NMF-l1</ce:bold>: t-NMF-l1 uses the same NMF implementation as the fix-NMF-l1. The difference between t-NMF-l1 and fix-NMF-l1 is that in every time slot, t-NMF-l1 generates a new topic matrix and initializes with <ce:bold><ce:italic>W</ce:italic></ce:bold><ce:italic><ce:sup loc=""""post"""">t</ce:sup></ce:italic><ce:sup loc=""""post"""">-1</ce:sup>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0010""""><ce:para id=""""para0074"""" view=""""all""""><ce:bold>Hie-NMF-l1</ce:bold>: Hie-Rank2 can cluster documents into hierarchies by repeatedly performing rank2-NMF <ce:cross-ref id=""""crf0078"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. The rank2-NMF is a fast active-set-type algorithm for NMF with <ce:italic>k</ce:italic> = 2. To improve the performance, the original rank2-NMF is replaced with NMF-l1. Hie-NMF-l1 is performed in each time slot.</ce:para></ce:list-item><ce:list-item id=""""celistitem0011""""><ce:para id=""""para0075"""" view=""""all""""><ce:bold>JPP</ce:bold>: JPP is a time-based collective factorization algorithm for topic discovery <ce:cross-ref id=""""crf0079"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>. It considers the difference between the previous decomposition and the current decomposition in the objective function to achieve online decomposition.</ce:para></ce:list-item><ce:list-item id=""""celistitem0012""""><ce:para id=""""para0076"""" view=""""all""""><ce:bold>ONMF</ce:bold>: ONMF <ce:cross-ref id=""""crf0080"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref> is an extension of an online dictionary learning method by adding positive constraints on the dictionary and the coefficients.</ce:para></ce:list-item><ce:list-item id=""""celistitem0013""""><ce:para id=""""para0077"""" view=""""all""""><ce:bold>OLDA</ce:bold>: Online LDA <ce:cross-ref id=""""crf0081"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> is an online probabilistic topic model. It supports batch mode. In every time slot, it updates the parameters of the topic-word distributions and estimates the document-topic distributions for evaluation <ce:cross-ref id=""""crf0082"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0014""""><ce:para id=""""para0078"""" view=""""all""""><ce:bold>HLDA</ce:bold>: HLDA <ce:cross-ref id=""""crf0083"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> is a hierarchical probabilistic topic model. In HLDA, a document is generated by choosing a path from the root to a leaf and sampling topics along the path. In the experiment, every path is regarded as a topic in HLDA. Therefore, the documents are assigned to the corresponding leaf topics. HLDA is not an online method and is used as a static hierarchical probabilistic baseline. The result of HLDA is generated by using a sampled document set in a time.</ce:para></ce:list-item><ce:list-item id=""""celistitem0015""""><ce:para id=""""para0079"""" view=""""all""""><ce:bold>HONMF</ce:bold>: The proposed hierarchical online NMF method for detecting topic hierarchies in a text stream. It can track the evolving process of the topics and the topic hierarchy. When evaluate HONMF, only the activated leaf nodes are used.</ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experiments	C.K. Vaca, A. Mantrach, A. Jaimes, M. Saerens, A time-based collective factorization for topic discovery and monitoring in news , Proceedings of the 23rd International Conference on World Wide Web (2014)	http://dx.doi.org/10.1016/j.patcog.2017.11.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0005	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0036		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0047	'The NMF algorithm is implemented with multiplicative-updates rules and l1-norm regularization [5][[ refid=''bib0005'' ]].t-NMF-l1: t-NMF-l1 uses the same NMF implementation as the fix-NMF-l1.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0071"""" view=""""all"""">In order to evaluate our method, seven baseline methods are compared in the experiments:<ce:list id=""""celist0003""""><ce:list-item id=""""celistitem0008""""><ce:para id=""""para0072"""" view=""""all""""><ce:bold>fix-NMF-l1</ce:bold>: fix-NMF-l1 only performs NMF on the data of the first time slot and does not change the topic distribution in the latter time slots. The NMF algorithm is implemented with multiplicative-updates rules and l1-norm regularization <ce:cross-ref id=""""crf0077"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0009""""><ce:para id=""""para0073"""" view=""""all""""><ce:bold>t-NMF-l1</ce:bold>: t-NMF-l1 uses the same NMF implementation as the fix-NMF-l1. The difference between t-NMF-l1 and fix-NMF-l1 is that in every time slot, t-NMF-l1 generates a new topic matrix and initializes with <ce:bold><ce:italic>W</ce:italic></ce:bold><ce:italic><ce:sup loc=""""post"""">t</ce:sup></ce:italic><ce:sup loc=""""post"""">-1</ce:sup>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0010""""><ce:para id=""""para0074"""" view=""""all""""><ce:bold>Hie-NMF-l1</ce:bold>: Hie-Rank2 can cluster documents into hierarchies by repeatedly performing rank2-NMF <ce:cross-ref id=""""crf0078"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. The rank2-NMF is a fast active-set-type algorithm for NMF with <ce:italic>k</ce:italic> = 2. To improve the performance, the original rank2-NMF is replaced with NMF-l1. Hie-NMF-l1 is performed in each time slot.</ce:para></ce:list-item><ce:list-item id=""""celistitem0011""""><ce:para id=""""para0075"""" view=""""all""""><ce:bold>JPP</ce:bold>: JPP is a time-based collective factorization algorithm for topic discovery <ce:cross-ref id=""""crf0079"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>. It considers the difference between the previous decomposition and the current decomposition in the objective function to achieve online decomposition.</ce:para></ce:list-item><ce:list-item id=""""celistitem0012""""><ce:para id=""""para0076"""" view=""""all""""><ce:bold>ONMF</ce:bold>: ONMF <ce:cross-ref id=""""crf0080"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref> is an extension of an online dictionary learning method by adding positive constraints on the dictionary and the coefficients.</ce:para></ce:list-item><ce:list-item id=""""celistitem0013""""><ce:para id=""""para0077"""" view=""""all""""><ce:bold>OLDA</ce:bold>: Online LDA <ce:cross-ref id=""""crf0081"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> is an online probabilistic topic model. It supports batch mode. In every time slot, it updates the parameters of the topic-word distributions and estimates the document-topic distributions for evaluation <ce:cross-ref id=""""crf0082"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0014""""><ce:para id=""""para0078"""" view=""""all""""><ce:bold>HLDA</ce:bold>: HLDA <ce:cross-ref id=""""crf0083"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> is a hierarchical probabilistic topic model. In HLDA, a document is generated by choosing a path from the root to a leaf and sampling topics along the path. In the experiment, every path is regarded as a topic in HLDA. Therefore, the documents are assigned to the corresponding leaf topics. HLDA is not an online method and is used as a static hierarchical probabilistic baseline. The result of HLDA is generated by using a sampled document set in a time.</ce:para></ce:list-item><ce:list-item id=""""celistitem0015""""><ce:para id=""""para0079"""" view=""""all""""><ce:bold>HONMF</ce:bold>: The proposed hierarchical online NMF method for detecting topic hierarchies in a text stream. It can track the evolving process of the topics and the topic hierarchy. When evaluate HONMF, only the activated leaf nodes are used.</ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_method_in	AGA	
cites	Hierarchical online NMF for topic detecting	J.W. Paisley, C. Wang, D.M. Blei, M.I. Jordan, Nested hierarchical Dirichlet processes , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 37 (2015), pp.256-270	http://dx.doi.org/10.1016/j.patcog.2017.11.002			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0020	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0030		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0049	'The advantage of detecting topics in a hierarchical way is two-fold: First, it can reduce the overlaps between different topics and lead to more separable topics, which has been proven in [20][[ refid=''bib0020'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0032"""" view=""""all"""">The key difference between ONMF and HONMF is that HONMF decomposes documents level by level in a topic hierarchy. The topics in the topic hierarchy are arranged with a decreasing topic area from up to bottom. The advantage of detecting topics in a hierarchical way is two-fold: First, it can reduce the overlaps between different topics and lead to more separable topics, which has been proven in <ce:cross-ref id=""""crf0061"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>. Second, in an online topic model, the word distributions of the topics are evolving continuously, and thus the overlaps between the topics may become larger. By organizing topics in a hierarchy, the impact of documents from other topics is controlled, thus more consistent topics would be generated.</ce:para>""''"'	cites	AGA	
cites	Hierarchical online NMF for topic detecting	S.P. Kasiviswanathan, P. Melville, A. Banerjee, V. Sindhwani, Emerging topic detection using dictionary learning , Proceedings of the 20th ACM Conference on Information and Knowledge Management (2011)	http://dx.doi.org/10.1016/j.patcog.2017.11.002			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0026	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0033		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0050	'In [26][[ refid=''bib0026'' ]], a method is proposed to get emerging topics from novel documents.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0048"""" view=""""all"""">In <ce:cross-ref id=""""crf0068"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>, a method is proposed to get emerging topics from novel documents. The limitation of the method is that the number of emerging topics should be predefined. Therefore, we also use FMS to determine the number of emerging topics: Suppose the document set of the current node is <ce:bold><ce:italic>X</ce:italic></ce:bold> and the document set of the found novel documents is <ce:bold><ce:italic>X</ce:italic></ce:bold><ce:italic><ce:inf loc=""""post"""">novel</ce:inf></ce:italic>. The FMS process is conducted on <ce:bold><ce:italic>X</ce:italic></ce:bold><ce:italic><ce:inf loc=""""post"""">novel</ce:inf></ce:italic>, and the bandwidth is set as the bandwidth of the current node. Then, the emerging topics are detected as follows. All candidate emerging topics (represented by document clusters) are ranked by their average similarities with the existing topics, and the one with the lowest similarity is selected as an emerging topic every time. Note that too small document clusters are not considered as candidate emerging topics (the same topic size threshold <ce:italic>θ<ce:inf loc=""""post"""">t</ce:inf></ce:italic> is used to measure whether a cluster is small). The selection process ends until the existing topics and the emerging topics contain more than 90% documents of <ce:bold><ce:italic>X</ce:italic></ce:bold>. After that, the initial topic vectors of the emerging topics are computed as the mean vectors of documents belonging to them. To combine the existing topics <ce:bold><ce:italic>W</ce:italic></ce:bold> and the emerging topics <ce:bold><ce:italic>W</ce:italic></ce:bold><ce:italic><ce:inf loc=""""post"""">e</ce:inf></ce:italic>, the initial state of the decomposition process is modified as:<ce:display><ce:formula id=""""eqn0008""""><ce:label>(8)</ce:label><mml:math altimg=""""si21.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mover accent=""""true""""><mml:mi mathvariant=""""bold-italic"""">A</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy=""""true"""">[</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant=""""bold-italic"""">A</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant=""""bold-italic"""">Σ</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant=""""bold-italic"""">Σ</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mspace width=""""0.16em""""/><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mspace width=""""0.16em""""/><mml:mi mathvariant=""""bold-italic"""">I</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo stretchy=""""true"""">]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width=""""1em""""/><mml:mover accent=""""true""""><mml:mi mathvariant=""""bold-italic"""">B</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy=""""true"""">[</mml:mo><mml:mrow><mml:mi mathvariant=""""bold-italic"""">B</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msub><mml:mi mathvariant=""""bold-italic"""">W</mml:mi><mml:mi mathvariant=""""normal"""">e</mml:mi></mml:msub></mml:mrow><mml:mo stretchy=""""true"""">]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width=""""1em""""/><mml:mover accent=""""true""""><mml:mi mathvariant=""""bold-italic"""">W</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy=""""true"""">[</mml:mo><mml:mrow><mml:mi mathvariant=""""bold-italic"""">W</mml:mi><mml:msub><mml:mi mathvariant=""""bold-italic"""">W</mml:mi><mml:mi mathvariant=""""normal"""">e</mml:mi></mml:msub></mml:mrow><mml:mo stretchy=""""true"""">]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>where <ce:italic>k<ce:inf loc=""""post"""">e</ce:inf></ce:italic> is the number of the selected emerging topics, <ce:bold><ce:italic>I</ce:italic></ce:bold> is a <ce:italic>k<ce:inf loc=""""post"""">e</ce:inf></ce:italic> × <ce:italic>k<ce:inf loc=""""post"""">e</ce:inf></ce:italic> identity matrix, <ce:bold>Σ</ce:bold><ce:inf loc=""""post"""">1</ce:inf> and <ce:bold>Σ</ce:bold><ce:inf loc=""""post"""">2</ce:inf> are matrices with all elements equal to <ce:italic>ε, t</ce:italic><ce:inf loc=""""post"""">0</ce:inf> is a constant to adjust the weights of the emerging topics to prevent that the decomposition result deviates too much from the initial topics.</ce:para>""''"'	cites	AGA	
cites	Experiments	C.K. Vaca, A. Mantrach, A. Jaimes, M. Saerens, A time-based collective factorization for topic discovery and monitoring in news , Proceedings of the 23rd International Conference on World Wide Web (2014)	http://dx.doi.org/10.1016/j.patcog.2017.11.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0005	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0038		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0054	'Hie-NMF-l1 is performed in each time slot.JPP: JPP is a time-based collective factorization algorithm for topic discovery [5][[ refid=''bib0005'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0071"""" view=""""all"""">In order to evaluate our method, seven baseline methods are compared in the experiments:<ce:list id=""""celist0003""""><ce:list-item id=""""celistitem0008""""><ce:para id=""""para0072"""" view=""""all""""><ce:bold>fix-NMF-l1</ce:bold>: fix-NMF-l1 only performs NMF on the data of the first time slot and does not change the topic distribution in the latter time slots. The NMF algorithm is implemented with multiplicative-updates rules and l1-norm regularization <ce:cross-ref id=""""crf0077"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0009""""><ce:para id=""""para0073"""" view=""""all""""><ce:bold>t-NMF-l1</ce:bold>: t-NMF-l1 uses the same NMF implementation as the fix-NMF-l1. The difference between t-NMF-l1 and fix-NMF-l1 is that in every time slot, t-NMF-l1 generates a new topic matrix and initializes with <ce:bold><ce:italic>W</ce:italic></ce:bold><ce:italic><ce:sup loc=""""post"""">t</ce:sup></ce:italic><ce:sup loc=""""post"""">-1</ce:sup>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0010""""><ce:para id=""""para0074"""" view=""""all""""><ce:bold>Hie-NMF-l1</ce:bold>: Hie-Rank2 can cluster documents into hierarchies by repeatedly performing rank2-NMF <ce:cross-ref id=""""crf0078"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. The rank2-NMF is a fast active-set-type algorithm for NMF with <ce:italic>k</ce:italic> = 2. To improve the performance, the original rank2-NMF is replaced with NMF-l1. Hie-NMF-l1 is performed in each time slot.</ce:para></ce:list-item><ce:list-item id=""""celistitem0011""""><ce:para id=""""para0075"""" view=""""all""""><ce:bold>JPP</ce:bold>: JPP is a time-based collective factorization algorithm for topic discovery <ce:cross-ref id=""""crf0079"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>. It considers the difference between the previous decomposition and the current decomposition in the objective function to achieve online decomposition.</ce:para></ce:list-item><ce:list-item id=""""celistitem0012""""><ce:para id=""""para0076"""" view=""""all""""><ce:bold>ONMF</ce:bold>: ONMF <ce:cross-ref id=""""crf0080"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref> is an extension of an online dictionary learning method by adding positive constraints on the dictionary and the coefficients.</ce:para></ce:list-item><ce:list-item id=""""celistitem0013""""><ce:para id=""""para0077"""" view=""""all""""><ce:bold>OLDA</ce:bold>: Online LDA <ce:cross-ref id=""""crf0081"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> is an online probabilistic topic model. It supports batch mode. In every time slot, it updates the parameters of the topic-word distributions and estimates the document-topic distributions for evaluation <ce:cross-ref id=""""crf0082"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0014""""><ce:para id=""""para0078"""" view=""""all""""><ce:bold>HLDA</ce:bold>: HLDA <ce:cross-ref id=""""crf0083"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> is a hierarchical probabilistic topic model. In HLDA, a document is generated by choosing a path from the root to a leaf and sampling topics along the path. In the experiment, every path is regarded as a topic in HLDA. Therefore, the documents are assigned to the corresponding leaf topics. HLDA is not an online method and is used as a static hierarchical probabilistic baseline. The result of HLDA is generated by using a sampled document set in a time.</ce:para></ce:list-item><ce:list-item id=""""celistitem0015""""><ce:para id=""""para0079"""" view=""""all""""><ce:bold>HONMF</ce:bold>: The proposed hierarchical online NMF method for detecting topic hierarchies in a text stream. It can track the evolving process of the topics and the topic hierarchy. When evaluate HONMF, only the activated leaf nodes are used.</ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_method_in	AGA	
cites	Related work	X. Zhang, D.B. Dunson, L. Carin, Hierarchical topic modeling for analysis of time-evolving personal choices , Proceedings of the 25th Annual Conference on Neural Information Processing Systems (2011)	http://dx.doi.org/10.1016/j.patcog.2017.11.002	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0019	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0019		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0055	'In [19][[ refid=''bib0019'' ]], HLDA is extended to a nonparametric topic-model tree to represent human choices by developing a new stick-breaking model.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0023"""" view=""""all"""">Methods proposed in <ce:cross-refs id=""""crf0044"""" refid=""""bib0018 bib0019 bib0020 bib0021"""">[18–21][[ refid=''''bib0018 bib0019 bib0020 bib0021'''' ]]</ce:cross-refs> belong to the hierarchical probabilistic topic models. In <ce:cross-ref id=""""crf0046"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>, the original LDA is extended to HLDA by combining the nested Chinese restaurant process (nCRP). In HLDA, a document is generated by choosing a path from the root to a leaf and sampling topics along the path. Several extensions of HLDA have been proposed in the latter researches. In <ce:cross-ref id=""""crf0047"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref>, HLDA is extended to a nonparametric topic-model tree to represent human choices by developing a new stick-breaking model. Recently, a hierarchical extension of HDP <ce:cross-ref id=""""crf0048"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> is also presented to overcome the drawback of HLDA, which can select multiple paths for a document in the topic hierarchy.</ce:para>""''"'	cites	AGA	
cites	Related work	C.K. Vaca, A. Mantrach, A. Jaimes, M. Saerens, A time-based collective factorization for topic discovery and monitoring in news , Proceedings of the 23rd International Conference on World Wide Web (2014)	http://dx.doi.org/10.1016/j.patcog.2017.11.002	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0005	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0013		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0057	'Similarly, in [5][[ refid=''bib0005'' ]], a transition matrix is used to represent the relations between the topics.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0021"""" view=""""all"""">The second category of methods extends matrix factorization based methods to find the topics in the text stream. In <ce:cross-ref id=""""crf0036"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref>, an invertible matrix is used to represent the transition relations between the old topics and the new topics. Constraints are added on the matrix to find the optimal topics. Similarly, in <ce:cross-ref id=""""crf0037"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>, a transition matrix is used to represent the relations between the topics. However, there are two differences: 1) In <ce:cross-ref id=""""crf0038"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>, the l1 regularization of the transition matrix is integrated into the objective function, while in <ce:cross-ref id=""""crf0039"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref>, it is only exploited to constrain the solution space; 2) In <ce:cross-ref id=""""crf0040"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>, the l1 regularization of the topic matrix is used to get sparse representations, while in <ce:cross-ref id=""""crf0041"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref>, more strict orthogonality constraints are utilized to get coherent topics. Unlike these methods, in <ce:cross-ref id=""""crf0042"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>, a box constraint is used to eliminate the difference between the topics found in different time slots, and a time regularization factor is also added to penalize static topics. In <ce:cross-ref id=""""crf0043"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>, the task is solved from a different perspective, which finds the topics that fit the present data and the decomposition results of the past data. However, the topics are also organized in flat structures in these methods.</ce:para>""''"'	cites	AGA	
cites	Related work	J. Mairal, F. Bach, J. Ponce, G. Sapiro, Online learning for matrix factorization and sparse coding , J. Mach. Learn. Res. , vol. 11 (2010), pp.19-60	http://dx.doi.org/10.1016/j.patcog.2017.11.002	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/br/bib0003	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/ctx/ctx0016		43	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-002/itrp/0067	'In [3][[ refid=''bib0003'' ]], the task is solved from a different perspective, which finds the topics that fit the present data and the decomposition results of the past data.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0021"""" view=""""all"""">The second category of methods extends matrix factorization based methods to find the topics in the text stream. In <ce:cross-ref id=""""crf0036"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref>, an invertible matrix is used to represent the transition relations between the old topics and the new topics. Constraints are added on the matrix to find the optimal topics. Similarly, in <ce:cross-ref id=""""crf0037"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>, a transition matrix is used to represent the relations between the topics. However, there are two differences: 1) In <ce:cross-ref id=""""crf0038"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>, the l1 regularization of the transition matrix is integrated into the objective function, while in <ce:cross-ref id=""""crf0039"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref>, it is only exploited to constrain the solution space; 2) In <ce:cross-ref id=""""crf0040"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>, the l1 regularization of the topic matrix is used to get sparse representations, while in <ce:cross-ref id=""""crf0041"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref>, more strict orthogonality constraints are utilized to get coherent topics. Unlike these methods, in <ce:cross-ref id=""""crf0042"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>, a box constraint is used to eliminate the difference between the topics found in different time slots, and a time regularization factor is also added to penalize static topics. In <ce:cross-ref id=""""crf0043"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>, the task is solved from a different perspective, which finds the topics that fit the present data and the decomposition results of the past data. However, the topics are also organized in flat structures in these methods.</ce:para>""''"'	uses_data_from	AGA	
cites	Related work	M. De Domenico, A. Solé-Ribalta, E. Cozzo, M. Kivelä, Y. Moreno, M.A. Porter, S. Gómez, A. Arenas, Mathematical formulation of multilayer networks , Phys. Rev. X , vol. 3 (2013), pp.041022	http://dx.doi.org/10.1016/j.patcog.2017.11.004	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/br/bib0003	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/ctx/ctx0009		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/itrp/0028	'Its mathematical formulation is given in [3][[ refid=''bib0003'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">Complex network is an interdisciplinary research, attracting researchers from computer science, physics, sociology, biology, and so on. Due to the pervasiveness of the network phenomenon, complex network has been adopted to model many things, such as the users’ friend network and the cell network in the brain. Comparing to the graph, the complex network area focuses more on the non-trivial structural properties. The two outstanding properties are small-world network published in Nature <ce:cross-ref id=""""crf0019"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> and power-law degree distribution <ce:cross-ref id=""""crf0020"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> published in Science. Besides, many other different network structural properties have also been discovered and defined in this area <ce:cross-refs id=""""crfs0005"""" refid=""""bib0015 bib0016"""">[15,16][[ refid=''''bib0015 bib0016'''' ]]</ce:cross-refs>. However, it is commonly accepted that the following network structural properties are the most fundamental and significant for describing the structure of a complex network: community <ce:cross-refs id=""""crfs0006"""" refid=""""bib0017 bib0018"""">[17,18][[ refid=''''bib0017 bib0018'''' ]]</ce:cross-refs>, degree distribution <ce:cross-refs id=""""crfs0007"""" refid=""""bib0019 bib0020 bib0021"""">[19–21][[ refid=''''bib0019 bib0020 bib0021'''' ]]</ce:cross-refs>, and max spanning tree <ce:cross-refs id=""""crfs0008"""" refid=""""bib0022 bib0023"""">[22,23][[ refid=''''bib0022 bib0023'''' ]]</ce:cross-refs>. Recently, the multilayer network has attracted the attention of researchers. Its mathematical formulation is given in <ce:cross-ref id=""""crf0021"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>. Similar to the one-layer complex network, its structures are defined and discussed in <ce:cross-ref id=""""crf0022"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>. Apart from formalization and structure definition, the multilayer network has been used for modelling the influence propagation over microblogs <ce:cross-ref id=""""crf0023"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref> and the analysis and management of change propagation <ce:cross-ref id=""""crf0024"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. However, most state-of-the-art research on multilayer networks focuses on basic structure analysis. Since the traditional network structural properties (i.e., community, degree distribution and max spanning tree) do not consider the directions of the edges in the network and our aim is to preserve these network properties after the embedding, we assume in this paper that the network is undirected.</ce:para>""''"'	cites	AGA	
cites	Introduction	M. Kivelä, A. Arenas, M. Barthelemy, J.P. Gleeson, Y. Moreno, M.A. Porter, Multilayer networks , J. Complex Netw. , vol. 2 (2014), pp.203-271	http://dx.doi.org/10.1016/j.patcog.2017.11.004	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/ctx/ctx0001		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/itrp/0029	'Multilayer network [1][[ refid=''bib0001'' ]] is a structure commonly used to describe and model the complex interaction between sets of entities/nodes.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0004"""" view=""""all"""">Multilayer network <ce:cross-ref id=""""crf0008"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> is a structure commonly used to describe and model the complex interaction between sets of entities/nodes. The structure has attracted the attention of researchers from many areas, such as computer scientists, sociologists, physicists, and biologists, due to its pervasiveness. As a result, research into multilayer network has become a multidisciplinary area of study. To date, many types of multilayer network with a variety of structures and names have been developed in the literature <ce:cross-refs id=""""crfs0001"""" refid=""""bib0001 bib0002 bib0003"""">[1–3][[ refid=''''bib0001 bib0002 bib0003'''' ]]</ce:cross-refs>. Multilayer network, as defined in this study, is composed of several homogeneous networks in multiple layers and the nodes in different layers may have external links across the layers, as illustrated in <ce:cross-ref id=""""crf0009"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref><ce:float-anchor refid=""""fig0001""""/>. One example, in the text mining area, is the author-paper-keyword structure shown in <ce:cross-ref id=""""crf0010"""" refid=""""fig0002"""">Fig. 2</ce:cross-ref><ce:float-anchor refid=""""fig0002""""/>. This structure is a multilayer network because it is composed of three layered networks (i.e., author social network, paper citation network and keyword co-occurrence network) and the nodes across networks are also linked (i.e., an author and a paper are linked if this author writes this paper, and a paper and a word are linked if this paper contains this word). In recommender systems, a multilayer network is composed of tag-user-movie mapping relations with tag similarity network, user social network and movie similarity network, as shown in <ce:cross-ref id=""""crf0011"""" refid=""""fig0003"""">Fig. 3</ce:cross-ref><ce:float-anchor refid=""""fig0003""""/>. Multilayer network would also be a good choice for big data modelling because there are complex interactions between multiple sources or attributes due to the Variety property of big data <ce:cross-ref id=""""crf0012"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>. Hence, it is crucial and urgent to develop more effective analytic tools for multilayer network to obtain better understanding and improving behaviour prediction of its underlying complex systems.</ce:para>""''"'	cites	AGA	
cites	Introduction	P. Hitzler, K. Janowicz, Linked data, big data, and the 4th paradigm , Semant. Web , vol. 4 (2013), pp.233-235	http://dx.doi.org/10.1016/j.patcog.2017.11.004	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/ctx/ctx0003		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/itrp/0033	'Multilayer network would also be a good choice for big data modelling because there are complex interactions between multiple sources or attributes due to the Variety property of big data [4][[ refid=''bib0004'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0004"""" view=""""all"""">Multilayer network <ce:cross-ref id=""""crf0008"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> is a structure commonly used to describe and model the complex interaction between sets of entities/nodes. The structure has attracted the attention of researchers from many areas, such as computer scientists, sociologists, physicists, and biologists, due to its pervasiveness. As a result, research into multilayer network has become a multidisciplinary area of study. To date, many types of multilayer network with a variety of structures and names have been developed in the literature <ce:cross-refs id=""""crfs0001"""" refid=""""bib0001 bib0002 bib0003"""">[1–3][[ refid=''''bib0001 bib0002 bib0003'''' ]]</ce:cross-refs>. Multilayer network, as defined in this study, is composed of several homogeneous networks in multiple layers and the nodes in different layers may have external links across the layers, as illustrated in <ce:cross-ref id=""""crf0009"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref><ce:float-anchor refid=""""fig0001""""/>. One example, in the text mining area, is the author-paper-keyword structure shown in <ce:cross-ref id=""""crf0010"""" refid=""""fig0002"""">Fig. 2</ce:cross-ref><ce:float-anchor refid=""""fig0002""""/>. This structure is a multilayer network because it is composed of three layered networks (i.e., author social network, paper citation network and keyword co-occurrence network) and the nodes across networks are also linked (i.e., an author and a paper are linked if this author writes this paper, and a paper and a word are linked if this paper contains this word). In recommender systems, a multilayer network is composed of tag-user-movie mapping relations with tag similarity network, user social network and movie similarity network, as shown in <ce:cross-ref id=""""crf0011"""" refid=""""fig0003"""">Fig. 3</ce:cross-ref><ce:float-anchor refid=""""fig0003""""/>. Multilayer network would also be a good choice for big data modelling because there are complex interactions between multiple sources or attributes due to the Variety property of big data <ce:cross-ref id=""""crf0012"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>. Hence, it is crucial and urgent to develop more effective analytic tools for multilayer network to obtain better understanding and improving behaviour prediction of its underlying complex systems.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experimental results and analysis	J. Chang, D.M. Blei, Relational topic models for document networks , Proceedings of the International Conference on Artificial Intelligence and Statistics (2009)	http://dx.doi.org/10.1016/j.patcog.2017.11.004	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/br/bib0048	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/ctx/ctx0030		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/itrp/0050	'To compare the efficiency, we also implement standard NMF which does not consider the horizontal network H2708 × 2708 and Relational Topic Model (RTM) [48][[ refid=''bib0048'' ]] which is a successful Bayesian model for the relational data and considers both horizontal network (document-word relationships) and vertical network (document network).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0068"""" view=""""all"""">After the embedding of <ce:italic>V</ce:italic><ce:inf loc=""""post"""">2708 × 1433</ce:inf> and <ce:italic>H</ce:italic><ce:inf loc=""""post"""">2708 × 2708</ce:inf> through our proposed algorithms, NNMF, CNMF, DNMF and TNMF, the documents are projected into a latent space and then given new representations. It is believed that the different classes are formed as a result of the intrinsics of the documents, so if the discovered latent space is good enough, it will cause the documents to cluster into these seven classes. According to this idea, we conduct the document clustering through the learned matrix <ce:italic>A</ce:italic> (the new representations of documents) by the k-means clustering algorithm.<ce:cross-ref id=""""crf0096"""" refid=""""fn0003""""><ce:sup loc=""""post"""">3</ce:sup></ce:cross-ref><ce:footnote id=""""fn0003""""><ce:label>3</ce:label><ce:note-para id=""""cenotep0003"""" view=""""all"""">Since <ce:italic>k</ce:italic>-means is not very stable, the reported results in this work are the average of ten independent runs.</ce:note-para></ce:footnote> To compare the efficiency, we also implement standard NMF which does not consider the horizontal network <ce:italic>H</ce:italic><ce:inf loc=""""post"""">2708 × 2708</ce:inf> and Relational Topic Model (RTM) <ce:cross-ref id=""""crf0097"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref> which is a successful Bayesian model for the relational data and considers both horizontal network (document-word relationships) and vertical network (document network). The final results are shown in <ce:cross-ref id=""""crf0098"""" refid=""""fig0006"""">Fig. 6</ce:cross-ref><ce:float-anchor refid=""""fig0006""""/>. Three subfigures denote three clustering result comparisons by the metric in <ce:cross-ref id=""""crf0099"""" refid=""""tbl0001"""">Table 1</ce:cross-ref>. We have tested four numbers of factors: <mml:math altimg=""""si2.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math><mml:math altimg=""""si3.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>300</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math><mml:math altimg=""""si8.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>500</mml:mn></mml:mrow></mml:math> and <mml:math altimg=""""si5.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>1000</mml:mn></mml:mrow></mml:math>. In each subfigure in <ce:cross-ref id=""""crf0100"""" refid=""""fig0006"""">Fig. 6</ce:cross-ref>, we have compared the results from NNMF, CNMF, DNMF, TNMF, NMF and RTM on the clustering evaluation metric. Except for NMF, the algorithms all consider the effects from the horizontal network <ce:italic>H</ce:italic><ce:inf loc=""""post"""">2708 × 2708</ce:inf>. From this result, we can see that NMF achieves the worst performance compared to others. Thus, we can draw the conclusion that incorporating the citation network is helpful for the clustering of the publications. Except for DNMF, which has similar performance to RTM, NNMF, CNMF and TNMF are better than RTM on this document clustering task. Notably, CNMF and TNMF achieve the best performance of all the algorithms. The reason is that the community structure of CNMF is beneficial for the clustering because it encourages ‘similar’ nodes to cluster together. For example, two documents <ce:italic>d<ce:inf loc=""""post"""">i</ce:inf></ce:italic> and <ce:italic>d<ce:inf loc=""""post"""">j</ce:inf></ce:italic> are in the same community in network <ce:italic>H</ce:italic> due to their ‘similarity’. Retaining the community structure will make it more possible for <ce:italic>d<ce:inf loc=""""post"""">i</ce:inf></ce:italic> and <ce:italic>d<ce:inf loc=""""post"""">j</ce:inf></ce:italic> to remain within the same cluster under the new representations. In the TNMF, preserving max spanning tree encourages the most important relations of all the nodes/documents. These relations in the tree can be seen as the “bones” of a network, which determine the weighted distances between the nodes (documents). Therefore, the TNMF can benefit for the document clustering. Each document will exhibit two natures from two networks: <ce:italic>H</ce:italic> and <ce:italic>V</ce:italic>. If the two natures are consistent, the constraint from <ce:italic>V</ce:italic> will help to enhance the learned network structure from <ce:italic>H</ce:italic>; if the two natures are not consistent, there will be a contradiction between <ce:italic>H</ce:italic> and <ce:italic>V</ce:italic>, which will prevent the network structure learning from <ce:italic>H</ce:italic>.</ce:para>""''"'	uses_data_from	AGA	
ERROR	Experimental results and analysis	I. Cantador, P. Brusilovsky, T. Kuflik, 2nd workshop on information heterogeneity and fusion in recommender systems (hetrec 2011) , Proceedings of the Fifth ACM Conference on Recommender systems, RecSys 2011, ACM (2011)	http://dx.doi.org/10.1016/j.patcog.2017.11.004	methods	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/br/bib0051	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/ctx/ctx0033		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/itrp/0051	'which records the bookmark options of users on webpages/URLs in this website according to users’ interests [51][[ refid=''bib0051'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0075"""" view=""""all"""">The dataset used for recommendation with two-layer network is <ce:italic>Delicious</ce:italic>. This dataset is collected from the Delicious website,<ce:cross-ref id=""""crf0113"""" refid=""""fn0005""""><ce:sup loc=""""post"""">5</ce:sup></ce:cross-ref><ce:footnote id=""""fn0005""""><ce:label>5</ce:label><ce:note-para id=""""cenotep0005"""" view=""""all""""><ce:inter-ref id=""""interref0003"""" xlink:href=""""http://www.delicious.com"""" xlink:type=""""simple"""">http://www.delicious.com</ce:inter-ref>.</ce:note-para></ce:footnote> which records the bookmark options of users on webpages/URLs in this website according to users’ interests <ce:cross-ref id=""""crf0114"""" refid=""""bib0051"""">[51][[ refid=''''bib0051'''' ]]</ce:cross-ref>. We filter this dataset by keeping the URLs that are marked by at least three users, and the number of URL is 5633. The links between URLs are generated by their tags. In the Delicious website, each URL will get tags from users, and these tags will give an hint for the content/semantics of this URL. We use these tags to compute the content similarity between URLs with tag-vector representations through cosine similarity metric. The statistics of the dataset are shown in <ce:cross-ref id=""""crf0115"""" refid=""""tbl0008"""">Table 8</ce:cross-ref><ce:float-anchor refid=""""tbl0008""""/>. In this dataset, vertical network <ce:italic>V</ce:italic><ce:inf loc=""""post"""">1867 × 5633</ce:inf> is formed by users and URLs. The horizontal networks are: the user friend network <ce:italic>H</ce:italic><ce:inf loc=""""post"""">1867 × 1867</ce:inf> and the content similarity network <ce:italic>H</ce:italic><ce:inf loc=""""post"""">5633 × 5633</ce:inf>. A certain number of user–URL pairs are kept to be the test data. The evaluation metrics are in <ce:cross-ref id=""""crf0116"""" refid=""""eq0032"""">Eqs. (32)</ce:cross-ref> and <ce:cross-ref id=""""crf0117"""" refid=""""eq0033"""">(33)</ce:cross-ref>. As shown in <ce:cross-ref id=""""crf0118"""" refid=""""fig0009"""">Fig. 9</ce:cross-ref><ce:float-anchor refid=""""fig0009""""/>, the two-layer network still outweighs the one-layer network.</ce:para>""''"'	cites	AGA	
cites	Experimental results and analysis	P. Sen, G.M. Namata, M. Bilgic, L. Getoor, B. Gallagher, T. Eliassi-Rad, Collective classification in network data , AI Mag. , vol. 29 (2008), pp.93-106	http://dx.doi.org/10.1016/j.patcog.2017.11.004	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/br/bib0050	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/ctx/ctx0032		34	6	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-004/itrp/0052	'Documents are a collection of papers from CiteSeer[50][[ refid=''bib0050'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0072"""" view=""""all"""">First, we introduce the dataset we use. Documents are a collection of papers from <ce:italic>CiteSeer</ce:italic><ce:cross-ref id=""""crf0109"""" refid=""""bib0050"""">[50][[ refid=''''bib0050'''' ]]</ce:cross-ref>. There are 3312 papers in the whole corpus. Each paper is represented by a binary vector using words. The labels of these papers are set as their research areas, such as AI (Artificial Intelligence), ML (Machine Learning), Agents, DB (Database), IR (Information Retrieval) and HCI (Human–Computer Interaction). The statistics are shown in <ce:cross-ref id=""""crf0110"""" refid=""""tbl0007"""">Table 7</ce:cross-ref><ce:float-anchor refid=""""tbl0007""""/>.</ce:para>""''"'	cites	AGA	
cites	Introduction	H. Nam, B. Han, Learning multi-domain convolutional neural networks for visual tracking , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2016)	http://dx.doi.org/10.1016/j.patcog.2017.11.007	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0020	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0006		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0033	'The MDNet [20][[ refid=''bib0020'' ]] tracker is the winner of VOT2015 competition.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0008"""" view=""""all"""">Over the last five years, deep learning <ce:cross-ref id=""""crf0091"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> have achieved an impressive suite of results thanks to their success on automatic feature extraction via multi-layer nonlinear transformations, especially in computer vision <ce:cross-refs id=""""crfs0001"""" refid=""""bib0013 bib0014"""">[13,14][[ refid=''''bib0013 bib0014'''' ]]</ce:cross-refs>, speech recognition <ce:cross-refs id=""""crfs0002"""" refid=""""bib0015 bib0016"""">[15,16][[ refid=''''bib0015 bib0016'''' ]]</ce:cross-refs> and natural language processing <ce:cross-refs id=""""crfs0003"""" refid=""""bib0017 bib0018"""">[17,18][[ refid=''''bib0017 bib0018'''' ]]</ce:cross-refs>. Motivated by these breakthroughs, several deep-learning-based trackers (e.g., FCNT <ce:cross-ref id=""""crf0092"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref>, MDNet <ce:cross-ref id=""""crf0093"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>, STCT <ce:cross-ref id=""""crf0094"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, SINT <ce:cross-ref id=""""crf0095"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>, SiameFC <ce:cross-ref id=""""crf0096"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>, C-COT <ce:cross-ref id=""""crf0097"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, GOTURN <ce:cross-ref id=""""crf0098"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>, TCNN <ce:cross-ref id=""""crf0099"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>, ADNet <ce:cross-ref id=""""crf0100"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> and SANet <ce:cross-ref id=""""crf0101"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>) have demonstrated the potential advantages for significantly improving the tracking performance. The performance on the OTB-100 <ce:cross-ref id=""""crf0102"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> dataset is constantly refreshed by the tracking methods based on deep learning (such as DeepSRDCF <ce:cross-ref id=""""crf0103"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref>, HCFT <ce:cross-ref id=""""crf0104"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> and HDT <ce:cross-ref id=""""crf0105"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>). The MDNet <ce:cross-ref id=""""crf0106"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> tracker is the winner of VOT2015 competition. All the top-4 trackers in the VOT2016 competition, including C-COT <ce:cross-ref id=""""crf0107"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, TCNN <ce:cross-ref id=""""crf0108"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>, SSAT<ce:cross-ref id=""""crf0109"""" refid=""""fn0001""""><ce:sup loc=""""post"""">1</ce:sup></ce:cross-ref><ce:cross-ref id=""""crf0111"""" refid=""""fn0002""""><ce:sup loc=""""post"""">2</ce:sup></ce:cross-ref></ce:para>""''"'	cites	AGA	
cites	Experiment and analysis	Y. Wu, J. Lim, M. Yang, Object tracking benchmark , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 37 (2015), pp.1834-1848	http://dx.doi.org/10.1016/j.patcog.2017.11.007	methods	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0009	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0097		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0047	'The 11 challenge factors as well as the evaluation metrics here are the same with the OTB-100 [9][[ refid=''bib0009'' ]] dataset.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0040a"""" view=""""all""""><ce:bold>TC-128:</ce:bold> The TC-128 <ce:cross-ref id=""""crf0235"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref> dataset is presented by Liang et al. and focus on color information. This benchmark contains 128 color sequences with ground truth and challenge factor annotations, including Illumination Variation (IV), Scale Variation (SV), Occlusion (OCC), Deformation (DEF), Motion Blur (MB), Fast Motion (FM), In-Plane Rotation (IPR), Out-of-Plane Rotation (OPR), Out-of-View (OV), Background Clutters (BC), and Low Resolution (LR). The 11 challenge factors as well as the evaluation metrics here are the same with the OTB-100 <ce:cross-ref id=""""crf0236"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> dataset. <ce:cross-ref id=""""crf0237"""" refid=""""fig0007"""">Fig. 7</ce:cross-ref><ce:float-anchor refid=""""fig0007""""/> illustrates an overall comparison of all 16 deep trackers and 6 traditional top-ranked trackers; while <ce:cross-ref id=""""crf0238"""" refid=""""fig0008"""">Fig. 8</ce:cross-ref><ce:float-anchor refid=""""fig0008""""/> reports the attribute-based performance of these trackers for highlighting the trackers’ abilities in handling different challenges. Besides, we test the speeds of the 22 trackers on this benchmark and report the comparison results in <ce:cross-ref id=""""crf0239"""" refid=""""fig0011"""">Fig. 11</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA	
cites	Experiment and analysis	P. Liang, E. Blasch, H. Ling, Encoding color information for visual tracking: algorithms and benchmark , IEEE Trans. Image Process. , vol. 24 (2015), pp.5630-5644	http://dx.doi.org/10.1016/j.patcog.2017.11.007	methods	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0096		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0048	'TC-128: The TC-128 [10][[ refid=''bib0010'' ]] dataset is presented by Liang et al. and focus on color information.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0040a"""" view=""""all""""><ce:bold>TC-128:</ce:bold> The TC-128 <ce:cross-ref id=""""crf0235"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref> dataset is presented by Liang et al. and focus on color information. This benchmark contains 128 color sequences with ground truth and challenge factor annotations, including Illumination Variation (IV), Scale Variation (SV), Occlusion (OCC), Deformation (DEF), Motion Blur (MB), Fast Motion (FM), In-Plane Rotation (IPR), Out-of-Plane Rotation (OPR), Out-of-View (OV), Background Clutters (BC), and Low Resolution (LR). The 11 challenge factors as well as the evaluation metrics here are the same with the OTB-100 <ce:cross-ref id=""""crf0236"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> dataset. <ce:cross-ref id=""""crf0237"""" refid=""""fig0007"""">Fig. 7</ce:cross-ref><ce:float-anchor refid=""""fig0007""""/> illustrates an overall comparison of all 16 deep trackers and 6 traditional top-ranked trackers; while <ce:cross-ref id=""""crf0238"""" refid=""""fig0008"""">Fig. 8</ce:cross-ref><ce:float-anchor refid=""""fig0008""""/> reports the attribute-based performance of these trackers for highlighting the trackers’ abilities in handling different challenges. Besides, we test the speeds of the 22 trackers on this benchmark and report the comparison results in <ce:cross-ref id=""""crf0239"""" refid=""""fig0011"""">Fig. 11</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experiment and analysis	Y. Wu, J. Lim, M. Yang, Object tracking benchmark , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 37 (2015), pp.1834-1848	http://dx.doi.org/10.1016/j.patcog.2017.11.007	methods	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0009	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0095		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0049	'The performance of the 23 trackers is quantitatively validated via two metrics [9][[ refid=''bib0009'' ]] including distance precision (DP)(%) rate at a threshold of 20 pixels and overlap success (OS)(%) at an overlap threshold 0.5.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0040"""" view=""""all""""><ce:bold>OTB-100:</ce:bold> The OTB-100 <ce:cross-ref id=""""crf0230"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> dataset is presented by Wu et al., which has been one of most commonly used benchmarks in evaluating online visual trackers. This dataset includes 100 challenging video clips annotated with different attributes, such as Illumination Variation (IV), Scale Variation (SV), Occlusion (OCC), Deformation (DEF), Motion Blur (MB), Fast Motion (FM), In-Plane Rotation (IPR), Out-of-Plane Rotation (OPR), Out-of-View (OV), Background Clutters (BC), and Low Resolution (LR). By the 11 different attributes, we can analyze the performance of trackers in different aspects. The performance of the 23 trackers is quantitatively validated via two metrics <ce:cross-ref id=""""crf0231"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> including distance precision (DP)(%) rate at a threshold of 20 pixels and overlap success (OS)(%) at an overlap threshold 0.5. The DP value denotes the percentage that the centre location error (i.e., the Euclidean distance between the center of the tracked target and that of the ground truth) is smaller than a certain threshold in the sequence. The OS value is calculated by the ratio of successfully tracked frames. Usually, the overlap score between the tracking bounding box <ce:italic>R<ce:inf loc=""""post"""">T</ce:inf></ce:italic> and the ground truth <ce:italic>R<ce:inf loc=""""post"""">G</ce:inf></ce:italic> is larger than a pre-defined threshold (such as 0.5), the target is regarded as being tracked successfully. <ce:cross-ref id=""""crf0232"""" refid=""""fig0006"""">Fig. 6</ce:cross-ref><ce:float-anchor refid=""""fig0006""""/> illustrates an overall comparison of all 16 deep trackers and 6 traditional top-ranked trackers; while <ce:cross-ref id=""""crf0233"""" refid=""""tbl0003"""">Tables 3</ce:cross-ref> and <ce:cross-ref id=""""crf0234"""" refid=""""tbl0004"""">4</ce:cross-ref> report the attribute-based performance of these trackers for highlighting the trackers’ abilities in handling different challenges.</ce:para>""''"'	uses_method_in	AGA	
cites	Experiment and analysis	Y. Wu, J. Lim, M. Yang, Object tracking benchmark , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 37 (2015), pp.1834-1848	http://dx.doi.org/10.1016/j.patcog.2017.11.007	methods	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0009	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0094		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0050	'OTB-100: The OTB-100 [9][[ refid=''bib0009'' ]] dataset is presented by Wu et al., which has been one of most commonly used benchmarks in evaluating online visual trackers.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0040"""" view=""""all""""><ce:bold>OTB-100:</ce:bold> The OTB-100 <ce:cross-ref id=""""crf0230"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> dataset is presented by Wu et al., which has been one of most commonly used benchmarks in evaluating online visual trackers. This dataset includes 100 challenging video clips annotated with different attributes, such as Illumination Variation (IV), Scale Variation (SV), Occlusion (OCC), Deformation (DEF), Motion Blur (MB), Fast Motion (FM), In-Plane Rotation (IPR), Out-of-Plane Rotation (OPR), Out-of-View (OV), Background Clutters (BC), and Low Resolution (LR). By the 11 different attributes, we can analyze the performance of trackers in different aspects. The performance of the 23 trackers is quantitatively validated via two metrics <ce:cross-ref id=""""crf0231"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> including distance precision (DP)(%) rate at a threshold of 20 pixels and overlap success (OS)(%) at an overlap threshold 0.5. The DP value denotes the percentage that the centre location error (i.e., the Euclidean distance between the center of the tracked target and that of the ground truth) is smaller than a certain threshold in the sequence. The OS value is calculated by the ratio of successfully tracked frames. Usually, the overlap score between the tracking bounding box <ce:italic>R<ce:inf loc=""""post"""">T</ce:inf></ce:italic> and the ground truth <ce:italic>R<ce:inf loc=""""post"""">G</ce:inf></ce:italic> is larger than a pre-defined threshold (such as 0.5), the target is regarded as being tracked successfully. <ce:cross-ref id=""""crf0232"""" refid=""""fig0006"""">Fig. 6</ce:cross-ref><ce:float-anchor refid=""""fig0006""""/> illustrates an overall comparison of all 16 deep trackers and 6 traditional top-ranked trackers; while <ce:cross-ref id=""""crf0233"""" refid=""""tbl0003"""">Tables 3</ce:cross-ref> and <ce:cross-ref id=""""crf0234"""" refid=""""tbl0004"""">4</ce:cross-ref> report the attribute-based performance of these trackers for highlighting the trackers’ abilities in handling different challenges.</ce:para>""''"'	uses_data_from	AGA	
cites	Experiment and analysis	M. Kristan, J. Matas, A. Leonardis, M. Felsberg, L. Cehovin, G. Fernández, T. Vojír, G. Häger, G. Nebehay, R.P. Pflugfelder, The visual object tracking VOT2015 challenge results , Proceedings of the IEEE International Conference on Computer Vision Workshops (2015)	http://dx.doi.org/10.1016/j.patcog.2017.11.007	methods	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0011	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0098		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0053	'VOT2015: The VOT2015 [11][[ refid=''bib0011'' ]] dataset consists of 60 short sequences annotated with 6 different attributes including occlusion, illumination change, motion change, size change, camera motion and unassigned.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0040b"""" view=""""all""""><ce:bold>VOT2015:</ce:bold> The VOT2015 <ce:cross-ref id=""""crf0240"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> dataset consists of 60 short sequences annotated with 6 different attributes including occlusion, illumination change, motion change, size change, camera motion and unassigned. The major difference between VOT2015 <ce:cross-ref id=""""crf0241"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> and OTB-100 <ce:cross-ref id=""""crf0242"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> is that the VOT2015 challenge provides a re-initialization protocol (i.e., trackers are reset with ground-truths in the middle of evaluation if tracking failures are observed). In this paper, we evaluate 15 deep-learning-based trackers and 7 baseline ones in terms of both accuracy and robustness (AR) rank and expected average overlap (EAO) metrics. It should be noted that the 15 trackers here are the same as trackers tested on OTB-100 and TC-128 except for MCPF <ce:cross-ref id=""""crf0243"""" refid=""""bib0085"""">[85][[ refid=''''bib0085'''' ]]</ce:cross-ref>, the code of which is packaged and cannot be changed. The AR rank is created by ranking the trackers over each sequence and averaging the rank lists according to the quantized accuracy and robustness. It does convert the accuracy and robustness to equal scales, thus, the averaged rank cannot be interpreted as a concrete tracking application result. To address this issue, the EAO <ce:cross-ref id=""""crf0244"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> rule is also introduced to rank different tracking algorithms. It estimates how accurate the estimated bounding box is after a certain number of frames are processed since initialization. <ce:cross-ref id=""""crf0245"""" refid=""""fig0009"""">Fig. 9</ce:cross-ref><ce:float-anchor refid=""""fig0009""""/> reports both accuracy-robust rank (AR) and expected accuracy overlap (EAO) plots of different trackers and <ce:cross-ref id=""""crf0246"""" refid=""""tbl0005"""">Table 5</ce:cross-ref> provides accuracy scores and failure times of different trackers for each individual attribute on the VOT2015 dataset.</ce:para>""''"'	uses_data_from	AGA	
cites	Deep visual tracking	R. Tao, E. Gavves, A.W.M. Smeulders, Siamese instance search for tracking , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2016)	http://dx.doi.org/10.1016/j.patcog.2017.11.007			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0022	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0036		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0060	'In [22][[ refid=''bib0022'' ]], Tao et al. propose a siamese network model to match the object template and candidates for visual tracking, in which the optimal state can be determined based on the highest matching score.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0021"""" view=""""all""""><ce:bold>CNN-M:</ce:bold> Different from the CNN-C-based trackers, the CNN-M ones use convolutional neural networks to learn effective matching functions. In <ce:cross-ref id=""""crf0154"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>, Tao et al. propose a siamese network model to match the object template and candidates for visual tracking, in which the optimal state can be determined based on the highest matching score. After that, Bertinetto et al. <ce:cross-ref id=""""crf0155"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> develop a fully connected siamese network to match the object template and current search region in a convolutional manner, shown as <ce:cross-ref id=""""crf0156"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref><ce:float-anchor refid=""""fig0004""""/>. Besides, Chen et al. <ce:cross-ref id=""""crf0157"""" refid=""""bib0089"""">[89][[ refid=''''bib0089'''' ]]</ce:cross-ref> present a more generic approach utilizing a novel two-flow convolutional neural network to include two inputs (one is the object image patch, another is the search region patch) and produce a response map that predicts how likely the object appears in a specific location. <ce:cross-refs id=""""crfs0017"""" refid=""""bib0079 bib0094 bib0100"""">[79,94,100][[ refid=''''bib0079 bib0094 bib0100'''' ]]</ce:cross-refs> also use two-path network to evaluate the object location. Recently, some trackers apply the satisfactory performance of correlation filter to deep neural network. Valmadre et al. <ce:cross-ref id=""""crf0158"""" refid=""""bib0088"""">[88][[ refid=''''bib0088'''' ]]</ce:cross-ref> interpret correlation filter as a differentiable layer in a siamese network. A closed-form solution via the fourier domain ensures the network being trained end to end. Similar idea can also be found in <ce:cross-ref id=""""crf0159"""" refid=""""bib0093"""">[93][[ refid=''''bib0093'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Deep visual tracking	H. Nam, M. Baek, B. Han, Modeling and propagating cnns in a tree structure for visual tracking , Clin. Orthopaedics Related Res. (2016)	http://dx.doi.org/10.1016/j.patcog.2017.11.007			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0026	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0082		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0078	'In [26][[ refid=''bib0026'' ]], Nam et al. effectively combine pre-trained convolutional layers and multiple fully-connected layers with a tree structure to achieve good tracking performance.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0034"""" view=""""all""""><ce:bold>IP-OL:</ce:bold> There also exist many research works <ce:cross-refs id=""""crfs0024"""" refid=""""bib0074 bib0075 bib0083 bib0089 bib0095 bib0097 bib0098"""">[74,75,83,89,95,97,98][[ refid=''''bib0074 bib0075 bib0083 bib0089 bib0095 bib0097 bib0098'''' ]]</ce:cross-refs> to simultaneously exploit the advantage of both offline pre-training and online learning. Some of them adopt the existing offline pre-trained networks and introduce additional structures online trained with subsequent data during the tracking process. The network in the FCNT <ce:cross-ref id=""""crf0203"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> method is comprised of VGG-16 convolutional layers and an additional network with three designed layers. The parameters of former layers are pre-trained with the ImageNet dataset and fixed during the tracking process. The later layers are flexible enough to capture the appearance change with online update (the similar idea is presented in <ce:cross-ref id=""""crf0204"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>). In <ce:cross-ref id=""""crf0205"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>, Nam et al. effectively combine pre-trained convolutional layers and multiple fully-connected layers with a tree structure to achieve good tracking performance. The other algorithms offline train a CNN structure and online fine-tune it to meet the requirement of the specific tracking task, such as SO-DLT <ce:cross-ref id=""""crf0206"""" refid=""""bib0074"""">[74][[ refid=''''bib0074'''' ]]</ce:cross-ref>, DST <ce:cross-ref id=""""crf0207"""" refid=""""bib0081"""">[81][[ refid=''''bib0081'''' ]]</ce:cross-ref>, CNN-Tracker <ce:cross-ref id=""""crf0208"""" refid=""""bib0098"""">[98][[ refid=''''bib0098'''' ]]</ce:cross-ref>, Trans-DLT <ce:cross-ref id=""""crf0209"""" refid=""""bib0083"""">[83][[ refid=''''bib0083'''' ]]</ce:cross-ref>, DNT <ce:cross-ref id=""""crf0210"""" refid=""""bib0099"""">[99][[ refid=''''bib0099'''' ]]</ce:cross-ref> and DRT <ce:cross-ref id=""""crf0211"""" refid=""""bib0100"""">[100][[ refid=''''bib0100'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Deep visual tracking	H. Nam, B. Han, Learning multi-domain convolutional neural networks for visual tracking , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2016)	http://dx.doi.org/10.1016/j.patcog.2017.11.007			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0020	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0087		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0088	'By using a large set of tracking videos with ground truths, the MDNet [20][[ refid=''bib0020'' ]] method pre-trains a CNN model with shared layers and multiple branches of domain-specific layers to obtain a generic object representation, shown as Fig. 5.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0036"""" view=""""all""""><ce:bold>VP-OL:</ce:bold> Besides the VP-NOL-based trackers, there exist some attempts to combine video pre-training and online learning for developing an effective tracking method. By using a large set of tracking videos with ground truths, the MDNet <ce:cross-ref id=""""crf0215"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> method pre-trains a CNN model with shared layers and multiple branches of domain-specific layers to obtain a generic object representation, shown as <ce:cross-ref id=""""crf0216"""" refid=""""fig0005"""">Fig. 5</ce:cross-ref><ce:float-anchor refid=""""fig0005""""/>. Domain-specific layers correspond to individual training sequences, where each branch is responsible for conducting a binary classification to identify the tracked object in each domain. Then, each domain is trained in the network iteratively to obtain a generic object representation in the shared layers. During the tracking process, the MDNet method constructs a new network to combine the pre-trained shared layers and online updates this network to capture the appearance change of the tracked object. The SANet <ce:cross-ref id=""""crf0217"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> method exploits the same idea with the MDNet tracker, and introduces an additional RNN-based structure to further enhance object representation.</ce:para>""''"'	cites	AGA	
cites	Background and related work	K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2016)	http://dx.doi.org/10.1016/j.patcog.2017.11.007	background	related work	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0067	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0021		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0095	'Later on, He et al. [67][[ refid=''bib0067'' ]] formulate network layers as learning residual functions with short-cut connections, which makes gradients flow through multiple layers easier and allows the training of extremely deep networks.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">Image classification is one of the earliest computer vision tasks where DNNs have shown their strong learning capabilities. In <ce:cross-ref id=""""crf0132"""" refid=""""bib0060"""">[60][[ refid=''''bib0060'''' ]]</ce:cross-ref>, an 8-layer CNN model is trained in an end-to-end manner on the ImageNet classification data set <ce:cross-ref id=""""crf0133"""" refid=""""bib0061"""">[61][[ refid=''''bib0061'''' ]]</ce:cross-ref> and delivers record-breaking performance. It further indicates that the applications of dropout layers <ce:cross-ref id=""""crf0134"""" refid=""""bib0062"""">[62][[ refid=''''bib0062'''' ]]</ce:cross-ref>, Rectified Linear Units (ReLUs) <ce:cross-ref id=""""crf0135"""" refid=""""bib0063"""">[63][[ refid=''''bib0063'''' ]]</ce:cross-ref>, and data augmentation techniques can effectively facilitate easier network training and significantly reduces overfitting. Following <ce:cross-ref id=""""crf0136"""" refid=""""bib0060"""">[60][[ refid=''''bib0060'''' ]]</ce:cross-ref>, deeper networks with more sophisticated architectures <ce:cross-refs id=""""crfs0011"""" refid=""""bib0064 bib0065"""">[64,65][[ refid=''''bib0064 bib0065'''' ]]</ce:cross-refs> have been designed, yielding higher classification accuracy. To alleviate the problem of exploding/vanishing gradients, Ioffe et al. <ce:cross-ref id=""""crf0137"""" refid=""""bib0066"""">[66][[ refid=''''bib0066'''' ]]</ce:cross-ref> propose a Batch Normalization method, which is able to accelerate network training and improve the final performance by reducing covariate shift. Later on, He et al. <ce:cross-ref id=""""crf0138"""" refid=""""bib0067"""">[67][[ refid=''''bib0067'''' ]]</ce:cross-ref> formulate network layers as learning residual functions with short-cut connections, which makes gradients flow through multiple layers easier and allows the training of extremely deep networks. The above progresses have significantly benefit many vision tasks including visual tracking. In particular, the pre-trained deep features on large scale image classification data sets capture high-level semantic meaning of objects, have strong generalization ability across domains, and are widely explored in other areas.</ce:para>""''"'	cites	AGA	
cites	Background and related work	N. Wang, S. Li, A. Gupta, D. Yeung, Transferring rich feature hierarchies for robust visual tracking , Clin. Orthopaedics Related Res. (2015)	http://dx.doi.org/10.1016/j.patcog.2017.11.007	background	related work	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0074	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0027		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0098	'For instance, some recent visual tracking methods [74][[ refid=''bib0074'' ]] pre-train networks on object detection data sets.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">Object detection is another research topic where DNN-based methods have achieved state-of-the-art performance. Most existing DNN-based detectors <ce:cross-refs id=""""crfs0012"""" refid=""""bib0068 bib0069"""">[68,69][[ refid=''''bib0068 bib0069'''' ]]</ce:cross-refs> are implemented in a two-step manner by first generating a set of candidate regions and then classifying them into object categories or background with DNNs. Fast R-CNN <ce:cross-ref id=""""crf0139"""" refid=""""bib0069"""">[69][[ refid=''''bib0069'''' ]]</ce:cross-ref> improves the efficiency by developing the ROI-pooling layer to extract features from shared convolutional feature maps. In <ce:cross-ref id=""""crf0140"""" refid=""""bib0070"""">[70][[ refid=''''bib0070'''' ]]</ce:cross-ref>, the region proposal network is proposed and trained end-to-end with Fast R-CNN to generate high-quality region proposals. Instead of performing detection with CNN-based classifiers, <ce:cross-ref id=""""crf0141"""" refid=""""bib0071"""">[71][[ refid=''''bib0071'''' ]]</ce:cross-ref> formulates the prediction of bounding boxes and class probabilities as a regression problem with DNNs, which delivers superior performance at a significantly accelerated speed. Some recent methods also focus on addressing object detection at the instance-level <ce:cross-ref id=""""crf0142"""" refid=""""bib0072"""">[72][[ refid=''''bib0072'''' ]]</ce:cross-ref> or in video sequences <ce:cross-ref id=""""crf0143"""" refid=""""bib0073"""">[73][[ refid=''''bib0073'''' ]]</ce:cross-ref> with deep-learning-based approaches. It should be noted that object detection and visual tracking are essentially different in that object detection aims to distinguish objects of different categories, while visual tracking is designed to locate objects of interests in an class-agnostic manner. Nonetheless, they are also highly correlated. For instance, some recent visual tracking methods <ce:cross-ref id=""""crf0144"""" refid=""""bib0074"""">[74][[ refid=''''bib0074'''' ]]</ce:cross-ref> pre-train networks on object detection data sets. Others <ce:cross-refs id=""""crfs0013"""" refid=""""bib0075 bib0076"""">[75,76][[ refid=''''bib0075 bib0076'''' ]]</ce:cross-refs> leverage object detection results or region proposals to facilitate more accurate online tracking.</ce:para>""''"'	uses_data_from	AGA	
cites	Background and related work	S. Ren, K. He, R.B. Girshick, J. Sun, Faster R-CNN: towards real-time object detection with region proposal networks , Proceedings of the Advances in Neural Information Processing Systems (2015)	http://dx.doi.org/10.1016/j.patcog.2017.11.007	background	related work	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0070	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0024		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0099	'In [70][[ refid=''bib0070'' ]], the region proposal network is proposed and trained end-to-end with Fast R-CNN to generate high-quality region proposals.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">Object detection is another research topic where DNN-based methods have achieved state-of-the-art performance. Most existing DNN-based detectors <ce:cross-refs id=""""crfs0012"""" refid=""""bib0068 bib0069"""">[68,69][[ refid=''''bib0068 bib0069'''' ]]</ce:cross-refs> are implemented in a two-step manner by first generating a set of candidate regions and then classifying them into object categories or background with DNNs. Fast R-CNN <ce:cross-ref id=""""crf0139"""" refid=""""bib0069"""">[69][[ refid=''''bib0069'''' ]]</ce:cross-ref> improves the efficiency by developing the ROI-pooling layer to extract features from shared convolutional feature maps. In <ce:cross-ref id=""""crf0140"""" refid=""""bib0070"""">[70][[ refid=''''bib0070'''' ]]</ce:cross-ref>, the region proposal network is proposed and trained end-to-end with Fast R-CNN to generate high-quality region proposals. Instead of performing detection with CNN-based classifiers, <ce:cross-ref id=""""crf0141"""" refid=""""bib0071"""">[71][[ refid=''''bib0071'''' ]]</ce:cross-ref> formulates the prediction of bounding boxes and class probabilities as a regression problem with DNNs, which delivers superior performance at a significantly accelerated speed. Some recent methods also focus on addressing object detection at the instance-level <ce:cross-ref id=""""crf0142"""" refid=""""bib0072"""">[72][[ refid=''''bib0072'''' ]]</ce:cross-ref> or in video sequences <ce:cross-ref id=""""crf0143"""" refid=""""bib0073"""">[73][[ refid=''''bib0073'''' ]]</ce:cross-ref> with deep-learning-based approaches. It should be noted that object detection and visual tracking are essentially different in that object detection aims to distinguish objects of different categories, while visual tracking is designed to locate objects of interests in an class-agnostic manner. Nonetheless, they are also highly correlated. For instance, some recent visual tracking methods <ce:cross-ref id=""""crf0144"""" refid=""""bib0074"""">[74][[ refid=''''bib0074'''' ]]</ce:cross-ref> pre-train networks on object detection data sets. Others <ce:cross-refs id=""""crfs0013"""" refid=""""bib0075 bib0076"""">[75,76][[ refid=''''bib0075 bib0076'''' ]]</ce:cross-refs> leverage object detection results or region proposals to facilitate more accurate online tracking.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiment and analysis	M. Kristan, J. Matas, A. Leonardis, M. Felsberg, L. Cehovin, G. Fernández, T. Vojír, G. Häger, G. Nebehay, R.P. Pflugfelder, The visual object tracking VOT2015 challenge results , Proceedings of the IEEE International Conference on Computer Vision Workshops (2015)	http://dx.doi.org/10.1016/j.patcog.2017.11.007	methods	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0011	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0101		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0107	'To address this issue, the EAO [11][[ refid=''bib0011'' ]] rule is also introduced to rank different tracking algorithms.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0040b"""" view=""""all""""><ce:bold>VOT2015:</ce:bold> The VOT2015 <ce:cross-ref id=""""crf0240"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> dataset consists of 60 short sequences annotated with 6 different attributes including occlusion, illumination change, motion change, size change, camera motion and unassigned. The major difference between VOT2015 <ce:cross-ref id=""""crf0241"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> and OTB-100 <ce:cross-ref id=""""crf0242"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> is that the VOT2015 challenge provides a re-initialization protocol (i.e., trackers are reset with ground-truths in the middle of evaluation if tracking failures are observed). In this paper, we evaluate 15 deep-learning-based trackers and 7 baseline ones in terms of both accuracy and robustness (AR) rank and expected average overlap (EAO) metrics. It should be noted that the 15 trackers here are the same as trackers tested on OTB-100 and TC-128 except for MCPF <ce:cross-ref id=""""crf0243"""" refid=""""bib0085"""">[85][[ refid=''''bib0085'''' ]]</ce:cross-ref>, the code of which is packaged and cannot be changed. The AR rank is created by ranking the trackers over each sequence and averaging the rank lists according to the quantized accuracy and robustness. It does convert the accuracy and robustness to equal scales, thus, the averaged rank cannot be interpreted as a concrete tracking application result. To address this issue, the EAO <ce:cross-ref id=""""crf0244"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> rule is also introduced to rank different tracking algorithms. It estimates how accurate the estimated bounding box is after a certain number of frames are processed since initialization. <ce:cross-ref id=""""crf0245"""" refid=""""fig0009"""">Fig. 9</ce:cross-ref><ce:float-anchor refid=""""fig0009""""/> reports both accuracy-robust rank (AR) and expected accuracy overlap (EAO) plots of different trackers and <ce:cross-ref id=""""crf0246"""" refid=""""tbl0005"""">Table 5</ce:cross-ref> provides accuracy scores and failure times of different trackers for each individual attribute on the VOT2015 dataset.</ce:para>""''"'	uses_method_in	AGA	
cites	Experiment and analysis	T. Zhang, C. Xu, M.-H. Yang, Multi-task correlation particle filter for robust object tracking , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2017)	http://dx.doi.org/10.1016/j.patcog.2017.11.007	methods	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0085	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0100		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0108	'It should be noted that the 15 trackers here are the same as trackers tested on OTB-100 and TC-128 except for MCPF [85][[ refid=''bib0085'' ]], the code of which is packaged and cannot be changed.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0040b"""" view=""""all""""><ce:bold>VOT2015:</ce:bold> The VOT2015 <ce:cross-ref id=""""crf0240"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> dataset consists of 60 short sequences annotated with 6 different attributes including occlusion, illumination change, motion change, size change, camera motion and unassigned. The major difference between VOT2015 <ce:cross-ref id=""""crf0241"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> and OTB-100 <ce:cross-ref id=""""crf0242"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> is that the VOT2015 challenge provides a re-initialization protocol (i.e., trackers are reset with ground-truths in the middle of evaluation if tracking failures are observed). In this paper, we evaluate 15 deep-learning-based trackers and 7 baseline ones in terms of both accuracy and robustness (AR) rank and expected average overlap (EAO) metrics. It should be noted that the 15 trackers here are the same as trackers tested on OTB-100 and TC-128 except for MCPF <ce:cross-ref id=""""crf0243"""" refid=""""bib0085"""">[85][[ refid=''''bib0085'''' ]]</ce:cross-ref>, the code of which is packaged and cannot be changed. The AR rank is created by ranking the trackers over each sequence and averaging the rank lists according to the quantized accuracy and robustness. It does convert the accuracy and robustness to equal scales, thus, the averaged rank cannot be interpreted as a concrete tracking application result. To address this issue, the EAO <ce:cross-ref id=""""crf0244"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> rule is also introduced to rank different tracking algorithms. It estimates how accurate the estimated bounding box is after a certain number of frames are processed since initialization. <ce:cross-ref id=""""crf0245"""" refid=""""fig0009"""">Fig. 9</ce:cross-ref><ce:float-anchor refid=""""fig0009""""/> reports both accuracy-robust rank (AR) and expected accuracy overlap (EAO) plots of different trackers and <ce:cross-ref id=""""crf0246"""" refid=""""tbl0005"""">Table 5</ce:cross-ref> provides accuracy scores and failure times of different trackers for each individual attribute on the VOT2015 dataset.</ce:para>""''"'	cites	AGA	
cites	Deep visual tracking	K. Zhang, Q. Liu, Y. Wu, M. Yang, Robust visual tracking via convolutional networks without training , IEEE Trans. Image Process. , vol. 25 (2015), pp.1779-1792	http://dx.doi.org/10.1016/j.patcog.2017.11.007			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0082	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0054		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0146	'The CNT [82][[ refid=''bib0082'' ]] method propagates an input image forward in a CNN network to extract weak features, and then learns a classifier for distinguishing these features into positive and negative ones.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0025"""" view=""""all"""">Motivated by the success of deep features on image classification, many researchers attempt to exploit deep networks for feature extraction in designing a tracking method. This kind of algorithms can be mainly divided into two aspects: FEN-SL (using deep features from a single layer); and FEN-ML (using deep features from multiple layers). <ce:italic>FEN-SL:</ce:italic> The DLT <ce:cross-ref id=""""crf0172"""" refid=""""bib0080"""">[80][[ refid=''''bib0080'''' ]]</ce:cross-ref>, Trans-DLT <ce:cross-ref id=""""crf0173"""" refid=""""bib0083"""">[83][[ refid=''''bib0083'''' ]]</ce:cross-ref> and CNN-SVM <ce:cross-ref id=""""crf0174"""" refid=""""bib0095"""">[95][[ refid=''''bib0095'''' ]]</ce:cross-ref> methods design deep networks for feature extraction and adopt the outputs of the networks as object features. The CNT <ce:cross-ref id=""""crf0175"""" refid=""""bib0082"""">[82][[ refid=''''bib0082'''' ]]</ce:cross-ref> method propagates an input image forward in a CNN network to extract weak features, and then learns a classifier for distinguishing these features into positive and negative ones. The DeepSRDCF <ce:cross-ref id=""""crf0176"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> method extracts features from the first layers of the VGG network, and combines deep features with the SRDCF framework to improve the tracking performance. The RPNT <ce:cross-ref id=""""crf0177"""" refid=""""bib0076"""">[76][[ refid=''''bib0076'''' ]]</ce:cross-ref> method utilizes a network similar with Faster R-CNN to draw proposals and extracts the image features using the outputs of last convolutional layers of Faster R-CNN. The RTT <ce:cross-ref id=""""crf0178"""" refid=""""bib0077"""">[77][[ refid=''''bib0077'''' ]]</ce:cross-ref> method applies RNN to get a saliency map of the search region, which helps the correlation filter to reduce the interference of background.</ce:para>""''"'	cites	AGA	
cites	Deep visual tracking	D. Gordon, A. Farhadi, D. Fox, Re3 : real-time recurrent regression networks for object tracking , Clin. Orthopaedics Related Res. (2017)	http://dx.doi.org/10.1016/j.patcog.2017.11.007			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0079	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0047		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0161	'Daniel et al. [79][[ refid=''bib0079'' ]] use a two-path network followed by two LSTM blocks to remember the object appearance and motion.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0022"""" view=""""all"""">The recurrent neural network (RNN) model is suitable for sequence modeling since its neuron’s output can be directly applied to itself in the next time. Motivated by some research works on handwriting recognition <ce:cross-refs id=""""crfs0018"""" refid=""""bib0103 bib0104"""">[103,104][[ refid=''''bib0103 bib0104'''' ]]</ce:cross-refs> or speech recognition <ce:cross-refs id=""""crfs0019"""" refid=""""bib0015 bib0016"""">[15,16][[ refid=''''bib0015 bib0016'''' ]]</ce:cross-refs>, some attempts have been done to exploit semantic information among spatial configurations and temporal association among frames in visual tracking. Cui et al. <ce:cross-ref id=""""crf0160"""" refid=""""bib0077"""">[77][[ refid=''''bib0077'''' ]]</ce:cross-ref> propose a RNN-based method to produce a confidence map and apply it to correlation filter. The RNN model is trained from four different directions, which makes the appearance model robust to partial occlusion. Fan et al. <ce:cross-ref id=""""crf0161"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> adopt a RNN model similar with the RTT <ce:cross-ref id=""""crf0162"""" refid=""""bib0077"""">[77][[ refid=''''bib0077'''' ]]</ce:cross-ref> method, in which the features produced by RNN are added into a CNN network to get a robust feature representation. The above-mentioned two papers mainly focus on establishing spatial relationship among different image parts using the RNN model. Besides, there exist some attempts to construct temporal correlation with RNN. Ning et al. <ce:cross-ref id=""""crf0163"""" refid=""""bib0075"""">[75][[ refid=''''bib0075'''' ]]</ce:cross-ref> investigate the regression capability of long short-term memory (LSTM) in the temporal domain, and propose to concatenate high-level visual features produced by convolutional networks with region information. Gan et al. <ce:cross-ref id=""""crf0164"""" refid=""""bib0078"""">[78][[ refid=''''bib0078'''' ]]</ce:cross-ref> feed the feature vector of the input frame into a recurrent neural network. The recurrent neural network effectively updates its internal memory vector based on the previous memory vector, previous location of an object and the current frame. Daniel et al. <ce:cross-ref id=""""crf0165"""" refid=""""bib0079"""">[79][[ refid=''''bib0079'''' ]]</ce:cross-ref> use a two-path network followed by two LSTM blocks to remember the object appearance and motion.</ce:para>""''"'	cites	AGA	
cites	Deep visual tracking	Q. Wang, J. Gao, J. Xing, M. Zhang, W. Hu, Dcfnet: discriminant correlation filters network for visual tracking , Clin. Orthopaedics Related Res. (2017)	http://dx.doi.org/10.1016/j.patcog.2017.11.007			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0093	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0041		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0163	'Similar idea can also be found in [93][[ refid=''bib0093'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0021"""" view=""""all""""><ce:bold>CNN-M:</ce:bold> Different from the CNN-C-based trackers, the CNN-M ones use convolutional neural networks to learn effective matching functions. In <ce:cross-ref id=""""crf0154"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>, Tao et al. propose a siamese network model to match the object template and candidates for visual tracking, in which the optimal state can be determined based on the highest matching score. After that, Bertinetto et al. <ce:cross-ref id=""""crf0155"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> develop a fully connected siamese network to match the object template and current search region in a convolutional manner, shown as <ce:cross-ref id=""""crf0156"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref><ce:float-anchor refid=""""fig0004""""/>. Besides, Chen et al. <ce:cross-ref id=""""crf0157"""" refid=""""bib0089"""">[89][[ refid=''''bib0089'''' ]]</ce:cross-ref> present a more generic approach utilizing a novel two-flow convolutional neural network to include two inputs (one is the object image patch, another is the search region patch) and produce a response map that predicts how likely the object appears in a specific location. <ce:cross-refs id=""""crfs0017"""" refid=""""bib0079 bib0094 bib0100"""">[79,94,100][[ refid=''''bib0079 bib0094 bib0100'''' ]]</ce:cross-refs> also use two-path network to evaluate the object location. Recently, some trackers apply the satisfactory performance of correlation filter to deep neural network. Valmadre et al. <ce:cross-ref id=""""crf0158"""" refid=""""bib0088"""">[88][[ refid=''''bib0088'''' ]]</ce:cross-ref> interpret correlation filter as a differentiable layer in a siamese network. A closed-form solution via the fourier domain ensures the network being trained end to end. Similar idea can also be found in <ce:cross-ref id=""""crf0159"""" refid=""""bib0093"""">[93][[ refid=''''bib0093'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Deep visual tracking	N. Wang, S. Li, A. Gupta, D. Yeung, Transferring rich feature hierarchies for robust visual tracking , Clin. Orthopaedics Related Res. (2015)	http://dx.doi.org/10.1016/j.patcog.2017.11.007			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0074	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0070		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0177	'The SO-DLT [74][[ refid=''bib0074'' ]] method first pre-trains a CNN model to recognize what is an object and then generates a probability map instead of producing a simple class label.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0029"""" view=""""all""""><ce:bold>EEN-M:</ce:bold> This kind of trackers usually exploits deep networks to generate a confidence map (or probability map, response map, heat map) and then uses other methods to localize the tracked object. In <ce:cross-ref id=""""crf0191"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref>, two deep networks are designed with the Conv4-3 and Conv5-3 layers of the VGG-16 model and then used to calculate the response maps. In <ce:cross-ref id=""""crf0192"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, the last convolutional layers are jointly combined to produce the final heat map. The SO-DLT <ce:cross-ref id=""""crf0193"""" refid=""""bib0074"""">[74][[ refid=''''bib0074'''' ]]</ce:cross-ref> method first pre-trains a CNN model to recognize what is an object and then generates a probability map instead of producing a simple class label. The SiameFC <ce:cross-ref id=""""crf0194"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> tracker utilizes a pre-trained fully convolutional siamese network, the inputs of which are the object template and current search region (<ce:cross-ref id=""""crf0195"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref>). In each frame, this method generates a response map regarding the tracked object with convolution operation. The similar structure is also adopted in the YCNN <ce:cross-ref id=""""crf0196"""" refid=""""bib0089"""">[89][[ refid=''''bib0089'''' ]]</ce:cross-ref> method.</ce:para>""''"'	cites	AGA	
cites	Deep visual tracking	K. Zhang, Q. Liu, Y. Wu, M. Yang, Robust visual tracking via convolutional networks without training , IEEE Trans. Image Process. , vol. 25 (2015), pp.1779-1792	http://dx.doi.org/10.1016/j.patcog.2017.11.007			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0082	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0075		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0183	'The CNT [82][[ refid=''bib0082'' ]] method collects a series of positive and negative patches to learn many image filters, and builds a robust appearance model using convolutional operators.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0032"""" view=""""all""""><ce:bold>NP-OL:</ce:bold> For exploiting deep learning to solve the tracking problem, an intuitive idea is to replace traditional appearance model with some deep networks (such as CNN). Li et al. <ce:cross-ref id=""""crf0199"""" refid=""""bib0091"""">[91][[ refid=''''bib0091'''' ]]</ce:cross-ref> present a deep-learning-based tracker with a CNNs pool, where each CNN is set up to obtain the scores of different particles in every frame. The CNT <ce:cross-ref id=""""crf0200"""" refid=""""bib0082"""">[82][[ refid=''''bib0082'''' ]]</ce:cross-ref> method collects a series of positive and negative patches to learn many image filters, and builds a robust appearance model using convolutional operators. These trackers can merely use a small number of layers to design the appearance model due to the limit of training data.</ce:para>""''"'	cites	AGA	
cites	Deep visual tracking	K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale image recognition , Clin. Orthopaedics Related Res. (2014)	http://dx.doi.org/10.1016/j.patcog.2017.11.007			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0064	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0076		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0186	'The well-known VGGNet [64][[ refid=''bib0064'' ]] (offline trained on the large-scale ImageNet dataset) is widely used to design the tracking methods because of their satisfactory performance on image classification.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0033"""" view=""""all""""><ce:italic>IP-NOL:</ce:italic> The lack of labeled data in online learning limits the performance of deep networks. Thus, it is reasonable to transfer the visual prior using existing networks pre-trained by massive natural images. The well-known VGGNet <ce:cross-ref id=""""crf0201"""" refid=""""bib0064"""">[64][[ refid=''''bib0064'''' ]]</ce:cross-ref> (offline trained on the large-scale ImageNet dataset) is widely used to design the tracking methods because of their satisfactory performance on image classification. In <ce:cross-ref id=""""crf0202"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref>, Danelljan et al. improve the SRDCF tracker by adopting the outputs of the VGGNet’s first convolutional layer as object features. To further exploit the abundant information within the VGGNet model, many research works <ce:cross-refs id=""""crfs0023"""" refid=""""bib0024 bib0030 bib0031"""">[24,30,31][[ refid=''''bib0024 bib0030 bib0031'''' ]]</ce:cross-refs> combine multi-level features from different convolutional layers to develop effective appearance models.</ce:para>""''"'	uses_data_from	AGA	
cites	Deep visual tracking	R. Tao, E. Gavves, A.W.M. Smeulders, Siamese instance search for tracking , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2016)	http://dx.doi.org/10.1016/j.patcog.2017.11.007			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0022	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0066		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0199	'In [22][[ refid=''bib0022'' ]], the SINT method generates a lot of particles and calculates their similarity scores using the siamese network.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0028"""" view=""""all""""><ce:bold>EEN-S:</ce:bold> This kind of methods (<ce:cross-refs id=""""crfs0021"""" refid=""""bib0020 bib0022 bib0026 bib0028 bib0075 bib0080 bib0091"""">[20,22,26,28,75,80,91][[ refid=''''bib0020 bib0022 bib0026 bib0028 bib0075 bib0080 bib0091'''' ]]</ce:cross-refs>) generates a series of candidates using particle filter or sliding window schemes, and then produces the scores of these candidates for localizing the tracked object. The DeepTrack <ce:cross-ref id=""""crf0188"""" refid=""""bib0091"""">[91][[ refid=''''bib0091'''' ]]</ce:cross-ref> method samples a set of candidates with a sliding window, and evaluates the likelihoods of these candidates using a CNN model designed by multiple convolutional layers and a joint learned fully-connected layer. In <ce:cross-ref id=""""crf0189"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>, the SINT method generates a lot of particles and calculates their similarity scores using the siamese network. The optimal state can be determined by the particle with the highest score. In addition to outputting score, the ADNet <ce:cross-ref id=""""crf0190"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> uses a network to output an action by reinforcement learning, which will guide the bounding box to object.</ce:para>""''"'	cites	AGA	
cites	Deep visual tracking	Y. Qi, S. Zhang, L. Qin, H. Yao, Q. Huang, J. Lim, M. Yang, Hedged deep tracking , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2016)	http://dx.doi.org/10.1016/j.patcog.2017.11.007			http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0031	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0060		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0212	'Qi et al. [31][[ refid=''bib0031'' ]] extract features from six convolutional layers and combine these layers using an adaptive weight scheme.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0026"""" view=""""all""""><ce:bold>FEN-ML:</ce:bold> Different layers of a deep network could provide multi-level feature description. Thus, it is reasonable to exploit multiple layers for feature extraction in developing a robust tracker. Ma et al. <ce:cross-ref id=""""crf0179"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> observe that different convolutional layers of a typical CNN model provide multiple levels of abstraction in the feature hierarchies. Features in earlier layers retain higher spatial resolution for precise localization with low-level visual information. While features in latter layers capture more semantic information and less fine-grained spatial details. Thus, they extract features from three different layers and use a fix weight to combine the feature maps generated by those layers, shown as <ce:cross-ref id=""""crf0180"""" refid=""""fig0003"""">Fig. 3</ce:cross-ref>. The results have demonstrated that the features extracted from multiple layers perform better than the features from a single layer for developing a robust tracking method. After that, Ma et al. <ce:cross-ref id=""""crf0181"""" refid=""""bib0097"""">[97][[ refid=''''bib0097'''' ]]</ce:cross-ref> use a designed network to replace the Conv3-3 layer in <ce:cross-ref id=""""crf0182"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> and therefore improve the tracking performance. Qi et al. <ce:cross-ref id=""""crf0183"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> extract features from six convolutional layers and combine these layers using an adaptive weight scheme. The RTT <ce:cross-ref id=""""crf0184"""" refid=""""bib0077"""">[77][[ refid=''''bib0077'''' ]]</ce:cross-ref> method uses a combination of four output maps of the deep network trained from four different directions. In addition, the C-COT <ce:cross-ref id=""""crf0185"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref> algorithm proposes a joint learning framework to fuse deep features from different spatial pyramids. Based on C-COT <ce:cross-ref id=""""crf0186"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, Martin et al. <ce:cross-ref id=""""crf0187"""" refid=""""bib0086"""">[86][[ refid=''''bib0086'''' ]]</ce:cross-ref> aim to combine hand-crafted features with deep features and reduce the algorithm redundancy.</ce:para>""''"'	cites	AGA	
cites	Background and related work	N. Wang, J. Shi, D. Yeung, J. Jia, Understanding and diagnosing visual tracking systems , Proceedings of the IEEE International Conference on Computer Vision (2015)	http://dx.doi.org/10.1016/j.patcog.2017.11.007	related work	background	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/br/bib0036	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/ctx/ctx0015		107	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-11-007/itrp/0252	'In [36][[ refid=''bib0036'' ]], Wang et al. demonstrate that feature extraction is also a very important issue in designing a robust tracker (such as the tracker with HOG features performs much better than that with Haar-like features).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">From the perspective of the observation model, the existing trackers usually can be categorized into either generative (e.g., <ce:cross-refs id=""""crfs0005"""" refid=""""bib0001 bib0037 bib0038 bib0039 bib0040"""">[1,37–40][[ refid=''''bib0001 bib0037 bib0038 bib0039 bib0040'''' ]]</ce:cross-refs>) or discriminative (e.g., <ce:cross-refs id=""""crfs0006"""" refid=""""bib0003 bib0007 bib0041 bib0042 bib0043 bib0044 bib0045 bib0046"""">[3,7,41–46][[ refid=''''bib0003 bib0007 bib0041 bib0042 bib0043 bib0044 bib0045 bib0046'''' ]]</ce:cross-refs>) methods. Generative methods focus on searching for the regions that are the most similar to the tracked object, including template-based <ce:cross-refs id=""""crfs0007"""" refid=""""bib0032 bib0038 bib0047"""">[32,38,47][[ refid=''''bib0032 bib0038 bib0047'''' ]]</ce:cross-refs>, subspace-based <ce:cross-ref id=""""crf0122"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>, sparse representation <ce:cross-refs id=""""crfs0008"""" refid=""""bib0048 bib0049"""">[48,49][[ refid=''''bib0048 bib0049'''' ]]</ce:cross-refs>, to name a few. While discriminative trackers usually consider tracking as a classification problem that distinguishes the tracked objects from its local surrounding backgrounds. Several classic machine learning techniques have been attempted to solve the tracking problem, such as boosting <ce:cross-refs id=""""crfs0009"""" refid=""""bib0050 bib0051"""">[50,51][[ refid=''''bib0050 bib0051'''' ]]</ce:cross-refs>, support vector machine <ce:cross-ref id=""""crf0123"""" refid=""""bib0052"""">[52][[ refid=''''bib0052'''' ]]</ce:cross-ref>, naive bayes <ce:cross-ref id=""""crf0124"""" refid=""""bib0042"""">[42][[ refid=''''bib0042'''' ]]</ce:cross-ref>, random forest <ce:cross-ref id=""""crf0125"""" refid=""""bib0053"""">[53][[ refid=''''bib0053'''' ]]</ce:cross-ref>, multiple instance learning <ce:cross-ref id=""""crf0126"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>, metric learning <ce:cross-ref id=""""crf0127"""" refid=""""bib0054"""">[54][[ refid=''''bib0054'''' ]]</ce:cross-ref>, structured learning <ce:cross-ref id=""""crf0128"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>, latent variable learning <ce:cross-ref id=""""crf0129"""" refid=""""bib0055"""">[55][[ refid=''''bib0055'''' ]]</ce:cross-ref>, correlation filter <ce:cross-ref id=""""crf0130"""" refid=""""bib0044"""">[44][[ refid=''''bib0044'''' ]]</ce:cross-ref> and so on. In <ce:cross-ref id=""""crf0131"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref>, Wang et al. demonstrate that feature extraction is also a very important issue in designing a robust tracker (such as the tracker with HOG features performs much better than that with Haar-like features). From the research experiences of the traditional tracking algorithms, we can conclude that any progress of feature extraction methods or machine learning techniques may facilitate developing the tracking method. Thus, we believe that the usage of deep learning could improve the tracking performance since the deep learning techniques have been shown powerful abilities on feature extraction and object classification.</ce:para>""''"'	cites	AGA	
cites_as_review	Related work	C. Li, , Content-Based Microscopic Image Analysis, Logos Verlag Berlin GmbH (2016)	http://dx.doi.org/10.1016/j.patcog.2017.12.021	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-021/br/bib0015	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-021/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-021/ctx/ctx0013	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-021/itrpl/bib0015-bib0016-ctx0013	58	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-021/itrp/0062	'Please refer to [15,16][[ refid=''bib0015 bib0016'' ]] for more detailed survey of each selected work.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all"""">Because microorganisms are widely explored in many production and research activities, they are grouped based on their application domains <ce:cross-ref id=""""crf0025"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref>, including agricultural microorganisms, food microorganisms, EMs, <ce:italic>etc</ce:italic>. In this section, selected works about microorganism classification using image analysis techniques are summarized. Please refer to <ce:cross-refs id=""""crfs0011"""" refid=""""bib0015 bib0016"""">[15,16][[ refid=''''bib0015 bib0016'''' ]]</ce:cross-refs> for more detailed survey of each selected work.</ce:para>""''"'	cites_as_review	ANG	
cites_as_review	Introduction	V.Y. Kulkarni, P.K. Sinha, Random forest classifiers: a survey and future research directions , Int. J. Adv. Comput. , vol. 36 (2013), pp.1144-1153	http://dx.doi.org/10.1016/j.patcog.2017.12.021	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-021/br/bib0013	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-021/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-021/ctx/ctx0011		58	5	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-021/itrp/0065	'According to [13][[ refid=''bib0013'' ]], RF are among the most accurate individual classification techniques.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">To jointly solve the problems above, we propose an EM classification model which incorporates pixel-level features and auxiliary global features into a CRF framework. As shown in <ce:cross-ref id=""""crf0020"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref><ce:float-anchor refid=""""fig0001""""/>, first we re-purpose one of the most successful DCNNs, called VGG-16 <ce:cross-ref id=""""crf0021"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>, which has been trained on 1.3 million images in ImageNet dataset <ce:cross-ref id=""""crf0022"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>, and fine-tune it using training EM images. For an image, feature maps output by the second last layer of the re-purposed VGG-16 are used to generate pixel-level features. We also extract global features from the image. Then extracted features together with the ground truth data are used to train <ce:italic>Random Forest</ce:italic> (RF) <ce:cross-ref id=""""crf0023"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> classifiers by analyzing pixel-level and global features in training images. According to <ce:cross-ref id=""""crf0024"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>, RF are among the most accurate individual classification techniques. The trained RF classifiers are used as the unary potentials by the CRF model. Finally, together with the pairwise potentials, the CRF model is applied to localize and label into the classes the objects of interest in the test EM images.</ce:para>""''"'	cites	ANG	
cites_as_review	Introduction	A. Kumar, J. Kim, W. Cai, M. Fulham, D. Feng, Content-based medical image retrieval: a survey of applications to multidimensional and multimodality data , J. Digital Imaging , vol. 26 (2013), pp.1025-1039	http://dx.doi.org/10.1016/j.patcog.2017.12.022	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-022/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-022/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-022/ctx/ctx0008		45	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-022/itrp/0012	'The grey-level distribution represented as a histogram [10][[ refid=''bib0010'' ]] has been effectively used to characterize intensity variations.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0010"""" view=""""all"""">Compared with processing original CT images, the other straightforward way is to design features that can best describe the characteristics of nodules. The grey-level distribution represented as a histogram <ce:cross-ref id=""""crf0016"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref> has been effectively used to characterize intensity variations.</ce:para>""''"'	cites	ANG	
cites_as_review	Introduction	S.S. Parveen, C. Kavitha, A review on computer aided detection and diagnosis of lung cancer nodules , Int. J. Comput. Technol. , vol. 3 (2012), pp.None	http://dx.doi.org/10.1016/j.patcog.2017.12.022	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-022/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-022/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-022/ctx/ctx0019		45	4	http://www.scar.disi.unibo.it/r/10-1016-j-patcog-2017-12-022/itrp/0037	'Parveen et al. [23][[ refid=''bib0023'' ]] have conducted reviews on computer aided detection and diagnosis methods for lung cancer nodules including both classical and modern methods for preprocessing, segmentation and classification, showing the high efficiency of artificial neural network based methods.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">Recently, inspired by a large amount of available data and more powerful computational resources, especially parallelization ability empowered by Graphic Processing Units (GPUs), convolutional neural networks (CNNs) <ce:cross-ref id=""""crf0026"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> have shown their abilities of outperforming the state-of-the-art in classical computer vision applications <ce:cross-ref id=""""crf0027"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, as well as in the field of medical image analysis <ce:cross-ref id=""""crf0028"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>. Parveen et al. <ce:cross-ref id=""""crf0029"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> have conducted reviews on computer aided detection and diagnosis methods for lung cancer nodules including both classical and modern methods for preprocessing, segmentation and classification, showing the high efficiency of artificial neural network based methods. In <ce:cross-ref id=""""crf0030"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>, they investigate more details on deep learning techniques including Deep Belief Network (DBN) and CNNs for classification of lung nodules. Their experiments and results have shown that deep learning framework can outperform the conventional feature computing CADe methods. Shin et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> have deployed researches on different CNNs architectures, different data sets on two specific CADe problems including thoraco-abdominal lymph node detection and interstitial lung disease classification, indicating the high potentials of CNNs in CADe field. Meanwhile, since CNNs can be trained end-to-end with the layers automatically learning discriminative features without handcrafting design, they are very suitable for lung nodule type classification considering the complex intensity and surrounding anatomical structure distributions. Lo et al. <ce:cross-ref id=""""crf0032"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> proposed the CNNs based method for pulmonary nodule detection in chest radiology images. Arnaud et al. <ce:cross-ref id=""""crf0033"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> have used the multi-view CNNs for pulmonary nodule false positive reduction in CT images, with a complete performance discussion over different fusion methods <ce:cross-ref id=""""crf0034"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. Cao et al. <ce:cross-ref id=""""crf0035"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> have proposed a multi-kernel based framework for feature selection and imbalanced data learning, using multiple kernel learning, multi-kernel feature selection and multi-kernel over-sampling. A few other studies have also extended the use of 2D CNNs to 3D volumetric analysis on 3D images, i.e., CT images. In all of these methods, volumetric images are projected to fixed views (planes), followed by that each view is processed under 2D CNNs and finally integrated under a multi-view fashion with the best fusion methods. Li et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref> have applied deep CNNs for nodule classification, which achieve better feature representations for solid, semisolid and GGO nodules. Lin et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> have proposed a set of fractal features based on fractional Brownian motion model to distinguish nodule malignancy instead of classical CT attenuation values. Experiments on 107 CT data have shown that their method achieve promising results in accuracy, sensitivity, etc. Liu et al. <ce:cross-ref id=""""crf0038"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> have adopted multi-view CNNs with two convolutional, two pooling and one fully connected layers for binary and ternary nodule classification. Shen et al. <ce:cross-ref id=""""crf0039"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> have proposed an end-to-end Multi-crop Convolutional Neural Network to automatically extract salient nodule information from raw CT images with multi-cropped regions and max-pooling operations to unify outputs of all regions, which can predict not only nodule malignancy but also nodule semantic attributes. Jiang et al. <ce:cross-ref id=""""crf0040"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> cut multi-group patches from original images, followed by Frangi filter enhancement to generate feedings for a four-channel CNNs. They acquire a relative low false positive rate at high sensitivity. Christodoulidis et al. <ce:cross-ref id=""""crf0041"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref> have proposed an improved method for lung pattern analysis by transferring knowledge from the similar domain of general texture classification. Anthimopoulos et al. <ce:cross-ref id=""""crf0042"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref> have applied deep CNNs to classify healthy, ground glass opacity (GGO), micro-nodules, consolidation, reticulation, honeycombing and a combination of GGO/reticulation nodules for interstitial lung diseases diagnosis. Their method has achieved 85.5% accuracy and demonstrating the potentials of CNNS in analyzing lung patterns. Chen et al. <ce:cross-ref id=""""crf0043"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref> exploit three multi-task learning schemes including stacked denoising autoencoder, CNNs and hand-crafted Haar-like and HoG features, to obtain semantic feature descriptions for lung nodules in CT images. Their method may provide quantitative assessments of nodule for better diagnosis.</ce:para>""''"'	cites	ANG	
uses_method_in	Experiments	G. Tzanetakis, P. Cook, Musical genre classification of audio signals , IEEE Transactions on Speech and Audio Processing , vol. 10 (2002), pp.293-302	http://dx.doi.org/10.1016/j.patrec.2013.05.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-05-012/br/b0090	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-05-012/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-05-012/ctx/ctx0026		31	6	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-05-012/itrp/0009	'Regarding the music genre dataset, we used Marsyas,8 a standard music information retrieval tool, to extract a collection of commonly used features in this kind of tasks (Tzanetakis and Cook, 2002[[ refid=''b0090'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0245"""" view=""""all"""">Regarding the music genre dataset, we used Marsyas,<ce:cross-ref id=""""c0210"""" refid=""""fn8""""><ce:sup loc=""""post"""">8</ce:sup></ce:cross-ref> a standard music information retrieval tool, to extract a collection of commonly used features in this kind of tasks (<ce:cross-ref id=""""c0095"""" refid=""""b0090"""">Tzanetakis and Cook, 2002[[ refid=''''b0090'''' ]]</ce:cross-ref>). These include means and variances of timbral features, time-domain Zero-Crossings, Spectral Centroid, Rolloff, Flux and Mel-Frequency Cepstral Coefficients (MFCC) over a texture window of 1<ce:hsp sp=""""0.25""""/>s. A total of 124 features were extracted. The details on these features fall out of the scope of this article. The interested reader is redirected to the appropriate literature (e.g. <ce:cross-refs id=""""r0055"""" refid=""""b0005 b0090"""">Aucouturier and Pachet, 2003; Tzanetakis and Cook, 2002[[ refid=''''b0005 b0090'''' ]]</ce:cross-refs>).</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experiments	Z. Cataltepe, A. Sonmez, K. Baglioglu, A. Erzan, Collective classification using heterogeneous classifiers , Machine Learning and Data Mining in Pattern Recognition (MLDM), Springer (2011)	http://dx.doi.org/10.1016/j.patrec.2013.07.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-07-009/br/b0015	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-07-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-07-009/ctx/ctx0051		52	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-07-009/itrp/0059	'We used the same dataset produced with ms=32 as in Cataltepe et al. (2011)[[ refid=''b0015'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0320"""" view=""""all"""">In this section, we report experiments using enriched features on a synthetic networked dataset. In order to create synthetic networked data, we used a method that allows varying content and link relevances with the class label and varying dependence (redundancy) between content and link. As in the “content based” networks of <ce:cross-ref id=""""c0245"""" refid=""""b0005"""">Balcan and Erzan. (2004)[[ refid=''''b0005'''' ]]</ce:cross-ref>, we generated content and link bits, and based on their link similarity we connected the nodes in the network. Content features <mml:math altimg=""""si150.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo stretchy=""""false"""">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy=""""false"""">)</mml:mo></mml:mrow></mml:math> are produced for each node <ce:italic>u</ce:italic>. In order to produce links between nodes, a similarity measure between them is needed. We used an integer power of inverse normalized hamming distance as the similarity measure. Class labels are determined according to the mode of the complete feature vector. We used the same dataset produced with <mml:math altimg=""""si151.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi mathvariant=""""italic"""">ms</mml:mi><mml:mo>=</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:math> as in <ce:cross-ref id=""""c0250"""" refid=""""b0015"""">Cataltepe et al. (2011)[[ refid=''''b0015'''' ]]</ce:cross-ref>. Please see <ce:cross-ref id=""""c0255"""" refid=""""b0015"""">Cataltepe et al. (2011)[[ refid=''''b0015'''' ]]</ce:cross-ref> for more details.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experiments	P. Sen, G.M. Namata, M. Bilgic, L. Getoor, B. Gallagher, T. Eliassi-Rad, Collective classification in network data , Artif. Intell. Mag. , vol. 29 (2008), pp.93-106	http://dx.doi.org/10.1016/j.patrec.2013.07.009	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-07-009/br/b0120	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-07-009/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-07-009/ctx/ctx0044		52	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-07-009/itrp/0074	'The WebKB (Sen et al., 2008[[ refid=''b0120'' ]]) dataset consists of web pages from different classes.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0245"""" view=""""all"""">In our experiments, we use real datasets that have been used in Collective Classification literature (<ce:cross-ref id=""""c0200"""" refid=""""b0120"""">Sen et al., 2008[[ refid=''''b0120'''' ]]</ce:cross-ref>), and a synthetic dataset from <ce:cross-ref id=""""c0205"""" refid=""""b0015"""">Cataltepe et al. (2011)[[ refid=''''b0015'''' ]]</ce:cross-ref>. The first two datasets, Cora and CiteSeer, are scientific citation datasets. Nodes are articles. There is a link between two nodes if one article cites the other one. The WebKB (<ce:cross-ref id=""""c0210"""" refid=""""b0120"""">Sen et al., 2008[[ refid=''''b0120'''' ]]</ce:cross-ref>) dataset consists of web pages from different classes. Two nodes are linked if there is a hyperlink between the corresponding web pages. For all datasets, links are undirected. All datasets have binary content features which show whether words from a dictionary exist in the article/webpage.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experimental results	Liu, J. Luo, J., Shah, M. 2009. Recognizing realistic actions from videos in the wild, IEEE CVPR.	http://dx.doi.org/10.1016/j.patrec.2013.08.008	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-08-008/br/b0050	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-08-008/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-08-008/ctx/ctx0026		37	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-08-008/itrp/0007	'The UCF11 dataset (Liu and Luo, 2009[[ refid=''b0050'' ]]) consists in 11 action categories: basketball shooting, biking/cycling, diving, golf swinging, horse back riding, soccer juggling, swinging, tennis swinging, trampoline jumping, volleyball spiking, and walking with a dog.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0190"""" view=""""all"""">The UCF11 dataset (<ce:cross-ref id=""""c0150"""" refid=""""b0050"""">Liu and Luo, 2009[[ refid=''''b0050'''' ]]</ce:cross-ref>) consists in 11 action categories: basketball shooting, biking/cycling, diving, golf swinging, horse back riding, soccer juggling, swinging, tennis swinging, trampoline jumping, volleyball spiking, and walking with a dog. We use the same evaluation protocol of the original paper (<ce:cross-ref id=""""c0155"""" refid=""""b0050"""">Liu and Luo, 2009[[ refid=''''b0050'''' ]]</ce:cross-ref>).</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Method	Benfold, I.R.B., 2011. Stable multi-target tracking in real-time surveillance video.	http://dx.doi.org/10.1016/j.patrec.2013.11.018	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-11-018/br/b0005	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-11-018/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-11-018/ctx/ctx0019		24	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2013-11-018/itrp/0018	'for the second dataset, the Oxford data, we use the published tracking results provided by Benfold (Benfold and Video, 2011[[ refid=''b0005'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0020"""" view=""""all"""">The extraction of pedestrian trajectories from surveillance video is non-trivial, particularly when there is occlusion and crowding. It is not our goal to develop a novel low level feature extractor and for that reason we rely upon the large amount of research in computer vision already devoted to producing tracking solutions. Extracting pedestrian trajectories requires two main stages: detection of pedestrians, and tracking of targeted pedestrians. Detection is achieved using the Felzenszwalb part based detector (<ce:cross-ref id=""""c0080"""" refid=""""b0025"""">Felzenszwalb et al., 2010[[ refid=''''b0025'''' ]]</ce:cross-ref>). Tracking of human targets in the image plane is achieved with the use of the Predator TLD tracker (<ce:cross-ref id=""""c0085"""" refid=""""b0040"""">Kalal and Matas, 2009[[ refid=''''b0040'''' ]]</ce:cross-ref>). We track the heads of pedestrians in the crowded PETS-2007 scene, see <ce:cross-ref id=""""c0120"""" refid=""""f0005"""">Fig. 1</ce:cross-ref><ce:float-anchor refid=""""f0005""""/>(a). for the second dataset, the Oxford data, we use the published tracking results provided by Benfold (<ce:cross-ref id=""""c0090"""" refid=""""b0005"""">Benfold and Video, 2011[[ refid=''''b0005'''' ]]</ce:cross-ref>). We select the TLD tracker due to high performance amongst state of the art trackers (<ce:cross-ref id=""""c0095"""" refid=""""b0045"""">Kalal and Matas, 2010[[ refid=''''b0045'''' ]]</ce:cross-ref>) and utilise its capability to learn a target model and discriminate between potential targets in a crowded surveillance scene. The pedestrian tracking performance of the TLD tracker is extensively tested against alternative recent tracking procedures in the author’s paper (<ce:cross-ref id=""""c0100"""" refid=""""b0045"""">Kalal and Matas, 2010[[ refid=''''b0045'''' ]]</ce:cross-ref>).</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experimental results	S. Gould, R. Fulton, D. Koller, Decomposing a scene into geometric and semantically consistent regions, in: International Conference on Computer Vision, 2009.	http://dx.doi.org/10.1016/j.patrec.2014.01.003	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-01-003/br/b0060	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-01-003/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-01-003/ctx/ctx0023		31	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-01-003/itrp/0004	'It contains 715 images which contains 8 semantic class labels [12][[ refid=''b0060'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0165"""" view=""""all"""">It contains 715 images which contains 8 semantic class labels <ce:cross-ref refid=""""b0060"""" id=""""c0205"""">[12][[ refid=''''b0060'''' ]]</ce:cross-ref>. It is shown that in the retrieval step, in 90% of the images in the test set, all semantic labels in the test image are shown in the set of retrieved images.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experimental results	J. Xiao, J. Hays, K. Ehinger, A. Oliva, A. Torralba, SUN database: large-scale scene recognition from abbey to zoo, in: Computer Vision and Pattern Recognition, 2010.	http://dx.doi.org/10.1016/j.patrec.2014.01.003	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-01-003/br/b0195	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-01-003/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-01-003/ctx/ctx0027		31	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-01-003/itrp/0010	'This dataset contains 9556 images with 515 object categories [39][[ refid=''b0195'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0180"""" view=""""all"""">This dataset contains 9556 images with 515 object categories <ce:cross-ref refid=""""b0195"""" id=""""c0260"""">[39][[ refid=''''b0195'''' ]]</ce:cross-ref>. Images are split into 8556 training images and 1000 test images <ce:cross-ref refid=""""b0120"""" id=""""c0265"""">[24][[ refid=''''b0120'''' ]]</ce:cross-ref>. The obtained results on this dataset are shown in <ce:cross-ref refid=""""f0015"""" id=""""c0270"""">Fig. 3</ce:cross-ref>d. The SUN dataset is large and very challenging. It contains indoor and outdoor scene images. There are many small objects in indoor scenes which are not very discriminative. Small objects are segmented into small regions. Small regions do not contain reliable features, hence, they usually are not assigned to true semantic class labels. Our approach receives 44.05% when 40 training images per each test image are retrieved. In indoor scenes, usually large number of semantic classes exists. Hence, large number of training images should be retrieved to cover all of the semantic class labels that exist in the test image.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experimental results	CLEF, PAN Lab 2012 & 2013: Uncovering Plagiarism, Authorship, and Social Software Misuse, 2013.	http://dx.doi.org/10.1016/j.patrec.2014.01.019	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-01-019/br/b0055	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-01-019/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-01-019/ctx/ctx0025		32	3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-01-019/itrp/0011	'We tested our algorithm on datasets from the two most recent PAN [11][[ refid=''b0055'' ]] competitions, which provide benchmark datasets for authorship attribution.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0080"""" view=""""all"""">We tested our algorithm on datasets from the two most recent PAN <ce:cross-ref id=""""c0140"""" refid=""""b0055"""">[11][[ refid=''''b0055'''' ]]</ce:cross-ref> competitions, which provide benchmark datasets for authorship attribution. From PAN 2013 we selected the author identification task described in <ce:cross-ref id=""""c0145"""" refid=""""b0085"""">[17][[ refid=''''b0085'''' ]]</ce:cross-ref>. In this task 349 training texts are provided, divided in 85 problems out of which 30 are in English, 30 in Greek and 25 in Spanish. For each set of documents written by a single author it must be determined if a questioned document was written by the same author or not. Each text is approximately 1000 words long, which is close to our empirical estimation of the minimum size for FCD to find relevant patterns in a data instance (Section <ce:cross-ref id=""""c0220"""" refid=""""s0010"""">2</ce:cross-ref>). For each problem, we consider an unknown text to be written by the same author of a given set of documents if the average FCD distance to the latter is smaller than the mean distance from all documents of a given language. Compared to the performance of the 18 methods reported in <ce:cross-ref id=""""c0150"""" refid=""""b0085"""">[17][[ refid=''''b0085'''' ]]</ce:cross-ref>, the FCD finds the correct solution in <mml:math altimg=""""si44.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mn>72.9</mml:mn><mml:mo>%</mml:mo></mml:mrow></mml:math> of the cases and yields the second best results, ranking first for the set of English problems and fifth for both the Greek and Spanish sets (<ce:cross-ref id=""""c0225"""" refid=""""t0020"""">Table 4</ce:cross-ref><ce:float-anchor refid=""""t0020""""/>), outperforming among others two compression-based and several n-grams-based methods. It must be stressed that the FCD took approximately 38<ce:hsp sp=""""0.25""""/>s to process the whole dataset, while the imposters method by Seidman <ce:cross-ref id=""""c0155"""" refid=""""b0160"""">[32][[ refid=''''b0160'''' ]]</ce:cross-ref>, which ranked first in the competition for all problems excluded the ones in Spanish, took more than 18<ce:hsp sp=""""0.25""""/>h. Furthermore, the latter method requires the setting of a threshold, while the FCD skips this step. On the other hand, the contest participants had only a small subset of the available ground truth to test their algorithms.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experiments	S. Lazebnik, C. Schmid, J. Ponce, A sparse texture representation using local affine regions , IEEE Trans. Pattern Anal. Mach.Intell. , vol. 27 (2005), pp.1265-1278	http://dx.doi.org/10.1016/j.patrec.2014.04.002	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-04-002/br/b0205	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-04-002/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-04-002/ctx/ctx0044		51	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-04-002/itrp/0130	'The Lazebnik’s texture dataset [41][[ refid=''b0205'' ]] has 1000 images of 25 different textures.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0095"""" view=""""all"""">To evaluate the effectiveness of the proposed linear codebook transformation method, we conduct image classification performances on several public image datasets: the Bird dataset <ce:cross-ref id=""""c0200"""" refid=""""b0015"""">[3][[ refid=''''b0015'''' ]]</ce:cross-ref>, the Butterfly dataset <ce:cross-ref id=""""c0205"""" refid=""""b0020"""">[4][[ refid=''''b0020'''' ]]</ce:cross-ref>, the Scene-15 dataset<ce:cross-ref id=""""c0210"""" refid=""""b0025"""">[5][[ refid=''''b0025'''' ]]</ce:cross-ref>, the Event dataset <ce:cross-ref id=""""c0215"""" refid=""""b0030"""">[6][[ refid=''''b0030'''' ]]</ce:cross-ref>, the Indoor dataset <ce:cross-ref id=""""c0220"""" refid=""""b0035"""">[7][[ refid=''''b0035'''' ]]</ce:cross-ref>, the Corel-5K dataset <ce:cross-ref id=""""c0225"""" refid=""""b0040"""">[8][[ refid=''''b0040'''' ]]</ce:cross-ref>, the Caltech-256 dataset <ce:cross-ref id=""""c0230"""" refid=""""b0045"""">[9][[ refid=''''b0045'''' ]]</ce:cross-ref>, Lazebnik’s texture dataset <ce:cross-ref id=""""c0235"""" refid=""""b0205"""">[41][[ refid=''''b0205'''' ]]</ce:cross-ref> and the PASCAL VOC 2007 dataset <ce:cross-ref id=""""c0240"""" refid=""""b0210"""">[42][[ refid=''''b0210'''' ]]</ce:cross-ref>. The Bird dataset has 100 images each of six different classes (egrets, mandarin ducks, snowy owls, puffins, toucans, and wood ducks). The Butterfly dataset consists of 619 images of seven classes. The Scene-15 dataset has fifteen classes ranging from 200 to 400 images per class. The Event dataset has eight sports event categories with the number of images in each category varying from 137 to 250. The indoor dataset has 15,620 images of 67 classes. The Corel-5K dataset consists of 50 categories of images while the Caltech-256 dataset has 30,607 images of 256 classes. The Lazebnik’s texture dataset <ce:cross-ref id=""""c0245"""" refid=""""b0205"""">[41][[ refid=''''b0205'''' ]]</ce:cross-ref> has 1000 images of 25 different textures. The PASCAL VOC 2007 dataset has around 10,000 images of twenty classes which are more difficult to classify than the above datasets. <ce:cross-ref id=""""c0325"""" refid=""""f0010"""">Fig. 2</ce:cross-ref><ce:float-anchor refid=""""f0010""""/> shows some example images of these image datasets.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesDataFrom_semweb
uses_data_from	Experimental setup	T. Sim, S. Baker, M. Bsat, The CMU pose, illumination, and expression database , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 25 (2003), pp.1615-1618	http://dx.doi.org/10.1016/j.patrec.2014.08.012	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/br/bib0026>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/ctx/ctx0021>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/itrp/0006	'We also used the CMU-PIE database [26][[ refid=''bib0026'' ]], which includes 41,368 face images of 68 people captured under 13 poses, 43 illuminations conditions, and with four different expressions: neutral, smile, blinking, and talk.'				100_classified_usesDataFrom
uses_data_from	Experimental setup	A. Oliva, A. Torralba, Modeling the shape of the scene: a holistic representation of the spatial envelope , Int. J. Comput. Vis. , vol. 42 (2001), pp.145-175	http://dx.doi.org/10.1016/j.patrec.2014.08.012	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/br/bib0028>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/ctx/ctx0024>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/itrp/0009	'The first database contains eight scenes categories provided by Oliva and Torralba [28][[ refid=''bib0028'' ]]: mountain (274 images), coast (360 images), highway (260 images), street (292 images), insidecity (308 images), forest (328 images), opencountry (410 images), and tallbuilding (356 images), where the size of each image is 256 × 256.'				100_classified_usesDataFrom
uses_data_from	Experimental results	T. Sim, S. Baker, M. Bsat, The CMU pose, illumination, and expression database , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 25 (2003), pp.1615-1618	http://dx.doi.org/10.1016/j.patrec.2014.08.012	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/br/bib0026>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/ctx/ctx0038>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/itrp/0054	'In the CMU-PIE dataset [26][[ refid=''bib0026'' ]] we focused on a two class classification problem: smile and neutral.'				100_classified_usesDataFrom
uses_data_from	Experimental setup	M. Lyons, S. Akamatsu, M. Kamachi, J. Gyoba, Coding facial expressions with gabor wavelets , Proceedings of 1998 Third IEEE International Conference on Automatic Face and Gesture Recognition (1998)	http://dx.doi.org/10.1016/j.patrec.2014.08.012	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/br/bib0024>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/ctx/ctx0019>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2014-08-012/itrp/0055	'Additionally, we used the Japanese Female Facial Expression (JAFFE) database [24][[ refid=''bib0024'' ]], which contains only 213 images of female facial expression expressed by 10 subjects.'				100_classified_usesDataFrom
cites	Introduction	Y. Lu, M. Castellanos, U. Dayal, C. Zhai, Automatic construction of a context-aware sentiment lexicon: an optimization approach , Proceedings of the 20th International Conference on World Wide Web, ACM (2011)	http://dx.doi.org/10.1016/j.patrec.2015.01.004	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-01-004/br/bib0002>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-01-004/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-01-004/ctx/ctx0002>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-01-004/itrp/0012	'These domain-specific sentiment words turn out to be a key determinant in identifying a sentiment from the past experiments, i.e. Ref. [2][[ refid=''bib0002'' ]].'				100_classified_usesDataFrom
uses_data_from	Experiments	M. Everingham, L.V. Gool, C. Williams, J. Winn, A. Zisserman, , in: The PASCAL Visual Object Classes Challenge 2007 (VOC2007) Results (2007)	http://dx.doi.org/10.1016/j.patrec.2015.03.010	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-03-010/br/bib0013>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-03-010/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-03-010/ctx/ctx0025>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-03-010/itrp/0009	'The Pascal VOC 2007 [13][[ refid=''bib0013'' ]] contains around 10 K images depicting 20 different object categories.'				100_classified_usesDataFrom
uses_data_from	Experiments	B. Caputo, E. Hayman, P. Mallikarjuna, Class-specific material categorisation , ICCV (2005)	http://dx.doi.org/10.1016/j.patrec.2015.03.010	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-03-010/br/bib0008>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-03-010/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-03-010/ctx/ctx0028>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-03-010/itrp/0010	'The KTH-TIPS2-a dataset [8][[ refid=''bib0008'' ]] contains 4395 images of 11 different texture materials acquired under different scales, poses and illumination conditions.'				100_classified_usesDataFrom
uses_data_from	Experiments	K. Bache, M. Lichman, UCI Machine Learning Repository, 2013. URL:	http://dx.doi.org/10.1016/j.patrec.2015.04.008	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-04-008/br/bib0002>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-04-008/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-04-008/ctx/ctx0022>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-04-008/itrp/0001	'We process the Iris dataset taken from the UCI repository [2][[ refid=''bib0002'' ]].'				100_classified_usesDataFrom
uses_data_from	Experimental results	P.J. Phillips, P.J. Flynn, W.T. Scruggs, K.W. Bowyer, J. Chang, K. Hoffman, J. Marques, J. Min, W.J. Worek, Overview of the face recognition grand challenge , CVPR 1 (2005)	http://dx.doi.org/10.1016/j.patrec.2015.05.005	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/br/bib0040>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/ctx/ctx0048>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/itrp/0046	'For this end, we manually built a database from frontal portraits from FRGC 2.0 [40][[ refid=''bib0040'' ]] and from the web.'				100_classified_usesDataFrom
uses_data_from	Experimental results	P.J. Phillips, H. Moon, S.A. Rizvi, P.J. Rauss, The Feret evaluation methodology for face-recognition algorithms , IEEE Trans. Pattern Anal Mach. Intell. , vol. 22 (2000), pp.1090-1104	http://dx.doi.org/10.1016/j.patrec.2015.05.005	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/br/bib0041>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/ctx/ctx0034>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/itrp/0049	'• FERET: The database [41][[ refid=''bib0041'' ]] contains more than 3500 face images from women and men (with different races such as African, Asian and Caucasian) involving different expressions and illumination conditions.'				100_classified_usesDataFrom
uses_data_from	Experimental results	A. Martinez, R. Benavente, The AR face database , CVC Tech. Rep. , vol. 24 (June 1998), pp.8 , http://www.cat.uab.cat/Public/Publications/1998/MaB1998/CVCReport24.pdf	http://dx.doi.org/10.1016/j.patrec.2015.05.005	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/br/bib0034>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/ctx/ctx0032>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/itrp/0055	'• AR: The images of database ‘AR’ [34][[ refid=''bib0034'' ]] were taken from 100 subjects (50 women and 50 men) with different facial expressions, illumination conditions, and occlusions with sun glasses and scarf (we used the cropped version).'				100_classified_usesDataFrom
uses_data_from	Experimental results	A.C. Gallagher, T. Chen, Understanding images of groups of people , IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2009) (2009)	http://dx.doi.org/10.1016/j.patrec.2015.05.005	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/br/bib0017>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/ctx/ctx0045>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-005/itrp/0072	'• GROUPS: The database [17][[ refid=''bib0017'' ]] consists of 28,231 face images collected from Flickr images.'				100_classified_usesDataFrom
uses_data_from	Experimentation and results	E.M. Bowden, M. Jung-Beeman, Normative data for 144 compound remote associate problems , Behav. Res. Method Instrum. Comput. , vol. 35 (2003), pp.634-639	http://dx.doi.org/10.1016/j.patrec.2015.05.015	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-015/br/bib0010>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-015/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-015/ctx/ctx0031>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-05-015/itrp/0039	'For comparison of performance, the normative data from [10][[ refid=''bib0010'' ]] is used.'				100_classified_usesDataFrom
uses_data_from	Experiments	P. Lucey, J.F. Cohn, T. Kanade, J. Saragih, Z. Ambadar, I. Matthews, The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-specified expression, IEEE , Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on (2010)	http://dx.doi.org/10.1016/j.patrec.2015.06.007	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-06-007/br/bib0015>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-06-007/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-06-007/ctx/ctx0031>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-06-007/itrp/0031	'For testing the recognition of basic emotions we used the Cohn-Kanade + Extended Cohn-Kanade [15][[ refid=''bib0015'' ]] dataset (with 7 emotions).'				100_classified_usesDataFrom
uses_data_from	Experiments and analysis	M. Everingham, L. Van Gool, C.K. Williams, J. Winn, A. Zisserman, The pascal visual object classes (voc) challenge , Int. J. Comput. Vis. , vol. 88 (2010), pp.303-338	http://dx.doi.org/10.1016/j.patrec.2015.08.011	methods	discussion	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-08-011/br/bib0003>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-08-011/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-08-011/ctx/ctx0028>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-08-011/itrp/0012	'MSRC dataset and VOC2007 dataset [3][[ refid=''bib0003'' ]]: MSRC dataset contains 4,323 images with 18 classes which are standard images.'				100_classified_usesDataFrom
uses_data_from	Experimental results	W. Choi, Y.-W. Chao, C. Pantofaru, S. Savarese, Understanding indoor scenes using 3D geometric phrases , Proceedings of the 2013 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE (2013)	http://dx.doi.org/10.1016/j.patrec.2015.08.014	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-08-014/br/bib0004>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-08-014/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-08-014/ctx/ctx0036>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-08-014/itrp/0048	'Because the indoor-scene-object dataset [4][[ refid=''bib0004'' ]] already has the ground truth layout, semantic label, and detection except cuboid annotation, we generate our dataset from the dataset as follows to get the ground truth cuboid while avoiding manual annotation.'				100_classified_usesDataFrom
uses_data_from	Recognition tasks	K. Lai, L. Bo, X. Ren, D. Fox, A large-scale hierarchical multi-view RGB-D object dataset , Proceedings of IEEE International Conference on Robotics and Automation (2011)	http://dx.doi.org/10.1016/j.patrec.2015.12.006			<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-12-006/br/bib0016>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-12-006/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-12-006/ctx/ctx0012>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2015-12-006/itrp/0009	'The Object dataset [16][[ refid=''bib0016'' ]] contains 51 object categories, with a total of 250,000 images including color and depth.'				100_classified_usesDataFrom
uses_data_from	Reconstruction helps recognition	N. Silberman, D. Hoiem, P. Kohli, R. Fergus, Indoor segmentation and support inference from RGBD images , Proceedings of the ECCV (2012)	http://dx.doi.org/10.1016/j.patrec.2016.01.019			<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2016-01-019/br/bib0069>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2016-01-019/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2016-01-019/ctx/ctx0045>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2016-01-019/itrp/0097	'We conduct these experiments on the NYUD2 dataset [69][[ refid=''bib0069'' ]].'				100_classified_usesDataFrom
uses_data_from	Experimental setup	P. Das, C. Xu, R.F. Doell, J.J. Corso, A thousand frames in just a few words: Lingual description of videos through latent topics and sparse object stitching , Proceedings of the 2013 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2013)	http://dx.doi.org/10.1016/j.patrec.2016.01.028	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2016-01-028/br/bib0004>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2016-01-028/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2016-01-028/ctx/ctx0011>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2016-01-028/itrp/0001	'The videos were taken from a challenging, recently published data set [4][[ refid=''bib0004'' ]], called the YouCook data set, consisting of instructional videos of different cooking styles, such as assembling, baking, grilling, etc. This collection of videos is challenging with diverse scenarios containing cluttered backgrounds, different subjects, occlusion of objects, shot from different viewpoints, and different illumination conditions.'				100_classified_usesDataFrom
extends	Methodology	K. Gibert, B. Sevilla-Villanueva, M. Sànchez-Marrè, The role of significance tests in consistent interpretation of nested partitions , J. Comput. Appl. Math. , vol. 292 (2016), pp.623-633	http://dx.doi.org/10.1016/j.patrec.2017.02.008	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-02-008/br/bib0021	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-02-008/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-02-008/ctx/ctx0034		37	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-02-008/itrp/0030	'This proposal is an extension of [21][[ refid=''bib0021'' ]] where a non-symmetric operator defined in the specific context of nested partitions was presented.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0058"""" view=""""all"""">This proposal is an extension of <ce:cross-ref id=""""crf0048"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> where a non-symmetric operator defined in the specific context of nested partitions was presented. In this work, the description-power is formalized as a general operator for any kind of variable and partition. Also, the proposal has been extended with the introduction of the new category of <ce:italic>basic descriptors</ce:italic>.</ce:para>""''"'	extends	ANG	
cites	Related work	Y. Song, L.-P. Morency, R. Davis, Action recognition by hierarchical sequence summarization , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2013)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0012	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0022		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0001	'Song et al. [12][[ refid=''bib0012'' ]] defined a feature function for the aforementioned CRFs model using a series of complex heuristics.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all"""">In the recent past, new approaches based on CRFs, HMMs and action grammars were proposed to model motion patterns for action recognition tasks <ce:cross-refs id=""""crfs0006"""" refid=""""bib0007 bib0010 bib0012"""">[7,10,12][[ refid=''''bib0007 bib0010 bib0012'''' ]]</ce:cross-refs>. Wang and Mori <ce:cross-ref id=""""crf0039"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref> combined a part-based approach with large-scale template features to obtain a discriminative model based on max-margin CRFs. Song et al. <ce:cross-ref id=""""crf0040"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> defined a feature function for the aforementioned CRFs model using a series of complex heuristics. In addition, Tang et al. <ce:cross-ref id=""""crf0041"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> proposed a max-margin method to model the temporal structure in a video. They used an HMM to learn the transitions of action appearances and the duration of actions.</ce:para>""''"'	cites	AGA	
cites	Related work	K. Tang, L. Fei-Fei, D. Koller, Learning latent temporal structure for complex event detection , Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, IEEE (2012)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0007	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0023		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0002	'In addition, Tang et al. [7][[ refid=''bib0007'' ]] proposed a max-margin method to model the temporal structure in a video.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all"""">In the recent past, new approaches based on CRFs, HMMs and action grammars were proposed to model motion patterns for action recognition tasks <ce:cross-refs id=""""crfs0006"""" refid=""""bib0007 bib0010 bib0012"""">[7,10,12][[ refid=''''bib0007 bib0010 bib0012'''' ]]</ce:cross-refs>. Wang and Mori <ce:cross-ref id=""""crf0039"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref> combined a part-based approach with large-scale template features to obtain a discriminative model based on max-margin CRFs. Song et al. <ce:cross-ref id=""""crf0040"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> defined a feature function for the aforementioned CRFs model using a series of complex heuristics. In addition, Tang et al. <ce:cross-ref id=""""crf0041"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> proposed a max-margin method to model the temporal structure in a video. They used an HMM to learn the transitions of action appearances and the duration of actions.</ce:para>""''"'	cites	AGA	
cites	Related work	Y. Wang, G. Mori, Hidden part models for human action recognition: probabilistic versus max margin , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 33 (2011), pp.1310-1323	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0021		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0006	'Wang and Mori [10][[ refid=''bib0010'' ]] combined a part-based approach with large-scale template features to obtain a discriminative model based on max-margin CRFs.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0014"""" view=""""all"""">In the recent past, new approaches based on CRFs, HMMs and action grammars were proposed to model motion patterns for action recognition tasks <ce:cross-refs id=""""crfs0006"""" refid=""""bib0007 bib0010 bib0012"""">[7,10,12][[ refid=''''bib0007 bib0010 bib0012'''' ]]</ce:cross-refs>. Wang and Mori <ce:cross-ref id=""""crf0039"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref> combined a part-based approach with large-scale template features to obtain a discriminative model based on max-margin CRFs. Song et al. <ce:cross-ref id=""""crf0040"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> defined a feature function for the aforementioned CRFs model using a series of complex heuristics. In addition, Tang et al. <ce:cross-ref id=""""crf0041"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> proposed a max-margin method to model the temporal structure in a video. They used an HMM to learn the transitions of action appearances and the duration of actions.</ce:para>""''"'	cites	AGA	
cites	Related work	J. Revaud, M. Douze, C. Schmid, H. Jégou, Event retrieval in large video collections with circulant temporal encoding , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2013)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0030	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0027		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0009	'A method that applies Fourier analysis was also proposed in [30][[ refid=''bib0030'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">In the recent literature, one can find works that apply temporal ordering models for activity recognition tasks <ce:cross-refs id=""""crfs0007"""" refid=""""bib0008 bib0027 bib0028"""">[8,27,28][[ refid=''''bib0008 bib0027 bib0028'''' ]]</ce:cross-refs>. Their aim was to infer complex actions from predefined useful basic-level action detectors.Sun and Nevatia <ce:cross-ref id=""""crf0042"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> imposed a representation for low-level action events that includes statistical information of the action transition probabilities. Spatio-temporal primitives of sub-gestures were used to model the goal actions after detecting them through genetic algorithms. The dynamics of the target actions were modeled using HMMs or dynamic time warping. Owing to the variability of motion patterns in videos, latent sequential models are not capable to overcome this problem. Thus, temporal pyramids were introduced in <ce:cross-refs id=""""crfs0008"""" refid=""""bib0003 bib0029"""">[3,29][[ refid=''''bib0003 bib0029'''' ]]</ce:cross-refs> to address this problem. A method that applies Fourier analysis was also proposed in <ce:cross-ref id=""""crf0043"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. In this paper, we model the temporal structure of videos following <ce:cross-ref id=""""crf0044"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>, which models the evolution of appearance or local motion using a learning-to-rank technique. We show the effect of aggregation of coherent frames. We also demonstrate how useful is to process input videos as subsequences of related frames.</ce:para>""''"'	cites	AGA	
cites	Related work	C. Sun, R. Nevatia, Active: activity concept transitions in video event classification , Proceedings of the IEEE International Conference on Computer Vision (2013)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0028	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0025		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0013	'Their aim was to infer complex actions from predefined useful basic-level action detectors.Sun and Nevatia [28][[ refid=''bib0028'' ]] imposed a representation for low-level action events that includes statistical information of the action transition probabilities.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">In the recent literature, one can find works that apply temporal ordering models for activity recognition tasks <ce:cross-refs id=""""crfs0007"""" refid=""""bib0008 bib0027 bib0028"""">[8,27,28][[ refid=''''bib0008 bib0027 bib0028'''' ]]</ce:cross-refs>. Their aim was to infer complex actions from predefined useful basic-level action detectors.Sun and Nevatia <ce:cross-ref id=""""crf0042"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> imposed a representation for low-level action events that includes statistical information of the action transition probabilities. Spatio-temporal primitives of sub-gestures were used to model the goal actions after detecting them through genetic algorithms. The dynamics of the target actions were modeled using HMMs or dynamic time warping. Owing to the variability of motion patterns in videos, latent sequential models are not capable to overcome this problem. Thus, temporal pyramids were introduced in <ce:cross-refs id=""""crfs0008"""" refid=""""bib0003 bib0029"""">[3,29][[ refid=''''bib0003 bib0029'''' ]]</ce:cross-refs> to address this problem. A method that applies Fourier analysis was also proposed in <ce:cross-ref id=""""crf0043"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. In this paper, we model the temporal structure of videos following <ce:cross-ref id=""""crf0044"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>, which models the evolution of appearance or local motion using a learning-to-rank technique. We show the effect of aggregation of coherent frames. We also demonstrate how useful is to process input videos as subsequences of related frames.</ce:para>""''"'	cites	AGA	
cites	Related work	B. Fernando, E. Gavves, J. Oramas, A. Ghodrati, T. Tuytelaars, Rank pooling for action recognition , IEEE Trans. Pattern Anal. Mach. Intell. (2016)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0009	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0028		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0014	'In this paper, we model the temporal structure of videos following [9][[ refid=''bib0009'' ]], which models the evolution of appearance or local motion using a learning-to-rank technique.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">In the recent literature, one can find works that apply temporal ordering models for activity recognition tasks <ce:cross-refs id=""""crfs0007"""" refid=""""bib0008 bib0027 bib0028"""">[8,27,28][[ refid=''''bib0008 bib0027 bib0028'''' ]]</ce:cross-refs>. Their aim was to infer complex actions from predefined useful basic-level action detectors.Sun and Nevatia <ce:cross-ref id=""""crf0042"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> imposed a representation for low-level action events that includes statistical information of the action transition probabilities. Spatio-temporal primitives of sub-gestures were used to model the goal actions after detecting them through genetic algorithms. The dynamics of the target actions were modeled using HMMs or dynamic time warping. Owing to the variability of motion patterns in videos, latent sequential models are not capable to overcome this problem. Thus, temporal pyramids were introduced in <ce:cross-refs id=""""crfs0008"""" refid=""""bib0003 bib0029"""">[3,29][[ refid=''''bib0003 bib0029'''' ]]</ce:cross-refs> to address this problem. A method that applies Fourier analysis was also proposed in <ce:cross-ref id=""""crf0043"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. In this paper, we model the temporal structure of videos following <ce:cross-ref id=""""crf0044"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>, which models the evolution of appearance or local motion using a learning-to-rank technique. We show the effect of aggregation of coherent frames. We also demonstrate how useful is to process input videos as subsequences of related frames.</ce:para>""''"'	cites	AGA	
cites	Methods	H. Wang, C. Schmid, Action recognition with improved trajectories , Proceedings of the IEEE International Conference on Computer Vision (2013)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0006	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0029		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0015	'Wang and Schmid [6][[ refid=''bib0006'' ]] used dense sampled local visual features at several spatial scales.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0017"""" view=""""all"""">Feature trajectories have shown to be efficient for representing videos. Wang and Schmid <ce:cross-ref id=""""crf0046"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref> used dense sampled local visual features at several spatial scales. They estimated a homography with RANSAC (random sample consensus) using SURF matching (speeded up robust features) between two consecutive frames. The calculated low-level descriptors were computed on the warped optical flow to capture motion patterns. Below, we explain the feature extraction methods used in this paper: histogram of oriented gradients (HOG), histogram of optical Flow (HOF), and motion boundary histogram (MBH). We also explain the steps of Fisher vectors (FVs).<ce:list id=""""celist0004""""><ce:list-item id=""""celistitem0005""""><ce:label>•</ce:label><ce:para id=""""para0018"""" view=""""all""""><ce:bold>HOG and HOF descriptors:</ce:bold> HOG captures information about the appearance whereas HOF captures local motion information. Wang et al. <ce:cross-ref id=""""crf0047"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> reported that HOG and HOF descriptors yield good results on different activity recognition datasets compared to classical descriptors. To compute the HOG descriptor, we computed gradient magnitude responses in the horizontal and vertical directions. To compute the HOF descriptors, optical flow displacement vectors in the horizontal and vertical directions were determined <ce:cross-ref id=""""crf0048"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>. As a result, a 2D vector field per frame was calculated. The orientations were quantized into eight bins for HOG and nine bins for HOF as described in <ce:cross-ref id=""""crf0049"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>. The length of HOG was 96 (2 × 2 × 3 × 8) while the length of HOF was 108 (2 × 2 × 3 × 9).</ce:para></ce:list-item><ce:list-item id=""""celistitem0006""""><ce:label>•</ce:label><ce:para id=""""para0019"""" view=""""all""""><ce:bold>MBH descriptor:</ce:bold> MBH is a very popular descriptor for video classification and detection tasks. Dalal et al. <ce:cross-ref id=""""crf0050"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> showed the robustness of MBH descriptor against camera and background motion. The simple idea behind MBH is computing oriented gradients over the vertical and horizontal optical flow displacements. Indeed, the horizontal and vertical displacements of the optical flow are treated as gray-level images of the motion displacements. For each optical flow component, a histogram of oriented gradients is computed using the same configuration used for still images. Indeed, information related to motion changes in the object boundaries is obtained using the flow difference whereas information about unmoving objects and camera motion is discarded.</ce:para></ce:list-item><ce:list-item id=""""celistitem0007""""><ce:label>•</ce:label><ce:para id=""""para0020"""" view=""""all""""><ce:bold>Fisher vectors (FVs):</ce:bold> In computer vision field, FVs have been widely used as an image representation by pooling local image features. It is also used as a global descriptor for image classification. FV can be used for frame level pooling, a subsequence level pooling or video level pooling as well.</ce:para><ce:para id=""""para0021"""" view=""""all"""">FV coding was derived from the well-known Fisher kernel, which is based on the assumption that the generation process of a local descriptor <ce:italic>X</ce:italic> can be modeled as a probability density function <ce:italic>p</ce:italic>(<ce:italic>X, θ</ce:italic>). Using the gradient of the <ce:italic>G</ce:italic> log-likelihood, it is possible to describe how the parameters in <ce:italic>θ</ce:italic> contribute to the generation process of <ce:italic>X</ce:italic>. Then, the sample can be described as follows:<ce:display><ce:formula id=""""eq0001""""><ce:label>(1)</ce:label><mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mi>X</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>∇</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></ce:formula></ce:display>The dimensionality of this vector depends on the number of parameters in <ce:italic>θ</ce:italic>. A Gaussian mixture model is used to model the probability density function. Note that <mml:math altimg=""""si5.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math> contains the parameters of the model, were <ce:italic>π, μ, σ</ce:italic> are Gaussian mixture weights, means and diagonal covariance, respectively. An improved Fisher vector was proposed in <ce:cross-ref id=""""crf0051"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> as follows:<ce:display><ce:formula id=""""eq0002""""><ce:label>(2)</ce:label><mml:math altimg=""""si6.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display><ce:display><ce:formula id=""""eq0003""""><ce:label>(3)</ce:label><mml:math altimg=""""si7.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id=""""para0022"""" view=""""all"""">where <ce:italic>γ<ce:inf loc=""""post"""">k</ce:inf></ce:italic> is the weight of local descriptor <ce:italic>x</ce:italic> corresponding to <ce:italic>k<ce:sup loc=""""post"""">th</ce:sup></ce:italic> Gaussian component, and thus<ce:display><ce:formula id=""""eq0004""""><ce:label>(4)</ce:label><mml:math altimg=""""si8.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo>⋯</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id=""""para0023"""" view=""""all"""">The parameter <ce:italic>γ<ce:inf loc=""""post"""">k</ce:inf></ce:italic> can be determined as follows:<ce:display><ce:formula id=""""eq0005""""><ce:label>(5)</ce:label><mml:math altimg=""""si9.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id=""""para0024"""" view=""""all"""">To construct the FV, the gradients of <ce:cross-ref id=""""crf0052"""" refid=""""eq0002"""">Eqs. (2)</ce:cross-ref> and <ce:cross-ref id=""""crf0053"""" refid=""""eq0003"""">(3)</ce:cross-ref> are concatenated as follows:<ce:display><ce:formula id=""""eq0006""""><ce:label>(6)</ce:label><mml:math altimg=""""si10.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>F</mml:mi><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:math></ce:formula></ce:display></ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_method_in	AGA	
cites	Related work	M. Jain, H. Jegou, P. Bouthemy, Better exploiting motion for better action recognition , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2013)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0008		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0016	'Jain et al. [4][[ refid=''bib0004'' ]] proposed to determine the location of actions in the video and then use them to refine recognition.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0010"""" view=""""all"""">In the literature, several researchers have studied the problem of capturing temporal patterns of videos for activity recognition. Important improvements have been seen in local motion patterns modeling. Jain et al. <ce:cross-ref id=""""crf0029"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref> proposed to determine the location of actions in the video and then use them to refine recognition. <ce:cross-ref id=""""crf0030"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> used the curvature of the trajectories of local descriptors and other kinematic properties to improve performance of activity recognition methods.</ce:para>""''"'	cites	AGA	
cites	Related work	A. Saleh, M.A.G.F. Akram, M. Abdel-Nasser, D. Puig, Exploiting the kinematic of the trajectories of the local descriptors to improve human action recognition, 2016.	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0015	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0009		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0017	'[15][[ refid=''bib0015'' ]] used the curvature of the trajectories of local descriptors and other kinematic properties to improve performance of activity recognition methods.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0010"""" view=""""all"""">In the literature, several researchers have studied the problem of capturing temporal patterns of videos for activity recognition. Important improvements have been seen in local motion patterns modeling. Jain et al. <ce:cross-ref id=""""crf0029"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref> proposed to determine the location of actions in the video and then use them to refine recognition. <ce:cross-ref id=""""crf0030"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> used the curvature of the trajectories of local descriptors and other kinematic properties to improve performance of activity recognition methods.</ce:para>""''"'	cites	AGA	
uses_method_in	Experimental results and discussion	B. Fernando, E. Gavves, J.M. Oramas, A. Ghodrati, T. Tuytelaars, Modeling video evolution for action recognition , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2015)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0046		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0018	'For the learning-to-rank method, we used the source code of [39][[ refid=''bib0039'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0043"""" view=""""all"""">To implement FVs, we set the number of Gaussians to K= 256 and randomly sample a subset of 256,000 features from the training set to estimate the GMM. Recent evaluations <ce:cross-refs id=""""crfs0011"""" refid=""""bib0005 bib0042 bib0043"""">[5,42,43][[ refid=''''bib0005 bib0042 bib0043'''' ]]</ce:cross-refs> showed that the aforementioned values give good results with action classification. The resulting GMM models were used to build FVs. We used VlFeat library to implement this part. For the learning-to-rank method, we used the source code of <ce:cross-ref id=""""crf0065"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>. For MKL method, we used the source code of <ce:cross-ref id=""""crf0066"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref>, we set the value of <ce:italic>λ</ce:italic> to 0.1 and the value of <ce:italic>γ</ce:italic> of the radial basis function to 0.1. In our experiments, we set C = 1.0 (regularization-loss trade off) for the SVM classifier, which gave good results when validating on a subset of training samples.</ce:para>""''"'	cites	AGA	
uses_method_in	Experimental results and discussion	F. Aiolli, M. Donini, Easymkl: a scalable multiple kernel learning algorithm , Neurocomputing , vol. 169 (2015), pp.215-224	http://dx.doi.org/10.1016/j.patrec.2017.06.010	results	discussion	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0038>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0047>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0019	'For MKL method, we used the source code of [38][[ refid=''bib0038'' ]], we set the value of λ to 0.1 and the value of γ of the radial basis function to 0.1.'			FDY+AGA	infered_pred1
cites	Methods	F. Aiolli, M. Donini, Easymkl: a scalable multiple kernel learning algorithm , Neurocomputing , vol. 169 (2015), pp.215-224	http://dx.doi.org/10.1016/j.patrec.2017.06.010	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0038	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0040		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0020	'To simplify the problem further, Aiolli and Donini [38][[ refid=''bib0038'' ]] proposed to minimize an upper-bound instead of corresponding to the ℓ1-norm of the distances, and thus they obtained the following equation: [[ formulaid=''id15_pos7'' ]]'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0034"""" view=""""all""""><ce:bold>A Scalable multiple kernel learning algorithm (EasyMKL):</ce:bold> In this paper, we use the EasyMKL method <ce:cross-ref id=""""crf0058"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> because it can easily deal with hundreds of thousands of kernels and more. EasyMKL method showed robustness in comparison with other alternative methods (random, average, etc.) even for data containing noise. EasyMKL method learns a vector of coefficients <ce:italic>η</ce:italic> that define the combined kernel according to:<ce:display><ce:formula id=""""eq0009""""><ce:label>(9)</ce:label><mml:math altimg=""""si25.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>R</mml:mi></mml:munderover><mml:msub><mml:mi>η</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></ce:formula></ce:display>It is clear that one must restrict the possible choices of <ce:italic>K</ce:italic>, and this can be done by a regularization term. The problem of learning the kernel combination is posed as a <mml:math altimg=""""si26.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:math> problem over variables <ce:italic>γ</ce:italic> and <ce:italic>η</ce:italic>. Aiolli and Donini <ce:cross-ref id=""""crf0059"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> proposed to maximize the distance between the positive and negative samples with a unitary norm vector <ce:italic>η</ce:italic> as the weak kernels combination vector:<ce:display><ce:formula id=""""eq0010""""><ce:label>(10)</ce:label><mml:math altimg=""""si27.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:munder><mml:mi>max</mml:mi><mml:mrow><mml:mi>η</mml:mi><mml:mo>:</mml:mo><mml:mo>∥</mml:mo><mml:mi>η</mml:mi><mml:mo>∥</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder><mml:munder><mml:mi>min</mml:mi><mml:mrow><mml:mstyle mathvariant=""""normal""""><mml:mi>Γ</mml:mi></mml:mstyle><mml:mo>∈</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mover accent=""""true""""><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>R</mml:mi></mml:munderover><mml:msub><mml:mi>η</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mover accent=""""true""""><mml:msub><mml:mi>K</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mover accent=""""true""""><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>γ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msup><mml:mrow><mml:mo>∥</mml:mo><mml:mi>γ</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></ce:formula></ce:display>Consider the following equation:<ce:display><ce:formula id=""""eq0011""""><ce:label>(11)</ce:label><mml:math altimg=""""si28.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>η</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mover accent=""""true""""><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>R</mml:mi></mml:munderover><mml:msub><mml:mi>η</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mover accent=""""true""""><mml:msub><mml:mi>K</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mover accent=""""true""""><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>γ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msup><mml:mrow><mml:mo>∥</mml:mo><mml:mi>γ</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></ce:formula></ce:display>If the vector of the <ce:italic>r</ce:italic>th entry is defined as <mml:math altimg=""""si29.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>γ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mover accent=""""true""""><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msub><mml:mover accent=""""true""""><mml:mi>K</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>r</mml:mi></mml:msub><mml:mover accent=""""true""""><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>γ</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math> then<ce:display><ce:formula id=""""eq0012""""><ce:label>(12)</ce:label><mml:math altimg=""""si30.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>η</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>γ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo><mml:mi>γ</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></ce:formula></ce:display>Consequently, the main problem can be rewritten as:<ce:display><ce:formula id=""""eq0013""""><ce:label>(13)</ce:label><mml:math altimg=""""si31.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:munder><mml:mi>min</mml:mi><mml:mrow><mml:mi>γ</mml:mi><mml:mo>∈</mml:mo><mml:mstyle mathvariant=""""normal""""><mml:mi>Γ</mml:mi></mml:mstyle></mml:mrow></mml:munder><mml:munder><mml:mi>max</mml:mi><mml:mrow><mml:mi>η</mml:mi><mml:mo>:</mml:mo><mml:mo>∥</mml:mo><mml:mi>η</mml:mi><mml:mo>∥</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>η</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mi>min</mml:mi><mml:mrow><mml:mi>γ</mml:mi><mml:mo>∈</mml:mo><mml:mstyle mathvariant=""""normal""""><mml:mi>Γ</mml:mi></mml:mstyle></mml:mrow></mml:munder><mml:munder><mml:mi>max</mml:mi><mml:mrow><mml:mi>η</mml:mi><mml:mo>:</mml:mo><mml:mo>∥</mml:mo><mml:mi>η</mml:mi><mml:mo>∥</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>γ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo><mml:mi>γ</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></ce:formula></ce:display>Finding <ce:italic>η</ce:italic>*, which is a simple analytic solution that maximizes <ce:italic>Q</ce:italic>:<ce:display><ce:formula id=""""eq0014""""><ce:label>(14)</ce:label><mml:math altimg=""""si32.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mi>γ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mo>∥</mml:mo><mml:mi>γ</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display>and<ce:display><ce:formula id=""""eq0015""""><ce:label>(15)</ce:label><mml:math altimg=""""si33.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:munder><mml:mi>min</mml:mi><mml:mrow><mml:mi>γ</mml:mi><mml:mo>∈</mml:mo><mml:mstyle mathvariant=""""normal""""><mml:mi>Γ</mml:mi></mml:mstyle></mml:mrow></mml:munder><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mi>min</mml:mi><mml:mrow><mml:mi>γ</mml:mi><mml:mo>∈</mml:mo><mml:mstyle mathvariant=""""normal""""><mml:mi>Γ</mml:mi></mml:mstyle></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>∥</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>γ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo><mml:mi>γ</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></ce:formula></ce:display>The optimal <ce:italic>γ</ce:italic> is a regularized minimizer of ℓ<ce:inf loc=""""post"""">2</ce:inf>-norm of the distances vector. It is possible to find the minimizer as this is a convex function. To simplify the problem further, Aiolli and Donini <ce:cross-ref id=""""crf0060"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> proposed to minimize an upper-bound instead of corresponding to the ℓ<ce:inf loc=""""post"""">1</ce:inf>-norm of the distances, and thus they obtained the following equation:<ce:display><ce:formula id=""""eq0016""""><ce:label>(16)</ce:label><mml:math altimg=""""si34.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:munder><mml:mi>min</mml:mi><mml:mrow><mml:mi>γ</mml:mi><mml:mo>∈</mml:mo><mml:mstyle mathvariant=""""normal""""><mml:mi>Γ</mml:mi></mml:mstyle></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∥</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>γ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mrow><mml:mi>λ</mml:mi><mml:mo>∥</mml:mo><mml:mi>γ</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:munder><mml:mi>min</mml:mi><mml:mrow><mml:mi>γ</mml:mi><mml:mo>∈</mml:mo><mml:mstyle mathvariant=""""normal""""><mml:mi>Γ</mml:mi></mml:mstyle></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mover accent=""""true""""><mml:mi>Y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mi>R</mml:mi></mml:munderover><mml:msub><mml:mover accent=""""true""""><mml:mi>K</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msubsup><mml:mrow><mml:mo>∥</mml:mo><mml:mi>γ</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></ce:formula></ce:display></ce:para>""''"'	cites	AGA	
uses_method_in	Methods	B. Fernando, E. Gavves, J. Oramas, A. Ghodrati, T. Tuytelaars, Rank pooling for action recognition , IEEE Trans. Pattern Anal. Mach. Intell. (2016)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0009	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0041		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0021	'To learn a representation of each video, we use the learning-to-rank technique, which consists of the following three steps: frame-level representation, sequence smoothing, and learning the representation of the whole video [9][[ refid=''bib0009'' ]].1.Frame-level representation: Each video can be represented as follows: X=[x1,x2,...,xn], where xt contains the descriptors of a frame at time step t.2.Sequence smoothing: To avoid abrupt action changes in videos, we smooth the sequence X using time varying mean as follows: mt=1t∑i=1txi.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0035"""" view=""""all"""">To learn a representation of each video, we use the learning-to-rank technique, which consists of the following three steps: frame-level representation, sequence smoothing, and learning the representation of the whole video <ce:cross-ref id=""""crf0061"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>.<ce:list id=""""celist0001""""><ce:list-item id=""""celistitem0010""""><ce:label>1.</ce:label><ce:para id=""""para0036"""" view=""""all""""><ce:bold>Frame-level representation:</ce:bold> Each video can be represented as follows: <mml:math altimg=""""si35.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>]</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math> where <ce:italic>x<ce:inf loc=""""post"""">t</ce:inf></ce:italic> contains the descriptors of a frame at time step <ce:italic>t</ce:italic>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0011""""><ce:label>2.</ce:label><ce:para id=""""para0037"""" view=""""all""""><ce:bold>Sequence smoothing:</ce:bold> To avoid abrupt action changes in videos, we smooth the sequence <ce:italic>X</ce:italic> using time varying mean as follows: <mml:math altimg=""""si36.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>t</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>t</mml:mi></mml:munderover><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math>. We then normalize <ce:italic>m<ce:inf loc=""""post"""">t</ce:inf></ce:italic> as follows: <mml:math altimg=""""si37.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>m</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mrow><mml:mo>∥</mml:mo></mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>∥</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math>. It is clear that <ce:italic>v<ce:inf loc=""""post"""">t</ce:inf></ce:italic> only contains information about direction of <ce:italic>m<ce:inf loc=""""post"""">t</ce:inf></ce:italic>. Therefore, this approach guarantees a smooth output.</ce:para></ce:list-item><ce:list-item id=""""celistitem0012""""><ce:label>3.</ce:label><ce:para id=""""para0038"""" view=""""all""""><ce:bold>Learning the representation of the whole video:</ce:bold> Learning-to-rank technique was proposed in <ce:cross-refs id=""""crfs0010"""" refid=""""bib0009 bib0039"""">[9,39][[ refid=''''bib0009 bib0039'''' ]]</ce:cross-refs> for activity recognition. Given the smoothed vectors, the learning-to-rank technique learns their rank (i.e., <mml:math altimg=""""si38.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>≻</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>≻</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>≻</mml:mo><mml:mo>⋯</mml:mo><mml:mo>≻</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math>). A linear learning-to-rank technique learns a pairwise linear function <ce:italic>ψ</ce:italic>(<ce:italic>m<ce:inf loc=""""post"""">t</ce:inf>; u</ce:italic>), where <mml:math altimg=""""si39.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>u</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant=""""double-struck"""">R</mml:mi><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math> is a vector containing its parameters. The ranking score of <ce:italic>m<ce:inf loc=""""post"""">t</ce:inf></ce:italic> is computed by <mml:math altimg=""""si40.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>u</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>.</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math>. The learning-to-rank technique optimizes the parameters <ce:italic>u</ce:italic> of <ce:italic>ψ</ce:italic>(<ce:italic>m<ce:inf loc=""""post"""">t</ce:inf>; u</ce:italic>) using the objective function of <ce:cross-ref id=""""crf0062"""" refid=""""eq0017"""">Eq. (17)</ce:cross-ref> with the constraint <mml:math altimg=""""si41.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mo>∀</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mspace width=""""1em""""/><mml:msub><mml:mi>v</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub><mml:mo>≻</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:msub><mml:mspace width=""""0.28em""""/><mml:mo>⟺</mml:mo><mml:mspace width=""""0.28em""""/><mml:msub><mml:mi>v</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub><mml:mo>.</mml:mo><mml:msup><mml:mi>u</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>≻</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:msub><mml:mo>.</mml:mo><mml:msup><mml:mi>u</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math> as follows:<ce:display><ce:formula id=""""eq0017""""><ce:label>(17)</ce:label><mml:math altimg=""""si42.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd columnalign=""""right""""><mml:mrow><mml:munder><mml:mrow><mml:mi>arg</mml:mi><mml:mi>min</mml:mi></mml:mrow><mml:mi>u</mml:mi></mml:munder><mml:mspace width=""""1em""""/><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mo>∥</mml:mo><mml:mi>u</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mo>∀</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>≻</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:munder><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width=""""1em""""/><mml:mi mathvariant=""""italic"""">s</mml:mi><mml:mo>.</mml:mo><mml:mi mathvariant=""""italic"""">t</mml:mi><mml:mo>.</mml:mo><mml:mspace width=""""1em""""/><mml:msup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign=""""right""""><mml:mrow><mml:msub><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where <ce:italic>C</ce:italic> is the regularization parameter and ϵ is the margin of tolerance. The parameters <ce:italic>u</ce:italic> are used to describe the evolution of actions in videos In other words, we use <ce:italic>u</ce:italic> to represent the whole video.</ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_method_in	AGA	
cites	Experimental results and discussion	M. Marszalek, I. Laptev, C. Schmid, Actions in context , IEEE Conference on Computer Vision and Pattern Recognition, IEEE (2009)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0040	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0043		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0024	'There is no overlap between the 33 movies in the training set and the 36 movies in the testing set [40][[ refid=''bib0040'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0041"""" view=""""all"""">We used two state-of-the-art datasets to evaluate the proposed method: HMDB51 and Hollywood2. Hollywood2 is one of the largest and most challenging available datasets for real world actions. There are 12 classes: answering phone, driving car, eating, fighting, getting out of car, shaking hands, hugging, kissing, running, sitting down, sitting up and standing up. The actions were collected from a set of 69 Hollywood movies. It consists of around 487k frames (about 20 h of video). It is divided into a training set of 823 sequences and a testing set of 884 sequences. There is no overlap between the 33 movies in the training set and the 36 movies in the testing set <ce:cross-ref id=""""crf0063"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref>. As is standard on this dataset, performance of our method is measured by mean average precision (mAP) over all classes.</ce:para>""''"'	cites	AGA	
cites	Introduction	Y. Wang, J. Song, L. Wang, L. Van Gool, O. Hilliges, Two-stream sr-cnns for action recognition in videos , None, BMVC (2016)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0001		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0025	'However, constructing robust models to recognize free-form activities of the same class still an open problem [1][[ refid=''bib0001'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">The main goal of the action recognition field is to give the computer the ability to recognize human action in real life videos. The need for action recognition methods in areas such as robot learning, analyzing video surveillance and human-computer interaction led to a big progress in the field. However, constructing robust models to recognize free-form activities of the same class still an open problem <ce:cross-ref id=""""crf0017"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. One of the sources of misclassification is the wide margin of variation inside the same class. Other sources can be the change in viewpoint, scale and background clutter. In addition, there are other high level unmeasurable factors that can play a role in human action recognition, such as human-objects interaction, human poses and scene context.</ce:para>""''"'	cites	AGA	
cites	Introduction	H. Wang, C. Schmid, Action recognition with improved trajectories , Proceedings of the IEEE International Conference on Computer Vision (2013)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0006	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0004		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0030	'A good example is Fisher vectors [6][[ refid=''bib0006'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">In fact, most of the development in the action recognition area over the last years has been related to two approaches. The first approach is the definition of local spatio-temporal features, such as spatio-temporal features <ce:cross-ref id=""""crf0018"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref> and densely sampled local visual features <ce:cross-ref id=""""crf0019"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>. We can also mention interest points, motion-based gradient descriptors <ce:cross-ref id=""""crf0020"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref> and dense trajectories <ce:cross-ref id=""""crf0021"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>. The second approach is concentrated on the exploration of encoding methods, which has a long history of success in object recognition field. A good example is Fisher vectors <ce:cross-ref id=""""crf0022"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>. In spite of the fact that the interest in action and events recognition has been increased <ce:cross-refs id=""""crfs0001"""" refid=""""bib0007 bib0008"""">[7,8][[ refid=''''bib0007 bib0008'''' ]]</ce:cross-refs>, there are not a lot of works to model temporal patterns inside videos. Obviously, modeling the temporal evolution of video is a challenging open problem due to the level of complexity mentioned before. In addition, actions in videos are performed at varying speeds, and often the speed of the same action can non-linearly change within a single video. A number of methods have been proposed to capture temporal evolution in videos for action recognition tasks exploiting the learning-to-rank technique <ce:cross-ref id=""""crf0023"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> and hidden Markov models <ce:cross-refs id=""""crfs0002"""" refid=""""bib0010 bib0011"""">[10,11][[ refid=''''bib0010 bib0011'''' ]]</ce:cross-refs>. In the last few years, conditional random fields based methods were also proposed <ce:cross-ref id=""""crf0024"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>, and recently, deep neural networks based methods were proposed to tackle the activity recognition problem <ce:cross-refs id=""""crfs0003"""" refid=""""bib0013 bib0014"""">[13,14][[ refid=''''bib0013 bib0014'''' ]]</ce:cross-refs>.</ce:para>""''"'	cites	AGA	
cites	Experimental results and discussion	B. Fernando, E. Gavves, J.M. Oramas, A. Ghodrati, T. Tuytelaars, Modeling video evolution for action recognition , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2015)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0048		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0039	'As we see in Tables 1–4, the recognition results are improved when we combine the proposed method with the baseline of [39][[ refid=''bib0039'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0045"""" view=""""all"""">In <ce:cross-ref id=""""crf0071"""" refid=""""tbl0003"""">Tables 3</ce:cross-ref><ce:float-anchor refid=""""tbl0003""""/> and <ce:cross-ref id=""""crf0072"""" refid=""""tbl0004"""">4</ce:cross-ref><ce:float-anchor refid=""""tbl0004""""/>, we present the recognition accuracy with HMDB51 dataset. As we can see, the cosine similarity and the correlation measure also gave the best recognition results. We notice that in both datasets, the median function gave recognition accuracy better than the one of the mean operator with the Euclidean distance. As we see in <ce:cross-refs id=""""crfs0012"""" refid=""""tbl0001 tbl0002 tbl0003 tbl0004"""">Tables 1–4</ce:cross-refs>, the recognition results are improved when we combine the proposed method with the baseline of <ce:cross-ref id=""""crf0073"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>. After Applying the MKL technique, we got the state-of-the-art results with Hollywood2 dataset and comparable values with HMDB51 dataset.</ce:para>""''"'	cites	AGA	
uses_method_in	Methods	F. Aiolli, M. Donini, Easymkl: a scalable multiple kernel learning algorithm , Neurocomputing , vol. 169 (2015), pp.215-224	http://dx.doi.org/10.1016/j.patrec.2017.06.010	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0038>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0037>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0046	'Notation: In this work, we follow [38][[ refid=''bib0038'' ]] to solve a classification problem with training samples defined as {(x1,y1),(x2,y2),…,(xl,yl)} and test samples defined {(xl+1,yl+1),(xl+2,yl+2),…,(xL,yL)}, where x ∈ Rm and y∈{−1,1} if we solve a binary classification problem or y ∈ {1, 2, .., C} if we solve a multi-class classification problem.'			FDY+AGA	infered_pred1
cites	Methods	F.R. Bach, G.R. Lanckriet, M.I. Jordan, Multiple kernel learning, conic duality, and the smo algorithm , Proceedings of the twenty-first international conference on Machine learning, ACM (2004)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0037	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0036		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0047	'This optimization problem can then be solved by any of standard optimization methods [37][[ refid=''bib0037'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0032"""" view=""""all"""">MKL algorithms have been developed for supervised, semi-supervised and unsupervised learning. Big part of the progress has been done on supervised learning with linear combinations of kernels. One can explain MKL algorithms as the addition of an extra parameter to the minimization problem of the learning algorithm. For instance, in case of supervised learning of a linear combination of a set of <ce:italic>n</ce:italic> kernels. Let us introduce a kernel <mml:math altimg=""""si17.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msup><mml:mi>K</mml:mi><mml:msup><mml:mrow/><mml:mo>′</mml:mo></mml:msup></mml:msup><mml:mo>=</mml:mo><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:msub><mml:mi>β</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math> where <ce:italic>β</ce:italic> is coefficients vector for kernels. Since the kernels are additive, the new function is still a kernel. Given a set of data <ce:italic>X</ce:italic> with labels <ce:italic>Y</ce:italic>, one can rewrite the minimization problem as follows: <mml:math altimg=""""si18.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>min</mml:mi><mml:mi>β</mml:mi></mml:msub><mml:mrow><mml:mi mathvariant=""""normal"""">E</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>K</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>K</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> where <ce:italic>R</ce:italic> is a regularization term and <ce:italic>E</ce:italic> is the error function. The definition of <ce:italic>E</ce:italic> depends on the solving method, which can be the square loss function or the hinge loss function (for SVM algorithms), and <ce:italic>R</ce:italic> is an ℓ<ce:inf loc=""""post""""><ce:italic>n</ce:italic></ce:inf>-norm or any combination of the norms. This optimization problem can then be solved by any of standard optimization methods <ce:cross-ref id=""""crf0056"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Methods	H. Wang, C. Schmid, Action recognition with improved trajectories , Proceedings of the IEEE International Conference on Computer Vision (2013)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0006	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0031		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0048	'To compute the HOF descriptors, optical flow displacement vectors in the horizontal and vertical directions were determined [6][[ refid=''bib0006'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0017"""" view=""""all"""">Feature trajectories have shown to be efficient for representing videos. Wang and Schmid <ce:cross-ref id=""""crf0046"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref> used dense sampled local visual features at several spatial scales. They estimated a homography with RANSAC (random sample consensus) using SURF matching (speeded up robust features) between two consecutive frames. The calculated low-level descriptors were computed on the warped optical flow to capture motion patterns. Below, we explain the feature extraction methods used in this paper: histogram of oriented gradients (HOG), histogram of optical Flow (HOF), and motion boundary histogram (MBH). We also explain the steps of Fisher vectors (FVs).<ce:list id=""""celist0004""""><ce:list-item id=""""celistitem0005""""><ce:label>•</ce:label><ce:para id=""""para0018"""" view=""""all""""><ce:bold>HOG and HOF descriptors:</ce:bold> HOG captures information about the appearance whereas HOF captures local motion information. Wang et al. <ce:cross-ref id=""""crf0047"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> reported that HOG and HOF descriptors yield good results on different activity recognition datasets compared to classical descriptors. To compute the HOG descriptor, we computed gradient magnitude responses in the horizontal and vertical directions. To compute the HOF descriptors, optical flow displacement vectors in the horizontal and vertical directions were determined <ce:cross-ref id=""""crf0048"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>. As a result, a 2D vector field per frame was calculated. The orientations were quantized into eight bins for HOG and nine bins for HOF as described in <ce:cross-ref id=""""crf0049"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>. The length of HOG was 96 (2 × 2 × 3 × 8) while the length of HOF was 108 (2 × 2 × 3 × 9).</ce:para></ce:list-item><ce:list-item id=""""celistitem0006""""><ce:label>•</ce:label><ce:para id=""""para0019"""" view=""""all""""><ce:bold>MBH descriptor:</ce:bold> MBH is a very popular descriptor for video classification and detection tasks. Dalal et al. <ce:cross-ref id=""""crf0050"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> showed the robustness of MBH descriptor against camera and background motion. The simple idea behind MBH is computing oriented gradients over the vertical and horizontal optical flow displacements. Indeed, the horizontal and vertical displacements of the optical flow are treated as gray-level images of the motion displacements. For each optical flow component, a histogram of oriented gradients is computed using the same configuration used for still images. Indeed, information related to motion changes in the object boundaries is obtained using the flow difference whereas information about unmoving objects and camera motion is discarded.</ce:para></ce:list-item><ce:list-item id=""""celistitem0007""""><ce:label>•</ce:label><ce:para id=""""para0020"""" view=""""all""""><ce:bold>Fisher vectors (FVs):</ce:bold> In computer vision field, FVs have been widely used as an image representation by pooling local image features. It is also used as a global descriptor for image classification. FV can be used for frame level pooling, a subsequence level pooling or video level pooling as well.</ce:para><ce:para id=""""para0021"""" view=""""all"""">FV coding was derived from the well-known Fisher kernel, which is based on the assumption that the generation process of a local descriptor <ce:italic>X</ce:italic> can be modeled as a probability density function <ce:italic>p</ce:italic>(<ce:italic>X, θ</ce:italic>). Using the gradient of the <ce:italic>G</ce:italic> log-likelihood, it is possible to describe how the parameters in <ce:italic>θ</ce:italic> contribute to the generation process of <ce:italic>X</ce:italic>. Then, the sample can be described as follows:<ce:display><ce:formula id=""""eq0001""""><ce:label>(1)</ce:label><mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mi>X</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>∇</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></ce:formula></ce:display>The dimensionality of this vector depends on the number of parameters in <ce:italic>θ</ce:italic>. A Gaussian mixture model is used to model the probability density function. Note that <mml:math altimg=""""si5.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math> contains the parameters of the model, were <ce:italic>π, μ, σ</ce:italic> are Gaussian mixture weights, means and diagonal covariance, respectively. An improved Fisher vector was proposed in <ce:cross-ref id=""""crf0051"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> as follows:<ce:display><ce:formula id=""""eq0002""""><ce:label>(2)</ce:label><mml:math altimg=""""si6.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display><ce:display><ce:formula id=""""eq0003""""><ce:label>(3)</ce:label><mml:math altimg=""""si7.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id=""""para0022"""" view=""""all"""">where <ce:italic>γ<ce:inf loc=""""post"""">k</ce:inf></ce:italic> is the weight of local descriptor <ce:italic>x</ce:italic> corresponding to <ce:italic>k<ce:sup loc=""""post"""">th</ce:sup></ce:italic> Gaussian component, and thus<ce:display><ce:formula id=""""eq0004""""><ce:label>(4)</ce:label><mml:math altimg=""""si8.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo>⋯</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id=""""para0023"""" view=""""all"""">The parameter <ce:italic>γ<ce:inf loc=""""post"""">k</ce:inf></ce:italic> can be determined as follows:<ce:display><ce:formula id=""""eq0005""""><ce:label>(5)</ce:label><mml:math altimg=""""si9.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id=""""para0024"""" view=""""all"""">To construct the FV, the gradients of <ce:cross-ref id=""""crf0052"""" refid=""""eq0002"""">Eqs. (2)</ce:cross-ref> and <ce:cross-ref id=""""crf0053"""" refid=""""eq0003"""">(3)</ce:cross-ref> are concatenated as follows:<ce:display><ce:formula id=""""eq0006""""><ce:label>(6)</ce:label><mml:math altimg=""""si10.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>F</mml:mi><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:math></ce:formula></ce:display></ce:para></ce:list-item></ce:list></ce:para>""''"'	cites	AGA	
cites	Methods	H. Wang, M.M. Ullah, A. Klaser, I. Laptev, C. Schmid, Evaluation of local spatio-temporal features for action recognition , British Machine Vision Conference (BMVC), BMVA Press (2009)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0031	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0030		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0049	'Wang et al. [31][[ refid=''bib0031'' ]] reported that HOG and HOF descriptors yield good results on different activity recognition datasets compared to classical descriptors.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0017"""" view=""""all"""">Feature trajectories have shown to be efficient for representing videos. Wang and Schmid <ce:cross-ref id=""""crf0046"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref> used dense sampled local visual features at several spatial scales. They estimated a homography with RANSAC (random sample consensus) using SURF matching (speeded up robust features) between two consecutive frames. The calculated low-level descriptors were computed on the warped optical flow to capture motion patterns. Below, we explain the feature extraction methods used in this paper: histogram of oriented gradients (HOG), histogram of optical Flow (HOF), and motion boundary histogram (MBH). We also explain the steps of Fisher vectors (FVs).<ce:list id=""""celist0004""""><ce:list-item id=""""celistitem0005""""><ce:label>•</ce:label><ce:para id=""""para0018"""" view=""""all""""><ce:bold>HOG and HOF descriptors:</ce:bold> HOG captures information about the appearance whereas HOF captures local motion information. Wang et al. <ce:cross-ref id=""""crf0047"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> reported that HOG and HOF descriptors yield good results on different activity recognition datasets compared to classical descriptors. To compute the HOG descriptor, we computed gradient magnitude responses in the horizontal and vertical directions. To compute the HOF descriptors, optical flow displacement vectors in the horizontal and vertical directions were determined <ce:cross-ref id=""""crf0048"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>. As a result, a 2D vector field per frame was calculated. The orientations were quantized into eight bins for HOG and nine bins for HOF as described in <ce:cross-ref id=""""crf0049"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>. The length of HOG was 96 (2 × 2 × 3 × 8) while the length of HOF was 108 (2 × 2 × 3 × 9).</ce:para></ce:list-item><ce:list-item id=""""celistitem0006""""><ce:label>•</ce:label><ce:para id=""""para0019"""" view=""""all""""><ce:bold>MBH descriptor:</ce:bold> MBH is a very popular descriptor for video classification and detection tasks. Dalal et al. <ce:cross-ref id=""""crf0050"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> showed the robustness of MBH descriptor against camera and background motion. The simple idea behind MBH is computing oriented gradients over the vertical and horizontal optical flow displacements. Indeed, the horizontal and vertical displacements of the optical flow are treated as gray-level images of the motion displacements. For each optical flow component, a histogram of oriented gradients is computed using the same configuration used for still images. Indeed, information related to motion changes in the object boundaries is obtained using the flow difference whereas information about unmoving objects and camera motion is discarded.</ce:para></ce:list-item><ce:list-item id=""""celistitem0007""""><ce:label>•</ce:label><ce:para id=""""para0020"""" view=""""all""""><ce:bold>Fisher vectors (FVs):</ce:bold> In computer vision field, FVs have been widely used as an image representation by pooling local image features. It is also used as a global descriptor for image classification. FV can be used for frame level pooling, a subsequence level pooling or video level pooling as well.</ce:para><ce:para id=""""para0021"""" view=""""all"""">FV coding was derived from the well-known Fisher kernel, which is based on the assumption that the generation process of a local descriptor <ce:italic>X</ce:italic> can be modeled as a probability density function <ce:italic>p</ce:italic>(<ce:italic>X, θ</ce:italic>). Using the gradient of the <ce:italic>G</ce:italic> log-likelihood, it is possible to describe how the parameters in <ce:italic>θ</ce:italic> contribute to the generation process of <ce:italic>X</ce:italic>. Then, the sample can be described as follows:<ce:display><ce:formula id=""""eq0001""""><ce:label>(1)</ce:label><mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mi>X</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>∇</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></ce:formula></ce:display>The dimensionality of this vector depends on the number of parameters in <ce:italic>θ</ce:italic>. A Gaussian mixture model is used to model the probability density function. Note that <mml:math altimg=""""si5.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math> contains the parameters of the model, were <ce:italic>π, μ, σ</ce:italic> are Gaussian mixture weights, means and diagonal covariance, respectively. An improved Fisher vector was proposed in <ce:cross-ref id=""""crf0051"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> as follows:<ce:display><ce:formula id=""""eq0002""""><ce:label>(2)</ce:label><mml:math altimg=""""si6.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display><ce:display><ce:formula id=""""eq0003""""><ce:label>(3)</ce:label><mml:math altimg=""""si7.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id=""""para0022"""" view=""""all"""">where <ce:italic>γ<ce:inf loc=""""post"""">k</ce:inf></ce:italic> is the weight of local descriptor <ce:italic>x</ce:italic> corresponding to <ce:italic>k<ce:sup loc=""""post"""">th</ce:sup></ce:italic> Gaussian component, and thus<ce:display><ce:formula id=""""eq0004""""><ce:label>(4)</ce:label><mml:math altimg=""""si8.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo>⋯</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id=""""para0023"""" view=""""all"""">The parameter <ce:italic>γ<ce:inf loc=""""post"""">k</ce:inf></ce:italic> can be determined as follows:<ce:display><ce:formula id=""""eq0005""""><ce:label>(5)</ce:label><mml:math altimg=""""si9.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id=""""para0024"""" view=""""all"""">To construct the FV, the gradients of <ce:cross-ref id=""""crf0052"""" refid=""""eq0002"""">Eqs. (2)</ce:cross-ref> and <ce:cross-ref id=""""crf0053"""" refid=""""eq0003"""">(3)</ce:cross-ref> are concatenated as follows:<ce:display><ce:formula id=""""eq0006""""><ce:label>(6)</ce:label><mml:math altimg=""""si10.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>F</mml:mi><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:math></ce:formula></ce:display></ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_data_from	AGA	
cites	Methods	N. Dalal, B. Triggs, C. Schmid, Human detection using oriented histograms of flow and appearance , Computer Vision–ECCV 2006, Springer (2006)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0032	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0033		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0050	'Dalal et al. [32][[ refid=''bib0032'' ]] showed the robustness of MBH descriptor against camera and background motion.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0017"""" view=""""all"""">Feature trajectories have shown to be efficient for representing videos. Wang and Schmid <ce:cross-ref id=""""crf0046"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref> used dense sampled local visual features at several spatial scales. They estimated a homography with RANSAC (random sample consensus) using SURF matching (speeded up robust features) between two consecutive frames. The calculated low-level descriptors were computed on the warped optical flow to capture motion patterns. Below, we explain the feature extraction methods used in this paper: histogram of oriented gradients (HOG), histogram of optical Flow (HOF), and motion boundary histogram (MBH). We also explain the steps of Fisher vectors (FVs).<ce:list id=""""celist0004""""><ce:list-item id=""""celistitem0005""""><ce:label>•</ce:label><ce:para id=""""para0018"""" view=""""all""""><ce:bold>HOG and HOF descriptors:</ce:bold> HOG captures information about the appearance whereas HOF captures local motion information. Wang et al. <ce:cross-ref id=""""crf0047"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> reported that HOG and HOF descriptors yield good results on different activity recognition datasets compared to classical descriptors. To compute the HOG descriptor, we computed gradient magnitude responses in the horizontal and vertical directions. To compute the HOF descriptors, optical flow displacement vectors in the horizontal and vertical directions were determined <ce:cross-ref id=""""crf0048"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>. As a result, a 2D vector field per frame was calculated. The orientations were quantized into eight bins for HOG and nine bins for HOF as described in <ce:cross-ref id=""""crf0049"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>. The length of HOG was 96 (2 × 2 × 3 × 8) while the length of HOF was 108 (2 × 2 × 3 × 9).</ce:para></ce:list-item><ce:list-item id=""""celistitem0006""""><ce:label>•</ce:label><ce:para id=""""para0019"""" view=""""all""""><ce:bold>MBH descriptor:</ce:bold> MBH is a very popular descriptor for video classification and detection tasks. Dalal et al. <ce:cross-ref id=""""crf0050"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> showed the robustness of MBH descriptor against camera and background motion. The simple idea behind MBH is computing oriented gradients over the vertical and horizontal optical flow displacements. Indeed, the horizontal and vertical displacements of the optical flow are treated as gray-level images of the motion displacements. For each optical flow component, a histogram of oriented gradients is computed using the same configuration used for still images. Indeed, information related to motion changes in the object boundaries is obtained using the flow difference whereas information about unmoving objects and camera motion is discarded.</ce:para></ce:list-item><ce:list-item id=""""celistitem0007""""><ce:label>•</ce:label><ce:para id=""""para0020"""" view=""""all""""><ce:bold>Fisher vectors (FVs):</ce:bold> In computer vision field, FVs have been widely used as an image representation by pooling local image features. It is also used as a global descriptor for image classification. FV can be used for frame level pooling, a subsequence level pooling or video level pooling as well.</ce:para><ce:para id=""""para0021"""" view=""""all"""">FV coding was derived from the well-known Fisher kernel, which is based on the assumption that the generation process of a local descriptor <ce:italic>X</ce:italic> can be modeled as a probability density function <ce:italic>p</ce:italic>(<ce:italic>X, θ</ce:italic>). Using the gradient of the <ce:italic>G</ce:italic> log-likelihood, it is possible to describe how the parameters in <ce:italic>θ</ce:italic> contribute to the generation process of <ce:italic>X</ce:italic>. Then, the sample can be described as follows:<ce:display><ce:formula id=""""eq0001""""><ce:label>(1)</ce:label><mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mi>X</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>∇</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></ce:formula></ce:display>The dimensionality of this vector depends on the number of parameters in <ce:italic>θ</ce:italic>. A Gaussian mixture model is used to model the probability density function. Note that <mml:math altimg=""""si5.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math> contains the parameters of the model, were <ce:italic>π, μ, σ</ce:italic> are Gaussian mixture weights, means and diagonal covariance, respectively. An improved Fisher vector was proposed in <ce:cross-ref id=""""crf0051"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> as follows:<ce:display><ce:formula id=""""eq0002""""><ce:label>(2)</ce:label><mml:math altimg=""""si6.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display><ce:display><ce:formula id=""""eq0003""""><ce:label>(3)</ce:label><mml:math altimg=""""si7.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id=""""para0022"""" view=""""all"""">where <ce:italic>γ<ce:inf loc=""""post"""">k</ce:inf></ce:italic> is the weight of local descriptor <ce:italic>x</ce:italic> corresponding to <ce:italic>k<ce:sup loc=""""post"""">th</ce:sup></ce:italic> Gaussian component, and thus<ce:display><ce:formula id=""""eq0004""""><ce:label>(4)</ce:label><mml:math altimg=""""si8.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo>⋯</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id=""""para0023"""" view=""""all"""">The parameter <ce:italic>γ<ce:inf loc=""""post"""">k</ce:inf></ce:italic> can be determined as follows:<ce:display><ce:formula id=""""eq0005""""><ce:label>(5)</ce:label><mml:math altimg=""""si9.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id=""""para0024"""" view=""""all"""">To construct the FV, the gradients of <ce:cross-ref id=""""crf0052"""" refid=""""eq0002"""">Eqs. (2)</ce:cross-ref> and <ce:cross-ref id=""""crf0053"""" refid=""""eq0003"""">(3)</ce:cross-ref> are concatenated as follows:<ce:display><ce:formula id=""""eq0006""""><ce:label>(6)</ce:label><mml:math altimg=""""si10.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>F</mml:mi><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:math></ce:formula></ce:display></ce:para></ce:list-item></ce:list></ce:para>""''"'	cites	AGA	
uses_method_in	Methods	I. Laptev, M. Marszalek, C. Schmid, B. Rozenfeld, Learning realistic human actions from movies , Computer Vision and Pattern Recognition, 2008. CVPR 2008. IEEE Conference on, IEEE (2008)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0003	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0032		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0051	'The orientations were quantized into eight bins for HOG and nine bins for HOF as described in [3][[ refid=''bib0003'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0017"""" view=""""all"""">Feature trajectories have shown to be efficient for representing videos. Wang and Schmid <ce:cross-ref id=""""crf0046"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref> used dense sampled local visual features at several spatial scales. They estimated a homography with RANSAC (random sample consensus) using SURF matching (speeded up robust features) between two consecutive frames. The calculated low-level descriptors were computed on the warped optical flow to capture motion patterns. Below, we explain the feature extraction methods used in this paper: histogram of oriented gradients (HOG), histogram of optical Flow (HOF), and motion boundary histogram (MBH). We also explain the steps of Fisher vectors (FVs).<ce:list id=""""celist0004""""><ce:list-item id=""""celistitem0005""""><ce:label>•</ce:label><ce:para id=""""para0018"""" view=""""all""""><ce:bold>HOG and HOF descriptors:</ce:bold> HOG captures information about the appearance whereas HOF captures local motion information. Wang et al. <ce:cross-ref id=""""crf0047"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref> reported that HOG and HOF descriptors yield good results on different activity recognition datasets compared to classical descriptors. To compute the HOG descriptor, we computed gradient magnitude responses in the horizontal and vertical directions. To compute the HOF descriptors, optical flow displacement vectors in the horizontal and vertical directions were determined <ce:cross-ref id=""""crf0048"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>. As a result, a 2D vector field per frame was calculated. The orientations were quantized into eight bins for HOG and nine bins for HOF as described in <ce:cross-ref id=""""crf0049"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>. The length of HOG was 96 (2 × 2 × 3 × 8) while the length of HOF was 108 (2 × 2 × 3 × 9).</ce:para></ce:list-item><ce:list-item id=""""celistitem0006""""><ce:label>•</ce:label><ce:para id=""""para0019"""" view=""""all""""><ce:bold>MBH descriptor:</ce:bold> MBH is a very popular descriptor for video classification and detection tasks. Dalal et al. <ce:cross-ref id=""""crf0050"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> showed the robustness of MBH descriptor against camera and background motion. The simple idea behind MBH is computing oriented gradients over the vertical and horizontal optical flow displacements. Indeed, the horizontal and vertical displacements of the optical flow are treated as gray-level images of the motion displacements. For each optical flow component, a histogram of oriented gradients is computed using the same configuration used for still images. Indeed, information related to motion changes in the object boundaries is obtained using the flow difference whereas information about unmoving objects and camera motion is discarded.</ce:para></ce:list-item><ce:list-item id=""""celistitem0007""""><ce:label>•</ce:label><ce:para id=""""para0020"""" view=""""all""""><ce:bold>Fisher vectors (FVs):</ce:bold> In computer vision field, FVs have been widely used as an image representation by pooling local image features. It is also used as a global descriptor for image classification. FV can be used for frame level pooling, a subsequence level pooling or video level pooling as well.</ce:para><ce:para id=""""para0021"""" view=""""all"""">FV coding was derived from the well-known Fisher kernel, which is based on the assumption that the generation process of a local descriptor <ce:italic>X</ce:italic> can be modeled as a probability density function <ce:italic>p</ce:italic>(<ce:italic>X, θ</ce:italic>). Using the gradient of the <ce:italic>G</ce:italic> log-likelihood, it is possible to describe how the parameters in <ce:italic>θ</ce:italic> contribute to the generation process of <ce:italic>X</ce:italic>. Then, the sample can be described as follows:<ce:display><ce:formula id=""""eq0001""""><ce:label>(1)</ce:label><mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msubsup><mml:mi>G</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mi>X</mml:mi></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>∇</mml:mi><mml:mi>θ</mml:mi></mml:msub><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>X</mml:mi><mml:mo>;</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></ce:formula></ce:display>The dimensionality of this vector depends on the number of parameters in <ce:italic>θ</ce:italic>. A Gaussian mixture model is used to model the probability density function. Note that <mml:math altimg=""""si5.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math> contains the parameters of the model, were <ce:italic>π, μ, σ</ce:italic> are Gaussian mixture weights, means and diagonal covariance, respectively. An improved Fisher vector was proposed in <ce:cross-ref id=""""crf0051"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref> as follows:<ce:display><ce:formula id=""""eq0002""""><ce:label>(2)</ce:label><mml:math altimg=""""si6.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display><ce:display><ce:formula id=""""eq0003""""><ce:label>(3)</ce:label><mml:math altimg=""""si7.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:msqrt><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>/</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id=""""para0022"""" view=""""all"""">where <ce:italic>γ<ce:inf loc=""""post"""">k</ce:inf></ce:italic> is the weight of local descriptor <ce:italic>x</ce:italic> corresponding to <ce:italic>k<ce:sup loc=""""post"""">th</ce:sup></ce:italic> Gaussian component, and thus<ce:display><ce:formula id=""""eq0004""""><ce:label>(4)</ce:label><mml:math altimg=""""si8.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo>⋯</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id=""""para0023"""" view=""""all"""">The parameter <ce:italic>γ<ce:inf loc=""""post"""">k</ce:inf></ce:italic> can be determined as follows:<ce:display><ce:formula id=""""eq0005""""><ce:label>(5)</ce:label><mml:math altimg=""""si9.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></ce:formula></ce:display></ce:para><ce:para id=""""para0024"""" view=""""all"""">To construct the FV, the gradients of <ce:cross-ref id=""""crf0052"""" refid=""""eq0002"""">Eqs. (2)</ce:cross-ref> and <ce:cross-ref id=""""crf0053"""" refid=""""eq0003"""">(3)</ce:cross-ref> are concatenated as follows:<ce:display><ce:formula id=""""eq0006""""><ce:label>(6)</ce:label><mml:math altimg=""""si10.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>F</mml:mi><mml:mi>V</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>K</mml:mi></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:math></ce:formula></ce:display></ce:para></ce:list-item></ce:list></ce:para>""''"'	cites	AGA	
uses_method_in	Methods	F. Aiolli, M. Donini, Easymkl: a scalable multiple kernel learning algorithm , Neurocomputing , vol. 169 (2015), pp.215-224	http://dx.doi.org/10.1016/j.patrec.2017.06.010	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0038>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0039>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0052	'The problem of learning the kernel combination is posed as a min−max problem over variables γ and η. Aiolli and Donini [38][[ refid=''bib0038'' ]] proposed to maximize the distance between the positive and negative samples with a unitary norm vector η as the weak kernels combination vector: [[ formulaid=''id15_pos1'' ]] Consider the following equation: [[ formulaid=''id15_pos2'' ]] If the vector of the rth entry is defined as dr(γ)=γTY^K^rY^γ, then [[ formulaid=''id15_pos3'' ]] Consequently, the main problem can be rewritten as: [[ formulaid=''id15_pos4'' ]] Finding η*, which is a simple analytic solution that maximizes Q: [[ formulaid=''id15_pos5'' ]] and [[ formulaid=''id15_pos6'' ]] The optimal γ is a regularized minimizer of ℓ2-norm of the distances vector.'			FDY+AGA	infered_pred1
uses_method_in	Methods	F. Aiolli, M. Donini, Easymkl: a scalable multiple kernel learning algorithm , Neurocomputing , vol. 169 (2015), pp.215-224	http://dx.doi.org/10.1016/j.patrec.2017.06.010	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0038>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0038>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0053	'A Scalable multiple kernel learning algorithm (EasyMKL): In this paper, we use the EasyMKL method [38][[ refid=''bib0038'' ]] because it can easily deal with hundreds of thousands of kernels and more.'			FDY+AGA	infered_pred1
cites	Related work	M. Jain, J.C. van Gemert, C.G. Snoek, What do 15,000 object categories tell us about classifying and localizing actions? , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2015)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0024	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0018		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0056	'Jain et al. [24][[ refid=''bib0024'' ]] showed how they can take advantage of objects in the videos for action classification.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">Jain et al. <ce:cross-ref id=""""crf0038"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref> showed how they can take advantage of objects in the videos for action classification. The aforementioned methods have a common point, which is capturing the local changes in small temporal window, but they are not designed to capture motion patterns to model the whole video, which is an important factor in some actions.</ce:para>""''"'	cites	AGA	
cites	Experimental results and discussion	B. Fernando, E. Gavves, J.M. Oramas, A. Ghodrati, T. Tuytelaars, Modeling video evolution for action recognition , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2015)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0053		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0057	'Fernando et al. [39][[ refid=''bib0039'' ]] used the time varying mean method for smoothing the feature vectors in order to cope with abrupt changes in human action.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0048"""" view=""""all"""">Fernando et al. <ce:cross-ref id=""""crf0081"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> used the <ce:italic>time varying mean</ce:italic> method for smoothing the feature vectors in order to cope with abrupt changes in human action. They did not use the <ce:italic>moving average</ce:italic> (MA) method for that task because of two reasons:<ce:list id=""""celist0002""""><ce:list-item id=""""celistitem0013""""><ce:label>1.</ce:label><ce:para id=""""para0049"""" view=""""all"""">A window size must be chosen, which is not always straightforward as actions often take place at different times.</ce:para></ce:list-item><ce:list-item id=""""celistitem0014""""><ce:label>2.</ce:label><ce:para id=""""para0050"""" view=""""all"""">The last frames of a video are ignored.</ce:para></ce:list-item></ce:list></ce:para>""''"'	cites	AGA	
cites	Experimental results and discussion	K. Simonyan, A. Zisserman, Two-stream convolutional networks for action recognition in videos , Advances in neural information processing systems (2014)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0013	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0052		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0058	'The model proposed in [13][[ refid=''bib0013'' ]] took approximately one day for one temporal CNN on a system consisting of four NVIDIA Titan cards (it took 3.1 times the training time if a single GPU was used).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0047"""" view=""""all"""">It is clear from <ce:cross-ref id=""""crf0077"""" refid=""""tbl0005"""">Table 5</ce:cross-ref> that the results of the proposed method with HMDB51 and Hollywood2 datasets are comparable to the ones of <ce:cross-ref id=""""crf0078"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>, as a result of the existence of a big number of slow actions in the datasets. The CNN model proposed in <ce:cross-ref id=""""crf0079"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> has a good performance because it represents a higher level of semantic concepts, but it has a high time complexity and requires complicated training passes. In turn, the proposed method is much faster. The model proposed in <ce:cross-ref id=""""crf0080"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> took approximately one day for one temporal CNN on a system consisting of four <ce:italic>NVIDIA Titan cards</ce:italic> (it took 3.1 times the training time if a single GPU was used). In turn, our approach took approximately 16 h on Core i7 2.5GHz CPU with 16GB RAM.</ce:para>""''"'	cites	AGA	
cites	Experimental results and discussion	K. Simonyan, A. Zisserman, Two-stream convolutional networks for action recognition in videos , Advances in neural information processing systems (2014)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0013	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0051		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0059	'The CNN model proposed in [13][[ refid=''bib0013'' ]] has a good performance because it represents a higher level of semantic concepts, but it has a high time complexity and requires complicated training passes.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0047"""" view=""""all"""">It is clear from <ce:cross-ref id=""""crf0077"""" refid=""""tbl0005"""">Table 5</ce:cross-ref> that the results of the proposed method with HMDB51 and Hollywood2 datasets are comparable to the ones of <ce:cross-ref id=""""crf0078"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>, as a result of the existence of a big number of slow actions in the datasets. The CNN model proposed in <ce:cross-ref id=""""crf0079"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> has a good performance because it represents a higher level of semantic concepts, but it has a high time complexity and requires complicated training passes. In turn, the proposed method is much faster. The model proposed in <ce:cross-ref id=""""crf0080"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> took approximately one day for one temporal CNN on a system consisting of four <ce:italic>NVIDIA Titan cards</ce:italic> (it took 3.1 times the training time if a single GPU was used). In turn, our approach took approximately 16 h on Core i7 2.5GHz CPU with 16GB RAM.</ce:para>""''"'	cites	AGA	
cites	Experimental results and discussion	B. Fernando, E. Gavves, J.M. Oramas, A. Ghodrati, T. Tuytelaars, Modeling video evolution for action recognition , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2015)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0050		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0060	'It is clear from Table 5 that the results of the proposed method with HMDB51 and Hollywood2 datasets are comparable to the ones of [39][[ refid=''bib0039'' ]], as a result of the existence of a big number of slow actions in the datasets.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0047"""" view=""""all"""">It is clear from <ce:cross-ref id=""""crf0077"""" refid=""""tbl0005"""">Table 5</ce:cross-ref> that the results of the proposed method with HMDB51 and Hollywood2 datasets are comparable to the ones of <ce:cross-ref id=""""crf0078"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref>, as a result of the existence of a big number of slow actions in the datasets. The CNN model proposed in <ce:cross-ref id=""""crf0079"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> has a good performance because it represents a higher level of semantic concepts, but it has a high time complexity and requires complicated training passes. In turn, the proposed method is much faster. The model proposed in <ce:cross-ref id=""""crf0080"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> took approximately one day for one temporal CNN on a system consisting of four <ce:italic>NVIDIA Titan cards</ce:italic> (it took 3.1 times the training time if a single GPU was used). In turn, our approach took approximately 16 h on Core i7 2.5GHz CPU with 16GB RAM.</ce:para>""''"'	uses_data_from	AGA	
cites	Related work	G. Chéron, I. Laptev, C. Schmid, P-cnn: Pose-based cnn features for action recognition , Proceedings of the IEEE International Conference on Computer Vision (2015)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0019	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0013		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0061	'For instance, [19][[ refid=''bib0019'' ]] represented different parts of human body with motion and appearance based descriptors to extract features from human pose.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0011"""" view=""""all"""">To avoid designing features, it is reasonable to apply deep learning methods <ce:cross-refs id=""""crfs0004"""" refid=""""bib0016 bib0017"""">[16,17][[ refid=''''bib0016 bib0017'''' ]]</ce:cross-refs>. The temporal pattern can thus be captured by the convolutional neural network (CNN) using two approaches. The first approach extends the connectivity of the network architecture along time. An example of this approach was proposed in <ce:cross-ref id=""""crf0031"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. The second approach stacks optical flow frames and inputs them into a CNN <ce:cross-ref id=""""crf0032"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>. This approach is called two-stream neural network because it has two kinds of inputs: raw RGB and stacked optical flow. This network can learn visual appearance and motion information in an unsupervised way from video cubes. Indeed, CNNs have been oriented to capture different types of information. For instance, <ce:cross-ref id=""""crf0033"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> represented different parts of human body with motion and appearance based descriptors to extract features from human pose. These descriptors were calculated from each frame and then aggregated over time to form a video descriptor. They captured temporal patterns by considering temporal differences between frames and then concatenated the difference of vectors. In <ce:cross-ref id=""""crf0034"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>, two CNNs were used to capture both appearance and motion based features in action tubes. The first network is called spatial-CNN network, which takes RGB frames as input and captures the appearance information of the actor and other visual details from the scene as well. The second network is called motion-CNN, which works on the optical flow and captures the temporal patterns of the actors. By combining the output of the hidden layers of the two networks, they extract spatio-temporal features. Srivastava et al. <ce:cross-ref id=""""crf0035"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> used the state of the long-short term memory (LSTM) encoder after observing the last input frame as a video representation. Du et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref> showed that skeleton based action recognition can be managed using a hierarchical recurrent neural network. Another popular way to tackle action recognition using deep neural networks is to combine the CNN and LSTM as demonstrated in <ce:cross-ref id=""""crf0037"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Related work	K. Simonyan, A. Zisserman, Two-stream convolutional networks for action recognition in videos , Advances in neural information processing systems (2014)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0013	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0012		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0062	'The second approach stacks optical flow frames and inputs them into a CNN [13][[ refid=''bib0013'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0011"""" view=""""all"""">To avoid designing features, it is reasonable to apply deep learning methods <ce:cross-refs id=""""crfs0004"""" refid=""""bib0016 bib0017"""">[16,17][[ refid=''''bib0016 bib0017'''' ]]</ce:cross-refs>. The temporal pattern can thus be captured by the convolutional neural network (CNN) using two approaches. The first approach extends the connectivity of the network architecture along time. An example of this approach was proposed in <ce:cross-ref id=""""crf0031"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. The second approach stacks optical flow frames and inputs them into a CNN <ce:cross-ref id=""""crf0032"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>. This approach is called two-stream neural network because it has two kinds of inputs: raw RGB and stacked optical flow. This network can learn visual appearance and motion information in an unsupervised way from video cubes. Indeed, CNNs have been oriented to capture different types of information. For instance, <ce:cross-ref id=""""crf0033"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> represented different parts of human body with motion and appearance based descriptors to extract features from human pose. These descriptors were calculated from each frame and then aggregated over time to form a video descriptor. They captured temporal patterns by considering temporal differences between frames and then concatenated the difference of vectors. In <ce:cross-ref id=""""crf0034"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>, two CNNs were used to capture both appearance and motion based features in action tubes. The first network is called spatial-CNN network, which takes RGB frames as input and captures the appearance information of the actor and other visual details from the scene as well. The second network is called motion-CNN, which works on the optical flow and captures the temporal patterns of the actors. By combining the output of the hidden layers of the two networks, they extract spatio-temporal features. Srivastava et al. <ce:cross-ref id=""""crf0035"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> used the state of the long-short term memory (LSTM) encoder after observing the last input frame as a video representation. Du et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref> showed that skeleton based action recognition can be managed using a hierarchical recurrent neural network. Another popular way to tackle action recognition using deep neural networks is to combine the CNN and LSTM as demonstrated in <ce:cross-ref id=""""crf0037"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Related work	A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, L. Fei-Fei, Large-scale video classification with convolutional neural networks , Proceedings of the IEEE conference on Computer Vision and Pattern Recognition (2014)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0011		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0063	'An example of this approach was proposed in [18][[ refid=''bib0018'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0011"""" view=""""all"""">To avoid designing features, it is reasonable to apply deep learning methods <ce:cross-refs id=""""crfs0004"""" refid=""""bib0016 bib0017"""">[16,17][[ refid=''''bib0016 bib0017'''' ]]</ce:cross-refs>. The temporal pattern can thus be captured by the convolutional neural network (CNN) using two approaches. The first approach extends the connectivity of the network architecture along time. An example of this approach was proposed in <ce:cross-ref id=""""crf0031"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. The second approach stacks optical flow frames and inputs them into a CNN <ce:cross-ref id=""""crf0032"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>. This approach is called two-stream neural network because it has two kinds of inputs: raw RGB and stacked optical flow. This network can learn visual appearance and motion information in an unsupervised way from video cubes. Indeed, CNNs have been oriented to capture different types of information. For instance, <ce:cross-ref id=""""crf0033"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> represented different parts of human body with motion and appearance based descriptors to extract features from human pose. These descriptors were calculated from each frame and then aggregated over time to form a video descriptor. They captured temporal patterns by considering temporal differences between frames and then concatenated the difference of vectors. In <ce:cross-ref id=""""crf0034"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>, two CNNs were used to capture both appearance and motion based features in action tubes. The first network is called spatial-CNN network, which takes RGB frames as input and captures the appearance information of the actor and other visual details from the scene as well. The second network is called motion-CNN, which works on the optical flow and captures the temporal patterns of the actors. By combining the output of the hidden layers of the two networks, they extract spatio-temporal features. Srivastava et al. <ce:cross-ref id=""""crf0035"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> used the state of the long-short term memory (LSTM) encoder after observing the last input frame as a video representation. Du et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref> showed that skeleton based action recognition can be managed using a hierarchical recurrent neural network. Another popular way to tackle action recognition using deep neural networks is to combine the CNN and LSTM as demonstrated in <ce:cross-ref id=""""crf0037"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Related work	J. Yue-Hei Ng, M. Hausknecht, S. Vijayanarasimhan, O. Vinyals, R. Monga, G. Toderici, Beyond short snippets: Deep networks for video classification , Proceedings of the IEEE conference on computer vision and pattern recognition (2015)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0017		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0066	'Another popular way to tackle action recognition using deep neural networks is to combine the CNN and LSTM as demonstrated in [23][[ refid=''bib0023'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0011"""" view=""""all"""">To avoid designing features, it is reasonable to apply deep learning methods <ce:cross-refs id=""""crfs0004"""" refid=""""bib0016 bib0017"""">[16,17][[ refid=''''bib0016 bib0017'''' ]]</ce:cross-refs>. The temporal pattern can thus be captured by the convolutional neural network (CNN) using two approaches. The first approach extends the connectivity of the network architecture along time. An example of this approach was proposed in <ce:cross-ref id=""""crf0031"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. The second approach stacks optical flow frames and inputs them into a CNN <ce:cross-ref id=""""crf0032"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>. This approach is called two-stream neural network because it has two kinds of inputs: raw RGB and stacked optical flow. This network can learn visual appearance and motion information in an unsupervised way from video cubes. Indeed, CNNs have been oriented to capture different types of information. For instance, <ce:cross-ref id=""""crf0033"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> represented different parts of human body with motion and appearance based descriptors to extract features from human pose. These descriptors were calculated from each frame and then aggregated over time to form a video descriptor. They captured temporal patterns by considering temporal differences between frames and then concatenated the difference of vectors. In <ce:cross-ref id=""""crf0034"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>, two CNNs were used to capture both appearance and motion based features in action tubes. The first network is called spatial-CNN network, which takes RGB frames as input and captures the appearance information of the actor and other visual details from the scene as well. The second network is called motion-CNN, which works on the optical flow and captures the temporal patterns of the actors. By combining the output of the hidden layers of the two networks, they extract spatio-temporal features. Srivastava et al. <ce:cross-ref id=""""crf0035"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> used the state of the long-short term memory (LSTM) encoder after observing the last input frame as a video representation. Du et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref> showed that skeleton based action recognition can be managed using a hierarchical recurrent neural network. Another popular way to tackle action recognition using deep neural networks is to combine the CNN and LSTM as demonstrated in <ce:cross-ref id=""""crf0037"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Related work	Y. Du, W. Wang, L. Wang, Hierarchical recurrent neural network for skeleton based action recognition , Proceedings of the IEEE conference on computer vision and pattern recognition (2015)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0022	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0016		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0067	'Du et al. [22][[ refid=''bib0022'' ]] showed that skeleton based action recognition can be managed using a hierarchical recurrent neural network.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0011"""" view=""""all"""">To avoid designing features, it is reasonable to apply deep learning methods <ce:cross-refs id=""""crfs0004"""" refid=""""bib0016 bib0017"""">[16,17][[ refid=''''bib0016 bib0017'''' ]]</ce:cross-refs>. The temporal pattern can thus be captured by the convolutional neural network (CNN) using two approaches. The first approach extends the connectivity of the network architecture along time. An example of this approach was proposed in <ce:cross-ref id=""""crf0031"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. The second approach stacks optical flow frames and inputs them into a CNN <ce:cross-ref id=""""crf0032"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>. This approach is called two-stream neural network because it has two kinds of inputs: raw RGB and stacked optical flow. This network can learn visual appearance and motion information in an unsupervised way from video cubes. Indeed, CNNs have been oriented to capture different types of information. For instance, <ce:cross-ref id=""""crf0033"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> represented different parts of human body with motion and appearance based descriptors to extract features from human pose. These descriptors were calculated from each frame and then aggregated over time to form a video descriptor. They captured temporal patterns by considering temporal differences between frames and then concatenated the difference of vectors. In <ce:cross-ref id=""""crf0034"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>, two CNNs were used to capture both appearance and motion based features in action tubes. The first network is called spatial-CNN network, which takes RGB frames as input and captures the appearance information of the actor and other visual details from the scene as well. The second network is called motion-CNN, which works on the optical flow and captures the temporal patterns of the actors. By combining the output of the hidden layers of the two networks, they extract spatio-temporal features. Srivastava et al. <ce:cross-ref id=""""crf0035"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> used the state of the long-short term memory (LSTM) encoder after observing the last input frame as a video representation. Du et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref> showed that skeleton based action recognition can be managed using a hierarchical recurrent neural network. Another popular way to tackle action recognition using deep neural networks is to combine the CNN and LSTM as demonstrated in <ce:cross-ref id=""""crf0037"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Related work	N. Srivastava, E. Mansimov, R. Salakhutdinov, Unsupervised learning of video representations using lstms. , ICML (2015)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0021	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0015		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0068	'Srivastava et al. [21][[ refid=''bib0021'' ]] used the state of the long-short term memory (LSTM) encoder after observing the last input frame as a video representation.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0011"""" view=""""all"""">To avoid designing features, it is reasonable to apply deep learning methods <ce:cross-refs id=""""crfs0004"""" refid=""""bib0016 bib0017"""">[16,17][[ refid=''''bib0016 bib0017'''' ]]</ce:cross-refs>. The temporal pattern can thus be captured by the convolutional neural network (CNN) using two approaches. The first approach extends the connectivity of the network architecture along time. An example of this approach was proposed in <ce:cross-ref id=""""crf0031"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. The second approach stacks optical flow frames and inputs them into a CNN <ce:cross-ref id=""""crf0032"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>. This approach is called two-stream neural network because it has two kinds of inputs: raw RGB and stacked optical flow. This network can learn visual appearance and motion information in an unsupervised way from video cubes. Indeed, CNNs have been oriented to capture different types of information. For instance, <ce:cross-ref id=""""crf0033"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> represented different parts of human body with motion and appearance based descriptors to extract features from human pose. These descriptors were calculated from each frame and then aggregated over time to form a video descriptor. They captured temporal patterns by considering temporal differences between frames and then concatenated the difference of vectors. In <ce:cross-ref id=""""crf0034"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>, two CNNs were used to capture both appearance and motion based features in action tubes. The first network is called spatial-CNN network, which takes RGB frames as input and captures the appearance information of the actor and other visual details from the scene as well. The second network is called motion-CNN, which works on the optical flow and captures the temporal patterns of the actors. By combining the output of the hidden layers of the two networks, they extract spatio-temporal features. Srivastava et al. <ce:cross-ref id=""""crf0035"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> used the state of the long-short term memory (LSTM) encoder after observing the last input frame as a video representation. Du et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref> showed that skeleton based action recognition can be managed using a hierarchical recurrent neural network. Another popular way to tackle action recognition using deep neural networks is to combine the CNN and LSTM as demonstrated in <ce:cross-ref id=""""crf0037"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Related work	G. Gkioxari, J. Malik, Finding action tubes , The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2015)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0020	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0014		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0069	'In [20][[ refid=''bib0020'' ]], two CNNs were used to capture both appearance and motion based features in action tubes.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0011"""" view=""""all"""">To avoid designing features, it is reasonable to apply deep learning methods <ce:cross-refs id=""""crfs0004"""" refid=""""bib0016 bib0017"""">[16,17][[ refid=''''bib0016 bib0017'''' ]]</ce:cross-refs>. The temporal pattern can thus be captured by the convolutional neural network (CNN) using two approaches. The first approach extends the connectivity of the network architecture along time. An example of this approach was proposed in <ce:cross-ref id=""""crf0031"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. The second approach stacks optical flow frames and inputs them into a CNN <ce:cross-ref id=""""crf0032"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>. This approach is called two-stream neural network because it has two kinds of inputs: raw RGB and stacked optical flow. This network can learn visual appearance and motion information in an unsupervised way from video cubes. Indeed, CNNs have been oriented to capture different types of information. For instance, <ce:cross-ref id=""""crf0033"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> represented different parts of human body with motion and appearance based descriptors to extract features from human pose. These descriptors were calculated from each frame and then aggregated over time to form a video descriptor. They captured temporal patterns by considering temporal differences between frames and then concatenated the difference of vectors. In <ce:cross-ref id=""""crf0034"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>, two CNNs were used to capture both appearance and motion based features in action tubes. The first network is called spatial-CNN network, which takes RGB frames as input and captures the appearance information of the actor and other visual details from the scene as well. The second network is called motion-CNN, which works on the optical flow and captures the temporal patterns of the actors. By combining the output of the hidden layers of the two networks, they extract spatio-temporal features. Srivastava et al. <ce:cross-ref id=""""crf0035"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> used the state of the long-short term memory (LSTM) encoder after observing the last input frame as a video representation. Du et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref> showed that skeleton based action recognition can be managed using a hierarchical recurrent neural network. Another popular way to tackle action recognition using deep neural networks is to combine the CNN and LSTM as demonstrated in <ce:cross-ref id=""""crf0037"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Experimental results and discussion	H. Kuehne, H. Jhuang, E. Garrote, T. Poggio, T. Serre, Hmdb: a large video database for human motion recognition , IEEE International Conference on Computer Vision (ICCV), IEEE (2011)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0041	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0044		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0070	'HMDB51 is a generic action classification dataset [41][[ refid=''bib0041'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0042"""" view=""""all"""">HMDB51 is a generic action classification dataset <ce:cross-ref id=""""crf0064"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref>. The videos of this dataset were collected from YouTube and some movies. It contains 6670 videos, which were further grouped into 51 action classes, in which each class contains around 100 videos. To measure the performance of the proposed method, we used three training and testing splits and then the average accuracy over them was computed.</ce:para>""''"'	uses_data_from	AGA	
cites	Experimental results and discussion	B. Fernando, E. Gavves, J.M. Oramas, A. Ghodrati, T. Tuytelaars, Modeling video evolution for action recognition , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2015)	http://dx.doi.org/10.1016/j.patrec.2017.06.010	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/ctx/ctx0054		54	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-06-010/itrp/0074	'The proposed method works better than the baseline of [39][[ refid=''bib0039'' ]] in the case of slow actions since it makes the input sequences more generalized and lightens the unnecessary details.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0053"""" view=""""all"""">The proposed method also outperforms fresh deep learning approaches because the coherence analysis step suppresses the redundant information in the videos. In other words, we suppress unnecessary information via computing one FV for each subsequence. <ce:cross-ref id=""""crf0083"""" refid=""""fig0003"""">Fig. 3</ce:cross-ref><ce:float-anchor refid=""""fig0003""""/> shows the confusion matrix of Hollywood2 dataset. As shown in <ce:cross-ref id=""""crf0084"""" refid=""""tbl0007"""">Table 7</ce:cross-ref><ce:float-anchor refid=""""tbl0007""""/>, with Hollywood2 database our method gives better results in the case of slow actions (with less dramatic changes) as in the following cases: AnswerPhone, FightPerson, SitDown, SitUp and StandUp. The proposed method works better than the baseline of <ce:cross-ref id=""""crf0085"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> in the case of slow actions since it makes the input sequences more generalized and lightens the unnecessary details.</ce:para>""''"'	cites	AGA	
cites	Related work and contributions	D. Xu, E. Ricci, Learning deep representations of appearance and motion for anomalous event detection , Proceedings of British Machine Vision Conference (2015)	http://dx.doi.org/10.1016/j.patrec.2017.07.016	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0020		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0003	'In general, the main limitation of tracking methods in complex and crowded scenes is the presence of occluded objects, which degrade the anomaly detection performance [10][[ refid=''bib0010'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0020"""" view=""""all"""">Jiang et al. <ce:cross-ref id=""""crf0035"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> proposed three different levels of spatio-temporal contexts to be extracted in order to perform the tracking process of all moving objects in the video. Brun et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> proposed a different approach using a string kernel and tracking-based approach for evaluating the similarity between trajectories and define a novelty score for different zones in a scene. Similarly, Yang et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> used a trajectory segmentation to perform the tracking process and a multi-instance learning to detect abnormal trajectories. In general, the main limitation of tracking methods in complex and crowded scenes is the presence of occluded objects, which degrade the anomaly detection performance <ce:cross-ref id=""""crf0038"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Related work and contributions	D. Xu, E. Ricci, Learning deep representations of appearance and motion for anomalous event detection , Proceedings of British Machine Vision Conference (2015)	http://dx.doi.org/10.1016/j.patrec.2017.07.016	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0026		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0006	'For instance, the one-class Support Vector Machine (SVM) was used by Xu and Ricci [10][[ refid=''bib0010'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0022"""" view=""""all"""">Regarding the learning methods, the most used approach is based on the one-class classifier, which has been extensively used for anomaly detection problems. For instance, the one-class Support Vector Machine (SVM) was used by Xu and Ricci <ce:cross-ref id=""""crf0043"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. Also, a similar one-class approach, named space-time Markov Random Field model, was devised by Kim and Grauman <ce:cross-ref id=""""crf0044"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>. There are some approaches that include both the feature extraction and the learning method in a single step. In <ce:cross-ref id=""""crf0045"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, a sparse combination is proposed, and it turns the original problem into a few costless small-scale least square optimization problem. Following a similar idea, a sparse reconstruction and a novel dictionary selection is presented in <ce:cross-ref id=""""crf0046"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref>. In <ce:cross-ref id=""""crf0047"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>, a probability model that takes the spatial and temporal contextual information into account is learned. The framework is unsupervised, without the need to label the training data to perform the anomaly detection task. It is also possible to include some <ce:italic>a priori</ce:italic> knowledge about the application. However, by using a different step for the classification process, it is needed to select the most appropriate classifier, in addition to specifying the descriptors in the feature extraction stage. These issues, by themselves, are hard to address for given applications. In this work, we promote the use of CAE in the context of anomaly detection. Differently from traditional methods, using a CAE, the feature extraction is integrated to the classification process. We propose the CAE’s reconstruction error as the “anomaly” score so that one can discriminate between normal and abnormal events in a video.</ce:para>""''"'	cites	AGA	
cites	Deep learning with auto-encoders	M. Hasan, J. Choi, J. Neumann, A.K. Roy-Chowdhury, L.S. Davis, Learning temporal regularity in video sequences , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (2016)	http://dx.doi.org/10.1016/j.patrec.2017.07.016			http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0046		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0022	'The learned filters in the deconvolutional layers serve as the base to reconstruct the shape of the input, taking into account the required reshape of the output, as presented in [18][[ refid=''bib0018'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0031"""" view=""""all"""">The deconvolutional layer performs an inverse operation of the convolution layer with deconvolutions. The learned filters in the deconvolutional layers serve as the base to reconstruct the shape of the input, taking into account the required reshape of the output, as presented in <ce:cross-ref id=""""crf0070"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. Convolutional and deconvolutional layers can be stacked to build deep architectures for CAEs. The filters in the first layers of the convolution layer (and later layers in the deconvolution layers) extract low-level features, whilst later layers can extract high-level features of the input frames, which in this work, are basically motion and appearance frames.</ce:para>""''"'	cites	AGA	
cites	Deep learning with auto-encoders	A. Krizhevsky, G.E. Hinton, Using very deep autoencoders for content-based image retrieval , Proceedings of 19th European Symposium on Artificial Neural Networks (2011)	http://dx.doi.org/10.1016/j.patrec.2017.07.016			http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0021	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0042		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0026	'They can also be built using deep architectures to learn a compressed representation of the input, by limiting the number of hidden units [21][[ refid=''bib0021'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0028"""" view=""""all"""">The drawback of the above formulation is that, without additional constraints, the final mapping is the identity. There are different approaches proposed in the literature to circumvent such limitation. Denoising AEs (DAE) <ce:cross-ref id=""""crf0062"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> are one of the most used models. A DAE reconstructs the input by using its partially corrupted version, where the corrupted version is obtained by adding some amount of noise, distributed according to the characteristics of the input vector. They can also be built using deep architectures to learn a compressed representation of the input, by limiting the number of hidden units <ce:cross-ref id=""""crf0063"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Experiments and results	D. Xu, E. Ricci, Learning deep representations of appearance and motion for anomalous event detection , Proceedings of British Machine Vision Conference (2015)	http://dx.doi.org/10.1016/j.patrec.2017.07.016	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0066		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0028	'For the UCSD Ped2 dataset, our result (FR+ED case) is close to that obtained by Xu and Ricci [10][[ refid=''bib0010'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0075"""" view=""""all""""><ce:cross-ref id=""""crf0116"""" refid=""""tbl0002"""">Table 2</ce:cross-ref> allows a broad comparison between the state-of-the-art results to ours, for the four cases. For the UCSD Ped2 dataset, our result (FR+ED case) is close to that obtained by Xu and Ricci <ce:cross-ref id=""""crf0117"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. For the Avenue dataset, our result (FR+ED case) was better than those achieved by Hasan et al. <ce:cross-ref id=""""crf0118"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. On other hand, for the UCSD Ped1 dataset, our result is much worse than that presented by Saligrama and Chen <ce:cross-ref id=""""crf0119"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>. Notice that all the above-mentioned state-of-the-art approaches are very elaborate, including many schemes such as data-augmentation, division of frames into patches to reduce iterations between objects, large CAE architectures, etc. However, no method achieve the best results for all datasets.</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	A.A. Sodemann, M.P. Ross, B.J. Borghetti, A review of anomaly detection in automated surveillance , IEEE Trans. Syst., Man Cybern. Part C , vol. 42 (2012), pp.1257-1272	http://dx.doi.org/10.1016/j.patrec.2017.07.016	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0001		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0029	'The classification of human behavior in videos has been a subject of great interest in computer vision [1][[ refid=''bib0001'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">The classification of human behavior in videos has been a subject of great interest in computer vision <ce:cross-ref id=""""crf0010"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. Particularly, in recent years, many efforts have been focused to detect anomalous (or abnormal) behaviors in automated video surveillance <ce:cross-refs id=""""crfs0001"""" refid=""""bib0002 bib0003 bib0004 bib0005 bib0006 bib0007 bib0008 bib0009 bib0010"""">[2–10][[ refid=''''bib0002 bib0003 bib0004 bib0005 bib0006 bib0007 bib0008 bib0009 bib0010'''' ]]</ce:cross-refs>. However, the definition of anomalous events in video surveillance is not only context-dependent but, also, dependent of human-defined semantics. As a matter of fact, there is no general rule for such a definition, except by the qualitative observation that anomalous events occur infrequently in comparison with normal events <ce:cross-ref id=""""crf0011"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Introduction	D. Xu, E. Ricci, Learning deep representations of appearance and motion for anomalous event detection , Proceedings of British Machine Vision Conference (2015)	http://dx.doi.org/10.1016/j.patrec.2017.07.016	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0007		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0047	'As a result, some features may perform well in particular domains and drive classifiers to bad classification accuracy in others, even combining motion and appearance features [10][[ refid=''bib0010'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0010"""" view=""""all"""">A key issue for anomaly detection methods is the extraction of relevant features from the raw image, to enable a good classification of different types of anomalies. In the literature, the most common approach is to use spatial and temporal features to model activity patterns. Such features are based on standard computer vision techniques and other variants, such as Histogram of Oriented Gradients (HOG) <ce:cross-ref id=""""crf0013"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>, Histogram of Optical Flow (HOF) <ce:cross-ref id=""""crf0014"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>, social force model <ce:cross-ref id=""""crf0015"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>, dense trajectories <ce:cross-ref id=""""crf0016"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref>, and dynamic textures <ce:cross-ref id=""""crf0017"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>. However, as pointed by Perlin and Lopes <ce:cross-ref id=""""crf0018"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>, those features, called hand-crafted descriptors, require that some <ce:italic>a priori</ce:italic> knowledge have to be incorporated during the training step. Such knowledge depends mostly on the surveillance target and it is difficult to define across different applications. As a result, some features may perform well in particular domains and drive classifiers to bad classification accuracy in others, even combining motion and appearance features <ce:cross-ref id=""""crf0019"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
uses_method_in	Proposed methods	J. Seward, Bzip2 C library, 2017.	http://dx.doi.org/10.1016/j.patrec.2017.07.016	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0041	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0060		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0058	'Considering that Kolmogorov complexity is not directly computable, we used the bzip2 algorithm [41][[ refid=''bib0041'' ]] as real-world compressor, so as to provide an approximation to NCR(x), according to Eq. (7).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0054"""" view=""""all"""">In our approach, we propose to use Kolmogorov complexity to estimate the spatial complexity of the video datasets (see <ce:cross-ref id=""""crf0098"""" refid=""""sec0008"""">Section 4</ce:cross-ref>). Considering that Kolmogorov complexity is not directly computable, we used the bzip2 algorithm <ce:cross-ref id=""""crf0099"""" refid=""""bib0041"""">[41][[ refid=''''bib0041'''' ]]</ce:cross-ref> as real-world compressor, so as to provide an approximation to <ce:italic>NCR</ce:italic>(<ce:italic>x</ce:italic>), according to <ce:cross-ref id=""""crf0100"""" refid=""""eq0007"""">Eq. (7)</ce:cross-ref>. Both train and test video subsets of all datasets were submitted to the compression algorithm. Then, the spatial complexity coefficient (<ce:italic>SCC</ce:italic>) was computed according to <ce:cross-ref id=""""crf0101"""" refid=""""eq0016"""">Eq. (16)</ce:cross-ref>, as follows:<ce:display><ce:formula id=""""eq0016""""><ce:label>(16)</ce:label><mml:math altimg=""""si32.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>S</mml:mi><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>N</mml:mi><mml:mi>C</mml:mi><mml:mi>R</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo>)</mml:mo><mml:mspace width=""""0.28em""""/><mml:mo>×</mml:mo><mml:mspace width=""""0.28em""""/><mml:mi>N</mml:mi><mml:mi>C</mml:mi><mml:mi>R</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>where <ce:italic>train</ce:italic> and <ce:italic>test</ce:italic> are the corresponding datasets. Supposing that the value computed for <ce:italic>SCC</ce:italic>(<ce:italic>train, test</ce:italic>) of a given dataset is larger than that computed for another dataset, this indicates that the former has a higher spatial complexity than the latter.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Proposed methods	X. Glorot, Y. Bengio, Understanding the difficulty of training deep feedforward neural networks , Proceedings of 13th International Conference on Artificial Intelligence and Statistics (2010)	http://dx.doi.org/10.1016/j.patrec.2017.07.016	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0047	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0058		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0059	'The weights were initialized using the Xavier algorithm [47][[ refid=''bib0047'' ]] that automatically determines the scale of initialization based on the number of input and output neurons.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0050"""" view=""""all"""">The training method uses the back propagation algorithm to minimize the reconstruction error <ce:italic>e</ce:italic> shown in <ce:cross-ref id=""""crf0090"""" refid=""""eq0002"""">Eq. (2)</ce:cross-ref>. However, as mentioned before, in our approach the input data is a cuboid <mml:math altimg=""""si27.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""bold"""">X</mml:mi></mml:math>. Therefore, the reconstruction error is evaluated over all dimensions. To optimize the loss function, we use stochastic gradient descent with the adaptive sub-gradient method AdaGrad <ce:cross-ref id=""""crf0091"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref>. It computes a dimension-wise learning rate that adapts the rate of gradients by a function of all previous updates in each dimension. AdaGrad is widely used due to its theoretical guarantee of convergence and empirical success. The weights were initialized using the Xavier algorithm <ce:cross-ref id=""""crf0092"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref> that automatically determines the scale of initialization based on the number of input and output neurons. It keeps the signal in a reasonable range of values through many layers.</ce:para>""''"'	uses_method_in	AGA	
cites	Related work and contributions	R. Cilibrasi, P.M.B. Vitányi, Clustering by compression , IEEE Trans. Inf. Theory , vol. 51 (2005), pp.1523-1545	http://dx.doi.org/10.1016/j.patrec.2017.07.016	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0038	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0037		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0062	'Long ago, Cilibrasi and Vitányi [38][[ refid=''bib0038'' ]] proposed the use of the Kolmogorov complexity to measure image complexity.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0025"""" view=""""all"""">An important issue for anomaly detection performance to be reviewed in this work is the spatial complexity of videos. Long ago, Cilibrasi and Vitányi <ce:cross-ref id=""""crf0057"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> proposed the use of the Kolmogorov complexity to measure image complexity. Later, Yu and Winkler <ce:cross-ref id=""""crf0058"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> showed that the Kolmogorov-based complexity of an image usually increases with decreasing resolution and that the spatial information is strongly correlated with compression-based complexity measures. From the above-mentioned works, we hypothesize that the video complexity can play an important role in the classification process, affecting its performance. This can be especially true for anomaly detection methods, where only one class is used during the training step. In this sense, a complexity measure may correlate with <ce:italic>a priori</ce:italic> performance limitation for a particular dataset. Therefore, we propose a measure of video complexity and investigate a relationship between it and the performance of a CAE to detect anomalies in videos.</ce:para>""''"'	cites	AGA	
cites	Related work and contributions	T. Xiao, C. Zhang, H. Zha, Learning to detect anomalies in surveillance video , IEEE Signal Process. Lett. , vol. 22 (2015), pp.1477-1481	http://dx.doi.org/10.1016/j.patrec.2017.07.016	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0030		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0068	'In [27][[ refid=''bib0027'' ]], a probability model that takes the spatial and temporal contextual information into account is learned.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0022"""" view=""""all"""">Regarding the learning methods, the most used approach is based on the one-class classifier, which has been extensively used for anomaly detection problems. For instance, the one-class Support Vector Machine (SVM) was used by Xu and Ricci <ce:cross-ref id=""""crf0043"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. Also, a similar one-class approach, named space-time Markov Random Field model, was devised by Kim and Grauman <ce:cross-ref id=""""crf0044"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref>. There are some approaches that include both the feature extraction and the learning method in a single step. In <ce:cross-ref id=""""crf0045"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, a sparse combination is proposed, and it turns the original problem into a few costless small-scale least square optimization problem. Following a similar idea, a sparse reconstruction and a novel dictionary selection is presented in <ce:cross-ref id=""""crf0046"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref>. In <ce:cross-ref id=""""crf0047"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>, a probability model that takes the spatial and temporal contextual information into account is learned. The framework is unsupervised, without the need to label the training data to perform the anomaly detection task. It is also possible to include some <ce:italic>a priori</ce:italic> knowledge about the application. However, by using a different step for the classification process, it is needed to select the most appropriate classifier, in addition to specifying the descriptors in the feature extraction stage. These issues, by themselves, are hard to address for given applications. In this work, we promote the use of CAE in the context of anomaly detection. Differently from traditional methods, using a CAE, the feature extraction is integrated to the classification process. We propose the CAE’s reconstruction error as the “anomaly” score so that one can discriminate between normal and abnormal events in a video.</ce:para>""''"'	cites	AGA	
cites	Related work and contributions	D. Xu, E. Ricci, Learning deep representations of appearance and motion for anomalous event detection , Proceedings of British Machine Vision Conference (2015)	http://dx.doi.org/10.1016/j.patrec.2017.07.016	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0033		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0069	'In [10][[ refid=''bib0010'' ]], an appearance and motion SDAE was proposed to extract features of video surveillance datasets.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0024"""" view=""""all"""">In <ce:cross-ref id=""""crf0053"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>, an appearance and motion SDAE was proposed to extract features of video surveillance datasets. Based on the features learned, multiple one-class SVM models were used to predict the anomaly scores and classify each frame. Despite the fact that AEs are very efficient methods for given applications, they cannot capture the 2D structure in image and video sequences, and the Convolutional AE (CAE) architecture can be more appropriated <ce:cross-ref id=""""crf0054"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>. A similar procedure is presented in <ce:cross-ref id=""""crf0055"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>, where two AE (SDAE and CAE) were used to learn regular motion patterns from video sequences. The main advantage of this approach is the possibility of capturing regularities (degrees of normality) from multiple datasets jointly. Nevertheless, the anomalies may be characterized by motion and appearance features, thus requiring that the input of the CAE includes such sort of features. In this work, we propose the aggregation of high-level features, such as optical flow and edge filter, with the input frames, in order to allow the identification of different types of anomalies. At this point, it is important to emphasize that CAEs for anomaly detection in video are still underexplored in the recent literature <ce:cross-ref id=""""crf0056"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA	
cites	Deep learning with auto-encoders	D.E. Rumelhart, G.E. Hinton, R.J. Williams, Learning representations by back-propagating errors , Nature , vol. 323 (1986), pp.533-536	http://dx.doi.org/10.1016/j.patrec.2017.07.016			http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0019	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0039		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0073	'The AE was introduced by Rumelhart et al. [19][[ refid=''bib0019'' ]] and is regarded as an unsupervised fully connected one-hidden-layer neural network to learn from unlabeled datasets.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0026"""" view=""""all"""">The AE was introduced by Rumelhart et al. <ce:cross-ref id=""""crf0059"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> and is regarded as an unsupervised fully connected one-hidden-layer neural network to learn from unlabeled datasets. The idea is that the AE is trained to reconstruct the input pattern at the output of the network. An AE takes an input <mml:math altimg=""""si1.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant=""""double-struck"""">R</mml:mi></mml:mrow><mml:mi>d</mml:mi></mml:msup></mml:mrow></mml:math> and first maps it to the latent representation (hidden layer) <mml:math altimg=""""si2.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi mathvariant=""""bold"""">h</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant=""""double-struck"""">R</mml:mi></mml:mrow><mml:msup><mml:mi>d</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:msup></mml:mrow></mml:math> using the mapping function <mml:math altimg=""""si3.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi mathvariant=""""bold"""">h</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mstyle mathvariant=""""normal""""><mml:mi>Θ</mml:mi></mml:mstyle></mml:msub><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">Wx</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> with parameters <mml:math altimg=""""si4.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mstyle mathvariant=""""normal""""><mml:mi>Θ</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi mathvariant=""""bold"""">W</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math>. For reconstructing the input, a reverse mapping of <mml:math altimg=""""si5.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>f</mml:mi><mml:mo>:</mml:mo><mml:mi mathvariant=""""bold"""">y</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:msup><mml:mstyle mathvariant=""""normal""""><mml:mi>Θ</mml:mi></mml:mstyle><mml:mo>′</mml:mo></mml:msup></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi><mml:mi>f</mml:mi><mml:mi>W</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mi mathvariant=""""bold"""">h</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> with <mml:math altimg=""""si6.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msup><mml:mstyle mathvariant=""""normal""""><mml:mi>Θ</mml:mi></mml:mstyle><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant=""""bold"""">W</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mo>′</mml:mo></mml:msup><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math> is used. The parameters <mml:math altimg=""""si7.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""bold"""">W</mml:mi></mml:math> learnt from the input layer to the hidden layer compose the encoder and the parameters <ce:bold>W</ce:bold>′ learnt from the hidden layer to the output layer define the decoder. The decoder parameters are normally related to the parameters in the encoder by <mml:math altimg=""""si8.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant=""""bold"""">W</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant=""""bold"""">W</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math> <ce:cross-ref id=""""crf0060"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Proposed methods	J. Duchi, E. Hazan, Y. Singer, Adaptive subgradient methods for online learning and stochastic optimization , J. Mach. Learn. Res. , vol. 12 (2011), pp.2121-2159	http://dx.doi.org/10.1016/j.patrec.2017.07.016	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0046	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0057		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0075	'To optimize the loss function, we use stochastic gradient descent with the adaptive sub-gradient method AdaGrad [46][[ refid=''bib0046'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0050"""" view=""""all"""">The training method uses the back propagation algorithm to minimize the reconstruction error <ce:italic>e</ce:italic> shown in <ce:cross-ref id=""""crf0090"""" refid=""""eq0002"""">Eq. (2)</ce:cross-ref>. However, as mentioned before, in our approach the input data is a cuboid <mml:math altimg=""""si27.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""bold"""">X</mml:mi></mml:math>. Therefore, the reconstruction error is evaluated over all dimensions. To optimize the loss function, we use stochastic gradient descent with the adaptive sub-gradient method AdaGrad <ce:cross-ref id=""""crf0091"""" refid=""""bib0046"""">[46][[ refid=''''bib0046'''' ]]</ce:cross-ref>. It computes a dimension-wise learning rate that adapts the rate of gradients by a function of all previous updates in each dimension. AdaGrad is widely used due to its theoretical guarantee of convergence and empirical success. The weights were initialized using the Xavier algorithm <ce:cross-ref id=""""crf0092"""" refid=""""bib0047"""">[47][[ refid=''''bib0047'''' ]]</ce:cross-ref> that automatically determines the scale of initialization based on the number of input and output neurons. It keeps the signal in a reasonable range of values through many layers.</ce:para>""''"'	uses_method_in	AGA	
cites	Proposed methods	M. Hasan, J. Choi, J. Neumann, A.K. Roy-Chowdhury, L.S. Davis, Learning temporal regularity in video sequences , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (2016)	http://dx.doi.org/10.1016/j.patrec.2017.07.016	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0056		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0076	'Our architecture is similar to the model recently proposed by Hasan et al. [18][[ refid=''bib0018'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0046"""" view=""""all"""">The CAE has a deep architecture organized in different encoder and decoder layers. The encoder consists of convolutional layers, whilst the decoder is based on deconvolutional layers – that are the reverse of the encoder with no tied weights. Our architecture is similar to the model recently proposed by Hasan et al. <ce:cross-ref id=""""crf0085"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. It is composed of three convolutional layers and two pooling layers on the encoder side, and the same reversed structure in the decoder side. The CAE is trained to learn the signature of normal events, considering the optimization presented in <ce:cross-ref id=""""crf0086"""" refid=""""eq0003"""">Eq. (3)</ce:cross-ref>. The architecture of our CAE-based approach is shown in <ce:cross-ref id=""""crf0087"""" refid=""""fig0002"""">Fig. 2</ce:cross-ref><ce:float-anchor refid=""""fig0002""""/>.</ce:para>""''"'	cites	AGA	
cites	Appearance and motion filters	R. Szeliski, Computer Vision: Algorithms and Applications , None, Springer-Verlag (2010)	http://dx.doi.org/10.1016/j.patrec.2017.07.016			http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0043	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0052		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0080	'Considering that a pixel located at (x, y) in the frame t with the intensity I(x, y, t) moves by Δx, Δy and Δt in the subsequent frame, by the brightness constancy assumption [43][[ refid=''bib0043'' ]], one can state that: [[ formulaid=''id22_pos0'' ]]'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0037"""" view=""""all"""">The general idea of the optical flow is to represent some kind of displacement or velocity related to the distance that a pixel moves between two subsequent frames. Considering that a pixel located at (<ce:italic>x, y</ce:italic>) in the frame <ce:italic>t</ce:italic> with the intensity <ce:italic>I</ce:italic>(<ce:italic>x, y, t</ce:italic>) moves by <ce:italic>Δx, Δy</ce:italic> and <ce:italic>Δt</ce:italic> in the subsequent frame, by the brightness constancy assumption <ce:cross-ref id=""""crf0075"""" refid=""""bib0043"""">[43][[ refid=''''bib0043'''' ]]</ce:cross-ref>, one can state that:<ce:display><ce:formula id=""""eq0008""""><ce:label>(8)</ce:label><mml:math altimg=""""si22.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>I</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>I</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mstyle mathvariant=""""normal""""><mml:mi>Δ</mml:mi></mml:mstyle><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mstyle mathvariant=""""normal""""><mml:mi>Δ</mml:mi></mml:mstyle><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mstyle mathvariant=""""normal""""><mml:mi>Δ</mml:mi></mml:mstyle><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display></ce:para>""''"'	cites	AGA	
cites	Related work and contributions	A. Adam, E. Rivlin, I. Shimshoni, D. Reinitz, Robust real-time unusual event detection using multiple fixed-location monitors , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 30 (2008), pp.555-560	http://dx.doi.org/10.1016/j.patrec.2017.07.016	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0015		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0092	'The limitation of this type of sensor is the field of view and resolution of the camera [23][[ refid=''bib0023'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0019"""" view=""""all"""">Video anomaly detection methods can be categorized according to the surveillance target, type of sensors, feature extraction process, and modeling (learning) methods <ce:cross-ref id=""""crf0032"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. Regarding surveillance target, the anomaly detection can be performed on traffic, individuals, crowds, and single or multiple objects. As for the types of sensors, visible-spectrum cameras are the most frequently used. The limitation of this type of sensor is the field of view and resolution of the camera <ce:cross-ref id=""""crf0033"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. Methods for feature extraction are dependent on the surveillance target. There are two main groups: those which first perform target tracking by analyzing individual moving objects in the scene (extracting complex motion features), and those that extract features directly from the image at the pixel level <ce:cross-ref id=""""crf0034"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Experiments and results	M. Hasan, J. Choi, J. Neumann, A.K. Roy-Chowdhury, L.S. Davis, Learning temporal regularity in video sequences , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (2016)	http://dx.doi.org/10.1016/j.patrec.2017.07.016	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0067		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0098	'For the Avenue dataset, our result (FR+ED case) was better than those achieved by Hasan et al. [18][[ refid=''bib0018'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0075"""" view=""""all""""><ce:cross-ref id=""""crf0116"""" refid=""""tbl0002"""">Table 2</ce:cross-ref> allows a broad comparison between the state-of-the-art results to ours, for the four cases. For the UCSD Ped2 dataset, our result (FR+ED case) is close to that obtained by Xu and Ricci <ce:cross-ref id=""""crf0117"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. For the Avenue dataset, our result (FR+ED case) was better than those achieved by Hasan et al. <ce:cross-ref id=""""crf0118"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. On other hand, for the UCSD Ped1 dataset, our result is much worse than that presented by Saligrama and Chen <ce:cross-ref id=""""crf0119"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>. Notice that all the above-mentioned state-of-the-art approaches are very elaborate, including many schemes such as data-augmentation, division of frames into patches to reduce iterations between objects, large CAE architectures, etc. However, no method achieve the best results for all datasets.</ce:para>""''"'	uses_data_from	AGA	
cites	Experiments and results	V. Saligrama, Z. Chen, Video anomaly detection based on local statistical aggregates , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (2012)	http://dx.doi.org/10.1016/j.patrec.2017.07.016	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/br/bib0048	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/sec/7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/ctx/ctx0068		68	7	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-07-016/itrp/0100	'On other hand, for the UCSD Ped1 dataset, our result is much worse than that presented by Saligrama and Chen [48][[ refid=''bib0048'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0075"""" view=""""all""""><ce:cross-ref id=""""crf0116"""" refid=""""tbl0002"""">Table 2</ce:cross-ref> allows a broad comparison between the state-of-the-art results to ours, for the four cases. For the UCSD Ped2 dataset, our result (FR+ED case) is close to that obtained by Xu and Ricci <ce:cross-ref id=""""crf0117"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. For the Avenue dataset, our result (FR+ED case) was better than those achieved by Hasan et al. <ce:cross-ref id=""""crf0118"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. On other hand, for the UCSD Ped1 dataset, our result is much worse than that presented by Saligrama and Chen <ce:cross-ref id=""""crf0119"""" refid=""""bib0048"""">[48][[ refid=''''bib0048'''' ]]</ce:cross-ref>. Notice that all the above-mentioned state-of-the-art approaches are very elaborate, including many schemes such as data-augmentation, division of frames into patches to reduce iterations between objects, large CAE architectures, etc. However, no method achieve the best results for all datasets.</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	K. Barnard, D. Forsyth, Learning the semantics of words and pictures , ICCV (2001)	http://dx.doi.org/10.1016/j.patrec.2017.09.012	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-012/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-012/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-012/ctx/ctx0001		38	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-012/itrp/0027	'Image tagging, also known as multi-label classification, is an important topic in computer vision and machine learning for its wide applications on scene classification and information retrieval [1][[ refid=''bib0001'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0004"""" view=""""all"""">Image tagging, also known as multi-label classification, is an important topic in computer vision and machine learning for its wide applications on scene classification and information retrieval <ce:cross-ref id=""""crf0014"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. It is still a challenge because of variations in scales, orientations and appearances for the same object, as well as occlusion between different classes. In addition, the multi-label setting is harder than the single labeling case, due to several tags used to describe the content of the image, such as objects, events, and scene descriptions.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments	A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks , Advances in Neural Information Processing Systems (2012)	http://dx.doi.org/10.1016/j.patrec.2017.09.012	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-012/br/bib0023>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-012/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-012/ctx/ctx0019>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-012/itrp/0060	'In all the following experiments, we first transferred the parameters of the trained CNN model [23][[ refid=''bib0023'' ]] to our scene categorization problems.'			FDY+AGA	infered_pred1
cites	Proposed methodology	C. Basu, H. Hirsh, W.W. Cohen, C.G. Nevill-Manning, Technical paper recommendation: a study in combining multiple information sources , J. Artif. Intell. Res.(JAIR) , vol. 14 (2001), pp.231-252	http://dx.doi.org/10.1016/j.patrec.2017.09.020	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/ctx/ctx0011		16	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/itrp/0001	'Prior research in [1][[ refid=''bib0001'' ]] found that using more sources of information can lead to better performance.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0021"""" view=""""all"""">To gather information about each reviewer, we use global and local public sources. Global sources like Aminer<ce:cross-ref id=""""crf0034"""" refid=""""fn0002""""><ce:sup loc=""""post"""">2</ce:sup></ce:cross-ref><ce:footnote id=""""fn0002""""><ce:label>2</ce:label><ce:note-para id=""""cenotep0002"""" view=""""all""""><ce:inter-ref id=""""interref0002"""" xlink:href=""""http://aminer.org"""" xlink:type=""""simple"""">aminer.org</ce:inter-ref>.</ce:note-para></ce:footnote> provide information on researchers from around the world in many different fields. In contrast, local sources like TDX<ce:cross-ref id=""""crf0035"""" refid=""""fn0003""""><ce:sup loc=""""post"""">3</ce:sup></ce:cross-ref><ce:footnote id=""""fn0003""""><ce:label>3</ce:label><ce:note-para id=""""cenotep0003"""" view=""""all""""><ce:inter-ref id=""""interref0003"""" xlink:href=""""http://tdx.cat"""" xlink:type=""""simple"""">tdx.cat</ce:inter-ref>.</ce:note-para></ce:footnote> focus on a particular field of study and/or region of the world. Prior research in <ce:cross-ref id=""""crf0036"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> found that using more sources of information can lead to better performance.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Preliminaries	R.R. Yager, Quantifier guided aggregation using owa operators , Int. J. Intell. Syst. , vol. 11 (1996), pp.49-73	http://dx.doi.org/10.1016/j.patrec.2017.09.020			http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/br/bib0020	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/ctx/ctx0010		16	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/itrp/0002	'There are different methods to obtain the weight vector W. For our purpose we will use a linguistic quantifier guided aggregation, a process in which the decision maker selects a quantifier representing the proportion of criteria necessary for a good solution [20][[ refid=''bib0020'' ]].Definition 3.2Given a regular increasing monotone (RIM) quantifier, Q:R→R, we define the vector of weights W=(w1,…,wp) as follows: [[ formulaid=''id6_pos0'' ]]'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">There are different methods to obtain the weight vector W. For our purpose we will use a linguistic quantifier guided aggregation, a process in which the decision maker selects a quantifier representing the proportion of criteria necessary for a good solution <ce:cross-ref id=""""crf0032"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>.<ce:enunciation id=""""enun0002""""><ce:label>Definition 3.2</ce:label><ce:para id=""""para0017"""" view=""""all"""">Given a regular increasing monotone (RIM) quantifier, <mml:math altimg=""""si9.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>Q</mml:mi><mml:mo>:</mml:mo><mml:mi mathvariant=""""double-struck"""">R</mml:mi><mml:mo>→</mml:mo><mml:mi mathvariant=""""double-struck"""">R</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math> we define the vector of weights <mml:math altimg=""""si10.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> as follows:<ce:display><ce:formula id=""""eq0002""""><ce:label>(2)</ce:label><mml:math altimg=""""si11.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>h</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mfrac><mml:mi>h</mml:mi><mml:mi>p</mml:mi></mml:mfrac><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>Q</mml:mi><mml:mrow><mml:mo stretchy=""""true"""">(</mml:mo><mml:mfrac><mml:mrow><mml:mi>h</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:mfrac><mml:mo stretchy=""""true"""">)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width=""""0.16em""""/><mml:mi>h</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>}</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display></ce:para></ce:enunciation></ce:para>""''"'	cites	AGA	
uses_method_in	Results and evaluation	M. Karimzadehgan, C. Zhai, G. Belford, Multi-aspect expertise matching for review assignment , Proceedings of the 17th ACM Conference on Information and Knowledge Management, ACM (2008)	http://dx.doi.org/10.1016/j.patrec.2017.09.020	results		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/br/bib0011	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/ctx/ctx0016		16	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/itrp/0003	'In order to compare the results to that of an expert, a grounded truth was created similar to [11][[ refid=''bib0011'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0056"""" view=""""all"""">In order to compare the results to that of an expert, a grounded truth was created similar to <ce:cross-ref id=""""crf0052"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>. An expert from the Artificial Intelligence community in Catalunya was consulted for the validation process. He assigned research topics from the CCIA conference to each of the Scientific Committee members. Then, he read the abstracts of each paper submitted to the conference and assigned relevant CCIA conference topics to each paper. This gave us a gold standard to evaluate our system.</ce:para>""''"'	cites	AGA	
cites	Related work	Y. Kalmukov, Architecture of a conference management system providing advanced paper assignment features,	http://dx.doi.org/10.1016/j.patrec.2017.09.020	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/br/bib0009	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/ctx/ctx0008		16	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/itrp/0004	'Information acquired explicitly requires input from the reviewer, whereas information acquired implicitly entails eliciting information in an automated way [9][[ refid=''bib0009'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">As can be seen in <ce:cross-ref id=""""crf0029"""" refid=""""tbl0001"""">Table 1</ce:cross-ref><ce:float-anchor refid=""""tbl0001""""/>, variables in both the reviewer and paper profiles were collected explicitly and/or implicitly. Information acquired explicitly requires input from the reviewer, whereas information acquired implicitly entails eliciting information in an automated way <ce:cross-ref id=""""crf0030"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>. Most of the papers consider a set of predetermined keywords either for profiling reviewers or papers where a conference provides a set of keywords from which authors and reviewers select to represent their papers or expertise, respectively. However, the range of approaches considered for the matching method is very wide, varying from crisp to fuzzy methods. Regarding the types of applications, all of them are oriented towards either the conference reviewer assignment problem or assignment of experts to project proposals.</ce:para>""''"'	cites	AGA	
uses_method_in	Preliminaries	R.R. Yager, On ordered weighted averaging aggregation operators in multicriteria decisionmaking , Syst. Man Cybern. IEEE Trans. , vol. 18 (1988), pp.183-190	http://dx.doi.org/10.1016/j.patrec.2017.09.020			<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/br/bib0019>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/ctx/ctx0009>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/itrp/0005	'In this section we provide a summary of the OWA operator introduced by Yager [19][[ refid=''bib0019'' ]] which will be applied in the proposed methodology.Definition 3.1An OWA operator of dimension n is a mapping of ϕ:Rp→R with an associated weighting vector W such that wh ∈ [0, 1] and ∑h=1pwh=1.'			FDY+AGA	infered_pred1
uses_method_in	Results and evaluation	N.D. Sidiropoulos, E. Tsakonas, Signal processing and optimization tools for conference review and session assignment , IEEE Signal Process. Mag. , vol. 32 (2015), pp.141-155	http://dx.doi.org/10.1016/j.patrec.2017.09.020	results		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/br/bib0016	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/ctx/ctx0015		16	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/itrp/0006	'Second, we compared the reviewer to paper assignments with the quality index (QI) defined in [16][[ refid=''bib0016'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0053"""" view=""""all"""">Second, we compared the reviewer to paper assignments with the quality index (QI) defined in <ce:cross-ref id=""""crf0051"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>. This measure represents, for each reviewer, the average percentage match between his/her topics and the topics of each paper to which he/she has been assigned. Out of the 46 assigned reviewers the mean and standard deviation of the QI for our method were 0.693 and 0.284, respectively.</ce:para>""''"'	cites_as_review	AGA	
cites	Proposed methodology	D.M. Blei, A.Y. Ng, M.I. Jordan, Latent dirichlet allocation , J. Mach. Learn. Res. , vol. 3 (2003), pp.993-1022	http://dx.doi.org/10.1016/j.patrec.2017.09.020	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/br/bib0002	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/ctx/ctx0012		16	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/itrp/0010	'Originally introduced in [2][[ refid=''bib0002'' ]], it is an unsupervised topic modeling method.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0027"""" view=""""all"""">First, we determine a set of <ce:italic>concepts</ce:italic> from the entire set of paper submissions. The Latent Dirichlet Allocation (LDA) approach has been considered to generate this list. Originally introduced in <ce:cross-ref id=""""crf0037"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>, it is an unsupervised topic modeling method. LDA has been used in other reviewer assignment systems such as the Toronto Paper Matching System <ce:cross-ref id=""""crf0038"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>. In our case, LDA considers the entire collection of <ce:italic>n</ce:italic> paper submissions <mml:math altimg=""""si15.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:math> and provides a set of concepts, <mml:math altimg=""""si16.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>s</mml:mi></mml:msubsup></mml:math>. Each concept is defined by a group of words. In addition, LDA calculates the proportion of each concept <ce:italic>C<ce:inf loc=""""post"""">j</ce:inf></ce:italic> represented in each paper <ce:italic>P<ce:inf loc=""""post"""">i</ce:inf>, α<ce:inf loc=""""post"""">ij</ce:inf></ce:italic>, and satisfies,<ce:display><ce:formula id=""""eq0003""""><ce:label>(3)</ce:label><mml:math altimg=""""si17.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>s</mml:mi></mml:munderover><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display></ce:para>""''"'	uses_method_in	AGA	
cites	Proposed methodology	L. Charlin, R.S. Zemel, The Toronto paper matching system: an automated paper-reviewer assignment system , in: ICML: Workshop on Peer Reviewing and Publishing Models (PEER) , vol. 10 (2013), pp.None	http://dx.doi.org/10.1016/j.patrec.2017.09.020	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/br/bib0003	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/ctx/ctx0013		16	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/itrp/0011	'LDA has been used in other reviewer assignment systems such as the Toronto Paper Matching System [3][[ refid=''bib0003'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0027"""" view=""""all"""">First, we determine a set of <ce:italic>concepts</ce:italic> from the entire set of paper submissions. The Latent Dirichlet Allocation (LDA) approach has been considered to generate this list. Originally introduced in <ce:cross-ref id=""""crf0037"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>, it is an unsupervised topic modeling method. LDA has been used in other reviewer assignment systems such as the Toronto Paper Matching System <ce:cross-ref id=""""crf0038"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>. In our case, LDA considers the entire collection of <ce:italic>n</ce:italic> paper submissions <mml:math altimg=""""si15.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup></mml:math> and provides a set of concepts, <mml:math altimg=""""si16.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>s</mml:mi></mml:msubsup></mml:math>. Each concept is defined by a group of words. In addition, LDA calculates the proportion of each concept <ce:italic>C<ce:inf loc=""""post"""">j</ce:inf></ce:italic> represented in each paper <ce:italic>P<ce:inf loc=""""post"""">i</ce:inf>, α<ce:inf loc=""""post"""">ij</ce:inf></ce:italic>, and satisfies,<ce:display><ce:formula id=""""eq0003""""><ce:label>(3)</ce:label><mml:math altimg=""""si17.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>s</mml:mi></mml:munderover><mml:msub><mml:mi>α</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display></ce:para>""''"'	uses_method_in	AGA	
cites	Introduction	C. Basu, H. Hirsh, W.W. Cohen, C.G. Nevill-Manning, Technical paper recommendation: a study in combining multiple information sources , J. Artif. Intell. Res.(JAIR) , vol. 14 (2001), pp.231-252	http://dx.doi.org/10.1016/j.patrec.2017.09.020	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/ctx/ctx0002		16	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/itrp/0015	'A reviewer may bid on papers for their novelty rather than their alignment with his/her research interests [1][[ refid=''bib0001'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0005"""" view=""""all"""">A number of academic research and commercial software have tried to address the automation of the reviewer assignment problem <ce:cross-refs id=""""crfs0001"""" refid=""""bib0003 bib0004 bib0015"""">[3,4,15][[ refid=''''bib0003 bib0004 bib0015'''' ]]</ce:cross-refs>. Reviewer preferences or bids are used to represent reviewer research interests. However, some shortcomings can be associated with the bidding process. A reviewer may bid on papers for their novelty rather than their alignment with his/her research interests <ce:cross-ref id=""""crf0018"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. In addition, reviewers may search for papers using keywords and bid on papers returned in their search rather than considering all the papers in the conference <ce:cross-ref id=""""crf0019"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites_as_review	AGA	
cites	Introduction	L. Charlin, R.S. Zemel, The Toronto paper matching system: an automated paper-reviewer assignment system , in: ICML: Workshop on Peer Reviewing and Publishing Models (PEER) , vol. 10 (2013), pp.None	http://dx.doi.org/10.1016/j.patrec.2017.09.020	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/br/bib0003	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/ctx/ctx0003		16	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/itrp/0016	'In addition, reviewers may search for papers using keywords and bid on papers returned in their search rather than considering all the papers in the conference [3][[ refid=''bib0003'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0005"""" view=""""all"""">A number of academic research and commercial software have tried to address the automation of the reviewer assignment problem <ce:cross-refs id=""""crfs0001"""" refid=""""bib0003 bib0004 bib0015"""">[3,4,15][[ refid=''''bib0003 bib0004 bib0015'''' ]]</ce:cross-refs>. Reviewer preferences or bids are used to represent reviewer research interests. However, some shortcomings can be associated with the bidding process. A reviewer may bid on papers for their novelty rather than their alignment with his/her research interests <ce:cross-ref id=""""crf0018"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. In addition, reviewers may search for papers using keywords and bid on papers returned in their search rather than considering all the papers in the conference <ce:cross-ref id=""""crf0019"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites_as_review	AGA	
cites	Introduction	D.K. Tayal, P. Saxena, A. Sharma, G. Khanna, S. Gupta, New method for solving reviewer assignment problem using type-2 fuzzy sets and fuzzy functions , Appl. Intell. , vol. 40 (2014), pp.54-73	http://dx.doi.org/10.1016/j.patrec.2017.09.020	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/ctx/ctx0006		16	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/itrp/0023	'As argued in [18][[ refid=''bib0018'' ]], there exists imprecision associated with reviewer expertise levels.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0008"""" view=""""all"""">As argued in <ce:cross-ref id=""""crf0021"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>, there exists imprecision associated with reviewer expertise levels. However, often in prior studies, reviewer expertise across different domains has been considered as a crisp set. As our information comes from multiple sources, an additional natural uncertainty exists. Therefore, we consider an Ordered Weighted Averaging (OWA) aggregation function <ce:cross-ref id=""""crf0022"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> to summarize the information coming from different sources and rank the candidate reviewers for each paper.</ce:para>""''"'	cites_as_review	AGA	
uses_method_in	Introduction	R.R. Yager, On ordered weighted averaging aggregation operators in multicriteria decisionmaking , Syst. Man Cybern. IEEE Trans. , vol. 18 (1988), pp.183-190	http://dx.doi.org/10.1016/j.patrec.2017.09.020	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/br/bib0019>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/ctx/ctx0007>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-09-020/itrp/0024	'Therefore, we consider an Ordered Weighted Averaging (OWA) aggregation function [19][[ refid=''bib0019'' ]] to summarize the information coming from different sources and rank the candidate reviewers for each paper.'			FDY+AGA	infered_pred1
uses_method_in	The proposed approach	A. Graves, G. Wayne, I. Danihelka, Neural turing machines, arXiv preprint	http://dx.doi.org/10.1016/j.patrec.2017.10.012			http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0008	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0021		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0006	'Since Neural Turing Machine [8][[ refid=''bib0008'' ]] can capture very long-term information with an external memory matrix, we utilize it as a further encoder of the CNN features to extract the temporal dynamics.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0021"""" view=""""all"""">RNNs are often used to extract temporal information between video frames. Although LSTM can well handle “the vanishing and exploding gradient problem” <ce:cross-ref id=""""crf0027"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>, it can’t memorize long-range temporal information due to the limited capacity of memory cells. Since Neural Turing Machine <ce:cross-ref id=""""crf0028"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref> can capture very long-term information with an external memory matrix, we utilize it as a further encoder of the CNN features to extract the temporal dynamics. The same memory matrix interacts with the decoder to provide additional temporal information.</ce:para>""''"'	cites	AGA	
uses_method_in	The proposed approach	A. Graves, G. Wayne, I. Danihelka, Neural turing machines, arXiv preprint	http://dx.doi.org/10.1016/j.patrec.2017.10.012			http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0008	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0026		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0007	'We utilize Neural Turing Machine [8][[ refid=''bib0008'' ]] to memorize the long-term temporal information.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0031"""" view=""""all"""">Although LSTM can well handle “the vanishing and exploding gradient problem”, it can’t deal with the long-period dependency between video frames. We utilize Neural Turing Machine <ce:cross-ref id=""""crf0034"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref> to memorize the long-term temporal information. Thus, the encoder and the decoder shares an external memory matrix which supplies additional temporal dynamics while generating texts.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments and preprocessing	L. Yao, A. Torabi, K. Cho, N. Ballas, C. Pal, H. Larochelle, A. Courville, Describing videos by exploiting temporal structure , CVPR (2015)	http://dx.doi.org/10.1016/j.patrec.2017.10.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0007	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0029		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0013	'We follow the splits made by [7][[ refid=''bib0007'' ]], separating the datasets into a training set of 1200 clips, a validation set of 100 clips and a test set of 670 clips.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0044"""" view=""""all"""">The MSVD dataset has 1970 open domain clips collected from YouTube and annotated using a crowd sourcing platform. It contains multiple topics including sports, cooking and movies. Each video has multiple natural language descriptions and the dataset has more than 80,000 captions in total. We follow the splits made by <ce:cross-ref id=""""crf0040"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>, separating the datasets into a training set of 1200 clips, a validation set of 100 clips and a test set of 670 clips.</ce:para>""''"'	uses_data_from	AGA	
cites	Related work	S. Venugopalan, H. Xu, J. Donahue, M. Rohrbach, R. Mooney, K. Saenko, Translating videos to natural language using deep recurrent neural networks , NAACL HLT (2015)	http://dx.doi.org/10.1016/j.patrec.2017.10.012	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0016	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0009		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0015	'Venugopalan et al. first apply it to generate descriptions of video clips with a CNN-based encoder and a LSTM-based decoder [16][[ refid=''bib0016'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">Video captioning draws more and more attention due to its importance in bridging vision and language. To solve this problem, variety of methods have been proposed, which can be mainly divided into two categories. The first category focuses on the identification of (subject, verb, object) triplets with visual classifiers, and captions are generated by combining predicted triplets with predefined sentence templates <ce:cross-refs id=""""crfs0003"""" refid=""""bib0013 bib0014"""">[13,14][[ refid=''''bib0013 bib0014'''' ]]</ce:cross-refs>. The template-based approaches obviously cannot express the richness of language and have the limited potential to unseen data. The second category is inspired by the encoder-decoder architecture originally used in machine translation <ce:cross-ref id=""""crf0015"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>. Venugopalan et al. first apply it to generate descriptions of video clips with a CNN-based encoder and a LSTM-based decoder <ce:cross-ref id=""""crf0016"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>. However, the temporal information of videos is inevitably left out with simple mean-pooling of CNN features. Thus, Xu et al. additionally utilize a recurrent neural network to capture the temporal dynamics <ce:cross-ref id=""""crf0017"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref>. Moreover, Zhu et al. train a Multirate Visual Recurrent Model (MVRM) to better incorporate both past and future temporal information <ce:cross-ref id=""""crf0018"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. Other works have then followed these kinds of approaches.</ce:para>""''"'	cites	AGA	
cites	Experiments and preprocessing	L. Yao, A. Torabi, K. Cho, N. Ballas, C. Pal, H. Larochelle, A. Courville, Describing videos by exploiting temporal structure , CVPR (2015)	http://dx.doi.org/10.1016/j.patrec.2017.10.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0007	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0041		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0025	'Compared with SA [7][[ refid=''bib0007'' ]], our method additionally utilizes memory networks to capture temporal dynamics for more intact visual representations.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0050"""" view=""""all"""">We compare our model with other five state-of-the-art methods <ce:cross-refs id=""""crfs0008"""" refid=""""bib0007 bib0019 bib0020 bib0023 bib0041"""">[7,19,20,23,41][[ refid=''''bib0007 bib0019 bib0020 bib0023 bib0041'''' ]]</ce:cross-refs> using single visual feature for video captioning. The experiment results of BLEU, METEOR and CIDER evaluation metrics are shown in <ce:cross-ref id=""""crf0056"""" refid=""""tbl0002"""">Table 2</ce:cross-ref><ce:float-anchor refid=""""tbl0002""""/>. Here we obtain comparable results with other state-of-the-art methods. Compared with SA <ce:cross-ref id=""""crf0057"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>, our method additionally utilizes memory networks to capture temporal dynamics for more intact visual representations. We gain a large margin performance improvement over SA, which implies the effectiveness of the memory networks for video captioning. Besides SA, M<ce:sup loc=""""post"""">3</ce:sup><ce:cross-ref id=""""crf0058"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> is the most similar method to ours. It also has an external memory matrix for the LSTM-based decoder. M<ce:sup loc=""""post"""">3</ce:sup>, however, only utilize the external memory matrix for long-range visual-textual information interactions. The temporal dynamics has not been well captured since the temporal order of input video frames doesn’t influence the captioning results. We first exploit the potential of memory networks to extract temporal dynamics. Our model outperforms all other methods except M<ce:sup loc=""""post"""">3</ce:sup>-google <ce:cross-ref id=""""crf0059"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> in terms of BLEU. It is because BLEU emphasizes more on N-gram similarity while our model combines visual concepts with temporal dynamics directly which sacrifices the semantic consistency to some extent. However, we outperform <ce:italic>M</ce:italic><ce:sup loc=""""post"""">3</ce:sup> on all metrics on MSR-VTT <ce:cross-ref id=""""crf0060"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> dataset with longer videos, which implies the importance of temporal dynamics for video captioning. Also, we achieve better performance in METEOR compared with other methods except HRNE <ce:cross-ref id=""""crf0061"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> because HRNE focus more on building a fine-grained hierarchical structure for captioning. It is beneficial for appropriate mapping of unigrams which is crucial for the METTOR metric.</ce:para>""''"'	uses_method_in	AGA	
cites	Experiments and preprocessing	J. Wang, W. Wang, Y. Huang, L. Wang, T. Tan, Multimodal memory modelling for video captioning, arXiv preprint	http://dx.doi.org/10.1016/j.patrec.2017.10.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0042		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0026	'Besides SA, M3[23][[ refid=''bib0023'' ]] is the most similar method to ours.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0050"""" view=""""all"""">We compare our model with other five state-of-the-art methods <ce:cross-refs id=""""crfs0008"""" refid=""""bib0007 bib0019 bib0020 bib0023 bib0041"""">[7,19,20,23,41][[ refid=''''bib0007 bib0019 bib0020 bib0023 bib0041'''' ]]</ce:cross-refs> using single visual feature for video captioning. The experiment results of BLEU, METEOR and CIDER evaluation metrics are shown in <ce:cross-ref id=""""crf0056"""" refid=""""tbl0002"""">Table 2</ce:cross-ref><ce:float-anchor refid=""""tbl0002""""/>. Here we obtain comparable results with other state-of-the-art methods. Compared with SA <ce:cross-ref id=""""crf0057"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>, our method additionally utilizes memory networks to capture temporal dynamics for more intact visual representations. We gain a large margin performance improvement over SA, which implies the effectiveness of the memory networks for video captioning. Besides SA, M<ce:sup loc=""""post"""">3</ce:sup><ce:cross-ref id=""""crf0058"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> is the most similar method to ours. It also has an external memory matrix for the LSTM-based decoder. M<ce:sup loc=""""post"""">3</ce:sup>, however, only utilize the external memory matrix for long-range visual-textual information interactions. The temporal dynamics has not been well captured since the temporal order of input video frames doesn’t influence the captioning results. We first exploit the potential of memory networks to extract temporal dynamics. Our model outperforms all other methods except M<ce:sup loc=""""post"""">3</ce:sup>-google <ce:cross-ref id=""""crf0059"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> in terms of BLEU. It is because BLEU emphasizes more on N-gram similarity while our model combines visual concepts with temporal dynamics directly which sacrifices the semantic consistency to some extent. However, we outperform <ce:italic>M</ce:italic><ce:sup loc=""""post"""">3</ce:sup> on all metrics on MSR-VTT <ce:cross-ref id=""""crf0060"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> dataset with longer videos, which implies the importance of temporal dynamics for video captioning. Also, we achieve better performance in METEOR compared with other methods except HRNE <ce:cross-ref id=""""crf0061"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> because HRNE focus more on building a fine-grained hierarchical structure for captioning. It is beneficial for appropriate mapping of unigrams which is crucial for the METTOR metric.</ce:para>""''"'	uses_method_in	AGA	
cites	Experiments and preprocessing	J. Wang, W. Wang, Y. Huang, L. Wang, T. Tan, Multimodal memory modelling for video captioning, arXiv preprint	http://dx.doi.org/10.1016/j.patrec.2017.10.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0043		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0027	'Our model outperforms all other methods except M3-google [23][[ refid=''bib0023'' ]] in terms of BLEU.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0050"""" view=""""all"""">We compare our model with other five state-of-the-art methods <ce:cross-refs id=""""crfs0008"""" refid=""""bib0007 bib0019 bib0020 bib0023 bib0041"""">[7,19,20,23,41][[ refid=''''bib0007 bib0019 bib0020 bib0023 bib0041'''' ]]</ce:cross-refs> using single visual feature for video captioning. The experiment results of BLEU, METEOR and CIDER evaluation metrics are shown in <ce:cross-ref id=""""crf0056"""" refid=""""tbl0002"""">Table 2</ce:cross-ref><ce:float-anchor refid=""""tbl0002""""/>. Here we obtain comparable results with other state-of-the-art methods. Compared with SA <ce:cross-ref id=""""crf0057"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>, our method additionally utilizes memory networks to capture temporal dynamics for more intact visual representations. We gain a large margin performance improvement over SA, which implies the effectiveness of the memory networks for video captioning. Besides SA, M<ce:sup loc=""""post"""">3</ce:sup><ce:cross-ref id=""""crf0058"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> is the most similar method to ours. It also has an external memory matrix for the LSTM-based decoder. M<ce:sup loc=""""post"""">3</ce:sup>, however, only utilize the external memory matrix for long-range visual-textual information interactions. The temporal dynamics has not been well captured since the temporal order of input video frames doesn’t influence the captioning results. We first exploit the potential of memory networks to extract temporal dynamics. Our model outperforms all other methods except M<ce:sup loc=""""post"""">3</ce:sup>-google <ce:cross-ref id=""""crf0059"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> in terms of BLEU. It is because BLEU emphasizes more on N-gram similarity while our model combines visual concepts with temporal dynamics directly which sacrifices the semantic consistency to some extent. However, we outperform <ce:italic>M</ce:italic><ce:sup loc=""""post"""">3</ce:sup> on all metrics on MSR-VTT <ce:cross-ref id=""""crf0060"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> dataset with longer videos, which implies the importance of temporal dynamics for video captioning. Also, we achieve better performance in METEOR compared with other methods except HRNE <ce:cross-ref id=""""crf0061"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> because HRNE focus more on building a fine-grained hierarchical structure for captioning. It is beneficial for appropriate mapping of unigrams which is crucial for the METTOR metric.</ce:para>""''"'	uses_method_in	AGA	
cites	Introduction	Y. Yan, F. Nie, W. Li, C. Gao, Y. Yang, D. Xu, Image classification by cross-media active learning with privileged information , TMM , vol. 18 (2016), pp.2494-2502	http://dx.doi.org/10.1016/j.patrec.2017.10.012	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0001		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0028	'Previous work [1][[ refid=''bib0001'' ]] has shown the potential of vision and text joint modeling for image classification.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">Video captioning, which aims at building the mapping from visual contents to texts, involves understanding both visual concepts and temporal dynamics. Previous work <ce:cross-ref id=""""crf0009"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> has shown the potential of vision and text joint modeling for image classification. However, unlike still images, a video which comprises of a sequence of images contains more information about visual concepts and the interactions between them. It is very difficult for existing methods <ce:cross-refs id=""""crfs0001"""" refid=""""bib0002 bib0003 bib0004 bib0005 bib0006"""">[2–6][[ refid=''''bib0002 bib0003 bib0004 bib0005 bib0006'''' ]]</ce:cross-refs> to capture all the information over a long period as a single visual representation. Yao et al. first attempt to focus on a subset of video frames at each time step with a soft attention mechanism, which is driven by a LSTM-based decoder <ce:cross-ref id=""""crf0010"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>. The LSTM-based decoder integrates both previously generated words and visual contents to guide visual attention and caption generation. Experiments have shown the effectiveness of the attention mechanism for video captioning.</ce:para>""''"'	cites	AGA	
cites	Introduction	A. Graves, G. Wayne, I. Danihelka, Neural turing machines, arXiv preprint	http://dx.doi.org/10.1016/j.patrec.2017.10.012	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0008	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0004		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0035	'Unfortunately, previous work has pointed out the weakness of LSTM for modeling very long sequence [8][[ refid=''bib0008'' ]] and current video captioning benchmark datasets generally include videos with long sequences.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0008"""" view=""""all"""">However, temporal dynamics has not been well captured by the attention mechanism. For example, the temporal order of input video frames doesn’t influence the captioning results with only the attention mechanism, which doesn’t meet our common sense. Preprocessing of CNN features with LSTM helps to incorporate the temporal dynamics to some extent. Unfortunately, previous work has pointed out the weakness of LSTM for modeling very long sequence <ce:cross-ref id=""""crf0011"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref> and current video captioning benchmark datasets generally include videos with long sequences.</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	A. Graves, G. Wayne, I. Danihelka, Neural turing machines, arXiv preprint	http://dx.doi.org/10.1016/j.patrec.2017.10.012	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0008	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0006		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0041	'Among such investigations, Neural Turing Machine [8][[ refid=''bib0008'' ]] shows a great advantage of memorizing long-range information.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0009"""" view=""""all"""">Recently, memory networks <ce:cross-refs id=""""crfs0002"""" refid=""""bib0008 bib0009 bib0010"""">[8–10][[ refid=''''bib0008 bib0009 bib0010'''' ]]</ce:cross-refs>, with the potential to capture long-term correlations in sequential problems, achieve great success in question answering <ce:cross-ref id=""""crf0012"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> and dialog systems <ce:cross-ref id=""""crf0013"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>. Among such investigations, Neural Turing Machine <ce:cross-ref id=""""crf0014"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref> shows a great advantage of memorizing long-range information. We are motivated by this and contend that it is very suited to capturing the temporal dynamics from 2D CNN features. The combination of visual concepts and temporal dynamics leads to a more intact visual representation of the video. Moreover, consider the generated caption “A group of people are playing soccer on the field”. The words “a” and “of” do not have corresponding visual information and language correlations make the visual information unnecessary when generating words like “of” and “on”. As a result, a feature selection algorithm is included to determine the attention on visual concepts, temporal dynamics and language model according to the part of speech.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments and preprocessing	N. Srivastava, G.E. Hinton, A. Krizhevsky, I. Sutskever, R. Salakhutdinov, Dropout: a simple way to prevent neural networks from overfitting. , JMLR , vol. 15 (2014), pp.1929-1958	http://dx.doi.org/10.1016/j.patrec.2017.10.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0038	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0037		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0049	'Dropout [38][[ refid=''bib0038'' ]] with a rate of 0.5 is utilized in our experiments as another regularization.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0048"""" view=""""all"""">We empirically set the dimension of hidden states to 512. Additionally, the length of memory vector is 1000 along with 10 memory locations which means the size of the external memory matrix is 10 × 1000. All experiments are conducted with a training mini-batch size of 64 and L2-decay term of 0.0001. Dropout <ce:cross-ref id=""""crf0053"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> with a rate of 0.5 is utilized in our experiments as another regularization. Moreover, we train our model with the Adadelta <ce:cross-ref id=""""crf0054"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> optimization algorithm and a clipnorm of 10. All of our experiments are implemented with Keras and Theano <ce:cross-ref id=""""crf0055"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experiments and preprocessing	C.D. Manning, M. Surdeanu, J. Bauer, J.R. Finkel, S. Bethard, D. McClosky, The stanford corenlp natural language processing toolkit. , ACL (2014)	http://dx.doi.org/10.1016/j.patrec.2017.10.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0037	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0036		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0050	'Moreover, we convert all captions to lower case and tokenize the sentences using the PTBTokenizer in Stanford CoreNLP tools [37][[ refid=''bib0037'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0047"""" view=""""all"""">The datasets have videos of various frame lengths. Thus, we subsample the video frames to ensure a fixed length of <ce:italic>K</ce:italic>. For those videos with less than <ce:italic>K</ce:italic> frames, we append the feature vectors with blank vectors. Following the setting of <ce:cross-ref id=""""crf0048"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>, we set <ce:italic>K</ce:italic> to 28 for MSVD and to 40 for MSR-VTT for a fair comparison. We extract features with pretrained 2D CNN networks, e.g., GoogleNet <ce:cross-ref id=""""crf0049"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref> for MSVD, VGG-19 <ce:cross-ref id=""""crf0050"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref> and ResNet-152 <ce:cross-ref id=""""crf0051"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref> for MSR-VTT. Moreover, we convert all captions to lower case and tokenize the sentences using the PTBTokenizer in Stanford CoreNLP tools <ce:cross-ref id=""""crf0052"""" refid=""""bib0037"""">[37][[ refid=''''bib0037'''' ]]</ce:cross-ref>. This yields a vocabulary of 13,010 in size for MSVD and 29,019 in size for MSR-VTT.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments and preprocessing	J. Xu, T. Mei, T. Yao, Y. Rui, Msr-vtt: A large video description dataset for bridging video and language , CVPR (2016)	http://dx.doi.org/10.1016/j.patrec.2017.10.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0032	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0030		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0054	'Following the split of [32][[ refid=''bib0032'' ]], we divide the whole dataset into a training set of 6513 clips, a validation set of 497 clips and a test set of 2990 clips.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0045"""" view=""""all"""">Microsoft Research-Video to Text (MSR-VTT) is a large-scale dataset to public for bridging video and language. The dataset contains 10,000 video clips and 200,000 sentences. Each video is labeled with 20 sentences. Following the split of <ce:cross-ref id=""""crf0041"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, we divide the whole dataset into a training set of 6513 clips, a validation set of 497 clips and a test set of 2990 clips.</ce:para>""''"'	uses_data_from	AGA	
cites	Experiments and preprocessing	R. Vedantam, C. Lawrence Zitnick, D. Parikh, Cider: Consensus-based image description evaluation , CVPR (2015)	http://dx.doi.org/10.1016/j.patrec.2017.10.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0035	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0032		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0057	'Based on the evaluation of [35][[ refid=''bib0035'' ]], METEOR is always better than BLEU in terms of consistency with human judgment and CIDER gets similar results compared with METEOR.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0046"""" view=""""all"""">We report the performance of our proposed model on three standard evaluation metrics: BLEU <ce:cross-ref id=""""crf0042"""" refid=""""bib0033"""">[33][[ refid=''''bib0033'''' ]]</ce:cross-ref>, METEOR <ce:cross-ref id=""""crf0043"""" refid=""""bib0034"""">[34][[ refid=''''bib0034'''' ]]</ce:cross-ref> and CIDER <ce:cross-ref id=""""crf0044"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref>. Specially, BLEU computes the <ce:italic>N</ce:italic>-gram similarity, and METEOR focuses on the mapping between unigrams while CIDER emphasizes more on the human judgment of similarity between generated sentences and references. Based on the evaluation of <ce:cross-ref id=""""crf0045"""" refid=""""bib0035"""">[35][[ refid=''''bib0035'''' ]]</ce:cross-ref>, METEOR is always better than BLEU in terms of consistency with human judgment and CIDER gets similar results compared with METEOR. Thus, similar to <ce:cross-ref id=""""crf0046"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>, we use the evaluation server introduced in <ce:cross-ref id=""""crf0047"""" refid=""""bib0036"""">[36][[ refid=''''bib0036'''' ]]</ce:cross-ref> and select the best model based on METEOR evaluation metric.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments and preprocessing	T.T.D. Team, R. Al-Rfou, G. Alain, A. Almahairi, C. Angermueller, D. Bahdanau, N. Ballas, F. Bastien, J. Bayer, A. Belikov, et al., Theano: a python framework for fast computation of mathematical expressions, arXiv preprint	http://dx.doi.org/10.1016/j.patrec.2017.10.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0040	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0039		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0058	'All of our experiments are implemented with Keras and Theano [40][[ refid=''bib0040'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0048"""" view=""""all"""">We empirically set the dimension of hidden states to 512. Additionally, the length of memory vector is 1000 along with 10 memory locations which means the size of the external memory matrix is 10 × 1000. All experiments are conducted with a training mini-batch size of 64 and L2-decay term of 0.0001. Dropout <ce:cross-ref id=""""crf0053"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> with a rate of 0.5 is utilized in our experiments as another regularization. Moreover, we train our model with the Adadelta <ce:cross-ref id=""""crf0054"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> optimization algorithm and a clipnorm of 10. All of our experiments are implemented with Keras and Theano <ce:cross-ref id=""""crf0055"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experiments and preprocessing	M.D. Zeiler, Adadelta: an adaptive learning rate method, arXiv preprint	http://dx.doi.org/10.1016/j.patrec.2017.10.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0038		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0059	'Moreover, we train our model with the Adadelta [39][[ refid=''bib0039'' ]] optimization algorithm and a clipnorm of 10.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0048"""" view=""""all"""">We empirically set the dimension of hidden states to 512. Additionally, the length of memory vector is 1000 along with 10 memory locations which means the size of the external memory matrix is 10 × 1000. All experiments are conducted with a training mini-batch size of 64 and L2-decay term of 0.0001. Dropout <ce:cross-ref id=""""crf0053"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> with a rate of 0.5 is utilized in our experiments as another regularization. Moreover, we train our model with the Adadelta <ce:cross-ref id=""""crf0054"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> optimization algorithm and a clipnorm of 10. All of our experiments are implemented with Keras and Theano <ce:cross-ref id=""""crf0055"""" refid=""""bib0040"""">[40][[ refid=''''bib0040'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_method_in	AGA	
cites	Related work	J. Wang, W. Wang, Y. Huang, L. Wang, T. Tan, Multimodal memory modelling for video captioning, arXiv preprint	http://dx.doi.org/10.1016/j.patrec.2017.10.012	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0018		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0066	'It memorizes long-term information including both previously generated words and the visual attention history to guide the attention mechanism [23][[ refid=''bib0023'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0018"""" view=""""all"""">To improve the capacity of memory cells in traditional neural networks, Graves et al. propose a Neural Turing Machine (NTM) with an external memory matrix. The memory matrix interacts with the internal states of neural networks by reading and writing which relied on a unique addressing mechanism <ce:cross-ref id=""""crf0022"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>. Compared with LSTM, NTM has shown a superior potential of both storage and accessing of long-term information. Besides the memory matrix in NTM, memory is also modeled as a differentiable list, a queue or a deque <ce:cross-refs id=""""crfs0004"""" refid=""""bib0021 bib0022"""">[21,22][[ refid=''''bib0021 bib0022'''' ]]</ce:cross-refs>. Rather than exploring different forms of dynamic storages, Weston et al. first model the static memory to storage long-term information <ce:cross-ref id=""""crf0023"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. These memory networks have been successfully applied to long-term dependency modeling related tasks. Recently, Wang et al. introduce the memory networks into video captioning by proposing a multimodal memory network. It memorizes long-term information including both previously generated words and the visual attention history to guide the attention mechanism <ce:cross-ref id=""""crf0024"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. In this paper, we exploit the potential of Neural Turing Machine to capture the temporal dynamics from 2D CNN features.</ce:para>""''"'	cites	AGA	
cites	Related work	L. Yao, A. Torabi, K. Cho, N. Ballas, C. Pal, H. Larochelle, A. Courville, Describing videos by exploiting temporal structure , CVPR (2015)	http://dx.doi.org/10.1016/j.patrec.2017.10.012	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0007	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0013		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0067	'In contrast, Yao et al. first introduce a soft attention mechanism into video captioning to weight input CNN features given previously generated words [7][[ refid=''bib0007'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0017"""" view=""""all"""">Recently, researchers begin to improve the encoder-decoder architecture by significantly changing their structures. A hierarchical framework containing a sentence generator and a paragraph generator is proposed by Yu et al. for the sentence decoder <ce:cross-ref id=""""crf0019"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref>. In contrast, Yao et al. first introduce a soft attention mechanism into video captioning to weight input CNN features given previously generated words <ce:cross-ref id=""""crf0020"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>. Moreover, Pan et al. propose to encode videos through hierarchical recurrent neural encoders (HRNE) along with the soft attention mechanism <ce:cross-ref id=""""crf0021"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>. We integrate attention weighted CNN features and temporal dynamics into a multimodal decoder for more intact visual representations in our paper. Instead of size-limited LSTM, memory networks, which have great advantages of memorizing long-term information, are used in our multimodal architecture to better capture the temporal dynamics.</ce:para>""''"'	cites	AGA	
cites	Related work	L. Zhu, Z. Xu, Y. Yang, Bidirectional multirate reconstruction for temporal modeling in videos , CVPR (2017)	http://dx.doi.org/10.1016/j.patrec.2017.10.012	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0011		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0069	'Moreover, Zhu et al. train a Multirate Visual Recurrent Model (MVRM) to better incorporate both past and future temporal information [18][[ refid=''bib0018'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">Video captioning draws more and more attention due to its importance in bridging vision and language. To solve this problem, variety of methods have been proposed, which can be mainly divided into two categories. The first category focuses on the identification of (subject, verb, object) triplets with visual classifiers, and captions are generated by combining predicted triplets with predefined sentence templates <ce:cross-refs id=""""crfs0003"""" refid=""""bib0013 bib0014"""">[13,14][[ refid=''''bib0013 bib0014'''' ]]</ce:cross-refs>. The template-based approaches obviously cannot express the richness of language and have the limited potential to unseen data. The second category is inspired by the encoder-decoder architecture originally used in machine translation <ce:cross-ref id=""""crf0015"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>. Venugopalan et al. first apply it to generate descriptions of video clips with a CNN-based encoder and a LSTM-based decoder <ce:cross-ref id=""""crf0016"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>. However, the temporal information of videos is inevitably left out with simple mean-pooling of CNN features. Thus, Xu et al. additionally utilize a recurrent neural network to capture the temporal dynamics <ce:cross-ref id=""""crf0017"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref>. Moreover, Zhu et al. train a Multirate Visual Recurrent Model (MVRM) to better incorporate both past and future temporal information <ce:cross-ref id=""""crf0018"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. Other works have then followed these kinds of approaches.</ce:para>""''"'	cites	AGA	
cites	Related work	A. Graves, G. Wayne, I. Danihelka, Neural turing machines, arXiv preprint	http://dx.doi.org/10.1016/j.patrec.2017.10.012	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0008	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0015		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0074	'The memory matrix interacts with the internal states of neural networks by reading and writing which relied on a unique addressing mechanism [8][[ refid=''bib0008'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0018"""" view=""""all"""">To improve the capacity of memory cells in traditional neural networks, Graves et al. propose a Neural Turing Machine (NTM) with an external memory matrix. The memory matrix interacts with the internal states of neural networks by reading and writing which relied on a unique addressing mechanism <ce:cross-ref id=""""crf0022"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>. Compared with LSTM, NTM has shown a superior potential of both storage and accessing of long-term information. Besides the memory matrix in NTM, memory is also modeled as a differentiable list, a queue or a deque <ce:cross-refs id=""""crfs0004"""" refid=""""bib0021 bib0022"""">[21,22][[ refid=''''bib0021 bib0022'''' ]]</ce:cross-refs>. Rather than exploring different forms of dynamic storages, Weston et al. first model the static memory to storage long-term information <ce:cross-ref id=""""crf0023"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. These memory networks have been successfully applied to long-term dependency modeling related tasks. Recently, Wang et al. introduce the memory networks into video captioning by proposing a multimodal memory network. It memorizes long-term information including both previously generated words and the visual attention history to guide the attention mechanism <ce:cross-ref id=""""crf0024"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. In this paper, we exploit the potential of Neural Turing Machine to capture the temporal dynamics from 2D CNN features.</ce:para>""''"'	cites	AGA	
uses_data_from	Experiments and preprocessing	J. Xu, T. Mei, T. Yao, Y. Rui, Msr-vtt: A large video description dataset for bridging video and language , CVPR (2016)	http://dx.doi.org/10.1016/j.patrec.2017.10.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0032	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0044		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0076	'However, we outperform M3 on all metrics on MSR-VTT [32][[ refid=''bib0032'' ]] dataset with longer videos, which implies the importance of temporal dynamics for video captioning.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0050"""" view=""""all"""">We compare our model with other five state-of-the-art methods <ce:cross-refs id=""""crfs0008"""" refid=""""bib0007 bib0019 bib0020 bib0023 bib0041"""">[7,19,20,23,41][[ refid=''''bib0007 bib0019 bib0020 bib0023 bib0041'''' ]]</ce:cross-refs> using single visual feature for video captioning. The experiment results of BLEU, METEOR and CIDER evaluation metrics are shown in <ce:cross-ref id=""""crf0056"""" refid=""""tbl0002"""">Table 2</ce:cross-ref><ce:float-anchor refid=""""tbl0002""""/>. Here we obtain comparable results with other state-of-the-art methods. Compared with SA <ce:cross-ref id=""""crf0057"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>, our method additionally utilizes memory networks to capture temporal dynamics for more intact visual representations. We gain a large margin performance improvement over SA, which implies the effectiveness of the memory networks for video captioning. Besides SA, M<ce:sup loc=""""post"""">3</ce:sup><ce:cross-ref id=""""crf0058"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> is the most similar method to ours. It also has an external memory matrix for the LSTM-based decoder. M<ce:sup loc=""""post"""">3</ce:sup>, however, only utilize the external memory matrix for long-range visual-textual information interactions. The temporal dynamics has not been well captured since the temporal order of input video frames doesn’t influence the captioning results. We first exploit the potential of memory networks to extract temporal dynamics. Our model outperforms all other methods except M<ce:sup loc=""""post"""">3</ce:sup>-google <ce:cross-ref id=""""crf0059"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> in terms of BLEU. It is because BLEU emphasizes more on N-gram similarity while our model combines visual concepts with temporal dynamics directly which sacrifices the semantic consistency to some extent. However, we outperform <ce:italic>M</ce:italic><ce:sup loc=""""post"""">3</ce:sup> on all metrics on MSR-VTT <ce:cross-ref id=""""crf0060"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> dataset with longer videos, which implies the importance of temporal dynamics for video captioning. Also, we achieve better performance in METEOR compared with other methods except HRNE <ce:cross-ref id=""""crf0061"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> because HRNE focus more on building a fine-grained hierarchical structure for captioning. It is beneficial for appropriate mapping of unigrams which is crucial for the METTOR metric.</ce:para>""''"'	uses_data_from	AGA	
cites	Experiments and preprocessing	P. Pan, Z. Xu, Y. Yang, F. Wu, Y. Zhuang, Hierarchical recurrent neural encoder for video representation with application to captioning , CVPR (2016)	http://dx.doi.org/10.1016/j.patrec.2017.10.012	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/br/bib0020	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/ctx/ctx0045		48	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-10-012/itrp/0077	'Also, we achieve better performance in METEOR compared with other methods except HRNE [20][[ refid=''bib0020'' ]] because HRNE focus more on building a fine-grained hierarchical structure for captioning.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0050"""" view=""""all"""">We compare our model with other five state-of-the-art methods <ce:cross-refs id=""""crfs0008"""" refid=""""bib0007 bib0019 bib0020 bib0023 bib0041"""">[7,19,20,23,41][[ refid=''''bib0007 bib0019 bib0020 bib0023 bib0041'''' ]]</ce:cross-refs> using single visual feature for video captioning. The experiment results of BLEU, METEOR and CIDER evaluation metrics are shown in <ce:cross-ref id=""""crf0056"""" refid=""""tbl0002"""">Table 2</ce:cross-ref><ce:float-anchor refid=""""tbl0002""""/>. Here we obtain comparable results with other state-of-the-art methods. Compared with SA <ce:cross-ref id=""""crf0057"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>, our method additionally utilizes memory networks to capture temporal dynamics for more intact visual representations. We gain a large margin performance improvement over SA, which implies the effectiveness of the memory networks for video captioning. Besides SA, M<ce:sup loc=""""post"""">3</ce:sup><ce:cross-ref id=""""crf0058"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> is the most similar method to ours. It also has an external memory matrix for the LSTM-based decoder. M<ce:sup loc=""""post"""">3</ce:sup>, however, only utilize the external memory matrix for long-range visual-textual information interactions. The temporal dynamics has not been well captured since the temporal order of input video frames doesn’t influence the captioning results. We first exploit the potential of memory networks to extract temporal dynamics. Our model outperforms all other methods except M<ce:sup loc=""""post"""">3</ce:sup>-google <ce:cross-ref id=""""crf0059"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> in terms of BLEU. It is because BLEU emphasizes more on N-gram similarity while our model combines visual concepts with temporal dynamics directly which sacrifices the semantic consistency to some extent. However, we outperform <ce:italic>M</ce:italic><ce:sup loc=""""post"""">3</ce:sup> on all metrics on MSR-VTT <ce:cross-ref id=""""crf0060"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref> dataset with longer videos, which implies the importance of temporal dynamics for video captioning. Also, we achieve better performance in METEOR compared with other methods except HRNE <ce:cross-ref id=""""crf0061"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> because HRNE focus more on building a fine-grained hierarchical structure for captioning. It is beneficial for appropriate mapping of unigrams which is crucial for the METTOR metric.</ce:para>""''"'	uses_method_in	AGA	
cites	Introduction	R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, S. Süsstrunk, Slic superpixels compared to state-of-the-art superpixel methods , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 34 (2012), pp.2274-2282	http://dx.doi.org/10.1016/j.patrec.2017.11.006	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/br/bib0002	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/ctx/ctx0009		14	3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/itrp/0008	'GWB uses Bayesian posterior estimation method to calculate the geodesic distance between superpixels [2][[ refid=''bib0002'' ]] which based on feature map, and it is described by a fixed weight by statistic in advance.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0010"""" view=""""all"""">Geodesic weighted Bayesian model <ce:cross-refs id=""""crfs0005"""" refid=""""bib0016 bib0017"""">[16,17][[ refid=''''bib0016 bib0017'''' ]]</ce:cross-refs> provide a saliency optimization algorithm by conditional random fields and Bayesian framework. GWB uses Bayesian posterior estimation method to calculate the geodesic distance between superpixels <ce:cross-ref id=""""crf0023"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref> which based on feature map, and it is described by a fixed weight by statistic in advance. Given an initial saliency map provided by any methods, GWB aims to re-infer the saliency probability according to the similarity between features. However, it is difficult to describe the dependencies between different scenes and objects by using a fixed probability influence relation. Meanwhile, when the features can not classify the foreground and background well, GWB can not provide a correct optimization direction on the original saliency map.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiments	X. Wang, H. Ma, X. Chen, Geodesic weighted Bayesian model for salient object detection , IEEE ICIP (2015)	http://dx.doi.org/10.1016/j.patrec.2017.11.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/br/bib0016	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/ctx/ctx0013		14	3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/itrp/0020	'Based on these methods, we test the performance of GWB [16][[ refid=''bib0016'' ]], AIM and AO-AIM model.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0034"""" view=""""all"""">On the other hand, we investigate nine methods for salient object detection as the baseline, which includes LC <ce:cross-ref id=""""crf0043"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>, FT <ce:cross-ref id=""""crf0044"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>, HC <ce:cross-ref id=""""crf0045"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>, RC <ce:cross-ref id=""""crf0046"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>, SF <ce:cross-ref id=""""crf0047"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref>, GS <ce:cross-ref id=""""crf0048"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref>, GC <ce:cross-ref id=""""crf0049"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>, HDCT <ce:cross-ref id=""""crf0050"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> and LPS <ce:cross-ref id=""""crf0051"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>. Based on these methods, we test the performance of GWB <ce:cross-ref id=""""crf0052"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>, AIM and AO-AIM model.</ce:para>""''"'	uses_method_in	AGA	
cites	Introduction	A. Borji, M.-M. Cheng, H. Jiang, J. Li, Salient object detection: a benchmark , IEEE Trans. Image Process. , vol. 24 (2015), pp.5706-5722	http://dx.doi.org/10.1016/j.patrec.2017.11.006	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/ctx/ctx0002		14	3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/itrp/0023	'Borji et al. [4][[ refid=''bib0004'' ]] summarizes the experiment results of 40 state-of-the-art models on 6 datasets, and provides performance evaluation indicators for saliency detection, which develops a test criteria for the study of saliency detection.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">Salient object detection has been an important research field in computer vision, and it can be widely applied in the area of semantic segmentation <ce:cross-ref id=""""crf0017"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref>, object recognition and detection <ce:cross-ref id=""""crf0018"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>. Salient object detection is a pixel-level classification task, and it is intended to label the foreground which are salient objects with semantics and background in images. Borji et al. <ce:cross-ref id=""""crf0019"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref> summarizes the experiment results of 40 state-of-the-art models on 6 datasets, and provides performance evaluation indicators for saliency detection, which develops a test criteria for the study of saliency detection. Many studies based on bottom up learning methods have focused on designing suitable feature for better classification <ce:cross-refs id=""""crfs0002"""" refid=""""bib0005 bib0010 bib0011"""">[5,10,11][[ refid=''''bib0005 bib0010 bib0011'''' ]]</ce:cross-refs>. The basic feature of color, texture and other feature are widely used in saliency classification, while edge feature plays an important role on boundary expression <ce:cross-ref id=""""crf0020"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. Meanwhile, it is similar to semantic segmentation <ce:cross-refs id=""""crfs0003"""" refid=""""bib0014 bib0024"""">[14,24][[ refid=''''bib0014 bib0024'''' ]]</ce:cross-refs>, better feature expression corresponds to better detection performance.</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	X. Wang, H. Ma, X. Chen, Salient object detection via fast r-cnn and low-level cues , 2016 IEEE International Conference on Image Processing (ICIP) (2016)	http://dx.doi.org/10.1016/j.patrec.2017.11.006	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/ctx/ctx0004		14	3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-11-006/itrp/0027	'The basic feature of color, texture and other feature are widely used in saliency classification, while edge feature plays an important role on boundary expression [18][[ refid=''bib0018'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">Salient object detection has been an important research field in computer vision, and it can be widely applied in the area of semantic segmentation <ce:cross-ref id=""""crf0017"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref>, object recognition and detection <ce:cross-ref id=""""crf0018"""" refid=""""bib0006"""">[6][[ refid=''''bib0006'''' ]]</ce:cross-ref>. Salient object detection is a pixel-level classification task, and it is intended to label the foreground which are salient objects with semantics and background in images. Borji et al. <ce:cross-ref id=""""crf0019"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref> summarizes the experiment results of 40 state-of-the-art models on 6 datasets, and provides performance evaluation indicators for saliency detection, which develops a test criteria for the study of saliency detection. Many studies based on bottom up learning methods have focused on designing suitable feature for better classification <ce:cross-refs id=""""crfs0002"""" refid=""""bib0005 bib0010 bib0011"""">[5,10,11][[ refid=''''bib0005 bib0010 bib0011'''' ]]</ce:cross-refs>. The basic feature of color, texture and other feature are widely used in saliency classification, while edge feature plays an important role on boundary expression <ce:cross-ref id=""""crf0020"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. Meanwhile, it is similar to semantic segmentation <ce:cross-refs id=""""crfs0003"""" refid=""""bib0014 bib0024"""">[14,24][[ refid=''''bib0014 bib0024'''' ]]</ce:cross-refs>, better feature expression corresponds to better detection performance.</ce:para>""''"'	cites	AGA	
cites	Methodology	S. Alpert, M. Galun, A. Brandt, R. Basri, Image segmentation by probabilistic bottom-up aggregation and cue integration , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 34 (2012), pp.315-327	http://dx.doi.org/10.1016/j.patrec.2017.12.016	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/ctx/ctx0022		27	3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/itrp/0001	'[[ formulaid=''id13_pos0'' ]] As stated in [1][[ refid=''bib0001'' ]], this model reveals that the overall probability of connecting two voxels is determined by each cue used individually, so that we can adjust the influence of cues dynamically on the basis of the attributes of voxels.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0020"""" view=""""all"""">To deduce <mml:math altimg=""""si18.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>±</mml:mo></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math> we adopt the probabilistic framework proposed in <ce:cross-ref id=""""crf0037"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>, by which the probability <mml:math altimg=""""si19.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>±</mml:mo></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math> can be calculated from the attributes <ce:italic>A<ce:inf loc=""""post"""">i</ce:inf></ce:italic> and <ce:italic>A<ce:inf loc=""""post"""">j</ce:inf></ce:italic> of <ce:italic>V<ce:inf loc=""""post"""">i</ce:inf></ce:italic> and <ce:italic>V<ce:inf loc=""""post"""">j</ce:inf></ce:italic>. The posterior probability is evaluated by the use of estimated prior and the obtained attributes. Here, we make an assumption that all the cues are independent. Based on this assumption, we adopt the joint probabilistic model, in order to take certain geometric cues into account.<ce:display><ce:formula id=""""eq0004""""><ce:label>(4)</ce:label><mml:math altimg=""""si20.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign=""""left""""><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∏</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign=""""left""""><mml:mrow><mml:mspace width=""""1em""""/><mml:mo>=</mml:mo><mml:munder><mml:mo>∏</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:munder><mml:mo>∏</mml:mo><mml:mi>k</mml:mi></mml:munder><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>As stated in <ce:cross-ref id=""""crf0038"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>, this model reveals that the overall probability of connecting two voxels is determined by each cue used individually, so that we can adjust the influence of cues dynamically on the basis of the attributes of voxels. By applying the Bayes formula to (4), we can obtain the probability of merging related to each cue:<ce:display><ce:formula id=""""eq0005""""><ce:label>(5)</ce:label><mml:math altimg=""""si21.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mtable displaystyle=""""true""""><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign=""""left""""><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd/><mml:mtd columnalign=""""left""""><mml:mrow><mml:mspace width=""""1em""""/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>−</mml:mo></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></ce:formula></ce:display>where <mml:math altimg=""""si22.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>±</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>±</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> stand for the likelihood densities given <mml:math altimg=""""si18.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>±</mml:mo></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math> which is estimated by the attributes of other voxels in the vicinity of <ce:italic>V<ce:inf loc=""""post"""">i</ce:inf></ce:italic> and <ce:italic>V<ce:inf loc=""""post"""">j</ce:inf></ce:italic>. Here, the likelihood density is estimated by only using the smoothness <ce:italic>C<ce:inf loc=""""post"""">n</ce:inf></ce:italic> and continuity <ce:italic>C<ce:inf loc=""""post"""">d</ce:inf></ce:italic> cues. <mml:math altimg=""""si23.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mo>±</mml:mo></mml:msubsup><mml:mo>|</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> denotes the prior probability (see <ce:cross-ref id=""""crf0039"""" refid=""""sec0010"""">Section 2.3.3</ce:cross-ref>), which is independent of those cues used for likelihood density estimation. The cues used to deduce the prior include the proximity <ce:italic>C<ce:inf loc=""""post"""">s</ce:inf></ce:italic> and closure cues <ce:italic>C<ce:inf loc=""""post"""">v</ce:inf></ce:italic>.</ce:para>""''"'	cites	AGA	
cites	Results and discussion	T. Hackel, J.D. Wegner, K. Schindler, Fast semantic segmentation of 3d point clouds with strongly varying density , ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, Prague, Czech Republic , vol. 3 (2016), pp.177-184	http://dx.doi.org/10.1016/j.patrec.2017.12.016	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/br/bib0008	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/ctx/ctx0023		27	3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/itrp/0002	'The first one is a general outdoor building facades scene, consisting of terrestrial laser scanning point clouds from the large-scale point cloud classification benchmark datasets published by ETH Zurich [8][[ refid=''bib0008'' ]], which is the largest known labeled 3D point cloud dataset of natural scenes.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0026"""" view=""""all"""">Point clouds acquired from two different scenes are used to test our VPM method. The first one is a general outdoor building facades scene, consisting of terrestrial laser scanning point clouds from the large-scale point cloud classification benchmark datasets published by ETH Zurich <ce:cross-ref id=""""crf0040"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref>, which is the largest known labeled 3D point cloud dataset of natural scenes. This dataset covers a wide variety of diverse urban scenes like churches, streets, squares, villages, and castles, which is quite suitable for our segmentation tests. The point cloud used here for testing is a scene of building facades in a town square, the area of which is about 650 m<ce:sup loc=""""post"""">2</ce:sup>, including building walls, vehicles, fences, windows, balcony, plants. The second test scene is a construction site located in the downtown of Munich, Germany, having both laser scanned and photogrammetric point clouds. The area covered by this dataset is around 540 m<ce:sup loc=""""post"""">2</ce:sup>, including foundation pits, ground objects, construction equipment. The terrestrial LiDAR point cloud is surveyed with a Leica HDS 7000, while the photogrammetric point cloud is generated from a structure from motion (SfM) system and multi-view stereo matching method as described in <ce:cross-refs id=""""crfs0001"""" refid=""""bib0022 bib0023 bib0027"""">[22,23,27][[ refid=''''bib0022 bib0023 bib0027'''' ]]</ce:cross-refs>, using a Nikon D3 DLSR camera with 105 images. The statistical outlier removal filtering <ce:cross-ref id=""""crf0041"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref> is applied to the photogrammetric point cloud prior to the further processing. The sizes of LiDAR and photogrammetric point clouds are around 18 and 12 millions points, respectively. It is noted that for all used datasets, we do not have any priors or constraints, namely the point clouds are unstructured and only the 3D position of the points is used but not RGB color or intensity values.</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	F. Bosché, Automated recognition of 3d cad model objects in laser scans and calculation of as-built dimensions for dimensional compliance control in construction , Adv. Eng. Inf. , vol. 24 (2010), pp.107-118	http://dx.doi.org/10.1016/j.patrec.2017.12.016	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/br/bib0003	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/ctx/ctx0001		27	3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/itrp/0017	'Recently, automatically creation of the as-built structures for Building Information Model (BIM) [3][[ refid=''bib0003'' ]] is drawing increasingly attention in the fields of engineering and construction.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0005"""" view=""""all"""">Recently, automatically creation of the as-built structures for Building Information Model (BIM) <ce:cross-ref id=""""crf0002"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref> is drawing increasingly attention in the fields of engineering and construction. A BIM can serve many applications, including work progress tracking, productivity improvement, security assurance, or accident investigation, benefiting from its rich semantic and geometric information and flexibility in use <ce:cross-ref id=""""crf0003"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>. Especially for the task of construction site monitoring and project management, the as-built structures and surfaces of BIM reconstructed from the geometric measurements (e.g., point clouds) can help the engineers and workers obtain the actual changes, situation, and progress of the project.</ce:para>""''"'	cites	AGA	
uses_data_from	Introduction	S. Tuttas, A. Braun, A. Borrmann, U. Stilla, Acquisition and consecutive registration of photogrammetric point clouds for construction progress monitoring using a 4d bim , PFG J. Photogramm. Remote Sens. Geoinf. Sci. , vol. 85 (2017), pp.3-15	http://dx.doi.org/10.1016/j.patrec.2017.12.016	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/ctx/ctx0005		27	3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/itrp/0021	'Moreover, we also conduct experiments using both laser scanned and photogrammetric point clouds from the same scene of a construction site, to compare and analyze the performance of the segmentation algorithms when dealing with datasets of significantly different sources [23][[ refid=''bib0023'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">To this end, for addressing problems of current point cloud segmentation methods and meeting our demands of further reconstructing as-built BIM, we present a voxel- and probabilistic model- based method (VPM) for segmenting the 3D point cloud of 3D construction site into meaningful segments. The segmentation is based on the pairwise connectivities between voxels assessed by the geometric cues in defined local vicinities. We compare qualitative and quantitative experimental results of our method with the results of four comparable methods. Moreover, we also conduct experiments using both laser scanned and photogrammetric point clouds from the same scene of a construction site, to compare and analyze the performance of the segmentation algorithms when dealing with datasets of significantly different sources <ce:cross-ref id=""""crf0007"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	A. Nurunnabi, D. Belton, G. West, Robust segmentation for multiple planar surface extraction in laser scanning 3d point cloud data , Pattern Recognition (ICPR), 2012 21st International Conference on (2012)	http://dx.doi.org/10.1016/j.patrec.2017.12.016	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/br/bib0014	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/ctx/ctx0006		27	3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/itrp/0022	'In model-based segmentation methods, parametric objects are directly fitted to the points [14][[ refid=''bib0014'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0008"""" view=""""all"""">In model-based segmentation methods, parametric objects are directly fitted to the points <ce:cross-ref id=""""crf0008"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref>. Examples for such algorithms are the 3D Hough Transform (HT) <ce:cross-ref id=""""crf0009"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> and the RANSAC <ce:cross-ref id=""""crf0010"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. The HT and its variations utilize a voting strategy in the parameter domain for extracting planes, cylinders, and spheres from the point cloud <ce:cross-ref id=""""crf0011"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>. In contrast, RANSAC and its extensions use random sample consensus algorithm to estimate optimal parameters of the geometric models in the spatial domain <ce:cross-ref id=""""crf0012"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>. The merit of model-based methods lies on the robustness to noise and outliers in the datasets while the geometric parameters are optimized simultaneously. However, when segmenting large-scale datasets, they normally have long computation time on account of the iteration process and high memory consumption due to the transformation between spatial and parameter domains. Furthermore, objects having no explicit mathematical expressions (e.g., irregular shaped objects or curved surfaces) can hardly be segmented by this kind of method.</ce:para>""''"'	cites	AGA	
cites	Introduction	M.-C. Chang, F.F. Leymarie, B.B. Kimia, Surface reconstruction from point clouds by transforming the medial scaffold , Comput. Vis. Image Understand. , vol. 113 (2009), pp.1130-1146	http://dx.doi.org/10.1016/j.patrec.2017.12.016	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/ctx/ctx0013		27	3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/itrp/0027	'In complex situations, since there are plenty of non-watertight and intersecting surfaces, without the help of the information of the entire structure, we can hardly identify and segment such complex surfaces [4][[ refid=''bib0004'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0010"""" view=""""all"""">The clustering-based methods group points having similarities in a spatial or feature space on the basis of their geometric characteristics or spatial distribution. Euclidean distance <ce:cross-ref id=""""crf0015"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>, normal vector <ce:cross-ref id=""""crf0016"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>, and points densities <ce:cross-ref id=""""crf0017"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> are representative similarity measures for clustering. This kind of methods requires no seeds and is deemed to be more robust under noisy conditions, but their clustering criteria normally consider pairwise information, which may be unreliable in complex situations. In complex situations, since there are plenty of non-watertight and intersecting surfaces, without the help of the information of the entire structure, we can hardly identify and segment such complex surfaces <ce:cross-ref id=""""crf0018"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Methodology	A.-V. Vo, L. Truong-Hong, D.F. Laefer, M. Bertolotto, Octree-based region growing for point cloud segmentation , ISPRS J. Photogramm. Remote Sens. , vol. 104 (2015), pp.88-100	http://dx.doi.org/10.1016/j.patrec.2017.12.016	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/br/bib0024	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/ctx/ctx0017		27	3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-016/itrp/0033	'The aim of using an octree to create the voxel structure is threefold [24][[ refid=''bib0024'' ]]: (1) Construction of a rasterized representation of the points, which simplifies the datasets and can overcome the uneven distributed point density; (2) Organization of the points by indexing the unorganized points with generated voxels in a tree structure; (3) Definition of neighboring relations of generated voxels.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">The point cloud is firstly rasterized by a 3D cubic grid, overlaying the bounding box of the entire point cloud with an octree-based structure. The aim of using an octree to create the voxel structure is threefold <ce:cross-ref id=""""crf0028"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>: (1) Construction of a rasterized representation of the points, which simplifies the datasets and can overcome the uneven distributed point density; (2) Organization of the points by indexing the unorganized points with generated voxels in a tree structure; (3) Definition of neighboring relations of generated voxels. The explicit linkage of nodes can be identified simultaneously with the creation of voxels, facilitating the traversal for searching adjacent voxels. The subdivision of the octree is stopped according to the divided size of voxels, determined empirically by the datasets and demands and leaving at least three points in each voxel for approximating the plane representation.</ce:para>""''"'	uses_data_from	AGA	
cites	Proposed framework	R.H.W. Pinheiro, G.D.C. Cavalcanti, T.I. Ren, Data-driven global-ranking local feature selection methods for text categorization , Expert Syst. Appl. , vol. 42 (2015), pp.1941-1949	http://dx.doi.org/10.1016/j.patrec.2017.12.025			http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-025/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-025/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-025/ctx/ctx0022		29	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-025/itrp/0001	'In this section we illustrate the proposed feature selection framework with a hypothetical toy dataset used by Pinheiro et al., [23][[ refid=''bib0023'' ]] consisting of 2 classes with 13 documents and 9 terms.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0032"""" view=""""all"""">In this section we illustrate the proposed feature selection framework with a hypothetical toy dataset used by Pinheiro et al., <ce:cross-ref id=""""crf0060"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> consisting of 2 classes with 13 documents and 9 terms. <ce:cross-ref id=""""crf0061"""" refid=""""tbl0003"""">Table 3</ce:cross-ref> shows binary representation of the document-term matrix of the toy dataset. The first step of our framework is to apply an LFEF to get RM and RaM as shown in <ce:cross-ref id=""""crf0062"""" refid=""""tbl0004"""">Table 4</ce:cross-ref>. The final sequences of terms obtained using conventional and the proposed framework are shown in <ce:cross-ref id=""""crf0063"""" refid=""""tbl0005"""">Table 5</ce:cross-ref>.</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	F. Sebastiani, Machine learning in automated text categorization , ACM Comput. Surv. , vol. 34 (2002), pp.1-47	http://dx.doi.org/10.1016/j.patrec.2017.12.025	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-025/br/bib0030	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-025/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-025/ctx/ctx0001		29	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2017-12-025/itrp/0016	'Due to the abundant and unwieldy size of the text content available on the web, manual organization of the text into many categories cannot be done [30][[ refid=''bib0030'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">Due to the abundant and unwieldy size of the text content available on the web, manual organization of the text into many categories cannot be done <ce:cross-ref id=""""crf0002"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. Thus statistical and machine learning methods have been extensively exploited in designing effective systems for automatic Text Categorization (TC) that can classify a huge collection of text documents into predefined categories based on their content <ce:cross-refs id=""""crf0003"""" refid=""""bib0001 bib0019 bib0025"""">[1,19,25][[ refid=''''bib0001 bib0019 bib0025'''' ]]</ce:cross-refs>. However, a completely automatic TC system is still a dream due to many of challenges being posed by the text documents day by day.</ce:para>""''"'	cites	AGA	
uses_method_in	Experimental results	I.J. Goodfellow, D. Warde-Farley, P. Lamblin, V. Dumoulin, M. Mirza, R. Pascanu, J. Bergstra, F. Bastien, Y. Bengio, Pylearn2: a machine learning research library, arXiv preprint, arXiv:	http://dx.doi.org/10.1016/j.patrec.2018.01.006	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/br/bib0012	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/ctx/ctx0022		25	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/itrp/0001	'CIFAR models were trained with whitened data from PyLearn2 [12][[ refid=''bib0012'' ]] and we applied a random horizontal flip on the input image to simulate a larger training dataset and avoid over-fitting.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0035"""" view=""""all"""">ShaResNet are trained using the same training process as their non-shared counterpart. We used a stochastic gradient descent with momentum and step dropping learning rate policy. CIFAR models were trained with whitened data from PyLearn2 <ce:cross-ref id=""""crf0050"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> and we applied a random horizontal flip on the input image to simulate a larger training dataset and avoid over-fitting. For ImageNet, we adopted a similar approach, we apply on the input image a random crop, random contrast, lighting and color normalization as well as horizontal flip. According to our experiments, the behaviors of our networks are very similar to the original ones. <ce:cross-ref id=""""crf0051"""" refid=""""fig0004"""">Fig. 4</ce:cross-ref><ce:float-anchor refid=""""fig0004""""/> presents the testing accuracy plots obtained on the CIFAR datasets. The gradient accumulation at shared convolutions does not induces instabilities at both training and testing time.</ce:para>""''"'	uses_data_from	AGA	
cites	Experimental results	K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition , 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2016)	http://dx.doi.org/10.1016/j.patrec.2018.01.006	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/br/bib0014	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/ctx/ctx0023		25	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/itrp/0002	'Blue curves are the original version [14][[ refid=''bib0014'' ]] (third architecture on Fig. 2) and red the shared version.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0036"""" view=""""all"""">The top sub-figure shows the test accuracy of the ResNet-164 architecture on CIFAR-10. Blue curves are the original version <ce:cross-ref id=""""crf0052"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> (third architecture on <ce:cross-ref id=""""crf0053"""" refid=""""fig0002"""">Fig. 2</ce:cross-ref>) and red the shared version. The plane line is the mean over 5 runs, the colored area represents the standard deviation around the mean. The dot curve is the pre-activation version from <ce:cross-ref id=""""crf0054"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> (fourth architecture on <ce:cross-ref id=""""crf0055"""" refid=""""fig0002"""">Fig. 2</ce:cross-ref>). The two shared architectures perform similarly to their original counter part. The bottom sub-figure presents another experiment on CIFAR-100. We use the Wide ResNet with a widen factor 10 and depth 28, curves are mean over 6 runs. As to the non-shared version, adding a dropout (plain line) increases the performance. However the effect is less significant and while models performs almost the same without dropout, dropout make the original version overcomes the shared one. One explanation could be that the robust redundancy at testing, induced by training with dropout, added to the shared layer may result in a too drastic reduction of the parameters of the model, resulting in a lower increase of performances compared to non-shared version.</ce:para>""''"'	cites	AGA	
uses_method_in	Experimental results	C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, Z. Wojna, Rethinking the inception architecture for computer vision , Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, (2016) , arXiv:1512.00567	http://dx.doi.org/10.1016/j.patrec.2018.01.006	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/br/bib0039	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/ctx/ctx0025		25	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/itrp/0008	'For comparison, we also add the Inception v2 [39][[ refid=''bib0039'' ]] model performance, in which the authors perform convolution factorization at inception module level to reduce model size.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0040"""" view=""""all"""">On Imagenet, <ce:cross-ref id=""""crf0058"""" refid=""""tbl0002"""">Table 2</ce:cross-ref> underlines that the sharing is more efficient as the network goes larger. We even reach similar accuracy (less than 0.2% drop) for the 152 layer architecture. <ce:cross-ref id=""""crf0059"""" refid=""""fig0005"""">Fig. 5</ce:cross-ref><ce:float-anchor refid=""""fig0005""""/> presents the top-1 error function of the weight on ImageNet. The shared architectures plot (green curve) is situated under the blue curve (residual networks). It illustrates that for large networks, shared networks are more efficient than their sequential peers with similar number of parameters. For comparison, we also add the Inception v2 <ce:cross-ref id=""""crf0060"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> model performance, in which the authors perform convolution factorization at inception module level to reduce model size.</ce:para>""''"'	uses_method_in	AGA	
cites	Related work	Y. LeCun, B. Boser, J.S. Denker, D. Henderson, R.E. Howard, W. Hubbard, L.D. Jackel, Backpropagation applied to handwritten zip code recognition , Neural Comput. , vol. 1 (1989), pp.541-551	http://dx.doi.org/10.1016/j.patrec.2018.01.006	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/ctx/ctx0005		25	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/itrp/0024	'CNNs were introduced in [23][[ refid=''bib0023'' ]] for hand written digits recognition.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0010"""" view=""""all"""">CNNs were introduced in <ce:cross-ref id=""""crf0010"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref> for hand written digits recognition. They became over the past years one of the most enthusiastic field of deep learning <ce:cross-ref id=""""crf0011"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>. The CNNs are usually built using a common framework. They contains many convolutional layers and operate a gradual spatial dimension reduction using convolutional strides or pooling layers <ce:cross-refs id=""""crfs0004"""" refid=""""bib0006 bib0018"""">[6,18][[ refid=''''bib0006 bib0018'''' ]]</ce:cross-refs>. This structure naturally integrates low/mid/high level features along with a dimension compression before ending with a classifier, commonly a perceptron <ce:cross-ref id=""""crf0012"""" refid=""""bib0032"""">[32][[ refid=''''bib0032'''' ]]</ce:cross-ref>, multi-layered or not, i.e. one or more fully connected layers.</ce:para>""''"'	cites	AGA	
cites	Related work	C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich, Going deeper with convolutions , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2015)	http://dx.doi.org/10.1016/j.patrec.2018.01.006	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/br/bib0038	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/ctx/ctx0011		25	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/itrp/0042	'GoogLeNet [38][[ refid=''bib0038'' ]] introduced a multiscale approach using the inception module, composed of parallel convolutions with different kernel sizes.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">Variations in the LeNet structure have also been used to improve convergence. In a Network in Network (NiN) <ce:cross-ref id=""""crf0016"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>, convolutions are mapped with a multilayer perceptron (1 × 1 convolutions), which prevent overfitting and improved accuracy on datasets such as CIFAR <ce:cross-ref id=""""crf0017"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>. GoogLeNet <ce:cross-ref id=""""crf0018"""" refid=""""bib0038"""">[38][[ refid=''''bib0038'''' ]]</ce:cross-ref> introduced a multiscale approach using the inception module, composed of parallel convolutions with different kernel sizes.</ce:para>""''"'	cites	AGA	
cites	Related work	W. Chen, J. Wilson, S. Tyree, K. Weinberger, Y. Chen, Compressing neural networks with the hashing trick , International Conference on Machine Learning (2015)	http://dx.doi.org/10.1016/j.patrec.2018.01.006	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/br/bib0005	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/ctx/ctx0017		25	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-01-006/itrp/0045	'In Hashnets [5][[ refid=''bib0005'' ]] uses a hash function to regroup connections that will share the same weights.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">To balance the increasing size of CNNs, various work consider reducing the weight number of the network to reduce memory size and or testing speed. We can distinguish three categories. The first kind of approaches consists in statically modifying the architecture to get lighter networks, e.g. the replacement of the fully connected layers by average pooling <ce:cross-refs id=""""crfs0005"""" refid=""""bib0014 bib0038"""">[14,38][[ refid=''''bib0014 bib0038'''' ]]</ce:cross-refs>, the replacement and factorization of convolutions <ce:cross-ref id=""""crf0028"""" refid=""""bib0039"""">[39][[ refid=''''bib0039'''' ]]</ce:cross-ref> or the weights constrained to be binary <ce:cross-refs id=""""crfs0006"""" refid=""""bib0008 bib0030"""">[8,30][[ refid=''''bib0008 bib0030'''' ]]</ce:cross-refs>. This work follows this approach as we modify the internal structure of the residual networks to make it lighter. The second category regroups works that dynamically modify the network at training. Among them, <ce:cross-ref id=""""crf0029"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> alternate between regularization and neuron deactivation (forcing weights to zero) to progressively reduce the number of neurons. In Hashnets <ce:cross-ref id=""""crf0030"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> uses a hash function to regroup connections that will share the same weights. Finally the third category post process the network to compress it. Some consider weight pruning <ce:cross-refs id=""""crfs0007"""" refid=""""bib0029 bib0035"""">[29,35][[ refid=''''bib0029 bib0035'''' ]]</ce:cross-refs> and sparsification <ce:cross-ref id=""""crf0031"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref>. Other try to compress the data via weight matrix factorization <ce:cross-refs id=""""crfs0008"""" refid=""""bib0011 bib0019 bib0040"""">[11,19,40][[ refid=''''bib0011 bib0019 bib0040'''' ]]</ce:cross-refs>. Han et al. <ce:cross-ref id=""""crf0033"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> remove redundant connections and allow weight sharing, As for dynamical network modifications, these compression methods may also apply to our proposed architectures and add a compression step to our optimized ResNet architecture.</ce:para>""''"'	cites	AGA	
uses_method_in	Complexity analysis	D. Cai, X. He, J. Han, Training linear discriminant analysis in linear time , Proceedings of the 24th IEEE International Conference on Data Engineering (ICDE’08) (2008)	http://dx.doi.org/10.1016/j.patrec.2018.02.011	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/br/bib0030	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/ctx/ctx0020		22	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/itrp/0003	'For state of the art algorithms, if we apply the Spectral Regression Discriminant Analysis algorithm in [30][[ refid=''bib0030'' ]], the time complexity of LDA can reach O(NSm).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0067"""" view=""""all"""">In general, the time complexity of LDA is <mml:math altimg=""""si67.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>O</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant=""""script"""">S</mml:mi></mml:msub><mml:mi>m</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msup><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math> where <mml:math altimg=""""si68.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>min</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant=""""script"""">S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math> <ce:cross-ref id=""""crf0047"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>. The time complexity of the target projection procedure is <ce:italic>O</ce:italic>(<ce:italic>n</ce:italic><ce:sup loc=""""post"""">3</ce:sup>). When we apply GE in the overall projection, the time complexity is <ce:italic>O</ce:italic>(<ce:italic>d</ce:italic><ce:sup loc=""""post"""">3</ce:sup>). Therefore the time complexity of CDM is obtained as <mml:math altimg=""""si69.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>O</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant=""""script"""">S</mml:mi></mml:msub><mml:mi>m</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mn>3</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mn>3</mml:mn></mml:msup><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math> where <mml:math altimg=""""si68.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>min</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant=""""script"""">S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>. For state of the art algorithms, if we apply the Spectral Regression Discriminant Analysis algorithm in <ce:cross-ref id=""""crf0048"""" refid=""""bib0030"""">[30][[ refid=''''bib0030'''' ]]</ce:cross-ref>, the time complexity of LDA can reach <mml:math altimg=""""si70.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>O</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant=""""script"""">S</mml:mi></mml:msub><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math>. If we apply the Optimized Coppersmith-Winograd algorithm on matrix inversion <ce:cross-ref id=""""crf0049"""" refid=""""bib0031"""">[31][[ refid=''''bib0031'''' ]]</ce:cross-ref>, the time complexity of our CDM becomes <mml:math altimg=""""si71.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>O</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant=""""script"""">S</mml:mi></mml:msub><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mn>2.373</mml:mn></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:math>. Apparently, CDM is much more efficient than these significant algorithms.</ce:para>""''"'	cites	AGA	
cites	The proposed approach	K. Fukunaga, Introduction to Statistical Pattern Recognition , None, Academic Press Professional, Inc. (1990)	http://dx.doi.org/10.1016/j.patrec.2018.02.011			http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/br/bib0011	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/ctx/ctx0008		22	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/itrp/0005	'But the separation method is not restricted to these two methods in practice.1.Linear Discriminant AnalysisLinear Discriminant Analysis (LDA) is a common scheme for feature extraction and dimensional reduction [11][[ refid=''bib0011'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0029"""" view=""""all"""">In the source projection and the overall projection, we apply two well-known separation methods to characterize or separate the classes of instances in this paper. But the separation method is not restricted to these two methods in practice.<ce:list id=""""celist0004""""><ce:list-item id=""""celistitem0011""""><ce:label>1.</ce:label><ce:para id=""""para0030"""" view=""""all""""><ce:italic>Linear Discriminant Analysis</ce:italic></ce:para><ce:para id=""""para0031"""" view=""""all"""">Linear Discriminant Analysis (LDA) is a common scheme for feature extraction and dimensional reduction <ce:cross-ref id=""""crf0019"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>. Classic LDA maps the instances onto a lower-dimensional feature space such that the ratio of the between-class distance to the within-class distance is maximized. This results in maximum discrimination. Because we do not evaluate the variants of LDA exhaustively and do not restrict to two classes, we apply the classic multi-class LDA in this paper. We can use the transformation matrix provided by LDA as <ce:bold>P</ce:bold> in the source projection or <ce:bold>H</ce:bold> in the overall projection.</ce:para></ce:list-item><ce:list-item id=""""celistitem0012""""><ce:label>2.</ce:label><ce:para id=""""para0032"""" view=""""all""""><ce:italic>Graph Embedding</ce:italic></ce:para><ce:para id=""""para0033"""" view=""""all"""">The Graph Embedding method (GE) is defined as an algorithm that finds low-dimensional vector representation relationships among the vertices of graph <mml:math altimg=""""si23.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""script"""">G</mml:mi></mml:math> that best preserve similarities between the vertex pairs in <mml:math altimg=""""si23.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""script"""">G</mml:mi></mml:math> <ce:cross-ref id=""""crf0020"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>. The similarity is measured by a similarity matrix that characterizes certain statistical or geometric properties of the data set. We obtain the representations of the vertices from the eigenvectors corresponding to the smallest eigenvalues of the graph Laplacian matrix. The eigenvectors can be easily obtained by solving the corresponding generalized eigenvalue problem <ce:cross-refs id=""""crfs0004"""" refid=""""bib0021 bib0022"""">[21,22][[ refid=''''bib0021 bib0022'''' ]]</ce:cross-refs>. When we apply GE to the source projection or the overall projection in CDM, the solution to the corresponding generalized eigenvalue problem is used as the transformation matrix <ce:bold>P</ce:bold> or <ce:bold>H</ce:bold>, respectively.</ce:para></ce:list-item></ce:list></ce:para>""''"'	cites	AGA	
uses_method_in	The proposed approach	S. Yan, D. Xu, B. Zhang, H.-J. Zhang, Q. Yang, S. Lin, Graph embedding and extensions: a general framework for dimensionality reduction , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 29 (2007), pp.40-51	http://dx.doi.org/10.1016/j.patrec.2018.02.011			http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/br/bib0021	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/ctx/ctx0009		22	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/itrp/0006	'We can use the transformation matrix provided by LDA as P in the source projection or H in the overall projection.2.Graph EmbeddingThe Graph Embedding method (GE) is defined as an algorithm that finds low-dimensional vector representation relationships among the vertices of graph G that best preserve similarities between the vertex pairs in G [21][[ refid=''bib0021'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0029"""" view=""""all"""">In the source projection and the overall projection, we apply two well-known separation methods to characterize or separate the classes of instances in this paper. But the separation method is not restricted to these two methods in practice.<ce:list id=""""celist0004""""><ce:list-item id=""""celistitem0011""""><ce:label>1.</ce:label><ce:para id=""""para0030"""" view=""""all""""><ce:italic>Linear Discriminant Analysis</ce:italic></ce:para><ce:para id=""""para0031"""" view=""""all"""">Linear Discriminant Analysis (LDA) is a common scheme for feature extraction and dimensional reduction <ce:cross-ref id=""""crf0019"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>. Classic LDA maps the instances onto a lower-dimensional feature space such that the ratio of the between-class distance to the within-class distance is maximized. This results in maximum discrimination. Because we do not evaluate the variants of LDA exhaustively and do not restrict to two classes, we apply the classic multi-class LDA in this paper. We can use the transformation matrix provided by LDA as <ce:bold>P</ce:bold> in the source projection or <ce:bold>H</ce:bold> in the overall projection.</ce:para></ce:list-item><ce:list-item id=""""celistitem0012""""><ce:label>2.</ce:label><ce:para id=""""para0032"""" view=""""all""""><ce:italic>Graph Embedding</ce:italic></ce:para><ce:para id=""""para0033"""" view=""""all"""">The Graph Embedding method (GE) is defined as an algorithm that finds low-dimensional vector representation relationships among the vertices of graph <mml:math altimg=""""si23.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""script"""">G</mml:mi></mml:math> that best preserve similarities between the vertex pairs in <mml:math altimg=""""si23.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mi mathvariant=""""script"""">G</mml:mi></mml:math> <ce:cross-ref id=""""crf0020"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>. The similarity is measured by a similarity matrix that characterizes certain statistical or geometric properties of the data set. We obtain the representations of the vertices from the eigenvectors corresponding to the smallest eigenvalues of the graph Laplacian matrix. The eigenvectors can be easily obtained by solving the corresponding generalized eigenvalue problem <ce:cross-refs id=""""crfs0004"""" refid=""""bib0021 bib0022"""">[21,22][[ refid=''''bib0021 bib0022'''' ]]</ce:cross-refs>. When we apply GE to the source projection or the overall projection in CDM, the solution to the corresponding generalized eigenvalue problem is used as the transformation matrix <ce:bold>P</ce:bold> or <ce:bold>H</ce:bold>, respectively.</ce:para></ce:list-item></ce:list></ce:para>""''"'	cites	AGA	
cites	Introduction	L. Duan, D. Xu, I.W. Tsang, Learning with augmented features for heterogeneous domain adaptation , Proceedings of the 29th International Conference on Machine Learning (ICML’12) (2012)	http://dx.doi.org/10.1016/j.patrec.2018.02.011	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/br/bib0009	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/ctx/ctx0004		22	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/itrp/0015	'this assumption may not be valid for many applications such as object recognition, where only visual features are available [9][[ refid=''bib0009'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0005"""" view=""""all"""">Most existing domain adaptation algorithms focus on improving generalizations across different data distributions between source and target domains, and often assume that the feature spaces of the two domains are the same. However, the data dimensions from the source and target domains may be different. This kind of problem is known as <ce:italic>heterogeneous domain adaptation</ce:italic> (HDA). Readers may refer to survey articles such as <ce:cross-refs id=""""crfs0002"""" refid=""""bib0004 bib0005"""">[4,5][[ refid=''''bib0004 bib0005'''' ]]</ce:cross-refs> for more information. A common assumption when applying HDA is that the source and target domains share co-occurrence features or data <ce:cross-refs id=""""crfs0003"""" refid=""""bib0006 bib0007 bib0008"""">[6–8][[ refid=''''bib0006 bib0007 bib0008'''' ]]</ce:cross-refs>. However. this assumption may not be valid for many applications such as object recognition, where only visual features are available <ce:cross-ref id=""""crf0013"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Introduction	R.A. Johnson, D.W. Wichern, Applied Multivariate Statistical Analysis , None, Pearson Prentice hall (2007)	http://dx.doi.org/10.1016/j.patrec.2018.02.011	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/ctx/ctx0005		22	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/itrp/0016	'In multivariate statistical analysis, discrimination (also called separation as a more descriptive term) is a technique used for separating distinct sets of observations, and often provides the basis for a classification rule [10][[ refid=''bib0010'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">In multivariate statistical analysis, <ce:italic>discrimination</ce:italic> (also called <ce:italic>separation</ce:italic> as a more descriptive term) is a technique used for separating distinct sets of observations, and often provides the basis for a classification rule <ce:cross-ref id=""""crf0014"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. Our approach is in part inspired by discrimination techniques, such as Fisher linear discriminant analysis <ce:cross-ref id=""""crf0015"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>. Two mapping functions are derived for the purpose of obtaining a low-dimensional representation of the data that separates the populations as much as possible. According to the supervision information in the target domain, our approach belongs to the <ce:italic>supervised</ce:italic> heterogeneous domain adaptation in which only labeled data are used in the target domain <ce:cross-ref id=""""crf0016"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>. We compare the proposed method with some related work in this field in <ce:cross-ref id=""""crf0017"""" refid=""""tbl0001"""">Table 1</ce:cross-ref><ce:float-anchor refid=""""tbl0001""""/>.</ce:para>""''"'	cites	AGA	
uses_method_in	Introduction	W. Li, L. Duan, D. Xu, I.W. Tsang, Learning with augmented features for supervised and semi-supervised heterogeneous domain adaptation , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 36 (2014), pp.1134-1148	http://dx.doi.org/10.1016/j.patrec.2018.02.011	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/br/bib0012	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/ctx/ctx0007		22	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/itrp/0018	'According to the supervision information in the target domain, our approach belongs to the supervised heterogeneous domain adaptation in which only labeled data are used in the target domain [12][[ refid=''bib0012'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">In multivariate statistical analysis, <ce:italic>discrimination</ce:italic> (also called <ce:italic>separation</ce:italic> as a more descriptive term) is a technique used for separating distinct sets of observations, and often provides the basis for a classification rule <ce:cross-ref id=""""crf0014"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. Our approach is in part inspired by discrimination techniques, such as Fisher linear discriminant analysis <ce:cross-ref id=""""crf0015"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>. Two mapping functions are derived for the purpose of obtaining a low-dimensional representation of the data that separates the populations as much as possible. According to the supervision information in the target domain, our approach belongs to the <ce:italic>supervised</ce:italic> heterogeneous domain adaptation in which only labeled data are used in the target domain <ce:cross-ref id=""""crf0016"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>. We compare the proposed method with some related work in this field in <ce:cross-ref id=""""crf0017"""" refid=""""tbl0001"""">Table 1</ce:cross-ref><ce:float-anchor refid=""""tbl0001""""/>.</ce:para>""''"'	uses_data_from	AGA	
cites	Complexity analysis	J.T. Zhou, I.W. Tsang, S.J. Pan, M. Tan, Heterogeneous domain adaptation for multiple classes , Proceedings of the 17th International Conference on Artificial Intelligence and Statistics (AISTATS’14) (2014)	http://dx.doi.org/10.1016/j.patrec.2018.02.011	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/br/bib0014	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/sec/6	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/ctx/ctx0018		22	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/itrp/0020	'Therefore, ART-c is not appropriate for large problems [14][[ refid=''bib0014'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0066"""" view=""""all"""">DAMA first builds a series of combinatorial Laplacian matrices in <mml:math altimg=""""si64.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mi mathvariant=""""double-struck"""">R</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant=""""script"""">S</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant=""""script"""">T</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant=""""script"""">S</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant=""""script"""">T</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math>. Next, DAMA must solve a generalized eigenvalue decomposition problem and it requires computation in <mml:math altimg=""""si65.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>O</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>+</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>3</mml:mn></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:math> time. Hence DAMA is not efficient for large-scale or high-dimensional data sets. The ART-c approach needs to solve an optimization problem that contains <mml:math altimg=""""si66.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant=""""script"""">S</mml:mi></mml:msub><mml:msub><mml:mi>N</mml:mi><mml:mi mathvariant=""""script"""">T</mml:mi></mml:msub></mml:mrow></mml:math> constraints, and its authors opted for a projection method based on Bregman’s algorithm. Therefore, ART-c is not appropriate for large problems <ce:cross-ref id=""""crf0046"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
uses_data_from	Experimental results	M.-R. Amini, N. Usunier, C. Goutte, Learning from multiple partially observed views - an application to multilingual text categorization , Proceedings of the 23rd Annual Conference on Advances in Neural Information Processing Systems (NIPS’09) (2009)	http://dx.doi.org/10.1016/j.patrec.2018.02.011	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/br/bib0026	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/ctx/ctx0013		22	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/itrp/0021	'The second data set is a subset of the Reuters RCV1/RCV2 collections [26][[ refid=''bib0026'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0052"""" view=""""all"""">The second data set is a subset of the Reuters RCV1/RCV2 collections <ce:cross-ref id=""""crf0031"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref>. It contains newswire articles written in <ce:monospace>English</ce:monospace>, <ce:monospace>French</ce:monospace>, <ce:monospace>German</ce:monospace>, <ce:monospace>Italian</ce:monospace>, and <ce:monospace>Spanish</ce:monospace>. There are six classes for these articles: <ce:monospace>C15</ce:monospace> (Performance), <ce:monospace>CCAT</ce:monospace> (Corporate/Industrial), <ce:monospace>E21</ce:monospace> (Government finance), <ce:monospace>ECAT</ce:monospace> (Economis), <ce:monospace>GCAT</ce:monospace> (Government/Social), and <ce:monospace>M11</ce:monospace> (Equity Markets).</ce:para>""''"'	uses_data_from	AGA	
ERROR	Experimental results	K. Saenko, B. Kulis, M. Fritz, T. Darrell, Adapting visual category models to new domains , Proceedings of the 11th European Conference on Computer Vision (ECCV’10) (2010)	http://dx.doi.org/10.1016/j.patrec.2018.02.011	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/br/bib0025	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/ctx/ctx0012		22	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/itrp/0022	'contains 4652 images from 31 categories22These 31 categories are: backpack, bike, bike helmet, bookcase, bottle, calculator, computer, desk chair, desk lamp, file cabinet, headphones, keyboard, laptop, letter tray, mobile phone, monitor, mouse, mug, notebook, pen, phone, printer, projector, puncher, ring binder, ruler, scissors, speaker, stapler, tape, and trash can originating from the following three domains: Amazon (images downloaded from an online retail website), dslr (high-resolution images taken from a digital DSLR camera), and webcam (low-resolution images taken from a web camera) [25][[ refid=''bib0025'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0050"""" view=""""all"""">The first data set<ce:cross-ref id=""""crf0027"""" refid=""""fn0001""""><ce:sup loc=""""post"""">1</ce:sup></ce:cross-ref><ce:footnote id=""""fn0001""""><ce:label>1</ce:label><ce:note-para id=""""cenotep0001"""" view=""""all"""">Visit <ce:inter-ref id=""""interref0001"""" xlink:href=""""http://vision.cs.uml.edu/adaptation.html"""" xlink:type=""""simple"""">http://vision.cs.uml.edu/adaptation.html</ce:inter-ref> for more details.</ce:note-para></ce:footnote> contains 4652 images from 31 categories<ce:cross-ref id=""""crf0028"""" refid=""""fn0002""""><ce:sup loc=""""post"""">2</ce:sup></ce:cross-ref><ce:footnote id=""""fn0002""""><ce:label>2</ce:label><ce:note-para id=""""cenotep0002"""" view=""""all"""">These 31 categories are: backpack, bike, bike helmet, bookcase, bottle, calculator, computer, desk chair, desk lamp, file cabinet, headphones, keyboard, laptop, letter tray, mobile phone, monitor, mouse, mug, notebook, pen, phone, printer, projector, puncher, ring binder, ruler, scissors, speaker, stapler, tape, and trash can</ce:note-para></ce:footnote> originating from the following three domains: <ce:monospace>Amazon</ce:monospace> (images downloaded from an online retail website), <ce:monospace>dslr</ce:monospace> (high-resolution images taken from a digital DSLR camera), and <ce:monospace>webcam</ce:monospace> (low-resolution images taken from a web camera) <ce:cross-ref id=""""crf0029"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref>. Speeded up robust features (SURF) are extracted from all the images.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experimental results	J. Shawe-Taylor, N. Cristianini, Kernel Methods for Pattern Analysis , None, Cambridge University Press (2004)	http://dx.doi.org/10.1016/j.patrec.2018.02.011	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/ctx/ctx0015		22	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/itrp/0033	'The algorithms are as follows:•SVM_T: SVM_T trains an SVM classifier for each category only on the labeled instances from the target domain.•KCCA: KCCA learns a common feature subspace by maximizing the correlation between source- and target-domain instances without using any label information [27][[ refid=''bib0027'' ]].•HeMap: HeMap uses the spectral embedding technique to locate two projection matrices for a common subspace.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0056"""" view=""""all"""">We compare our results with the results reported in <ce:cross-ref id=""""crf0035"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>, which use HDA approaches on classification tasks. The algorithms are as follows:<ce:list id=""""celist0007""""><ce:list-item id=""""celistitem0013""""><ce:label>•</ce:label><ce:para id=""""para0057"""" view=""""all"""">SVM_T: SVM_T trains an SVM classifier for each category only on the labeled instances from the target domain.</ce:para></ce:list-item><ce:list-item id=""""celistitem0014""""><ce:label>•</ce:label><ce:para id=""""para0058"""" view=""""all"""">KCCA: KCCA learns a common feature subspace by maximizing the correlation between source- and target-domain instances without using any label information <ce:cross-ref id=""""crf0036"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0015""""><ce:label>•</ce:label><ce:para id=""""para0059"""" view=""""all"""">HeMap: HeMap uses the spectral embedding technique to locate two projection matrices for a common subspace. The label information is also not used <ce:cross-ref id=""""crf0037"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0016""""><ce:label>•</ce:label><ce:para id=""""para0060"""" view=""""all"""">DAMA: DAMA extends existing manifold alignment approaches by making use of labels to link different features spaces <ce:cross-ref id=""""crf0038"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0017""""><ce:label>•</ce:label><ce:para id=""""para0061"""" view=""""all"""">ARC-t: ARC-t learns an asymmetric transformation for different domains <ce:cross-ref id=""""crf0039"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>.</ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_method_in	AGA	
cites	Experimental results	L. Duan, D. Xu, I.W. Tsang, Learning with augmented features for heterogeneous domain adaptation , Proceedings of the 29th International Conference on Machine Learning (ICML’12) (2012)	http://dx.doi.org/10.1016/j.patrec.2018.02.011	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/br/bib0009	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/ctx/ctx0014		22	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-011/itrp/0034	'We compare our results with the results reported in [9][[ refid=''bib0009'' ]], which use HDA approaches on classification tasks.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0056"""" view=""""all"""">We compare our results with the results reported in <ce:cross-ref id=""""crf0035"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>, which use HDA approaches on classification tasks. The algorithms are as follows:<ce:list id=""""celist0007""""><ce:list-item id=""""celistitem0013""""><ce:label>•</ce:label><ce:para id=""""para0057"""" view=""""all"""">SVM_T: SVM_T trains an SVM classifier for each category only on the labeled instances from the target domain.</ce:para></ce:list-item><ce:list-item id=""""celistitem0014""""><ce:label>•</ce:label><ce:para id=""""para0058"""" view=""""all"""">KCCA: KCCA learns a common feature subspace by maximizing the correlation between source- and target-domain instances without using any label information <ce:cross-ref id=""""crf0036"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0015""""><ce:label>•</ce:label><ce:para id=""""para0059"""" view=""""all"""">HeMap: HeMap uses the spectral embedding technique to locate two projection matrices for a common subspace. The label information is also not used <ce:cross-ref id=""""crf0037"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0016""""><ce:label>•</ce:label><ce:para id=""""para0060"""" view=""""all"""">DAMA: DAMA extends existing manifold alignment approaches by making use of labels to link different features spaces <ce:cross-ref id=""""crf0038"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref>.</ce:para></ce:list-item><ce:list-item id=""""celistitem0017""""><ce:label>•</ce:label><ce:para id=""""para0061"""" view=""""all"""">ARC-t: ARC-t learns an asymmetric transformation for different domains <ce:cross-ref id=""""crf0039"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref>.</ce:para></ce:list-item></ce:list></ce:para>""''"'	cites	AGA	
uses_data_from	Experiment and result analysis	J. Pennington, R. Socher, C.D. Manning, Glove: global vectors for word representation , EMNLP, October , vol. 14 (2014), pp.1532-1543	http://dx.doi.org/10.1016/j.patrec.2018.02.017	results	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/br/bib0026	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/ctx/ctx0023		26	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/itrp/0003	'provided by Pennington et al. [26][[ refid=''bib0026'' ]] as the representation of words in the datasets.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0025"""" view=""""all"""">For all RNN models in the experiments, we use the publicly available word embedding<ce:cross-ref id=""""crf0045"""" refid=""""cit_1""""><ce:sup loc=""""post"""">1</ce:sup></ce:cross-ref><ce:footnote id=""""cit_1""""><ce:label>1</ce:label><ce:note-para id=""""notep0000"""" view=""""all""""><ce:inter-ref id=""""interref0001"""" xlink:href=""""http://nlp.stanford.edu/data/glove.42B.300d.zip"""" xlink:type=""""simple"""">http://nlp.stanford.edu/data/glove.42B.300d.zip</ce:inter-ref>.</ce:note-para></ce:footnote> provided by Pennington et al. <ce:cross-ref id=""""crf0046"""" refid=""""bib0026"""">[26][[ refid=''''bib0026'''' ]]</ce:cross-ref> as the representation of words in the datasets. The word embeddings are 300-dimensional vectors trained on the dataset of Wikipedia, containing approximately 200 million words. With the standard BIO tagging scheme, the output of RNN models at every time step will be a three-element vector, where each element separately stands for the probability of Label B, Label I and Label O.</ce:para>""''"'	uses_data_from	AGA	
cites	The model	Chung, J., Gulcehre, C., Cho, K., & Bengio, Y. (2014). Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:	http://dx.doi.org/10.1016/j.patrec.2018.02.017	model		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/br/bib0022	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/ctx/ctx0020		26	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/itrp/0004	'Chung et al. [22][[ refid=''bib0022'' ]] have demonstrated the superiority of the gated units in both effectiveness and efficiency.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0016"""" view=""""all"""">Chung et al. <ce:cross-ref id=""""crf0037"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref> have demonstrated the superiority of the gated units in both effectiveness and efficiency. Inspired by this finding, we leverage a gated-unit structure for the hidden layer of the OLSRNN model shown in <ce:cross-ref id=""""crf0038"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref>. The structure contains three layers of units, namely, update gate layer, input-tanh layer and memory unit layer. The update gate layer decides the importance of each dimensionality in the value of memory unit layer; the input-tanh layer decides what should be added to the current memory unit layer; then, the memory unit layer carries the contextual information, which is significant to predict current output.</ce:para>""''"'	cites	AGA	
cites	Experiment and result analysis	Y. Bengio, P. Simard, P. Frasconi, Learning long-term dependencies with gradient descent is difficult , IEEE Trans. Neural Netw. , vol. 5 (1994), pp.157-166	http://dx.doi.org/10.1016/j.patrec.2018.02.017	methods	discussion	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/br/bib0027	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/ctx/ctx0026		26	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/itrp/0007	'As for the SRNN model, it does not converge within the 60 epochs in training, which is due to the poor capacity of learning and the problem of vanishing gradient [27][[ refid=''bib0027'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0034"""" view=""""all"""">Apparent in <ce:cross-ref id=""""crf0053"""" refid=""""fig0003"""">Fig. 3</ce:cross-ref> are the significant differences among the convergence rates of the different models. OLSRNN model takes approximately 25 epochs for convergence, which is approximately 30% less than the LSTM model and 20% less than the GRU model. This finding can be explained by the simpler calculation in the proposed hidden layer structure of the OLSRNN model than those of the LSTM and GRU models, where excessive nonlinear operations cause difficulties to learn the mutual relationship between historical information and current input. As for the SRNN model, it does not converge within the 60 epochs in training, which is due to the poor capacity of learning and the problem of vanishing gradient <ce:cross-ref id=""""crf0054"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
uses_method_in	Experiment and result analysis	A. Graves, N. Jaitly, Towards end-to-end speech recognition with recurrent neural networks , ICML , vol. 14 (2014), pp.1764-1772	http://dx.doi.org/10.1016/j.patrec.2018.02.017	discussion	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/ctx/ctx0025		26	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/itrp/0010	'Before optimization, all the weights in the networks are initialized simply by sampling from a flat uniform distribution in the range [−0.1, 0.1], as Graves et al. [18][[ refid=''bib0018'' ]] experimentally proved that the results of the RNN models are insensitive to either the distribution or the range of weight initialization.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0028"""" view=""""all"""">We use the cross entropy between the predicted probability <mml:math altimg=""""si8.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mi>o</mml:mi><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:msubsup></mml:math> and the true label <mml:math altimg=""""si9.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:msubsup><mml:mi>y</mml:mi><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:msubsup></mml:math> as the cost function of models<ce:display><ce:formula id=""""eqn0005""""><ce:label>(5)</ce:label><mml:math altimg=""""si10.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>J</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>o</mml:mi><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></ce:formula></ce:display>which will be minimized during the training by stochastic gradient descent. Before optimization, all the weights in the networks are initialized simply by sampling from a flat uniform distribution in the range [−0.1, 0.1], as Graves et al. <ce:cross-ref id=""""crf0050"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> experimentally proved that the results of the RNN models are insensitive to either the distribution or the range of weight initialization. We set an initial learning rate at 0.001 and diminish it by 70% after every 20 epochs of training on the training sets.</ce:para>""''"'	cites	AGA	
cites	Introduction	M.I. Jordan, Serial order: a parallel distributed processing approach , Adv. Psychol. , vol. 121 (1997), pp.471-495	http://dx.doi.org/10.1016/j.patrec.2018.02.017	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/br/bib0009	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/ctx/ctx0008		26	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/itrp/0011	'Enlightened by Jordan Networks [9][[ refid=''bib0009'' ]], each input of the output layer node in the OLSRNN model not only comes from the output of the current hidden layer but also that of the output layer at the previous time step.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0008"""" view=""""all"""">In term of this, in this paper we propose an augmented recurrent neural network (RNN) called output layer self-connection recurrent neural networks (OLSRNNs), which are trained to recognize opinion targets. In comparison with previous work, we further attempt to capture the temporal dependencies in the RNN output sequences. Enlightened by Jordan Networks <ce:cross-ref id=""""crf0015"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>, each input of the output layer node in the OLSRNN model not only comes from the output of the current hidden layer but also that of the output layer at the previous time step. Moreover, we equip the proposed model with a new hidden layer structure, which transforms some units based on the hidden layer structure of the LSTM model <ce:cross-ref id=""""crf0016"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. The aim is to learn the long-range dependencies in the input sequence and to create a more compact model.</ce:para>""''"'	cites	AGA	
cites	Introduction	S. Hochreiter, J. Schmidhuber, Long short-term memory , Neural Comput. , vol. 9 (1997), pp.1735-1780	http://dx.doi.org/10.1016/j.patrec.2018.02.017	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/br/bib0010	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/ctx/ctx0009		26	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/itrp/0012	'Moreover, we equip the proposed model with a new hidden layer structure, which transforms some units based on the hidden layer structure of the LSTM model [10][[ refid=''bib0010'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0008"""" view=""""all"""">In term of this, in this paper we propose an augmented recurrent neural network (RNN) called output layer self-connection recurrent neural networks (OLSRNNs), which are trained to recognize opinion targets. In comparison with previous work, we further attempt to capture the temporal dependencies in the RNN output sequences. Enlightened by Jordan Networks <ce:cross-ref id=""""crf0015"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>, each input of the output layer node in the OLSRNN model not only comes from the output of the current hidden layer but also that of the output layer at the previous time step. Moreover, we equip the proposed model with a new hidden layer structure, which transforms some units based on the hidden layer structure of the LSTM model <ce:cross-ref id=""""crf0016"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>. The aim is to learn the long-range dependencies in the input sequence and to create a more compact model.</ce:para>""''"'	cites	AGA	
cites	Introduction	O. Irsoy, C. Cardie, Opinion mining with deep recurrent neural networks , EMNLP October (2014)	http://dx.doi.org/10.1016/j.patrec.2018.02.017	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/br/bib0003	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/ctx/ctx0002		26	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/itrp/0015	'Opinion target recognition can be deemed a problem of token-level sequence labelling, and each word in the sentence is assigned to a label with the standard BIO tagging scheme [3][[ refid=''bib0003'' ]]: Label B means that the word is the beginning of an opinion target; Label I means that the word is the continuation of an opinion target; and label O means that the words are not part of any opinion targets.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0005"""" view=""""all"""">With the continuous popularity of electronic commerce, the number of customer reviews increases rapidly and in turn stimulates the technological development of opinion target recognition <ce:cross-refs id=""""crf0002"""" refid=""""bib0001 bib0002"""">[1,2][[ refid=''''bib0001 bib0002'''' ]]</ce:cross-refs>. An opinion target generally consists of one or more words expressed by opinion holders in customer reviews. Opinion target recognition can be deemed a problem of token-level sequence labelling, and each word in the sentence is assigned to a label with the standard BIO tagging scheme <ce:cross-ref id=""""crf0004"""" refid=""""bib0003"""">[3][[ refid=''''bib0003'''' ]]</ce:cross-ref>: Label B means that the word is the beginning of an opinion target; Label I means that the word is the continuation of an opinion target; and label O means that the words are not part of any opinion targets. For example, <ce:cross-ref id=""""crf0005"""" refid=""""tbl0001"""">Table 1</ce:cross-ref><ce:float-anchor refid=""""tbl0001""""/> shows a consumer review annotated with a standard BIO tagging scheme for the task of opinion target recognition.</ce:para>""''"'	cites	AGA	
cites	Introduction	M. Hu, B. Liu, Mining opinion features in customer reviews , AAAI 2004, , vol. 4 (2004), pp.755-760	http://dx.doi.org/10.1016/j.patrec.2018.02.017	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/ctx/ctx0003		26	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/itrp/0016	'For the first group, the most representative work using frequent term mining approach is proposed by Hu and Liu [4][[ refid=''bib0004'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0006"""" view=""""all"""">The existing works on opinion target extraction can be divided into three groups: frequent term mining, unsupervised rule based approach and supervised sequence labeling. For the first group, the most representative work using frequent term mining approach is proposed by Hu and Liu <ce:cross-ref id=""""crf0006"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>. The second group is to address this problem by manually constructing grammar rules or by using feature–opinion relation analysis <ce:cross-refs id=""""crf0007"""" refid=""""bib0005 bib0006"""">[5,6][[ refid=''''bib0005 bib0006'''' ]]</ce:cross-refs>. The third is supervised sequence labeling based approaches <ce:cross-ref id=""""crf0009"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> and among them RNN-based methods <ce:cross-refs id=""""crf0010"""" refid=""""bib0003 bib0008"""">[3,8][[ refid=''''bib0003 bib0008'''' ]]</ce:cross-refs> have attracted many researchers recently. Liu et al. <ce:cross-ref id=""""crf0012"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref> experimented with various existing RNN models and proved that RNN-based methods outperform the others on the task without any extra preprocessing techniques and task-specific feature engineering efforts. Consequently, we focus on the RNN-based methods in this paper.</ce:para>""''"'	cites	AGA	
cites	Related work	S.S. Htay, K.T. Lynn, Extracting product features and opinion words using pattern knowledge in customer reviews , Sci. World J. (2013)	http://dx.doi.org/10.1016/j.patrec.2018.02.017	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/br/bib0005	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/ctx/ctx0012		26	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/itrp/0034	'Htay and Lynn [5][[ refid=''bib0005'' ]] addressed the problem with the POS patterns of opinion targets and achieved an acceptable result.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0011"""" view=""""all"""">Hu and Liu <ce:cross-ref id=""""crf0017"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref> extracted nouns and noun phrases that appear at high frequency in the datasets by using association-rule mining; then, they used pruning search to obtain the true opinion targets in the candidate set. Yi et al. <ce:cross-ref id=""""crf0018"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> recognized opinion targets by using the hybrid language model. Htay and Lynn <ce:cross-ref id=""""crf0019"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> addressed the problem with the POS patterns of opinion targets and achieved an acceptable result. Considering the difficulty of ensuring the completeness of the rules and the laborious task of manually creating these rules, the performance of rule-based methods may be adversely affected.</ce:para>""''"'	cites	AGA	
cites	Related work	M. Hu, B. Liu, Mining opinion features in customer reviews , AAAI 2004, , vol. 4 (2004), pp.755-760	http://dx.doi.org/10.1016/j.patrec.2018.02.017	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/ctx/ctx0010		26	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/itrp/0036	'Hu and Liu [4][[ refid=''bib0004'' ]] extracted nouns and noun phrases that appear at high frequency in the datasets by using association-rule mining; then, they used pruning search to obtain the true opinion targets in the candidate set.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0011"""" view=""""all"""">Hu and Liu <ce:cross-ref id=""""crf0017"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref> extracted nouns and noun phrases that appear at high frequency in the datasets by using association-rule mining; then, they used pruning search to obtain the true opinion targets in the candidate set. Yi et al. <ce:cross-ref id=""""crf0018"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> recognized opinion targets by using the hybrid language model. Htay and Lynn <ce:cross-ref id=""""crf0019"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> addressed the problem with the POS patterns of opinion targets and achieved an acceptable result. Considering the difficulty of ensuring the completeness of the rules and the laborious task of manually creating these rules, the performance of rule-based methods may be adversely affected.</ce:para>""''"'	uses_data_from	AGA	
cites	Related work	N. Jakob, I. Gurevych, Extracting opinion targets in a single- and cross-domain setting with conditional random fields , EMNLP ’10 (2010)	http://dx.doi.org/10.1016/j.patrec.2018.02.017	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/br/bib0007	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/ctx/ctx0016		26	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/itrp/0041	'Jakob and Gurevych [7][[ refid=''bib0007'' ]] trained a CRF model on the datasets of several domains together to solve the problem of cross-domain adaption.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">Wong et al. <ce:cross-ref id=""""crf0020"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> and Kim et al. <ce:cross-ref id=""""crf0021"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> extracted opinion targets with the hidden Markov model (HMM) and maximum entropy model based on statistical features, respectively. Other researchers comparatively preferred to use the conditional random field model <ce:cross-ref id=""""crf0022"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> because of the HMM''''s failure to handle long-range dependencies and the label bias problem in MaxEnt. Zhang et al. <ce:cross-ref id=""""crf0023"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> addressed the problem by using a CRF model and various sophisticated rules, which combine rules and statistics. Jakob and Gurevych <ce:cross-ref id=""""crf0024"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> trained a CRF model on the datasets of several domains together to solve the problem of cross-domain adaption.</ce:para>""''"'	uses_data_from	AGA	
cites	Related work	R. Klinger, K. Tomanek, Classical Probabilistic Models and Conditional Random Fields , None, TU (2007)	http://dx.doi.org/10.1016/j.patrec.2018.02.017	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/br/bib0014	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/ctx/ctx0014		26	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-02-017/itrp/0043	'Other researchers comparatively preferred to use the conditional random field model [14][[ refid=''bib0014'' ]] because of the HMM''s failure to handle long-range dependencies and the label bias problem in MaxEnt.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all"""">Wong et al. <ce:cross-ref id=""""crf0020"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> and Kim et al. <ce:cross-ref id=""""crf0021"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> extracted opinion targets with the hidden Markov model (HMM) and maximum entropy model based on statistical features, respectively. Other researchers comparatively preferred to use the conditional random field model <ce:cross-ref id=""""crf0022"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> because of the HMM''''s failure to handle long-range dependencies and the label bias problem in MaxEnt. Zhang et al. <ce:cross-ref id=""""crf0023"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> addressed the problem by using a CRF model and various sophisticated rules, which combine rules and statistics. Jakob and Gurevych <ce:cross-ref id=""""crf0024"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> trained a CRF model on the datasets of several domains together to solve the problem of cross-domain adaption.</ce:para>""''"'	cites	AGA	
uses_method_in	Experimental investigation	M. Lan, C.L. Tan, J. Su, Y. Lu, Supervised and traditional term weighting methods for automatic text categorization , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31 (2009), pp.721-735	http://dx.doi.org/10.1016/j.patrec.2018.03.003	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/br/bib0017	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/ctx/ctx0023		32	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/itrp/0003	'Following [17][[ refid=''bib0017'' ]], we used linear SVM for simplicity and high performance.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0041"""" view=""""all"""">TC results are well suited to evaluate the term weighting methods. The <ce:italic>k</ce:italic> nearest neighbor (kNN) algorithm is an effective classification method. We used the simplest case where <mml:math altimg=""""si64.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math> meant a document was assigned to the class of the single nearest neighbor. Support vector machine (SVM) is another widely-used classification method, and has better performance than many other methods for TC. Term selection does not improve or even slightly degrades SVM performance <ce:cross-refs id=""""crfs0005"""" refid=""""bib0018 bib0019"""">[18,19][[ refid=''''bib0018 bib0019'''' ]]</ce:cross-refs>, so it is ideal to assess loss effects from weight reductions in <ce:italic>lrp</ce:italic>. Following <ce:cross-ref id=""""crf0043"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref>, we used linear SVM for simplicity and high performance.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Methodology: Latent relevance probability weighting scheme	M. Lan, C.L. Tan, J. Su, Y. Lu, Supervised and traditional term weighting methods for automatic text categorization , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31 (2009), pp.721-735	http://dx.doi.org/10.1016/j.patrec.2018.03.003	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/br/bib0017>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/ctx/ctx0020>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/itrp/0004	'Consider the extreme case, α=1, then lrp=rp.After replacing posterior estimators by maximum likelihood estimators for θ1, θ0 in rp, [[ formulaid=''id14_pos2'' ]] rp and rf[17][[ refid=''bib0017'' ]] share the same part, n11/n10, while the expression of rp is contradictory to rf.'			FDY+AGA	infered_pred1
uses_data_from	Experimental investigation	I. Guyon, A. Saffari, G. Dror, G. Cawley, Analysis of the IJCNN 2007 agnostic learning vs. prior knowledge challenge , Neural Netw. , vol. 21 (2008), pp.544-550	http://dx.doi.org/10.1016/j.patrec.2018.03.003	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/br/bib0011	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/ctx/ctx0027		32	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/itrp/0009	'Nova was downloaded from the IJCNN 2006 performance prediction challenge, which comes from the 20 Newsgroup dataset [11][[ refid=''bib0011'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0044"""" view=""""all"""">We chose three small text datasets, Dexter, Nova, and Farm Ads, which have only two classes including positive class and negative class. Farm Ads and the NIPS benchmark dataset Dexter <ce:cross-ref id=""""crf0046"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref> were downloaded from the UCI Machine Learning Repository <ce:cross-ref id=""""crf0047"""" refid=""""bib0002"""">[2][[ refid=''''bib0002'''' ]]</ce:cross-ref>. Nova was downloaded from the IJCNN 2006 performance prediction challenge, which comes from the 20 Newsgroup dataset <ce:cross-ref id=""""crf0048"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>. <ce:cross-ref id=""""crf0049"""" refid=""""tbl0005"""">Table 5</ce:cross-ref><ce:float-anchor refid=""""tbl0005""""/> summarizes the datasets.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Experimental investigation	C. Chang, C. Lin, LIBSVM : a library for support vector machines , ACM Trans. Intell. Syst. Technol. , vol. 2 (2011), pp.27	http://dx.doi.org/10.1016/j.patrec.2018.03.003	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/ctx/ctx0024		32	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/itrp/0010	'The kNN algorithm was from the Matlab toolbox, and linear SVM was from LIBSVM-3.21, integrated software [4][[ refid=''bib0004'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0042"""" view=""""all"""">All algorithms were run in Matlab R2014b. The kNN algorithm was from the Matlab toolbox, and linear SVM was from LIBSVM-3.21, integrated software <ce:cross-ref id=""""crf0044"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref>.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experimental investigation	F. Sebastiani, Machine learning in automated text categorization , ACM Comput. Surv. , vol. 34 (2002), pp.1-47	http://dx.doi.org/10.1016/j.patrec.2018.03.003	methods		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/ctx/ctx0025		32	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/itrp/0011	'For multi-class text collections, the micro-averaged F1 measure was adopted [23][[ refid=''bib0023'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0043"""" view=""""all"""">Two classification effectiveness measures, accuracy and <ce:italic>F</ce:italic><ce:inf loc=""""post"""">1</ce:inf>, were adopted. Accuracy was used only for two-class cases. For multi-class text collections, the micro-averaged <ce:italic>F</ce:italic><ce:inf loc=""""post"""">1</ce:inf> measure was adopted <ce:cross-ref id=""""crf0045"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Introduction	T.T. Nguyen, K. Chang, S. Hui, Supervised term weighting centroid-based classifiers for text categorization , Knowl. Inf. Syst. , vol. 35 (2013), pp.61-85	http://dx.doi.org/10.1016/j.patrec.2018.03.003	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/br/bib0020	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/ctx/ctx0008		32	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/itrp/0014	'Another approach is to use terms weighted on the Kullback–Leibler (KL) divergence measure between pairs of class-conditional term probabilities, and Jensen–Shannon (JS) divergence for multi-class data [20][[ refid=''bib0020'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0009"""" view=""""all"""">Some other approaches suggested to use probabilistic models, which have proven very effective in information retrieval and TC <ce:cross-refs id=""""crfs0002"""" refid=""""bib0014 bib0016"""">[14,16][[ refid=''''bib0014 bib0016'''' ]]</ce:cross-refs>. One approach is to weight terms based on their statistical confidence intervals <ce:cross-ref id=""""crf0011"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>. It has also been proposed that the ratio and absolute difference of term occurrence can be used to improve the performance <ce:cross-refs id=""""crfs0003"""" refid=""""bib0001 bib0007"""">[1,7][[ refid=''''bib0001 bib0007'''' ]]</ce:cross-refs>. Another approach is to use terms weighted on the Kullback–Leibler (KL) divergence measure between pairs of class-conditional term probabilities, and Jensen–Shannon (JS) divergence for multi-class data <ce:cross-ref id=""""crf0012"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>. Inverse category frequency has also been considered for term weighting schemes, which favors terms occurring in fewer classes rather than fewer documents <ce:cross-refs id=""""crfs0004"""" refid=""""bib0021 bib0025"""">[21,25][[ refid=''''bib0021 bib0025'''' ]]</ce:cross-refs>.</ce:para>""''"'	uses_data_from	AGA	
cites	Introduction	F. Sebastiani, Machine learning in automated text categorization , ACM Comput. Surv. , vol. 34 (2002), pp.1-47	http://dx.doi.org/10.1016/j.patrec.2018.03.003	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/br/bib0023	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/ctx/ctx0001		32	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/itrp/0017	'Another important step is to assign appropriate weights to terms according to their different semantic contribution in a document [23][[ refid=''bib0023'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">Another important step is to assign appropriate weights to terms according to their different semantic contribution in a document <ce:cross-ref id=""""crf0008"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. Term frequency-inverse document frequency (<ce:italic>tf</ce:italic> × <ce:italic>idf</ce:italic>) is a weighting scheme that reflects how important a word is to a document in information retrieval <ce:cross-ref id=""""crf0009"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref>, and is widely used in text classification.</ce:para>""''"'	cites	AGA	
cites	Introduction	P. Soucy, G.W. Mineau, Beyond TFIDF weighting for text categorization in the vector space model , Proc. Int’l Joint Conf. Artificial Intelligence (2005)	http://dx.doi.org/10.1016/j.patrec.2018.03.003	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/br/bib0024	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/ctx/ctx0006		32	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/itrp/0024	'One approach is to weight terms based on their statistical confidence intervals [24][[ refid=''bib0024'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0009"""" view=""""all"""">Some other approaches suggested to use probabilistic models, which have proven very effective in information retrieval and TC <ce:cross-refs id=""""crfs0002"""" refid=""""bib0014 bib0016"""">[14,16][[ refid=''''bib0014 bib0016'''' ]]</ce:cross-refs>. One approach is to weight terms based on their statistical confidence intervals <ce:cross-ref id=""""crf0011"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref>. It has also been proposed that the ratio and absolute difference of term occurrence can be used to improve the performance <ce:cross-refs id=""""crfs0003"""" refid=""""bib0001 bib0007"""">[1,7][[ refid=''''bib0001 bib0007'''' ]]</ce:cross-refs>. Another approach is to use terms weighted on the Kullback–Leibler (KL) divergence measure between pairs of class-conditional term probabilities, and Jensen–Shannon (JS) divergence for multi-class data <ce:cross-ref id=""""crf0012"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>. Inverse category frequency has also been considered for term weighting schemes, which favors terms occurring in fewer classes rather than fewer documents <ce:cross-refs id=""""crfs0004"""" refid=""""bib0021 bib0025"""">[21,25][[ refid=''''bib0021 bib0025'''' ]]</ce:cross-refs>.</ce:para>""''"'	cites	AGA	
uses_method_in	Model specification	M. Lan, C.L. Tan, J. Su, Y. Lu, Supervised and traditional term weighting methods for automatic text categorization , IEEE Trans. Pattern Anal. Mach. Intell. , vol. 31 (2009), pp.721-735	http://dx.doi.org/10.1016/j.patrec.2018.03.003	model		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/br/bib0017>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/ctx/ctx0015>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/itrp/0042	'Following the rf method [17][[ refid=''bib0017'' ]], we call this the relevance probability (rp).'			FDY+AGA	infered_pred1
cites	Model specification	S.E. Robertson, K.S. Jones, Relevance weighting of search terms , J. Am. Soc. Inf. Sci. , vol. 27 (1976), pp.129-146	http://dx.doi.org/10.1016/j.patrec.2018.03.003	model		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/br/bib0022	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/ctx/ctx0014		32	5	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-003/itrp/0043	'The matching score is the summation of the log probability ratios, which are used to derive relevance weighting functions [22][[ refid=''bib0022'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0017"""" view=""""all"""">For a document, <mml:math altimg=""""si14.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math> and its label, <ce:italic>C</ce:italic>, let <mml:math altimg=""""si17.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math> denote the positive class, and <mml:math altimg=""""si18.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math> the negative. Then,<ce:display><ce:formula id=""""eq0002""""><ce:label>(2)</ce:label><mml:math altimg=""""si19.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>D</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>Pr</mml:mi><mml:mo>(</mml:mo><mml:mi>D</mml:mi><mml:mo>|</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mi>Pr</mml:mi><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>Pr</mml:mi><mml:mo>(</mml:mo><mml:mi>D</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>To avoid further expansion of <mml:math altimg=""""si20.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>Pr</mml:mi><mml:mo>(</mml:mo><mml:mi>D</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math> we use log probability rather than probability. Thus, it satisfies the classification task<ce:display><ce:formula id=""""eq0003""""><ce:label>(3)</ce:label><mml:math altimg=""""si21.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>log</mml:mi><mml:mfrac><mml:mrow><mml:mi>Pr</mml:mi><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>|</mml:mo><mml:mi>D</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>Pr</mml:mi><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>|</mml:mo><mml:mi>D</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mfrac><mml:mrow><mml:mi>Pr</mml:mi><mml:mo>(</mml:mo><mml:mi>D</mml:mi><mml:mo>|</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mi>Pr</mml:mi><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>Pr</mml:mi><mml:mo>(</mml:mo><mml:mi>D</mml:mi><mml:mo>|</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo><mml:mi>Pr</mml:mi><mml:mo>(</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>Ignoring the constant (prior class probability ratio), the classification task can be achieved by the matching score function <ce:cross-ref id=""""crf0022"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref>,<ce:display><ce:formula id=""""eq0004""""><ce:label>(4)</ce:label><mml:math altimg=""""si22.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mfrac><mml:mrow><mml:mi>Pr</mml:mi><mml:mo>(</mml:mo><mml:mi>D</mml:mi><mml:mo>|</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>Pr</mml:mi><mml:mo>(</mml:mo><mml:mi>D</mml:mi><mml:mo>|</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>p</mml:mi></mml:munderover><mml:mi>log</mml:mi><mml:mfrac><mml:mrow><mml:mi>Pr</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>Pr</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>u</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>where <ce:italic>X<ce:inf loc=""""post"""">u</ce:inf></ce:italic> ∈ {0, 1}. The second equality holds based on the NB [A5] assumption that the terms are conditionally independent, given the document label. The matching score is the summation of the log probability ratios, which are used to derive relevance weighting functions <ce:cross-ref id=""""crf0023"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA	
cites	Experimental protocols and results	R.M. Colque, C. Caetano, M. Toledo, W.R. Schwartz, Histograms of optical flow orientation and magnitude and entropy to detect anomalous events in videos , IEEE Trans. Circuits Syst. Video Technol. , vol. PP (2016), pp.None	http://dx.doi.org/10.1016/j.patrec.2018.03.004	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/br/bib0009	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/ctx/ctx0020		21	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/itrp/0002	'For HOFM, we use the parameter settings as per [9][[ refid=''bib0009'' ]] where a regular grid of size 30 × 30 × 3 is created.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0024"""" view=""""all"""">Action-vectors are compared against recent state-of-the-art feature descriptors for describing human actions: a) HOFM (histogram of optical flow and magnitude) <ce:cross-ref id=""""crf0039"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> and b) 3D convolutional neural network (3DCNN) features <ce:cross-ref id=""""crf0040"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>. For HOFM, we use the parameter settings as per <ce:cross-ref id=""""crf0041"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> where a regular grid of size 30 × 30 × 3 is created. The first two dimensions correspond to grid cell dimensions (width and height) in space, and the third dimension corresponds to the depth in time. For 3DCNN, a pre-trained network trained on the sports 1M dataset as per <ce:cross-ref id=""""crf0042"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> was used to obtain the features. Each 3DCNN features summarizes the information in 16 frames into a single descriptor and resulting in 20 feature descriptors for every 10 s clip used in our experiments. The classification outputs of these 20 descriptors are then combined using majority voting to produce the final classification output for the clip.</ce:para>""''"'	uses_method_in	AGA	
cites	Experimental protocols and results	D. Tran, L. Bourdev, R. Fergus, L. Torresani, M. Paluri, Learning spatiotemporal features with 3d convolutional networks , Proceedings of the IEEE international conference on computer vision (2015)	http://dx.doi.org/10.1016/j.patrec.2018.03.004	methods	results	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/br/bib0021	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/ctx/ctx0021		21	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/itrp/0004	'For 3DCNN, a pre-trained network trained on the sports 1M dataset as per [21][[ refid=''bib0021'' ]] was used to obtain the features.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0024"""" view=""""all"""">Action-vectors are compared against recent state-of-the-art feature descriptors for describing human actions: a) HOFM (histogram of optical flow and magnitude) <ce:cross-ref id=""""crf0039"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> and b) 3D convolutional neural network (3DCNN) features <ce:cross-ref id=""""crf0040"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref>. For HOFM, we use the parameter settings as per <ce:cross-ref id=""""crf0041"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> where a regular grid of size 30 × 30 × 3 is created. The first two dimensions correspond to grid cell dimensions (width and height) in space, and the third dimension corresponds to the depth in time. For 3DCNN, a pre-trained network trained on the sports 1M dataset as per <ce:cross-ref id=""""crf0042"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> was used to obtain the features. Each 3DCNN features summarizes the information in 16 frames into a single descriptor and resulting in 20 feature descriptors for every 10 s clip used in our experiments. The classification outputs of these 20 descriptors are then combined using majority voting to produce the final classification output for the clip.</ce:para>""''"'	uses_data_from	AGA	
uses_method_in	Proposed framework	P. Kenny, G. Boulianne, P. Dumouchel, Eigenvoice modeling with sparse training data , IEEE Trans. Speech Audio Process. , vol. 13 (2005), pp.345-354	http://dx.doi.org/10.1016/j.patrec.2018.03.004			<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/br/bib0020>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/ctx/ctx0017>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/itrp/0005	'After the final M-step i.e. estimation of T and Σ matrices, the action-vector for a given clip can be represented using the mean of its posterior distribution as [[ formulaid=''id11_pos0'' ]] This process of obtaining the action-vector is known as factor analysis [20][[ refid=''bib0020'' ]].'			FDY+AGA	infered_pred1
uses_method_in	Proposed framework	P. Kenny, G. Boulianne, P. Dumouchel, Eigenvoice modeling with sparse training data , IEEE Trans. Speech Audio Process. , vol. 13 (2005), pp.345-354	http://dx.doi.org/10.1016/j.patrec.2018.03.004			http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/br/bib0020	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/ctx/ctx0016		21	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/itrp/0006	'Using EM algorithm [20][[ refid=''bib0020'' ]], we iteratively estimate the posterior mean and covariance in the E-step and use the same to update T and Σ in the M-step.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0018"""" view=""""all"""">From <ce:cross-ref id=""""crf0031"""" refid=""""eq0006"""">Eq. (5)</ce:cross-ref>, the mean and covariance matrix of the posterior distribution are given by<ce:display><ce:formula id=""""eq0007""""><ce:label>(6a)</ce:label><mml:math altimg=""""si19.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi mathvariant=""""bold"""">w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant=""""bold"""">M</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant=""""bold"""">T</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mi mathvariant=""""bold-italic"""">Σ</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mover accent=""""true""""><mml:mi mathvariant=""""bold"""">s</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></ce:formula></ce:display>and<ce:display><ce:formula id=""""eq0008""""><ce:label>(6b)</ce:label><mml:math altimg=""""si20.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:mrow><mml:mi mathvariant=""""normal"""">Cov</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant=""""bold"""">w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant=""""bold"""">M</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant=""""bold"""">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></ce:formula></ce:display>respectively. Using EM algorithm <ce:cross-ref id=""""crf0032"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref>, we iteratively estimate the posterior mean and covariance in the E-step and use the same to update <ce:bold>T</ce:bold> and <ce:bold>Σ</ce:bold> in the M-step.</ce:para>""''"'	cites	AGA	
cites	Related work	Y. Zhao, B. Deng, C. Shen, Y. Liu, H. Lu, X.-S. Hua, Spatio-temporal autoencoder for video anomaly detection , Proceedings of the 2017 ACM on Multimedia Conference, ACM (2017)	http://dx.doi.org/10.1016/j.patrec.2018.03.004	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/br/bib0012	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/ctx/ctx0009		21	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/itrp/0008	'For extracting both appearance and motion features simultaneously, in [12][[ refid=''bib0012'' ]], 3D convolutional layers were added to the AE network above.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0008"""" view=""""all"""">Recently, deep learning methods have also been used for anomaly detection in videos. In <ce:cross-ref id=""""crf0022"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref>, appearance and motion features were learned using two stacked denoising auto-encoders (AE) trained on patches extracted from each image in the video and corresponding optical flow map, respectively. A fusion of the two AE outputs with a one-class SVM was used for learning normal appearance and motion. For extracting both appearance and motion features simultaneously, in <ce:cross-ref id=""""crf0023"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref>, 3D convolutional layers were added to the AE network above. Instead of training a one-class SVM, the reconstruction error was directly used for predicting anomalies. A variant of AE involving 2D CNN for appearance features and a long-short memory (LSTM) was introduced in <ce:cross-ref id=""""crf0024"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> for motion modelling. The deep learning methods described above can register only significant deviations from normal behaviour in constrained environments and hence cannot be used for recognizing snatch thefts in unconstrained environments which vary only subtly from regular activities.</ce:para>""''"'	cites	AGA	
cites	Introduction	H. Bouma, J. Baan, G.J. Burghouts, P.T. Eendebak, J.R. van Huis, J. Dijk, J.H. van Rest, Automatic detection of suspicious behavior of pickpockets with track-based features in a shopping mall , SPIE Security+ Defence, International Society for Optics and Photonics (2014)	http://dx.doi.org/10.1016/j.patrec.2018.03.004	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/ctx/ctx0001		21	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/itrp/0019	'Even when conducted in crowded scenes as in [1][[ refid=''bib0001'' ]], the entire pickpocket incident is staged with apriori knowledge of how the incident is going to take place which makes analysis a lot easier.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0005"""" view=""""all"""">Most of the existing literature on detecting anomalous activities like snatching uses datasets collected in controlled laboratory settings with no crowd or background and with an excellent viewing angle of the activity. Even when conducted in crowded scenes as in <ce:cross-ref id=""""crf0007"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>, the entire pickpocket incident is staged with <ce:italic>apriori</ce:italic> knowledge of how the incident is going to take place which makes analysis a lot easier. So, to analyze real-life thefts, we present a dataset called Snatch 1.0<ce:cross-ref id=""""crf0008"""" refid=""""fn0001""""><ce:sup loc=""""post"""">1</ce:sup></ce:cross-ref><ce:footnote id=""""fn0001""""><ce:label>1</ce:label><ce:note-para id=""""cenotep0001"""" view=""""all""""><ce:inter-ref id=""""interref0001"""" xlink:href=""""http://www.iith.ac.in/vilg/datasets/"""" xlink:type=""""simple"""">http://www.iith.ac.in/vilg/datasets/</ce:inter-ref>.</ce:note-para></ce:footnote> collected from unconstrained surveillance footage. This dataset contains surveillance footage obtained from the traffic police department of Hyderabad city of India which includes various instances of snatch thefts (details in <ce:cross-ref id=""""crf0009"""" refid=""""sec0007"""">Section 4.1</ce:cross-ref>). It was observed that snatching incidents in surveillance videos can occur in a variety of <ce:italic>scenarios</ce:italic> which are of diverse types and lead to different victim <ce:italic>reactions</ce:italic>. Some of the examples of snatch thefts are shown in <ce:cross-ref id=""""crf0010"""" refid=""""fig0001"""">Fig. 1</ce:cross-ref><ce:float-anchor refid=""""fig0001""""/>.</ce:para>""''"'	cites	AGA	
cites	Related work	R.M. Colque, C. Caetano, M. Toledo, W.R. Schwartz, Histograms of optical flow orientation and magnitude and entropy to detect anomalous events in videos , IEEE Trans. Circuits Syst. Video Technol. , vol. PP (2016), pp.None	http://dx.doi.org/10.1016/j.patrec.2018.03.004	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/br/bib0009	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/ctx/ctx0006		21	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-004/itrp/0027	'In [9][[ refid=''bib0009'' ]], apart from magnitude and direction of motion, entropy information was further added to form a combined histogram of flow orientation, motion, and entropy (HOFME) descriptor.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0007"""" view=""""all"""">A majority of existing literature in the field of anomaly detection is aimed towards detection of generalized abnormal patterns <ce:cross-refs id=""""crfs0002"""" refid=""""bib0005 bib0006"""">[5,6][[ refid=''''bib0005 bib0006'''' ]]</ce:cross-refs> or behaviour in case of individuals or crowds <ce:cross-ref id=""""crf0018"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref>. Many approaches model normal behaviour extensively and consider events which do not follow these models as anomalous activities. One approach <ce:cross-ref id=""""crf0019"""" refid=""""bib0008"""">[8][[ refid=''''bib0008'''' ]]</ce:cross-ref> proposed a motion-influence map which localizes both global and local unusual activities. The motion-influence map considers the speed and direction of various objects to determine their relative influence on other objects for detecting unusual motion patterns. In <ce:cross-ref id=""""crf0020"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref>, apart from magnitude and direction of motion, entropy information was further added to form a combined histogram of flow orientation, motion, and entropy (HOFME) descriptor. The usage of entropy was to determine the density of motion during normal events. In <ce:cross-ref id=""""crf0021"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref>, a roadside surveillance scene was divided into zones like traffic lanes, stationary areas, etc. each of which was termed as a scene context and the direction and flow of persons in each of these contexts were measured. Further, the interaction between any two individuals in the close spatial vicinity was measured for gaze and motion direction information. This was termed as social context and revealed normal behaviour in different scene contexts.</ce:para>""''"'	cites	AGA	
cites	Related work	K.C. Peng, T. Chen, A. Sadovnik, A mixed bag of emotions: model, predict, and transfer emotion distributions , None (2015)	http://dx.doi.org/10.1016/j.patrec.2018.03.015	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/br/bib0025	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/ctx/ctx0021		33	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/itrp/0004	'Peng et al. [25][[ refid=''bib0025'' ]] changed the way by simply predicting a single dominant emotion, and used the modern deep learning to predict the emotion distribution of images and established a new database, i.e., Emotion6.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all""""><ce:bold>Emotional image color transfer.</ce:bold> Recently, Yang and Peng <ce:cross-ref id=""""crf0025"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> firstly proposed an emotion-based color transfer algorithm, which followed the traditional color transfer framework but added a single color scheme for emotions. Later, Wang et al. <ce:cross-ref id=""""crf0026"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> designed an automated system, which can adjust the image color based on an emotional word. They adopted a 5-color theme in the work <ce:cross-ref id=""""crf0027"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> and built a color theme database with emotion words. Ryoo <ce:cross-ref id=""""crf0028"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> proposed an affective color transfer method. They used the feature based facial expression recognition to recognize human emotion and then mapped the color palette of the input image to the emotional color palette. He et al. <ce:cross-ref id=""""crf0029"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref> developed a color transfer framework to evoke different emotions for images based on 3-color emotion combinations in <ce:cross-ref id=""""crf0030"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. However, this method involves only 27 emotion words, which are not enough to express most of the feelings. Peng et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref> adapt a dimensional emotion model to build the correlation among certain emotion categories and proposed a framework for changing image emotion by using their emotion predictor. Peng et al. <ce:cross-ref id=""""crf0032"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> changed the way by simply predicting a single dominant emotion, and used the modern deep learning to predict the emotion distribution of images and established a new database, i.e., Emotion6.</ce:para>""''"'	uses_data_from	AGA	
cites	Related work	M. Limmer, H.P.A. Lensch, Infrared colorization using deep convolutional neural networks , Comput. Sci. Comput. Vis. Pattern Recogn. (2016)	http://dx.doi.org/10.1016/j.patrec.2018.03.015	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/br/bib0029	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/ctx/ctx0026		33	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/itrp/0005	'Limmer and Lensch [29][[ refid=''bib0029'' ]] proposed a method for transferring the RGB color spectrum to near-infrared (NIR) images using deep multi-scale convolutional neural networks.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all""""><ce:bold>Image editing based on deep learning.</ce:bold> Recently, deep learning made great success in many domains, such as large-scale visual recognition tasks. Izuka et al. <ce:cross-ref id=""""crf0034"""" refid=""""bib0027"""">[27][[ refid=''''bib0027'''' ]]</ce:cross-ref> established an image colorization network using deep learning. This network integrates a priori knowledge of global classification of images and local coloring information of images. Gatys et al. <ce:cross-ref id=""""crf0035"""" refid=""""bib0007"""">[7][[ refid=''''bib0007'''' ]]</ce:cross-ref> introduced an artificial system based on a Deep Neural Network (DNN) that creates artistic images of high perceptual quality. Yan et al. <ce:cross-ref id=""""crf0036"""" refid=""""bib0028"""">[28][[ refid=''''bib0028'''' ]]</ce:cross-ref> presented an automatic photo enhancement method based on deep learning. They use a DNN with multiple hidden layers to represent the highly nonlinear and spatially varying color mapping between input and enhanced images. Limmer and Lensch <ce:cross-ref id=""""crf0037"""" refid=""""bib0029"""">[29][[ refid=''''bib0029'''' ]]</ce:cross-ref> proposed a method for transferring the RGB color spectrum to near-infrared (NIR) images using deep multi-scale convolutional neural networks.</ce:para>""''"'	cites	AGA	
uses_method_in	Method	A. Krizhevsky, I. Sutskever, G.E. Hinton, ImageNet classification with deep convolutional neural networks , Adv. Neural Inf. Process. Syst. , vol. 25 (2012), pp.1-9	http://dx.doi.org/10.1016/j.patrec.2018.03.015	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/br/bib0030>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/ctx/ctx0027>				http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/itrp/0006	'We establish the emotion classification network inspired by the image classification network structure [30][[ refid=''bib0030'' ]], in which the global information of the image is acquired by full convolution.'			FDY+AGA	infered_pred1
cites	Introduction	Digital cimena system specification Version 1.2 with Errata as of 30 August 2012 Incorporated. Digital Cinema Initiatives, LLC, Member Representatives Committee, 2012.	http://dx.doi.org/10.1016/j.patrec.2018.03.015	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/ctx/ctx0001		33	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/itrp/0014	'In the field of cinema industry, when a movie image is analyzed emotionally, it can greatly enhance the performance of the work and express the specific emotion [1][[ refid=''bib0001'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0005"""" view=""""all"""">In the field of cinema industry, when a movie image is analyzed emotionally, it can greatly enhance the performance of the work and express the specific emotion <ce:cross-ref id=""""crf0008"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref>. When people design art works, they often use different colors to convey different feelings. Additionally, in the fields of multimedia processing, the image color editing method is also extensive, including color transfer, image coloring, image editing, etc. These methods focus on dealing with the color of the picture to achieve certain appearance, however, most of them do not consider the emotional factors. Currently, there exists few emotional-based color editing methods which pose a variety of problems, such as inaccurate image emotion calculation and unnatural color editing.</ce:para>""''"'	cites	AGA	
cites	Related work	Y.C. Huang, Y.S. Tung, J.C. Chen, An adaptive edge detection based colorization algorithm and its applications , ACM International Conference on Multimedia (2005)	http://dx.doi.org/10.1016/j.patrec.2018.03.015	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/br/bib0004	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/ctx/ctx0013		33	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/itrp/0033	'Huang et al. [4][[ refid=''bib0004'' ]] proposed a colorization approach to prevent the colorization process from bleeding over object boundaries.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0012"""" view=""""all""""><ce:bold>Traditional image color transfer.</ce:bold> Xiang et al. <ce:cross-ref id=""""crf0014"""" refid=""""bib0009"""">[9][[ refid=''''bib0009'''' ]]</ce:cross-ref> proposed a GMM-based color editing method, which exploits Gaussian mixture model (GMM) to model the regional color distribution of the target image. Wang et al. <ce:cross-ref id=""""crf0015"""" refid=""""bib0010"""">[10][[ refid=''''bib0010'''' ]]</ce:cross-ref> proposed a color enhancement algorithm based on image segmentation. This algorithm needs the user to provide a target color theme. For non-professional users, it is difficult to select a color theme which meets the needs. Later, they proposed an instance-based image enhancement method <ce:cross-ref id=""""crf0016"""" refid=""""bib0005"""">[5][[ refid=''''bib0005'''' ]]</ce:cross-ref> that defined a color and tone style as a set of explicit or implicit rules governing color and tone adjustments. But this method is only used in two cases. Most of the previous image editing methods require user intervention. Liu and Zhang <ce:cross-ref id=""""crf0017"""" refid=""""bib0011"""">[11][[ refid=''''bib0011'''' ]]</ce:cross-ref> proposed a novel automatic grayscale image colorization method based on histogram regression. Hashemi et al. <ce:cross-ref id=""""crf0018"""" refid=""""bib0012"""">[12][[ refid=''''bib0012'''' ]]</ce:cross-ref> presented an image enhancement method based on genetic algorithm. Singh and Kapoor <ce:cross-ref id=""""crf0019"""" refid=""""bib0013"""">[13][[ refid=''''bib0013'''' ]]</ce:cross-ref> designed an image-based histogram equalization method for contrast enhancement of low exposure grayscale images. Hwang et al. <ce:cross-ref id=""""crf0020"""" refid=""""bib0014"""">[14][[ refid=''''bib0014'''' ]]</ce:cross-ref> proposed a technique to automatically enhance the perceptual quality of an image based on a coarse-to-fine (image, then pixel) search. Sheng et al. <ce:cross-ref id=""""crf0021"""" refid=""""bib0015"""">[15][[ refid=''''bib0015'''' ]]</ce:cross-ref> proposed a new histogram equalization method for effective and efficient mean brightness preservation and contrast enhancement, which prevents intensity saturation and has ability to preserve image fine details. By exploiting the constraints of the gradient mesh, Yang and Peng <ce:cross-ref id=""""crf0022"""" refid=""""bib0016"""">[16][[ refid=''''bib0016'''' ]]</ce:cross-ref> accordingly propose a linear-operator-based color transfer framework. Colorization is a computer-assisted process for adding colors to grayscale images or movies. Huang et al. <ce:cross-ref id=""""crf0023"""" refid=""""bib0004"""">[4][[ refid=''''bib0004'''' ]]</ce:cross-ref> proposed a colorization approach to prevent the colorization process from bleeding over object boundaries. Gupta et al. <ce:cross-ref id=""""crf0024"""" refid=""""bib0017"""">[17][[ refid=''''bib0017'''' ]]</ce:cross-ref> presented a new method for colorizing gray images using semantically similar reference images. Those methods do not take into consideration the emotion information, which can hardly edit an image to satisfy a target emotion.</ce:para>""''"'	cites	AGA	
cites	Related work	S. Kobayash, Art of Color Combinations , None, Kodansha International (1995)	http://dx.doi.org/10.1016/j.patrec.2018.03.015	related work		http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/br/bib0020	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/ctx/ctx0017		33	4	http://www.scar.disi.unibo.it/r/10-1016-j-patrec-2018-03-015/itrp/0037	'They adopted a 5-color theme in the work [20][[ refid=''bib0020'' ]] and built a color theme database with emotion words.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all""""><ce:bold>Emotional image color transfer.</ce:bold> Recently, Yang and Peng <ce:cross-ref id=""""crf0025"""" refid=""""bib0018"""">[18][[ refid=''''bib0018'''' ]]</ce:cross-ref> firstly proposed an emotion-based color transfer algorithm, which followed the traditional color transfer framework but added a single color scheme for emotions. Later, Wang et al. <ce:cross-ref id=""""crf0026"""" refid=""""bib0019"""">[19][[ refid=''''bib0019'''' ]]</ce:cross-ref> designed an automated system, which can adjust the image color based on an emotional word. They adopted a 5-color theme in the work <ce:cross-ref id=""""crf0027"""" refid=""""bib0020"""">[20][[ refid=''''bib0020'''' ]]</ce:cross-ref> and built a color theme database with emotion words. Ryoo <ce:cross-ref id=""""crf0028"""" refid=""""bib0021"""">[21][[ refid=''''bib0021'''' ]]</ce:cross-ref> proposed an affective color transfer method. They used the feature based facial expression recognition to recognize human emotion and then mapped the color palette of the input image to the emotional color palette. He et al. <ce:cross-ref id=""""crf0029"""" refid=""""bib0022"""">[22][[ refid=''''bib0022'''' ]]</ce:cross-ref> developed a color transfer framework to evoke different emotions for images based on 3-color emotion combinations in <ce:cross-ref id=""""crf0030"""" refid=""""bib0023"""">[23][[ refid=''''bib0023'''' ]]</ce:cross-ref>. However, this method involves only 27 emotion words, which are not enough to express most of the feelings. Peng et al. <ce:cross-ref id=""""crf0031"""" refid=""""bib0024"""">[24][[ refid=''''bib0024'''' ]]</ce:cross-ref> adapt a dimensional emotion model to build the correlation among certain emotion categories and proposed a framework for changing image emotion by using their emotion predictor. Peng et al. <ce:cross-ref id=""""crf0032"""" refid=""""bib0025"""">[25][[ refid=''''bib0025'''' ]]</ce:cross-ref> changed the way by simply predicting a single dominant emotion, and used the modern deep learning to predict the emotion distribution of images and established a new database, i.e., Emotion6.</ce:para>""''"'	uses_data_from	AGA	
uses_data_from	Implementation and evaluation	J. Micheel, I. Graham, N. Brownlee, The auckland data set: an access link observed, in: Proc. of Access Networks and Systems, 2001, pp. 19–30.	http://dx.doi.org/10.1016/j.peva.2015.06.011	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-peva-2015-06-011/br/br000045>	<http://www.scar.disi.unibo.it/r/10-1016-j-peva-2015-06-011/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-peva-2015-06-011/ctx/ctx0014>				http://www.scar.disi.unibo.it/r/10-1016-j-peva-2015-06-011/itrp/0040	'Datasets: In our experiments we have used real Internet traffic datasets [9][[ refid=''br000045'' ]] that are openly available from the WAND Network Research Group from the University of Waikato, New Zealand.'				100_classified_usesDataFrom
uses_data_from	Experimental results	T. Opsahl, P. Panzarasa, Clustering in weighted networks , Soc. Networks , vol. 31 (2009), pp.None	http://dx.doi.org/10.1016/j.peva.2015.06.012	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-peva-2015-06-012/br/br000090>	<http://www.scar.disi.unibo.it/r/10-1016-j-peva-2015-06-012/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-peva-2015-06-012/ctx/ctx0033>				http://www.scar.disi.unibo.it/r/10-1016-j-peva-2015-06-012/itrp/0047	'Our datasets contain three real networks: (i) A Facebook-like social network containing 1899 users and 20,296 directed edges [18][[ refid=''br000090'' ]].'				100_classified_usesDataFrom
cites	Related work	L. Guo, S. Chen, Z. Xiao, X. Zhang, Analysis of multimedia workloads with implications for internet streaming , WWW (2005)	http://dx.doi.org/10.1016/j.pmcj.2010.07.006	related work		<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2010-07-006/br/br000045>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2010-07-006/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2010-07-006/ctx/ctx0009>				http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2010-07-006/itrp/0008	'Video streaming solutions fit into three general categories: streaming, downloading, and pseudo-streaming [9][[ refid=''br000045'' ]].'				100_classified_usesDataFrom
cites	Experiments	D.H. Hu, Q. Yang, Cigar: concurrent and interleaving goal and activity recognition, in: AAAI’08: Proceedings of the Twenty-Third AAAI Conference on Artificial Intelligence, pp. 1363–1368.	http://dx.doi.org/10.1016/j.pmcj.2011.08.004	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2011-08-004/br/br000080>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2011-08-004/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2011-08-004/ctx/ctx0035>				http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2011-08-004/itrp/0030	'The performance of Model I (Table 5) outperforms state-of-the-art recognizers [16][[ refid=''br000080'' ]] applied on the same dataset.'				100_classified_usesDataFrom
uses_data_from	Introduction	N. Kiukkonen, J. Blom, O. Dousse, D. Gatica-Perez, J. Laurila, Towards rich mobile phone datasets: Lausanne data collection campaign, in: Proc. ICPS, 2010.	http://dx.doi.org/10.1016/j.pmcj.2013.03.006	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2013-03-006/br/br000050>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2013-03-006/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2013-03-006/ctx/ctx0003>				http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2013-03-006/itrp/0025	'And finally, we conduct our analysis on a longitudinal dataset involving 71 volunteer users carrying a smartphone over 17 months, from the Lausanne Data Collection Campaign [10][[ refid=''br000050'' ]].'				100_classified_usesDataFrom
uses_data_from	Methodology	J.K. Laurila, D. Gatica-Perez, I. Aad, T.-M.-T.D. Jan Blom, O. Bornet, O. Dousse, J. Eberle, M. Miettinen, The mobile data challenge: big data for mobile computing research, in: Mobile Data Challenge by NOKIA Workshop, in Conjunction with Int. Conf. on Pervasive Computing, 2012.	http://dx.doi.org/10.1016/j.pmcj.2013.08.002	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2013-08-002/br/br000080>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2013-08-002/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2013-08-002/ctx/ctx0018>				http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2013-08-002/itrp/0039	'Our research is based on two different mobile datasets: a large dataset from the NOKIA Lausanne Data Collection Campaign [16][[ refid=''br000080'' ]] and a preliminary dataset that we have collected during an unrelated experiment that was organized separately.'				100_classified_usesDataFrom
uses_data_from	An exemplar of inference management	L. Bao, S.S. Intille, Activity recognition from user-annotated acceleration data , Pervasive Computing , vol. vol. 3001 (2004), pp.1-17	http://dx.doi.org/10.1016/j.pmcj.2013.08.003			<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2013-08-003/br/br000125>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2013-08-003/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2013-08-003/ctx/ctx0030>				http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2013-08-003/itrp/0038	'To evaluate, we use an annotated acceleration dataset collected under controlled condition from 20 individuals [25][[ refid=''br000125'' ]].'				100_classified_usesDataFrom
cites_as_review	Introduction	K. Mille, Big data analytics in biomedical research , Biomed. Comput. Rev. (2012)	http://dx.doi.org/10.1016/j.pmcj.2015.10.014	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2015-10-014/br/br000020>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2015-10-014/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2015-10-014/ctx/ctx0004>				http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2015-10-014/itrp/0023	'The payer–provider data comprises of the Electronic Health Records (EHRs), pharmacy prescriptions, insurance data, and patients’ feedback, whereas the genomic-driven data consists of genotyping data, gene extraction data, and sequencing data [4][[ refid=''br000020'' ]].'				100_classified_usesDataFrom
uses_data_from	Experiment and evaluation	D. Cook, M. Schmitter-Edgecombe, Assessing the quality of activities in a smart environment , Methods Inf. Med. , vol. 48 (2009), pp.480-485	http://dx.doi.org/10.1016/j.pmcj.2016.06.012	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-06-012/br/br000165>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-06-012/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-06-012/ctx/ctx0040>				http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-06-012/itrp/0017	'The fourth dataset is the interleaved activities of daily living (labelled as IAA) dataset from the CASAS smart home project [33][[ refid=''br000165'' ]].'				100_classified_usesDataFrom
uses_data_from	Experiment and evaluation	B. Logan, J. Healey, M. Philipose, E.M. Tapia, S. Intille, A long-term evaluation of sensing modalities for activity recognition, in: Proceedings of UbiComp’07, 2007, pp. 483–500.	http://dx.doi.org/10.1016/j.pmcj.2016.06.012	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-06-012/br/br000080>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-06-012/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-06-012/ctx/ctx0038>				http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-06-012/itrp/0043	'The third dataset is the PlaceLab Couple dataset [16][[ refid=''br000080'' ]].'				100_classified_usesDataFrom
uses_data_from	Experiments	R. Wang, F. Chen, Z. Chen, T. Li, G. Harari, S. Tignor, X. Zhou, D. Ben-Zeev, A.T. Campbell, StudentLife: assessing mental health, academic performance and behavioral trends of college students using smartphones , Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing, ACM (2014)	http://dx.doi.org/10.1016/j.pmcj.2016.08.019	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/br/br000085>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/ctx/ctx0076>				http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/itrp/0050	'We use the WiFi data from the StudentLife dataset [17][[ refid=''br000085'' ]] for this experiment.'				100_classified_usesDataFrom
uses_data_from	Experiments	N. Eagle, A. Pentland, Reality mining: Sensing complex social systems , Pers. Ubiquitous Comput. , vol. 10 (2006), pp.255-268	http://dx.doi.org/10.1016/j.pmcj.2016.08.019	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/br/br000075>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/ctx/ctx0071>				http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/itrp/0055	'In this experiment, we demonstrate our SECC model in extracting proximity contexts and communities of users that have similar proximity behaviors simultaneously from the Bluetooth data of the Reality Mining dataset [15][[ refid=''br000075'' ]].'				100_classified_usesDataFrom
uses_data_from	Experiments	R. Wang, F. Chen, Z. Chen, T. Li, G. Harari, S. Tignor, X. Zhou, D. Ben-Zeev, A.T. Campbell, StudentLife: assessing mental health, academic performance and behavioral trends of college students using smartphones , Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing, ACM (2014)	http://dx.doi.org/10.1016/j.pmcj.2016.08.019	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/br/br000085>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/ctx/ctx0077>				http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/itrp/0062	'The StudentLife dataset2 [17][[ refid=''br000085'' ]] was collected from 48 students of Dartmouth College during 10 week spring term in 2013.'				100_classified_usesDataFrom
uses_data_from	Experiments	M. Zhang, A.A. Sawchuk, USC-HAD: a daily activity dataset for ubiquitous activity recognition using wearable sensors , Proceedings of The 2012 ACM Conference on Ubiquitous Computing, ACM (2012)	http://dx.doi.org/10.1016/j.pmcj.2016.08.019	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/br/br000070>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/ctx/ctx0068>				http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-08-019/itrp/0118	'The USC human activity dataset (USC-HAD)1 [14][[ refid=''br000070'' ]] was collected using the MotionNode sensing platform.'				100_classified_usesDataFrom
uses_method_in	Experiment results	V. Otsason, A. Varshavsky, A. Lamarca, E.D. Lara, Accurate GSM Indoor Localization, in: Proceeding UbiComp’05 Proceedings of the 7th international conference on Ubiquitous Computing, 2005, pp. 141–158.	http://dx.doi.org/10.1016/j.pmcj.2016.09.018	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-09-018/br/br000240>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-09-018/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-09-018/ctx/ctx0040>				http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2016-09-018/itrp/0019	'Here, all compared algorithms assume the training set is restricted to the data collected on the same floor as the test location, an approaches replicated from a similar experimental environment [48][[ refid=''br000240'' ]].'				100_classified_usesDataFrom
uses_data_from	Experiments and evaluation	M. Zhang, A.A. Sawchuk, Usc-had: A daily activity dataset for ubiquitous activity recognition using wearable sensors, in: ACM International Conference on Ubiquitous Computing (Ubicomp) Workshop on Situation, Activity and Goal Awareness (SAGAware), Pittsburgh, Pennsylvania, USA, September 2012.	http://dx.doi.org/10.1016/j.pmcj.2017.01.003	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2017-01-003/br/br000335>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2017-01-003/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2017-01-003/ctx/ctx0061>				http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2017-01-003/itrp/0043	'USC Human Activity Dataset (HAD): The dataset includes the most basic and common low-level human activities in daily life from a diverse group of human subjects [67][[ refid=''br000335'' ]].'				100_classified_usesDataFrom
uses_data_from	Experimental evaluation	T. van Kasteren, G. Englebienne, B. Krse, Human activity recognition from wireless sensor network data: Benchmark and software , Activity Recognition in Pervasive Intelligent Environments (2011)	http://dx.doi.org/10.1016/j.pmcj.2017.05.003	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2017-05-003/br/b61>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2017-05-003/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2017-05-003/ctx/ctx0045>				http://www.scar.disi.unibo.it/r/10-1016-j-pmcj-2017-05-003/itrp/0091	'This dataset [61][[ refid=''b61'' ]] was collected from sensors deployed in three rooms of an apartment of a 26-year-old male.'				100_classified_usesDataFrom
extends	Task-level programming using skills	M.R. Pedersen, L. Nalpantidis, R.S. Andersen, C. Schou, S. Bøgh, V. Krüger, O. Madsen, Robot skills for manufacturing: from concept to industrial deployment , Robot. Comput. Integr. Manuf. , vol. 37 (2016), pp.282-291	http://dx.doi.org/10.1016/j.rcim.2018.03.008			http://www.scar.disi.unibo.it/r/10-1016-j-rcim-2018-03-008/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-rcim-2018-03-008/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-rcim-2018-03-008/ctx/ctx0018		34	7	http://www.scar.disi.unibo.it/r/10-1016-j-rcim-2018-03-008/itrp/0035	'The skill model is based on the concept presented in [1][[ refid=''bib0001'' ]] and is expanded here to include online manual parametrization.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">Robotic skills combine low-level functionality from multiple devices into coherent higher-level programming blocks. This section briefly introduces the concept of robotic skills and how they are used for task-level programming. The skill model is based on the concept presented in <ce:cross-ref id=""""crf0031"""" refid=""""bib0001"""">[1][[ refid=''''bib0001'''' ]]</ce:cross-ref> and is expanded here to include online manual parametrization.</ce:para>""''"'	extends	ANG	
uses_data_from	Experiments and results	M. Cummins, P. Newman, FAB-MAP: probabilistic localization and mapping in the space of appearance , The International Journal of Robotics Research , vol. 27 (2008), pp.647-665	http://dx.doi.org/10.1016/j.robot.2011.05.007	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2011-05-007/br/br000080>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2011-05-007/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2011-05-007/ctx/ctx0043>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2011-05-007/itrp/0022	'The first experiment is an outdoor environment, the City Centre dataset, which was collected by Cummins and Newman [16][[ refid=''br000080'' ]].'				100_classified_usesDataFrom
uses_data_from	Experiments and results	M. Cummins, P. Newman, FAB-MAP: probabilistic localization and mapping in the space of appearance , The International Journal of Robotics Research , vol. 27 (2008), pp.647-665	http://dx.doi.org/10.1016/j.robot.2011.05.007	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2011-05-007/br/br000080>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2011-05-007/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2011-05-007/ctx/ctx0048>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2011-05-007/itrp/0044	'The City Centre dataset was collected by Cummins and Newman [16][[ refid=''br000080'' ]].'				100_classified_usesDataFrom
uses_data_from	Experiments and results	M. Cummins, P. Newman, FAB-MAP: probabilistic localization and mapping in the space of appearance , The International Journal of Robotics Research , vol. 27 (2008), pp.647-665	http://dx.doi.org/10.1016/j.robot.2011.05.007	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2011-05-007/br/br000080>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2011-05-007/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2011-05-007/ctx/ctx0050>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2011-05-007/itrp/0072	'This dataset was collected from the corridor of a building without any moving objects by Angeli et al. [16][[ refid=''br000080'' ]].'				100_classified_usesDataFrom
cites	Literature review	D. Sack, W. Burgard, A comparison of methods for line extraction from range data, in: Proceeding of the 5th IFAC Symposium on Intelligent Autonomous Vehicles IAV, 2004.	http://dx.doi.org/10.1016/j.robot.2013.04.009			<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2013-04-009/br/br000135>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2013-04-009/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2013-04-009/ctx/ctx0018>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2013-04-009/itrp/0042	'A recent work [27][[ refid=''br000135'' ]] presents two approaches for extracting lines from laser data.'				100_classified_usesDataFrom
cites	Literature review	K.O. Arras, Y.S. Rolland, Feature extraction and scene interpretation for map-based navigation and map building, in: Proceedings of SPIE Mobile Robotics XII, 1997.	http://dx.doi.org/10.1016/j.robot.2013.04.009			<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2013-04-009/br/br000120>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2013-04-009/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2013-04-009/ctx/ctx0015>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2013-04-009/itrp/0057	'[24][[ refid=''br000120'' ]] uses a hierarchical clustering approach to extract lines from the points obtained from laser data.'				100_classified_usesDataFrom
uses_data_from	Introduction	M. Smith, I. Baldwin, W. Churchill, R. Paul, P. Newman, The new college vision and laser data set , Int. J. Robot. Res. , vol. 28 (2009), pp.595-599	http://dx.doi.org/10.1016/j.robot.2014.03.015	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-03-015/br/br000080>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-03-015/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-03-015/ctx/ctx0007>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-03-015/itrp/0043	'Experimentation was performed using omni-directional images from two of our own outdoor datasets and panoramic images from the popular NewCollege dataset [16][[ refid=''br000080'' ]], all of which are publicly available.'				100_classified_usesDataFrom
cites	Experiments and results	M. Cummins, P. Newman, FAB-MAP: probabilistic localization and mapping in the space of appearance , Int. J. Robot. Res. , vol. 27 (2008), pp.647-665	http://dx.doi.org/10.1016/j.robot.2014.08.005	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-08-005/br/br000030>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-08-005/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-08-005/ctx/ctx0030>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-08-005/itrp/0034	'In a first experiment we evaluated the performance of FAB-MAP [6][[ refid=''br000030'' ]] (using the openFAB-MAP implementation) on the Nordland dataset.'				100_classified_usesDataFrom
uses_data_from	Experiments	M. Bosse, P. Newman, J. Leonard, S. Teller, Simultaneous localization and map building in large-scale cyclic environments using the atlas framework , Int. J. Robot. Res. , vol. 23 (2004), pp.1113-1139	http://dx.doi.org/10.1016/j.robot.2014.09.006	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-09-006/br/br000250>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-09-006/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-09-006/ctx/ctx0034>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-09-006/itrp/0046	'More experiments were carried out with the famous Killian Court dataset, collected and shared by Bosse et al. [50][[ refid=''br000250'' ]].'				100_classified_usesDataFrom
uses_method_in	Experiments	L. Natale, F. Nori, G. Metta, M. Fumagalli, S. Ivaldi, U. Pattacini, M. Randazzo, A. Schmitz, G.G. Sandini, The iCub platform: a tool for studying intrinsically motivated learning , Intrinsically Motivated Learning in Natural and Artificial Systems, Springer-Verlag (2013)	http://dx.doi.org/10.1016/j.robot.2014.11.005	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-11-005/br/br000180>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-11-005/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-11-005/ctx/ctx0068>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2014-11-005/itrp/0107	'We use the iCub humanoid robot [36][[ refid=''br000180'' ]] to collect a new dataset.'				100_classified_usesDataFrom
uses_data_from	Results	J. Sturm, N. Engelhard, F. Endres, W. Burgard, D. Cremers, A benchmark for the evaluation of RGB-D SLAM systems , 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS, IEEE (2012)	http://dx.doi.org/10.1016/j.robot.2015.03.007	results		<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2015-03-007/br/br000125>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2015-03-007/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2015-03-007/ctx/ctx0029>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2015-03-007/itrp/0013	'(2) The trajectories and maps built from the open dataset provided by [25][[ refid=''br000125'' ]].'				100_classified_usesDataFrom
uses_data_from	Experimental evaluation	D. Nister, H. Stewenius, Scalable recognition with a vocabulary tree, in: IEEE Computer Society Conference on Computer Vision and Pattern Recognition, Vol. 2, 2006, pp. 2161–2168.	http://dx.doi.org/10.1016/j.robot.2015.08.009	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2015-08-009/br/br000125>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2015-08-009/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2015-08-009/ctx/ctx0053>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2015-08-009/itrp/0065	'In addition to these objects, we created models from the image dataset provided by Nister and Stewenius [25][[ refid=''br000125'' ]].'				100_classified_usesDataFrom
uses_data_from	Experimental evaluation	J. Sturm, N. Engelhard, F. Endres, W. Burgard, D. Cremers, A benchmark for the evaluation of RGB-D SLAM systems, in: Proc. of the International Conference on Intelligent Robot Systems, IROS, 2012. URL:	http://dx.doi.org/10.1016/j.robot.2015.08.009	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2015-08-009/br/br000230>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2015-08-009/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2015-08-009/ctx/ctx0052>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2015-08-009/itrp/0066	'We evaluate our system in five different datasets with sets of from 7 to 500 objects: the Desktop dataset, used for testing purposes; one of the sequences of the RGB-D SLAM Dataset [46][[ refid=''br000230'' ]], which provides ground truth of the camera pose; the Aroa’s room dataset, a child’s real room with dozens of different objects; the Snack dataset, a sequence that shows several instances of the same object models and forces camera relocation; and the Snack with clutter dataset, a small area with repeated objects in a small space with occlusion and background clutter.'				100_classified_usesDataFrom
uses_data_from	Experiments and results	M. Cummins, P. Newman, Fab-map: Probabilistic localization and mapping in the space of appearance , Int. J. Robot. Res. , vol. 27 (2008), pp.647-665	http://dx.doi.org/10.1016/j.robot.2017.03.004	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-004/br/b3>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-004/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-004/ctx/ctx0046>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-004/itrp/0022	'This dataset [3][[ refid=''b3'' ]] consists of left and right view images collected “roughly” with a spatial frequency of 1.5 m by a Segway robot along a 2 km path in a urban environment.'				100_classified_usesDataFrom
uses_data_from	Experiments and results	M. Cummins, P. Newman, Fab-map: Probabilistic localization and mapping in the space of appearance , Int. J. Robot. Res. , vol. 27 (2008), pp.647-665	http://dx.doi.org/10.1016/j.robot.2017.03.004	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-004/br/b3>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-004/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-004/ctx/ctx0047>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-004/itrp/0023	'This dataset [3][[ refid=''b3'' ]] consists of left and right images collected with a spatial frequency of 1.5 m by a Segway robot along a 1.9 km path in a university campus.'				100_classified_usesDataFrom
uses_data_from	Experiments and results	J.-L. Blanco, F.-A. Moreno, J. González, A collection of outdoor robotic datasets with centimeter-accuracy ground truth , Auton. Robots , vol. 27 (2009), pp.327-351 , http://www.mrpt.org/Paper:Malaga_Dataset_2009	http://dx.doi.org/10.1016/j.robot.2017.03.004	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-004/br/b41>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-004/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-004/ctx/ctx0048>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-004/itrp/0045	'This dataset [41][[ refid=''b41'' ]] was acquired in a university parking area using an electric car equipped with two Firewire colour cameras.'				100_classified_usesDataFrom
uses_data_from	Experimental results	RAWSEEDS, Robotics advancement through Webpublishing of sensorial and elaborated extensive data sets (project FP6-IST-045144), 2009	http://dx.doi.org/10.1016/j.robot.2017.03.016	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-016/br/b40>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-016/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-016/ctx/ctx0042>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-016/itrp/0026	'To further test the proposed algorithm, we use the Bicocca 25b dataset from the RAWSEEDS project [40][[ refid=''b40'' ]].'				100_classified_usesDataFrom
uses_data_from	Experimental results	M. Smith, I. Baldwin, W. Churchill, R. Paul, P. Newman, The new college vision and laser data set , Int. J. Robot. Res. , vol. 28 (2009), pp.595-599	http://dx.doi.org/10.1016/j.robot.2017.03.016	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-016/br/b39>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-016/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-016/ctx/ctx0037>				http://www.scar.disi.unibo.it/r/10-1016-j-robot-2017-03-016/itrp/0045	'In particular, a qualitative test is conducted on the New College dataset [39][[ refid=''b39'' ]], where we examine the different types of bases (raw images and descriptors) in order to show the flexibility of basis representation of our approach as well as the robustness to dynamics in the scene.'				100_classified_usesDataFrom
extends	Conclusion	M. Kristan, V.S. Kenk, S. Kovačič, J. Perš, Fast image-based obstacle detection from unmanned surface vehicles , IEEE Trans. Cybern. , vol. 46 (2016), pp.641-654	http://dx.doi.org/10.1016/j.robot.2018.02.017	conclusion		http://www.scar.disi.unibo.it/r/10-1016-j-robot-2018-02-017/br/b7	http://www.scar.disi.unibo.it/r/10-1016-j-robot-2018-02-017/sec/8	http://www.scar.disi.unibo.it/r/10-1016-j-robot-2018-02-017/ctx/ctx0060		69	8	http://www.scar.disi.unibo.it/r/10-1016-j-robot-2018-02-017/itrp/0044	'Our model extends the recent state-of-the-art semantic segmentation graphical model from [7[[ refid=''b7'' ]]] by incorporating boat roll and pitch measurements from the on-board IMU.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p83"""">We proposed a new segmentation model for obstacle detection in USVs. Our model extends the recent state-of-the-art semantic segmentation graphical model from [<ce:cross-ref refid=""""b7"""" id=""""d1e6375"""">7[[ refid=''''b7'''' ]]</ce:cross-ref>] by incorporating boat roll and pitch measurements from the on-board IMU. In addition, we propose a stereo verification scheme to reduce the false positive and false negative detections. To evaluate our new segmentation model, we captured a new challenging dataset that consists of several synchronized video sequences and IMU measurements, as well as annotations of water-edge and obstacles in each image. This new dataset is the largest multi-sensor USV dataset, and will be made publicly available.</ce:para>""''"'	extends	ANG	
extends	Introduction	'T. van der Storm, W.R. Cook, A. Loh, Object grammars: Compositional & bidirectional mapping between text and graphs , Proceedings of the 5th International Conference on Software Language Engineering (SLE''12), Springer , vol. vol. 7745 (2012), pp.4-23'	http://dx.doi.org/10.1016/j.scico.2014.02.023	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-scico-2014-02-023/br/br0590	http://www.scar.disi.unibo.it/r/10-1016-j-scico-2014-02-023/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-scico-2014-02-023/ctx/ctx0003		66	7	http://www.scar.disi.unibo.it/r/10-1016-j-scico-2014-02-023/itrp/0043	'This paper extends and revises [59][[ refid=''br0590'' ]] with an extended introduction motivating the design of Object Grammars, additional details on the implementation of Object Grammars in Ensō (Section 5), an additional case-study to evaluate Object Grammars (Section 6), and additional directions for further research (Section 8).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""pr0160"""" view=""""all"""">The form of Object Grammars presented in this paper is one of the foundations of Ensō, a new programming system for the definition, composition and interpretation of external DSLs. At the time of writing, Ensō is implemented in the Ruby programming language <ce:cross-ref refid=""""br0210"""" id=""""crf0120"""">[21][[ refid=''''br0210'''' ]]</ce:cross-ref>. For more information and links to the source code, the reader is referred to <ce:inter-ref xlink:role=""""http://www.elsevier.com/xml/linking-roles/text/html"""" xlink:href=""""http://www.enso-lang.org"""" id=""""inf0010"""" xlink:type=""""simple"""">http://www.enso-lang.org</ce:inter-ref>. This paper extends and revises <ce:cross-ref refid=""""br0590"""" id=""""crf0130"""">[59][[ refid=''''br0590'''' ]]</ce:cross-ref> with an extended introduction motivating the design of Object Grammars, additional details on the implementation of Object Grammars in Ensō (Section <ce:cross-ref refid=""""se0220"""" id=""""crf0140"""">5</ce:cross-ref>), an additional case-study to evaluate Object Grammars (Section <ce:cross-ref refid=""""se0290"""" id=""""crf0150"""">6</ce:cross-ref>), and additional directions for further research (Section <ce:cross-ref refid=""""se0380"""" id=""""crf0160"""">8</ce:cross-ref>).</ce:para>""''"'	extends	ANG	
extends	Introduction	J. Cámara, A. Lopes, D. Garlan, B. Schmerl, Impact models for architecture-based self-adaptive systems , Proceedings of the 11th International Symposium on Formal Aspects of Component Software , vol. vol. 7795 (2015), pp.1-19	http://dx.doi.org/10.1016/j.scico.2015.12.006	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-scico-2015-12-006/br/br0060	http://www.scar.disi.unibo.it/r/10-1016-j-scico-2015-12-006/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-scico-2015-12-006/ctx/ctx0006		39	9	http://www.scar.disi.unibo.it/r/10-1016-j-scico-2015-12-006/itrp/0029	'This paper revises and extends the work presented in [6][[ refid=''br0060'' ]] by addressing the explicit modeling of assumptions about the environment in specifications, independent from those about adaptation impact.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""pr0070"""" view=""""all"""">This paper revises and extends the work presented in <ce:cross-ref refid=""""br0060"""" id=""""crf0090"""">[6][[ refid=''''br0060'''' ]]</ce:cross-ref> by addressing the explicit modeling of assumptions about the environment in specifications, independent from those about adaptation impact. Based on a notion of environment model, we provide a turn-based game semantics of adaptation strategies and show how probabilistic model checking can be used to develop a risk-averse strategy selector. This strategy selection scheme goes beyond the original one employed by Rainbow, which is based on maximizing a probabilistic notion of aggregate utility <ce:cross-ref refid=""""br0090"""" id=""""crf0100"""">[9][[ refid=''''br0090'''' ]]</ce:cross-ref>. This extended version of the work also includes additional details in the formalization of the semantics of our impact model language. We also report on the new experiments that we carried out to analyze the benefits of the proposed models.</ce:para>""''"'	extends	ANG	
extends	Conclusion	C. Luo, F. He, C. Ghezzi, Inferring software behavioral models with MapReduce , Dependable Software Engineering: Theories, Tools, and Applications, Springer International Publishing , vol. vol. 9409 (2015), pp.135-149	http://dx.doi.org/10.1016/j.scico.2017.04.004	conclusion		http://www.scar.disi.unibo.it/r/10-1016-j-scico-2017-04-004/br/br0120	http://www.scar.disi.unibo.it/r/10-1016-j-scico-2017-04-004/sec/10	http://www.scar.disi.unibo.it/r/10-1016-j-scico-2017-04-004/ctx/ctx0085		84	9	http://www.scar.disi.unibo.it/r/10-1016-j-scico-2017-04-004/itrp/0130	'This paper extends our previous work [12][[ refid=''br0120'' ]] in several ways.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""pr1970"""" view=""""all"""">In this paper, we presented an approach to infer software behavior models from large logs using MapReduce. In our approach, the logs are first parsed and sliced, then the model is inferred by the distributed <ce:italic>k</ce:italic>-tail algorithm. Our approach can also be used as a log preprocessor and combined with existing model inference algorithms. Experiments on Amazon clusters and large datasets show the efficiency and scalability of our approach. This paper extends our previous work <ce:cross-ref refid=""""br0120"""" id=""""crf1750"""">[12][[ refid=''''br0120'''' ]]</ce:cross-ref> in several ways. Specially, we describe several practical optimizations, formally prove the correctness of our approach, and provide more complete experimental assessment under various settings.</ce:para>""''"'	extends	ANG	
uses_data_from	Experimental setup and results	N. Murray, L. Marchesotti, F. Perronnin, Ava: a large-scale database for aesthetic visual analysis, in: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2012, pp. 2408–2415.	http://dx.doi.org/10.1016/j.sigpro.2014.12.008	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2014-12-008/br/bib38>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2014-12-008/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2014-12-008/ctx/ctx0033>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2014-12-008/itrp/0039	'In our experiments, we selected a color harmony evaluation subset (CHE-dataset) from AVA dataset [38][[ refid=''bib38'' ]] for the training and evaluation purpose.'				100_classified_usesDataFrom
uses_data_from	Experiments	M. Stikic, T. Huynh, K. Van Laerhoven, B. Schiele, Adl recognition based on the combination of rfid and accelerometer sensing, in: IEEE Second International Conference on Pervasive Computing Technologies for Healthcare, 2008. PervasiveHealth 2008, 2008, pp. 258–263.	http://dx.doi.org/10.1016/j.sigpro.2014.12.012	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2014-12-012/br/bib50>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2014-12-012/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2014-12-012/ctx/ctx0026>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2014-12-012/itrp/0010	'To evaluate our algorithm, we have conducted extensive experiments and made the comparisons on a number of datasets regarding different multimedia applications:•ADL-RFID[50][[ refid=''bib50'' ]]: It contains 10 housekeeping activities (vacuuming, ironing, dusting, brooming, mopping, cleaning windows, making bed, watering plants, washing dishes, and setting the table).'				100_classified_usesDataFrom
uses_data_from	Experiments	Z.-H. Zhou, M.-L. Zhang, Multi-instance multi-label learning with application to scene classification, in: Neural Information Processing Systems, 2006, pp. 1609–1616.	http://dx.doi.org/10.1016/j.sigpro.2014.12.012	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2014-12-012/br/bib53>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2014-12-012/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2014-12-012/ctx/ctx0028>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2014-12-012/itrp/0015	'In total, KTH contains 599 video clips (2391 sequences) with the resolution of 160×120 pixels.•MIML dataset[53][[ refid=''bib53'' ]]: It consists of 2000 natural scene images belonging to the classes desert, mountains, sea, sunset, and trees.'				100_classified_usesDataFrom
uses_data_from	Experiments	Trevid. 〈	http://dx.doi.org/10.1016/j.sigpro.2015.01.001	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-01-001/br/bib29>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-01-001/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-01-001/ctx/ctx0015>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-01-001/itrp/0019	'The experimental data are mainly based on the collection of TREC video retrieval evaluation (TRECVID) [29][[ refid=''bib29'' ]] provided by the National Institute of Standards and Technology (NIST).'				100_classified_usesDataFrom
uses_method_in	Experimental results and analysis	F. Ahmed, M.Y. Siyal, V. Uddin Abbas, A secure and robust hash-based scheme for image authentication , Signal Process. , vol. 90 (2010), pp.1456-1470	http://dx.doi.org/10.1016/j.sigpro.2015.10.027	methods	discussion	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-10-027/br/bib14>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-10-027/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-10-027/ctx/ctx0036>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-10-027/itrp/0051	'To have a fair comparison, we have implemented the method proposed by Lv and Wang [14][[ refid=''bib14'' ]] and evaluated it on the same dataset in this experiment.'				100_classified_usesDataFrom
uses_data_from	Experimental results and analysis	H. Jegou, M. Douze, C. Schmid, Available:	http://dx.doi.org/10.1016/j.sigpro.2015.10.027	methods	discussion	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-10-027/br/bib27>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-10-027/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-10-027/ctx/ctx0032>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-10-027/itrp/0055	'The original image dataset contains 500 different images which are in BMP format and of various sizes; some of them are selected from internet [27][[ refid=''bib27'' ]] and some are captured with digital cameras by ourselves.'				100_classified_usesDataFrom
uses_data_from	Experiment	R.K. Kishore, S. Mubarak, Recognizing 50 human action categories of web videos , Mach. Vis. Appl. , vol. 24 (2013), pp.971-981	http://dx.doi.org/10.1016/j.sigpro.2015.10.035	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-10-035/br/bib4>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-10-035/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-10-035/ctx/ctx0030>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2015-10-035/itrp/0046	'UCF50[4][[ refid=''bib4'' ]]: It contains 50 action categories and 6617 action videos which are realistic videos taken from Youtube.'				100_classified_usesDataFrom
cites_as_review	Introduction	S. Ahmed, M. Alouini, A survey of correlated waveform design for multifunction software radar , IEEE Aerosp. Electron. Syst. Magaz. , vol. 31 (2016), pp.19-31	http://dx.doi.org/10.1016/j.sigpro.2018.06.007	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/br/bib0026>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/ctx/ctx0027>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/itrp/0009	'In order to avoid this hardware modification and to make it possible to use multi-function software radar [26][[ refid=''bib0026'' ]], identical RFAs that all work at the same power level, should be used.'			FDY+AGA	infered_pred1
cites_as_review	Simulation results	S. Ahmed, M. Alouini, A survey of correlated waveform design for multifunction software radar , IEEE Aerosp. Electron. Syst. Magaz. , vol. 31 (2016), pp.19-31	http://dx.doi.org/10.1016/j.sigpro.2018.06.007	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/br/bib0026>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/ctx/ctx0073>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/itrp/0016	'However, BPSK waveforms and infinite alphabet waveforms with 128 symbols can be generated in 10−4 s and 3 min, respectively [26][[ refid=''bib0026'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites_as_review	Introduction	S. Ahmed, M. Alouini, A survey of correlated waveform design for multifunction software radar , IEEE Aerosp. Electron. Syst. Magaz. , vol. 31 (2016), pp.19-31	http://dx.doi.org/10.1016/j.sigpro.2018.06.007	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/br/bib0026>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/ctx/ctx0008>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/itrp/0020	'Therefore, waveform design using the covariance matrix can reduce the complexity [26][[ refid=''bib0026'' ]].'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
cites_as_review	Proposed method for waveform covariance matrix design	S. Ahmed, M. Alouini, A survey of correlated waveform design for multifunction software radar , IEEE Aerosp. Electron. Syst. Magaz. , vol. 31 (2016), pp.19-31	http://dx.doi.org/10.1016/j.sigpro.2018.06.007	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/br/bib0026>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/ctx/ctx0047>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/itrp/0024	'These values, approximately are the same as the time that the iterative methods need to generate the waveforms realizing the covariance matrix [26][[ refid=''bib0026'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Simulation results	H. Deng, Z. Geng, B. Himed, Mimo radar waveform design for transmit beamforming and orthogonality , IEEE Trans. Aerosp. Electron. Systems , vol. 52 (2016), pp.1421-1433	http://dx.doi.org/10.1016/j.sigpro.2018.06.007	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/br/bib0022>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/ctx/ctx0069>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/itrp/0078	'As can be seen, even one degree of error in the initial estimation of only two interferers’ directions, causes significant SINR degradation for all methods except our proposed method and method in [22][[ refid=''bib0022'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Simulation results	H. Deng, Z. Geng, B. Himed, Mimo radar waveform design for transmit beamforming and orthogonality , IEEE Trans. Aerosp. Electron. Systems , vol. 52 (2016), pp.1421-1433	http://dx.doi.org/10.1016/j.sigpro.2018.06.007	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/br/bib0022>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/ctx/ctx0059>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/itrp/0079	'Increasing the number of nulls in the transmit beam-pattern with fixed number of transmit antennas, decreases the nulls depths [22][[ refid=''bib0022'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Signal model	H.L.V. Trees, Optimum Array Processing Part IV of Detection, Estimation, and Modulation Theory , None, John Wiley (2002)	http://dx.doi.org/10.1016/j.sigpro.2018.06.007	model		<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/br/bib0031>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/ctx/ctx0034>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/itrp/0086	'The optimum value of wLMr×1 using MVDR [31][[ refid=''bib0031'' ]] is as follows: [[ formulaid=''id9_pos2'' ]] by replacing (8) in (6), the output SINR for a specific R is: [[ formulaid=''id9_pos3'' ]]'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Signal model	M. Greco, F. Gini, A. Farina, Radar detection and classification of jamming signals belonging to a cone class , IEEE Trans. Signal Processing , vol. 56 (2008), pp.1984-1993	http://dx.doi.org/10.1016/j.sigpro.2018.06.007	model		<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/br/bib0032>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/ctx/ctx0031>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/itrp/0094	'Consider a point like target at direction θ0 and Q signal-dependent interference sources (point like scatterers or digital radio frequency memory repeat jammer [32][[ refid=''bib0032'' ]]) at directions θi,i=1,.,Q.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Proposed method for waveform covariance matrix design	S. Ahmed, J.S. Thompson, Y.R. Petillot, B. Mulgrew, Finite alphabet constant-envelope waveform design for MIMO radar , IEEE Trans. Signal Process. , vol. 59 (2011), pp.5326-5337	http://dx.doi.org/10.1016/j.sigpro.2018.06.007	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/br/bib0013>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/ctx/ctx0053>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/itrp/0124	'Finally, the BPSK waveforms which realise this covariance matrix are generated as follows [13][[ refid=''bib0013'' ]]: [[ formulaid=''id15_pos5'' ]] where X is the transmit waveforms matrix and ψ is a matrix including zero mean and unit variance Gaussian random variables.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites_as_review	Introduction	S. Ahmed, M. Alouini, A survey of correlated waveform design for multifunction software radar , IEEE Aerosp. Electron. Syst. Magaz. , vol. 31 (2016), pp.19-31	http://dx.doi.org/10.1016/j.sigpro.2018.06.007	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/br/bib0026>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/ctx/ctx0013>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/itrp/0128	'Generally, the time required to use closed-form waveform design methods is much lower than that of iterative counterparts [26][[ refid=''bib0026'' ]].'		<http://purl.org/spar/cito/citesAsReview>		top100compsc
uses_method_in	Simulation results	H. Deng, Z. Geng, B. Himed, Mimo radar waveform design for transmit beamforming and orthogonality , IEEE Trans. Aerosp. Electron. Systems , vol. 52 (2016), pp.1421-1433	http://dx.doi.org/10.1016/j.sigpro.2018.06.007	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/br/bib0022>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/ctx/ctx0055>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/itrp/0165	'At first, we evaluate the null generating efficiency of the proposed method compared to the method in [22][[ refid=''bib0022'' ]].'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Simulation results	S. Ahmed, M.S. Alouini, Mimo-radar waveform covariance matrix for high sinr and low side-lobe levels , IEEE Trans. Signal Process. , vol. 62 (2014), pp.2056-2065	http://dx.doi.org/10.1016/j.sigpro.2018.06.007	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/br/bib0023>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/ctx/ctx0067>				http://www.scar.disi.unibo.it/r/10-1016-j-sigpro-2018-06-007/itrp/0168	'Also, because of decreasing the number of total antennas compared to the previous simulation, the performance of the method in [23][[ refid=''bib0023'' ]] outperforms phased array counterpart.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Web-Based simulation advantages and disadvantages	M.M.G. DeRico, R.B. Byrnes Jr., J.H. Schafer, J.A. Martin, M.D. McNett, G.F. Stone III, Using intelligent agents to combine heterogeneous distributed data, in: IEEE International Conference on Systems, Man, and Cybernetics, San Diego, California, USA, 1998, pp. 2831–2835.	http://dx.doi.org/10.1016/j.simpat.2009.09.013	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-simpat-2009-09-013/br/bib29>	<http://www.scar.disi.unibo.it/r/10-1016-j-simpat-2009-09-013/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-simpat-2009-09-013/ctx/ctx0028>				http://www.scar.disi.unibo.it/r/10-1016-j-simpat-2009-09-013/itrp/0125	'Obtaining data from the Web has become second nature to most users [29][[ refid=''bib29'' ]], and the Internet provides a familiar interface for both interacting with and controlling a simulation.'				100_classified_usesDataFrom
uses_data_from	Experimentation and result analysis	K. Geurts, Traffic Accidents Data Set, Research Group Data and Modeling, Limburgs Universitair Centrum, Belgium <	http://dx.doi.org/10.1016/j.simpat.2015.10.001	discussion	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-simpat-2015-10-001/br/b0095>	<http://www.scar.disi.unibo.it/r/10-1016-j-simpat-2015-10-001/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-simpat-2015-10-001/ctx/ctx0060>				http://www.scar.disi.unibo.it/r/10-1016-j-simpat-2015-10-001/itrp/0047	'This dataset includes a total of 340,184 traffic accident records [19][[ refid=''b0095'' ]].'				100_classified_usesDataFrom
cites	Background and related work	M.T. Lee, J. Thorpe, J. Verhoeven, Intonation and phonation in young adults with Down syndrome , J. Voice , vol. 23 (2009), pp.82-87	http://dx.doi.org/10.1016/j.specom.2018.03.006	background	related work	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/br/bib0025	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/ctx/ctx0021		57	4	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/itrp/0015	'Lee et al. (2009)[[ refid=''bib0025'' ]] combined words, reading and natural speech.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0015"""" view=""""all"""">The unit of analysis and the phonation tasks used by the researchers are different. <ce:cross-ref id=""""crf0051"""" refid=""""bib0038"""">Rochet-Capellan and Dohen (2015)[[ refid=''''bib0038'''' ]]</ce:cross-ref> used Vowel–Consonant–Vowel by syllabes, <ce:cross-ref id=""""crf0052"""" refid=""""bib0040"""">Saz et al. (2009a)[[ refid=''''bib0040'''' ]]</ce:cross-ref> and <ce:cross-ref id=""""crf0053"""" refid=""""bib0001"""">Albertini et al. (2010)[[ refid=''''bib0001'''' ]]</ce:cross-ref> recorded words, <ce:cross-ref id=""""crf0054"""" refid=""""bib0039"""">Rodger (2009)[[ refid=''''bib0039'''' ]]</ce:cross-ref> and <ce:cross-ref id=""""crf0055"""" refid=""""bib0049"""">Zampini et al. (2016)[[ refid=''''bib0049'''' ]]</ce:cross-ref> built these corpora using semi-spontaneous speech and <ce:cross-ref id=""""crf0056"""" refid=""""bib0008"""">Corrales-Astorgano et al. (2016)[[ refid=''''bib0008'''' ]]</ce:cross-ref> analyzed sentences. <ce:cross-ref id=""""crf0057"""" refid=""""bib0025"""">Lee et al. (2009)[[ refid=''''bib0025'''' ]]</ce:cross-ref> combined words, reading and natural speech. The majority of the studies are focused on the English language (<ce:cross-ref id=""""crf0058"""" refid=""""bib0023"""">Kent and Vorperian, 2013[[ refid=''''bib0023'''' ]]</ce:cross-ref>), but there are others focused on Italian (<ce:cross-refs id=""""crfs0003"""" refid=""""bib0049 bib0001"""">Zampini et al., 2016; Albertini et al., 2010[[ refid=''''bib0049 bib0001'''' ]]</ce:cross-refs>), Spanish (<ce:cross-refs id=""""crfs0004"""" refid=""""bib0008 bib0040"""">Corrales-Astorgano et al., 2016; Saz et al., 2009a[[ refid=''''bib0008 bib0040'''' ]]</ce:cross-refs>), French (<ce:cross-ref id=""""crf0059"""" refid=""""bib0038"""">Rochet-Capellan and Dohen, 2015[[ refid=''''bib0038'''' ]]</ce:cross-ref>) or Farsi (<ce:cross-ref id=""""crf0060"""" refid=""""bib0043"""">Seifpanahi et al., 2011[[ refid=''''bib0043'''' ]]</ce:cross-ref>).</ce:para>""''"'	cites	AGA	
cites	Background and related work	A.L. Pentz Jr, Formant amplitude of children with Down syndrome , Am. J. Ment. Defic. , vol. 92 (1987), pp.230-233	http://dx.doi.org/10.1016/j.specom.2018.03.006	background	related work	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/br/bib0037	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/ctx/ctx0028		57	4	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/itrp/0022	'Moreover, the voice of people with Down syndrome showed significantly reduced formant amplitude intensity levels (Pentz Jr, 1987[[ refid=''bib0037'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0017"""" view=""""all"""">Formant frequency and amplitude have also been studied in people with Down syndrome. A larger vowel space in people with Down syndrome was found by <ce:cross-ref id=""""crf0065"""" refid=""""bib0038"""">Rochet-Capellan and Dohen (2015)[[ refid=''''bib0038'''' ]]</ce:cross-ref>, while other studies denoted a reduction of the vowel space in children (<ce:cross-ref id=""""crf0066"""" refid=""""bib0036"""">Moura et al., 2008[[ refid=''''bib0036'''' ]]</ce:cross-ref>) and adults (<ce:cross-ref id=""""crf0067"""" refid=""""bib0004"""">Bunton and Leddy, 2011[[ refid=''''bib0004'''' ]]</ce:cross-ref>). Moreover, the voice of people with Down syndrome showed significantly reduced formant amplitude intensity levels (<ce:cross-ref id=""""crf0068"""" refid=""""bib0037"""">Pentz Jr, 1987[[ refid=''''bib0037'''' ]]</ce:cross-ref>).</ce:para>""''"'	cites	AGA	
cites	Experimental procedure	D. Escudero, C. González, Y. Gutiérrez, E. Rodero, Identifying characteristic prosodic patterns through the analysis of the information of sp_tobi label sequences , Comput. Speech Lang. , vol. 45 (2017), pp.39-57	http://dx.doi.org/10.1016/j.specom.2018.03.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/br/bib0013	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/ctx/ctx0040		57	4	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/itrp/0032	'A similar methodology was used by Escudero et al. (2017)[[ refid=''bib0013'' ]], where the characteristic prosodic patterns of the style of different groups of speakers was investigated.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0039"""" view=""""all"""">In order to evaluate the impact of prosody in the perception of the listeners, we used prosody transfer techniques. These techniques have previously been used in other studies of the state of the art. For instance, <ce:cross-ref id=""""crf0088"""" refid=""""bib0028"""">Luo et al. (2017)[[ refid=''''bib0028'''' ]]</ce:cross-ref> investigated the role of different prosodic features in the naturalness of English L2 speech. The prosodic modification method was applied to native and L2 learners’ speech. Later, they used a perceptual test to evaluate the impact of prosody modification. A similar methodology was used by <ce:cross-ref id=""""crf0089"""" refid=""""bib0013"""">Escudero et al. (2017)[[ refid=''''bib0013'''' ]]</ce:cross-ref>, where the characteristic prosodic patterns of the style of different groups of speakers was investigated. After the prosodic modification of the utterances, the characteristic prosodic patterns were validated using a perceptual test. The procedure described in <ce:cross-ref id=""""crf0090"""" refid=""""bib0013"""">Escudero et al. (2017)[[ refid=''''bib0013'''' ]]</ce:cross-ref> for transferring prosody is used in the experiments reported in this paper.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experimental procedure	D. Escudero, C. González, Y. Gutiérrez, E. Rodero, Identifying characteristic prosodic patterns through the analysis of the information of sp_tobi label sequences , Comput. Speech Lang. , vol. 45 (2017), pp.39-57	http://dx.doi.org/10.1016/j.specom.2018.03.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/br/bib0013	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/ctx/ctx0041		57	4	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/itrp/0033	'The procedure described in Escudero et al. (2017)[[ refid=''bib0013'' ]] for transferring prosody is used in the experiments reported in this paper.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0039"""" view=""""all"""">In order to evaluate the impact of prosody in the perception of the listeners, we used prosody transfer techniques. These techniques have previously been used in other studies of the state of the art. For instance, <ce:cross-ref id=""""crf0088"""" refid=""""bib0028"""">Luo et al. (2017)[[ refid=''''bib0028'''' ]]</ce:cross-ref> investigated the role of different prosodic features in the naturalness of English L2 speech. The prosodic modification method was applied to native and L2 learners’ speech. Later, they used a perceptual test to evaluate the impact of prosody modification. A similar methodology was used by <ce:cross-ref id=""""crf0089"""" refid=""""bib0013"""">Escudero et al. (2017)[[ refid=''''bib0013'''' ]]</ce:cross-ref>, where the characteristic prosodic patterns of the style of different groups of speakers was investigated. After the prosodic modification of the utterances, the characteristic prosodic patterns were validated using a perceptual test. The procedure described in <ce:cross-ref id=""""crf0090"""" refid=""""bib0013"""">Escudero et al. (2017)[[ refid=''''bib0013'''' ]]</ce:cross-ref> for transferring prosody is used in the experiments reported in this paper.</ce:para>""''"'	uses_method_in	AGA	
cites	Introduction	C.V. Guimaraes, L.F. Donnelly, S.R. Shott, R.S. Amin, M. Kalra, Relative rather than absolute macroglossia in patients with Down syndrome: implications for treatment of obstructive sleep apnea , Pediatr. Radiol. , vol. 38 (2008), pp.1062	http://dx.doi.org/10.1016/j.specom.2018.03.006	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/br/bib0018	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/ctx/ctx0002		57	4	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/itrp/0040	'Many DS individuals have some physiological peculiarities that affect their voice production, such as a smaller vocal tract with respect to the tongue size or soft palatal shape, among others Guimaraes et al. (2008)[[ refid=''bib0018'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0001"""" view=""""all"""">Individuals with Down syndrome (DS) have problems in their language development that make their social relationships and their developmental ability more problematic (<ce:cross-refs id=""""crfs0001"""" refid=""""bib0007 bib0031 bib0006"""">Cleland et al., 2010; Martin et al., 2009; Chapman, 1997[[ refid=''''bib0007 bib0031 bib0006'''' ]]</ce:cross-refs>). Many DS individuals have some physiological peculiarities that affect their voice production, such as a smaller vocal tract with respect to the tongue size or soft palatal shape, among others <ce:cross-ref id=""""crf0020"""" refid=""""bib0018"""">Guimaraes et al. (2008)[[ refid=''''bib0018'''' ]]</ce:cross-ref>. Muscular hypotonia also affects their capabilities for performing a correct articulation, degrading the quality of the spectral characteristics of sounds (<ce:cross-ref id=""""crf0021"""" refid=""""bib0030"""">Markaki and Stylianou, 2011[[ refid=''''bib0030'''' ]]</ce:cross-ref>). In addition, hearing loss during childhood (<ce:cross-ref id=""""crf0022"""" refid=""""bib0044"""">Shott et al., 2001[[ refid=''''bib0044'''' ]]</ce:cross-ref>) and fluency deficits (<ce:cross-ref id=""""crf0023"""" refid=""""bib0009"""">Devenny and Silverman, 1990[[ refid=''''bib0009'''' ]]</ce:cross-ref>) influence the frequency, energy and temporal domains of the voice signal.</ce:para>""''"'	cites	AGA	
uses_method_in	Experimental procedure	F. Eyben, F. Weninger, F. Gross, B. Schuller, Recent developments in opensmile, the Munich open-source multimedia feature extractor , Proceedings of the 21st ACM international conference on Multimedia, ACM (2013)	http://dx.doi.org/10.1016/j.specom.2018.03.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/br/bib0015	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/ctx/ctx0034		57	4	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/itrp/0052	'Acoustic low-level descriptors (LLD) and temporal features were automatically extracted from each recording using the openSmile toolkit (Eyben et al., 2013[[ refid=''bib0015'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0027"""" view=""""all"""">Acoustic low-level descriptors (LLD) and temporal features were automatically extracted from each recording using the openSmile toolkit (<ce:cross-ref id=""""crf0083"""" refid=""""bib0015"""">Eyben et al., 2013[[ refid=''''bib0015'''' ]]</ce:cross-ref>). Two minimalistic feature sets were used. On the one hand, these sets provided enough features to characterize the audio recordings. On the other hand, we avoid the problem of having too many parameters relative to the number of observations. This problem can produce overfitting in the training phase, because the classifier adapts to the concrete set of inputs. This adaptation can produce good classification results for this particular set, but negatively affects the generalization capacity of the classifier. The Geneva Minimalistic Standard Parameter Set (GeMAPS) and the extended Geneva Minimalistic Acoustic Parameter Set (eGeMAPS), described by <ce:cross-ref id=""""crf0084"""" refid=""""bib0014"""">Eyben et al. (2016)[[ refid=''''bib0014'''' ]]</ce:cross-ref>, were selected. The features extracted from each recording are sorted into four groups:<ce:list id=""""celist0004""""><ce:list-item id=""""celistitem0007""""><ce:label>•</ce:label><ce:para id=""""para0028"""" view=""""all"""">Frequency related features: fundamental frequency and jitter.</ce:para></ce:list-item><ce:list-item id=""""celistitem0008""""><ce:label>•</ce:label><ce:para id=""""para0029"""" view=""""all"""">Energy related features: loudness, shimmer and</ce:para><ce:para id=""""para0030"""" view=""""all"""">Harmonics-to-Noise Ratio.</ce:para></ce:list-item><ce:list-item id=""""celistitem0009""""><ce:label>•</ce:label><ce:para id=""""para0031"""" view=""""all"""">Spectral features: alpha ratio, Hammarberg index, spectral slope, formant 1, 2, 3 relative energy, harmonic difference H1-H2, harmonic difference H1-A3, formant 1, 2, 3 frequency and formant 1, 2, 3 bandwidth.</ce:para></ce:list-item><ce:list-item id=""""celistitem0010""""><ce:label>•</ce:label><ce:para id=""""para0032"""" view=""""all"""">Temporal features: the rate of loudness peaks per second, mean length and standard deviation of continuous voiced and unvoiced segments and the rate of voiced segments per second, approximating the pseudo syllable rate.</ce:para></ce:list-item></ce:list></ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experimental procedure	Boersma, P., 2006. Praat: doing phonetics by computer.	http://dx.doi.org/10.1016/j.specom.2018.03.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/br/bib0003	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/ctx/ctx0036		57	4	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/itrp/0054	'Therefore, the Praat software (Boersma, 2006[[ refid=''bib0003'' ]]) was used to extract all silences from each recording and these silences were excluded from the analysis process.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0033"""" view=""""all"""">In total, there are 25 LLD. The arithmetic mean and the coefficient of variation are calculated on these 25 LLD. Some functionals are applied to fundamental frequency and loudness: 20-th, 50-th, and 80-th percentile, the range of 20-th to 80-th percentile, and the mean and standard deviation of the slope of rising/falling signal parts. All these functionals are computed by the openSmile toolkit. In addition, the process used by the openSmile toolkit to extract the eGeMAPS features did not differentiate between silences and unvoiced regions, which can produce errors in the functions applied to each feature. Therefore, the Praat software (<ce:cross-ref id=""""crf0085"""" refid=""""bib0003"""">Boersma, 2006[[ refid=''''bib0003'''' ]]</ce:cross-ref>) was used to extract all silences from each recording and these silences were excluded from the analysis process.</ce:para>""''"'	uses_method_in	AGA	
uses_method_in	Experimental procedure	B.W. Schuller, S. Steidl, A. Batliner, J. Hirschberg, J.K. Burgoon, A. Baird, A.C. Elkins, Y. Zhang, E. Coutinho, K. Evanini, The interspeech 2016 computational paralinguistics challenge: Deception, sincerity & native language. , INTERSPEECH (2016)	http://dx.doi.org/10.1016/j.specom.2018.03.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/br/bib0042	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/ctx/ctx0038		57	4	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/itrp/0062	'The unweighted average recall (UAR) (Schuller et al., 2016[[ refid=''bib0042'' ]]) was also used.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0038"""" view=""""all"""">To analyze the performance of the classification, we used the classification rate. The unweighted average recall (UAR) (<ce:cross-ref id=""""crf0087"""" refid=""""bib0042"""">Schuller et al., 2016[[ refid=''''bib0042'''' ]]</ce:cross-ref>) was also used. This metric is the mean of sensitivity (recall of positive instances) and specificity (recall of negative instances). UAR was chosen as the classification metric because it equally weights each class regardless of its number of samples, so it represents more precisely the accuracy of a classification test using unbalanced data.</ce:para>""''"'	cites	AGA	
cites	Background and related work	G. Albertini, S. Bonassi, V. Dall’Armi, I. Giachetti, S. Giaquinto, M. Mignano, Spectral analysis of the voice in down syndrome , Res. Dev. Disabil. , vol. 31 (2010), pp.995-1001	http://dx.doi.org/10.1016/j.specom.2018.03.006	background	related work	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/br/bib0001	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/ctx/ctx0013		57	4	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/itrp/0074	'Albertini et al. (2010)[[ refid=''bib0001'' ]] found lower shimmer (amplitude perturbations) in male adults with Down syndrome than in adults without intellectual disabilities.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0013"""" view=""""all"""">The age of the population selected for the study seems to be important for the results obtained, due to the physiological differences between children and adults. Concerning adults, <ce:cross-ref id=""""crf0035"""" refid=""""bib0025"""">Lee et al. (2009)[[ refid=''''bib0025'''' ]]</ce:cross-ref>, <ce:cross-ref id=""""crf0036"""" refid=""""bib0038"""">Rochet-Capellan and Dohen (2015)[[ refid=''''bib0038'''' ]]</ce:cross-ref>, <ce:cross-ref id=""""crf0037"""" refid=""""bib0001"""">Albertini et al. (2010)[[ refid=''''bib0001'''' ]]</ce:cross-ref> and <ce:cross-ref id=""""crf0038"""" refid=""""bib0008"""">Corrales-Astorgano et al. (2016)[[ refid=''''bib0008'''' ]]</ce:cross-ref> found significantly higher F0 values in adults with Down syndrome as compared to adults without intellectual disabilities. In addition, <ce:cross-ref id=""""crf0039"""" refid=""""bib0025"""">Lee et al. (2009)[[ refid=''''bib0025'''' ]]</ce:cross-ref> and <ce:cross-ref id=""""crf0040"""" refid=""""bib0043"""">Seifpanahi et al. (2011)[[ refid=''''bib0043'''' ]]</ce:cross-ref> found lower jitter (frequency perturbations) in adult speakers with Down syndrome. As for energy, <ce:cross-ref id=""""crf0041"""" refid=""""bib0001"""">Albertini et al. (2010)[[ refid=''''bib0001'''' ]]</ce:cross-ref> found significantly lower energy values in adults with Down syndrome. Moreover, <ce:cross-ref id=""""crf0042"""" refid=""""bib0040"""">Saz et al. (2009a)[[ refid=''''bib0040'''' ]]</ce:cross-ref> concluded that adults with Down syndrome had poor control over energy in stressed versus unstressed vowels. <ce:cross-ref id=""""crf0043"""" refid=""""bib0001"""">Albertini et al. (2010)[[ refid=''''bib0001'''' ]]</ce:cross-ref> found lower shimmer (amplitude perturbations) in male adults with Down syndrome than in adults without intellectual disabilities. Finally, temporal domain results depend on the unit of analysis employed. <ce:cross-ref id=""""crf0044"""" refid=""""bib0040"""">Saz et al. (2009a)[[ refid=''''bib0040'''' ]]</ce:cross-ref> found that people with cognitive disorders presented an excessive variability in vowel duration, while <ce:cross-ref id=""""crf0045"""" refid=""""bib0038"""">Rochet-Capellan and Dohen (2015)[[ refid=''''bib0038'''' ]]</ce:cross-ref> and <ce:cross-ref id=""""crf0046"""" refid=""""bib0004"""">Bunton and Leddy (2011)[[ refid=''''bib0004'''' ]]</ce:cross-ref> reported longer durations of vowels in adults with Down syndrome. <ce:cross-ref id=""""crf0047"""" refid=""""bib0001"""">Albertini et al. (2010)[[ refid=''''bib0001'''' ]]</ce:cross-ref> discovered a lower duration of words in male adults with Down syndrome. Moreover, people with Down syndrome present some disfluency problems. Although disfluency (stuttering or cluttering) has not been demonstrated as a universal characteristic of Down syndrome, it is a common problem of this population (<ce:cross-refs id=""""crfs0002"""" refid=""""bib0045 bib0009 bib0012"""">Van Borsel and Vandermeulen, 2008; Devenny and Silverman, 1990; Eggers and Van Eerdenbrugh, 2017[[ refid=''''bib0045 bib0009 bib0012'''' ]]</ce:cross-refs>). These disfluencies can affect the speech rhythm of people with Down syndrome.</ce:para>""''"'	cites	AGA	
cites	Experimental procedure	Boersma, P., 2006. Praat: doing phonetics by computer.	http://dx.doi.org/10.1016/j.specom.2018.03.006	methods		http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/br/bib0003	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/ctx/ctx0044		57	4	http://www.scar.disi.unibo.it/r/10-1016-j-specom-2018-03-006/itrp/0087	'Once the segmentation was corrected, a prosody transfer algorithm implemented in Praat (Boersma, 2006[[ refid=''bib0003'' ]]) was executed.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""para0041"""" view=""""all"""">Once the segmentation was corrected, a prosody transfer algorithm implemented in Praat (<ce:cross-ref id=""""crf0093"""" refid=""""bib0003"""">Boersma, 2006[[ refid=''''bib0003'''' ]]</ce:cross-ref>) was executed. This algorithm transfers, phoneme by phoneme, the pitch, energy and duration from one audio to another. Therefore, the new audio file contains the original utterance but with the prosody transferred from another utterance. The algorithm was executed combining the audios of each speaker with the audios of the rest of the speakers, so, in total, 3525 audio files were generated (not all the speakers had the same number of recordings). As a result, there are four types of audio files, as shown in <ce:cross-ref id=""""crf0094"""" refid=""""fig0002"""">Fig. 2</ce:cross-ref>. Five audio files of each type were selected randomly for the perception test, so the test included twenty audio files, balanced in terms of gender.</ce:para>""''"'	uses_method_in	AGA	
extends	Introduction	E.D. Santis, L. Livi, A. Sadeghian, A. Rizzi, Modeling and recognition of smart grid faults by a combined approach of dissimilarity learning and one-class classification , Neurocomputing , vol. 170 (2015), pp.368-383	http://dx.doi.org/10.1016/j.swevo.2017.10.007	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-swevo-2017-10-007/br/bib42	http://www.scar.disi.unibo.it/r/10-1016-j-swevo-2017-10-007/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-swevo-2017-10-007/ctx/ctx0009		44	8	http://www.scar.disi.unibo.it/r/10-1016-j-swevo-2017-10-007/itrp/0014	'The current work extends the study discussed in Ref. [42][[ refid=''bib42'' ]] based on a One-class classification paradigm.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0020"""" view=""""all"""">The current work extends the study discussed in Ref. <ce:cross-ref refid=""""bib42"""" id=""""crosref0065"""">[42][[ refid=''''bib42'''' ]]</ce:cross-ref> based on a One-class classification paradigm. In fact in the present work the adopted paradigm is the two-class classification approach, operated with a different decision rule for the label assignment task, this time based on a combination of a measure of the clusters purity and the absolute position of a test pattern compared to the representatives of the generated clusters. Results of a random initialized <ce:italic>k</ce:italic>-means here are compared with an improved version of the <ce:italic>k</ce:italic>-means boosted with a more effective initialization procedure, designed to reduce the complexity of the classifier and the training time. The proposed classifier is based on a Clustering-Evolutionary Computing approach, where a model of the power grid faults is learned upon an historical data set built through real-world data. Once trained the model can be used online to classify unseen power grid states, discriminating faults from standard functioning states. Furthermore, it is presented a complexity study of the data set of SG states at hands, by means of the skewness statistic computed upon the distribution of dissimilarity values, increasing the numerosity of the sample. Finally, introducing briefly the main classification techniques based on suitable transformation in non-Euclidean spaces (even non-metric) two standard Support Vector Machines (SVMs) are trained, for comparison purposes, on suitable kernels designed in the Pseudo-Euclidean space and in the Dissimilarity Space on the ACEA data, respectively.</ce:para>""''"'	extends	ANG	
uses_method_in	The GET framework	IETF, BSD syslog protocol, RFC (2007). Online:	http://dx.doi.org/10.1016/j.sysarc.2015.11.010			<http://www.scar.disi.unibo.it/r/10-1016-j-sysarc-2015-11-010/br/bib0010>	<http://www.scar.disi.unibo.it/r/10-1016-j-sysarc-2015-11-010/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-sysarc-2015-11-010/ctx/ctx0014>				http://www.scar.disi.unibo.it/r/10-1016-j-sysarc-2015-11-010/itrp/0030	'The Dispatcher gathers raw logs and data from event sources through data transfer protocols like Syslog [10][[ refid=''bib0010'' ]].'				100_classified_usesDataFrom
cites	Introduction	G. Lugano, Mobile social networking in theory and practice , First Monday , vol. 3 (2008), pp.None	http://dx.doi.org/10.1016/j.tele.2010.03.002	introduction		http://www.scar.disi.unibo.it/r/10-1016-j-tele-2010-03-002/br/bib18	http://www.scar.disi.unibo.it/r/10-1016-j-tele-2010-03-002/sec/1	http://www.scar.disi.unibo.it/r/10-1016-j-tele-2010-03-002/ctx/ctx0002		33	4	http://www.scar.disi.unibo.it/r/10-1016-j-tele-2010-03-002/itrp/0016	'Relationships that exist professionally and personally are susceptible to structural shifts as smartphones effect personal privacy while blending and expanding social networks (Lugano, 2008[[ refid=''bib18'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""">The definition for communication, a message sent between people, remains the same; but the method of transmitting the message changes. The degree of importance that a person places on the information to be shared with respect to time, subject matter, and the kind of relationship existing between the communicating parties helps to determine the method of transaction. Not only have the communication utilities available in mobile phones improved, but the innovation of the smartphone has increased the methods for exchanging information. A smartphone is a mobile phone with built-in applications, i.e. video player, MP3 player, television, camera, with the ability to access the Internet (<ce:cross-ref refid=""""bib21"""">PCMAG.com, 2009[[ refid=''''bib21'''' ]]</ce:cross-ref>). While second generation mobile phones have similar utilities, the smartphone has a computer operating system to run applications. The utilization of the smartphone is changing the social availability of people through the use of its various applications and utilities. Relationships that exist professionally and personally are susceptible to structural shifts as smartphones effect personal privacy while blending and expanding social networks (<ce:cross-ref refid=""""bib18"""">Lugano, 2008[[ refid=''''bib18'''' ]]</ce:cross-ref>). The purpose of this descriptive study was to discover the utilization of mobile phone utilities for communication within a non-electronic (human to human) social support network and to see how people felt about sharing ‘private’ information through the mobile phone with select social network members. </ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	ICTs and communication discourse	T.A. Van Dijk, Social cognition and discourse , Handbook of Social Psychology and Language, Wiley (1989)	http://dx.doi.org/10.1016/j.tele.2011.02.001			http://www.scar.disi.unibo.it/r/10-1016-j-tele-2011-02-001/br/b0365	http://www.scar.disi.unibo.it/r/10-1016-j-tele-2011-02-001/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-tele-2011-02-001/ctx/ctx0010		74	5	http://www.scar.disi.unibo.it/r/10-1016-j-tele-2011-02-001/itrp/0092	'Van Dijk (1989)[[ refid=''b0365'' ]] defines discourse as a specific form of language that expands beyond the boundaries of semantic presentation.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0045"""" view=""""all""""> <ce:cross-ref refid=""""b0180"""">Kaplan and Duchon (1988)[[ refid=''''b0180'''' ]]</ce:cross-ref> argue that ICTs should be viewed from its social and organizational aspects and from the perspectives of its role in communication discourse. <ce:cross-ref refid=""""b0365"""">Van Dijk (1989)[[ refid=''''b0365'''' ]]</ce:cross-ref> defines discourse as a specific form of language that expands beyond the boundaries of semantic presentation. In this context, discourse is used for the purpose of social interaction and therefore should be interpreted as a means of completing communication between and among different social actors. In this context discourse distinguishes itself from as being passive format of grammar sentences. </ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Literature review	V. Venkatesh, G.B. Davis, A theoretical extension of the technology acceptance model: four longitudinal field studies , Management Science , vol. 46 (2000), pp.186-204	http://dx.doi.org/10.1016/j.tele.2012.01.003			http://www.scar.disi.unibo.it/r/10-1016-j-tele-2012-01-003/br/b0470	http://www.scar.disi.unibo.it/r/10-1016-j-tele-2012-01-003/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-tele-2012-01-003/ctx/ctx0022		83	4	http://www.scar.disi.unibo.it/r/10-1016-j-tele-2012-01-003/itrp/0001	'Building upon the robustness of TAM, researchers expanded the model to TAM2, adding the impacts of three interrelated social forces on individuals’ adoption of a new technology (Venkatesh and Davis, 2000[[ refid=''b0470'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0055"""" view=""""all"""">While TRA focuses on explaining behavioral intention in general from a social psychology perspective, TAM centers specifically on predicting behavioral intention to use and the actual use of an information technology from information systems and management perspectives. TRA posits that attitude and subjective norm affect intention. Subjective norm refers to an individual’s belief that she or he should perform a certain behavior because other people important to the individual expect the behavior (<ce:cross-ref refid=""""b0155"""" id=""""c0100"""">Fishbein and Aizen, 1975[[ refid=''''b0155'''' ]]</ce:cross-ref>). Adapting the generic behavior model to the specific domain of technology acceptance, TAM replaces TRA’s attitudinal determinants with perceived usefulness and perceived ease of use (<ce:cross-ref refid=""""b0040"""" id=""""c0105"""">Bagozzi et al., 1992[[ refid=''''b0040'''' ]]</ce:cross-ref>). Also, TAM omits subjective norm because subjective norm does not significantly influence intention over and above perceived usefulness and perceived ease of use (<ce:cross-ref refid=""""b0110"""" id=""""c0110"""">Davis, 1989[[ refid=''''b0110'''' ]]</ce:cross-ref>). Building upon the robustness of TAM, researchers expanded the model to TAM2, adding the impacts of three interrelated social forces on individuals’ adoption of a new technology (<ce:cross-ref refid=""""b0470"""" id=""""c0115"""">Venkatesh and Davis, 2000[[ refid=''''b0470'''' ]]</ce:cross-ref>). TAM2 incorporated subjective norm, voluntariness, and image with the original TAM. TAM2 takes into account the influence of social forces on the adoption decision. However, the three constructs in TAM2 act as moderating factors of perceived usefulness, or antecedents affecting perceived usefulness of a technology, not as direct determinants of the technology use. The united theory of acceptance and technology use (UTAUT), a variation of TAM, proposes social influences as direct determinants of technology adoption, but none of the social influence constructs are found significant in influencing technology use in voluntary contexts where individuals are not mandated to use the technology (<ce:cross-ref refid=""""b0475"""" id=""""c0120"""">Venkatesh et al., 2003[[ refid=''''b0475'''' ]]</ce:cross-ref>).</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Study 2: Classification of app reviews and apps by type of psychological needs involved	T.J. Strader, S.N. Ramaswami, P.A. Houle, Perceived network externalities and communication technology acceptance , Eur. J. Inf. Syst. , vol. 16 (2007), pp.54-65	http://dx.doi.org/10.1016/j.tele.2017.03.001			http://www.scar.disi.unibo.it/r/10-1016-j-tele-2017-03-001/br/b0315	http://www.scar.disi.unibo.it/r/10-1016-j-tele-2017-03-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-tele-2017-03-001/ctx/ctx0063		69	5	http://www.scar.disi.unibo.it/r/10-1016-j-tele-2017-03-001/itrp/0102	'Network externalities mean that users can get additional values as mobile IM user network expands (Strader et al., 2007[[ refid=''b0315'' ]]).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0215"""" view=""""all"""">The above analysis was based on the total mentions of the needs without adjusting for the number of downloads of the various apps. To analyze the data with app as the unit of analysis and to adjust the data by apps’ downloads (which were crawled from the Huawei App Store), we calculated the weighted average score <mml:math altimg=""""si1.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mrow><mml:mover accent=""""true""""><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy=""""true"""">‾</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:msubsup><mml:mrow><mml:mo>∑</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math>, where <ce:italic>i</ce:italic> is the type of needs, k is the serial number of the apps, and <ce:italic>P</ce:italic> is the proportion of reviews for a given type of needs and a given app calculated as <mml:math altimg=""""si2.gif"""" display=""""inline"""" overflow=""""scroll""""><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant=""""italic"""">ki</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mtext>The number of i th dimesion labeled reviews of Kth app</mml:mtext></mml:mrow><mml:mrow><mml:mtext>The total number of labeled reviews of Kth app</mml:mtext></mml:mrow></mml:mfrac></mml:mrow></mml:math>. As shown in <ce:cross-ref refid=""""t0015"""" id=""""c0350"""">Table 3</ce:cross-ref><ce:float-anchor refid=""""t0015""""/>, there were high adjusted proportions of utilitarian and hedonic needs. This time, social needs rose to the third highest category with 10.31%, followed by the need for low-cost at 7.11%. The increased frequencies of social needs as compared to the results in <ce:cross-ref refid=""""t0015"""" id=""""c0355"""">Table 3</ce:cross-ref> and <ce:cross-ref refid=""""f0005"""" id=""""c0360"""">Fig. 1</ce:cross-ref> meant that social mobile apps may produce significant network externalities as the number of users increases (<ce:cross-ref refid=""""b0190"""" id=""""c0365"""">Lin and Bhattacherjee, 2008[[ refid=''''b0190'''' ]]</ce:cross-ref>). Network externalities mean that users can get additional values as mobile IM user network expands (<ce:cross-ref refid=""""b0315"""" id=""""c0370"""">Strader et al., 2007[[ refid=''''b0315'''' ]]</ce:cross-ref>). A social mobile app with a high number of downloads will further attract more users. For example, the top two most downloaded apps (WeChat and QQ) are both social apps.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
cites	Methods	R.P. McDonald, M.R. Ho, Principles and practice in reporting structural equation analyses , Psychol. Methods , vol. 7 (2002), pp.64-82	http://dx.doi.org/10.1016/j.tele.2017.06.006	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-tele-2017-06-006/br/b0275>	<http://www.scar.disi.unibo.it/r/10-1016-j-tele-2017-06-006/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-tele-2017-06-006/ctx/ctx0071>				http://www.scar.disi.unibo.it/r/10-1016-j-tele-2017-06-006/itrp/0054	'Several studies, as reported by McDonald and Ho (2002)[[ refid=''b0275'' ]], indicated that unless extreme values of skewness and kurtosis are detected, the use of the Maximum Likelihood estimation generates robustness in the case of multivariate nonnormality and, hence, the parameter estimates maintain their validity.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
cites	Literature review	E.F. Gross, Adolescent Internet use: What we expect, what teens report? , Appl. Dev. Psychol. , vol. 25 (2004), pp.633-649	http://dx.doi.org/10.1016/j.tele.2017.06.006			<http://www.scar.disi.unibo.it/r/10-1016-j-tele-2017-06-006/br/b9010>	<http://www.scar.disi.unibo.it/r/10-1016-j-tele-2017-06-006/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-tele-2017-06-006/ctx/ctx0051>				http://www.scar.disi.unibo.it/r/10-1016-j-tele-2017-06-006/itrp/0093	'A study by Gross (2004)[[ refid=''b9010'' ]] reported that both genders were embracing the Internet as a means of communicating with their friends.'		<http://purl.org/spar/cito/usesMethodIn>		top100compsc
uses_method_in	Graph querying	M. Horridge, P. Patel-Schneider, Manchester syntax for OWL 1.1, in: Proceedings of the Second Workshop on Web Ontology Language (OWL) Experiences, Directions (OWLED’08), 2008, online.	http://dx.doi.org/10.1016/j.websem.2009.12.002			http://www.scar.disi.unibo.it/r/10-1016-j-websem-2009-12-002/br/bib28	http://www.scar.disi.unibo.it/r/10-1016-j-websem-2009-12-002/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-websem-2009-12-002/ctx/ctx0036		48	7	http://www.scar.disi.unibo.it/r/10-1016-j-websem-2009-12-002/itrp/0053	'All queries, like the descriptions in Section 4.3, are specified in Manchester Syntax [28][[ refid=''bib28'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""">We will demonstrate graph querying using a KB built with four line graphs out of the 96 in our original corpus (see <ce:cross-ref refid=""""fig4"""">Fig. 4</ce:cross-ref>). The results apply to the full KB without any intended loss of generality. All queries, like the descriptions in Section <ce:cross-ref refid=""""sec7"""">4.3</ce:cross-ref>, are specified in Manchester Syntax <ce:cross-ref refid=""""bib28"""">[28][[ refid=''''bib28'''' ]]</ce:cross-ref>. The Manchester OWL Syntax is a more intuitive syntax for OWL descriptions. We use the same typographical conventions discussed in <ce:cross-ref refid=""""sec5"""">4.1</ce:cross-ref>. The only new constructs we use here are the keywords “and”, and “that”, which denote the logical operator <ce:italic>and</ce:italic>, where both conjuncts have to be true for the condition to hold; “or”, which denotes the logical <ce:italic>inclusive or</ce:italic>, where just one or both disjuncts must be true for the condition to hold, and finally “some”, which stands for the <ce:italic>existence quantifier</ce:italic> (at least one). A simple example is <ce:sans-serif>Graph</ce:sans-serif> that <ce:bold> <ce:sans-serif>hasTitle</ce:sans-serif> </ce:bold> <ce:italic>some</ce:italic> <ce:sans-serif>Title</ce:sans-serif>, meaning “return all those graphs that have at least one title”. In order to make exposition clearer, however, we have slightly abused the notation of Manchester Syntax. However, in the interest of comprehensiveness, we have decided to include an appendix with the fully formalized queries, should the reader wish to execute them him/herself. </ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
uses_data_from	Experimental results and discussion	Consensus Workshop Track, OAEI 2006,	http://dx.doi.org/10.1016/j.websem.2010.01.001	discussion	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2010-01-001/br/bib33>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2010-01-001/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2010-01-001/ctx/ctx0046>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2010-01-001/itrp/0015	'The third dataset is composed of 45 pairs of real-world ontologies coming from the Consensus Workshop track [33][[ refid=''bib33'' ]] of the OAEI contest 2006 (pairs result from all combinations per two).'				100_classified_usesDataFrom
uses_data_from	Experimental results and discussion	Ontology Alignment Evaluation Initiative,	http://dx.doi.org/10.1016/j.websem.2010.01.001	discussion	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2010-01-001/br/bib31>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2010-01-001/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2010-01-001/ctx/ctx0043>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2010-01-001/itrp/0021	'The first dataset has been derived from the benchmarking series of the OAEI contest [31][[ refid=''bib31'' ]].'				100_classified_usesDataFrom
uses_data_from	Experiments	, None (None) , http://www.ertico.com/en/about_ertico/links/gdf_-_geographic_data_files.htm	http://dx.doi.org/10.1016/j.websem.2010.11.002	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2010-11-002/br/bib0105>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2010-11-002/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2010-11-002/ctx/ctx0057>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2010-11-002/itrp/0060	'The first dataset, which we dubbed the GIS Transportation Dataset, was created from instance data of the Road and Ferries package of a GIS data model known as GDF (Geographic Data Files) [21][[ refid=''bib0105'' ]].'				100_classified_usesDataFrom
uses_data_from	Experiment	S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, Z.G. Ives, Dbpedia: a nucleus for a web of open data, in: Aberer et al.	http://dx.doi.org/10.1016/j.websem.2011.08.002	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2011-08-002/br/b0015>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2011-08-002/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2011-08-002/ctx/ctx0016>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2011-08-002/itrp/0051	'Resources comprise RDF data from DBpedia [3][[ refid=''b0015'' ]] and documents from Wikipedia.'				100_classified_usesDataFrom
cites	Implementation	H. Wang, T. Penin, K. Xu, J. Chen, X. Sun, L. Fu, Q. Liu, Y. Yu, T. Tran, P. Haase, R. Studer, Hermes: a travel through semantics on the data web, in: SIGMOD Conference, 2009, pp. 1135–1138.	http://dx.doi.org/10.1016/j.websem.2011.08.004	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2011-08-004/br/b0210>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2011-08-004/sec/5>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2011-08-004/ctx/ctx0037>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2011-08-004/itrp/0039	'The Hermes system [42][[ refid=''b0210'' ]] targets semantic search in a multi-dataset scenario.'				100_classified_usesDataFrom
uses_data_from	Experimental corpus	Aidan Hogan, Andreas Harth, Jürgen Umbrich, Sheila Kinsella, Axel Polleres, Stefan Decker, Searching and browsing linked data with SWSE: the Semantic Web search engine , J. Web Sem. , vol. 9 (2011), pp.365-401	http://dx.doi.org/10.1016/j.websem.2011.11.002	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2011-11-002/br/b0160>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2011-11-002/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2011-11-002/ctx/ctx0032>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2011-11-002/itrp/0036	'In terms of diversity, the corpus consists of RDF from 783 pay-level-domains [32][[ refid=''b0160'' ]].'				100_classified_usesDataFrom
cites	Introduction	Christian Bizer, Jens Lehmann, Georgi Kobilarov, Sören Auer, Christian Becker, Richard Cyganiak, Sebastian Hellmann, DBpedia — a crystallization point for the web of data , J. Web Sem. , vol. 7 (2009), pp.154-165	http://dx.doi.org/10.1016/j.websem.2012.02.001	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2012-02-001/br/br000015>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2012-02-001/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2012-02-001/ctx/ctx0003>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2012-02-001/itrp/0014	'This resulted in rich datasets, most prominently the DBpedia [3][[ refid=''br000015'' ]] corpus extracted from semi-structured WikipediA articles.'				100_classified_usesDataFrom
cites	Background and related work	Gunnar Aastrand Grimnes, (still) Nothing Clever. Personal Weblog.	http://dx.doi.org/10.1016/j.websem.2012.02.001	related work	background	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2012-02-001/br/br000110>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2012-02-001/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2012-02-001/ctx/ctx0014>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2012-02-001/itrp/0196	'Most recently, Grimnes [22][[ refid=''br000110'' ]] provided a detailed analysis of the BTC-201010 dataset.'				100_classified_usesDataFrom
cites	Introduction	T. Heath, C. Bizer, Linked data: evolving the web into a global data space , Synthesis Lectures on the Semantic Web: Theory and Technology, Morgan & Claypool (2011)	http://dx.doi.org/10.1016/j.websem.2012.06.002	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2012-06-002/br/br000005>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2012-06-002/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2012-06-002/ctx/ctx0002>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2012-06-002/itrp/0013	'Data is provided by different, connected data sources using different publishing strategies like static RDF documents and SPARQL endpoints [1][[ refid=''br000005'' ]].'				100_classified_usesDataFrom
uses_data_from	Evaluation	S. Tejada, C. Knoblock, S. Minton, Learning object identification rules for information integration , Information Systems , vol. 26 (2001), pp.607-633	http://dx.doi.org/10.1016/j.websem.2013.06.001	results		<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2013-06-001/br/br000115>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2013-06-001/sec/8>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2013-06-001/ctx/ctx0029>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2013-06-001/itrp/0011	'The Restaurant data set [23][[ refid=''br000115'' ]] contains a set of records from the Fodor’s and Zagat’s restaurant guides.'				100_classified_usesDataFrom
uses_data_from	Experiments	J. Bhagat, F. Tanoh, E. Nzuobontane, T. Laurent, J. Orlowski, M. Roos, K. Wolstencroft, S. Aleksejevs, R. Stevens, S. Pettifer, R. Lopez, C.A. Globe, BioCatalogue: a universal catalogue of web services for the life sciences , Nucleic Acids Res. (2010)	http://dx.doi.org/10.1016/j.websem.2014.07.007	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2014-07-007/br/br000135>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2014-07-007/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2014-07-007/ctx/ctx0023>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2014-07-007/itrp/0003	'Thus, we have built up a dataset of 2260 web resources from BioCatalogue [27][[ refid=''br000135'' ]], which is a popular registry in the Life Sciences domain.'				100_classified_usesDataFrom
uses_data_from	Experiments	A.J. Jimeno-Yepes, B.T. McInnes, A.R. Aronson, Exploiting mesh indexing in medline to generate a data set for word sense disambiguation , BMC Bioinform. , vol. 12 (2011), pp.223	http://dx.doi.org/10.1016/j.websem.2014.07.007	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2014-07-007/br/br000110>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2014-07-007/sec/6>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2014-07-007/ctx/ctx0019>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2014-07-007/itrp/0050	'We use the MSH-WSD dataset [22][[ refid=''br000110'' ]] for evaluating this phase.'				100_classified_usesDataFrom
cites	Introduction	M. Lenzerini, Data integration: A theoretical perspective, in: Proc. of the 21st ACM SIGACT SIGMOD SIGART Symp. on Principles of Database Systems, PODS 2002, 2002, pp. 233–246.	http://dx.doi.org/10.1016/j.websem.2015.04.002	introduction		<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-04-002/br/br000010>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-04-002/sec/1>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-04-002/ctx/ctx0002>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-04-002/itrp/0008	'Like in data integration systems [2][[ refid=''br000010'' ]], the mapping is crucial for keeping the conceptual representation of the domain independent from the implementation issues, and for masking the user from all the details and the idiosyncrasies of the data sources.'				100_classified_usesDataFrom
cites	Experimental evaluation	P.J. Stone, D.C. Dunphy, M.S. Smith, D.M. Ogilvie, The General Inquirer: A Computer Approach to Content Analysis , None, MIT Press (1966)	http://dx.doi.org/10.1016/j.websem.2015.05.006	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-05-006/br/br000155>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-05-006/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-05-006/ctx/ctx0034>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-05-006/itrp/0050	'The second baseline, Harvard General Inquirer (INQ) [31][[ refid=''br000155'' ]], has words manually classified syntactically, semantically and grammatically.'				100_classified_usesDataFrom
uses_data_from	Experiments	J. Lehmann, Dl-learner: Learning concepts in description logics , J. Mach. Learn. Res. , vol. 10 (2009), pp.2639-2642	http://dx.doi.org/10.1016/j.websem.2015.08.002	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-08-002/br/br000185>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-08-002/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-08-002/ctx/ctx0049>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-08-002/itrp/0041	'For our next experiment we use the MUTAG dataset, which is distributed as an example dataset for the DL-Learner9 [37][[ refid=''br000185'' ]] toolkit.'				100_classified_usesDataFrom
uses_data_from	Experiments	V. de~Boer, J. Wielemaker, J. van Gent, M. Hildebrand, A. Isaac, J. van Ossenbruggen, G. Schreiber, Supporting linked data production for cultural heritage institutes: The amsterdam museum case study , The Semantic Web: Research and Applications, Springer Berlin Heidelberg , vol. vol. 7295 (2012), pp.733-747	http://dx.doi.org/10.1016/j.websem.2015.08.002	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-08-002/br/br000190>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-08-002/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-08-002/ctx/ctx0053>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-08-002/itrp/0057	'For our fifth classification experiment we use a dataset from the Amsterdam Museum [38][[ refid=''br000190'' ]], which contains information about around 70000 artifacts in the museum’s collection.'				100_classified_usesDataFrom
uses_data_from	Experiments	G.K.D. de~Vries, A fast approximation of the Weisfeiler-Lehman graph kernel for RDF data , ECML/PKDD (1), Springer (2013)	http://dx.doi.org/10.1016/j.websem.2015.08.002	methods		<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-08-002/br/br000045>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-08-002/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-08-002/ctx/ctx0050>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-08-002/itrp/0058	'For our third experiment we use a dataset from the British Geological Survey (BGS),10 as we did earlier in [9][[ refid=''br000045'' ]].'				100_classified_usesDataFrom
uses_data_from	Experimental evaluation	Billion Triples Challenge 2012.	http://dx.doi.org/10.1016/j.websem.2015.10.002	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-10-002/br/br000180>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-10-002/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-10-002/ctx/ctx0031>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-10-002/itrp/0052	'The sources were extracted from 8 online datasets, some referenced on the Billion Triples Challenge (BTC) 2012 Dataset webpage [36][[ refid=''br000180'' ]].'				100_classified_usesDataFrom
uses_data_from	Experimental evaluation	W. Van Woensel, Online Documentation.	http://dx.doi.org/10.1016/j.websem.2015.10.002	results	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-10-002/br/br000175>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-10-002/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-10-002/ctx/ctx0030>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-10-002/itrp/0053	'All resources related to the experiments, including dataset and queries, can be found on [35][[ refid=''br000175'' ]] (queries are also included in Appendix A).'				100_classified_usesDataFrom
uses_data_from	Domain-targeted phrase table augmentation	A. Miles, S. Bechhofer, SKOS simple knowledge organization system, W3c Recommendation, World Wide Web Consortium, 2009.	http://dx.doi.org/10.1016/j.websem.2015.12.001			<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-12-001/br/br000065>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-12-001/sec/3>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-12-001/ctx/ctx0014>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2015-12-001/itrp/0071	'In particular, the method exploits the Articles Categories dataset, which links Wikipedia titles to categories using the SKOS vocabulary [13][[ refid=''br000065'' ]].'				100_classified_usesDataFrom
cites	Building a live knowledge graph of connected things	Danh Le-Phuoc, Hoan~Quoc Nguyen-Mau, Josiane~Xavier Parreira, Manfred Hauswirth, A middleware framework for scalable management of linked streams , Web Semant.: Sci. Serv. Agents World Wide Web (2012)	http://dx.doi.org/10.1016/j.websem.2016.02.003			<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-02-003/br/br000020>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-02-003/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-02-003/ctx/ctx0007>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-02-003/itrp/0025	'In addition to NOAA, LSM sensor data sources [4][[ refid=''br000020'' ]] offer weather data of 60,000 places around the worlds via Web-based APIs from weather data providers.'				100_classified_usesDataFrom
uses_data_from	Applying CohEEL	Z. Zuo, G. Kasneci, T. Gruetze, F. Naumann, BEL: Bagging for entity linking, in: Proceedings of the International Conference on Computational Linguistics, COLING, 2014, pp. 2075–2086.	http://dx.doi.org/10.1016/j.websem.2016.03.001			<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-03-001/br/br000100>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-03-001/sec/4>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-03-001/ctx/ctx0038>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-03-001/itrp/0060	'The news article dataset contains 100 randomly picked Reuters articles from the CoNLL-YAGO dataset [20][[ refid=''br000100'' ]].'				100_classified_usesDataFrom
uses_data_from	Applications and experiments	E. Gabrilovich, M. Ringgaard, A. Subramanya, FACC1: Freebase annotation of ClueWeb corpora, version 1 (release date 2013-06-26, format version 1, correction level 0).	http://dx.doi.org/10.1016/j.websem.2016.03.004	motivation	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-03-004/br/br000325>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-03-004/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-03-004/ctx/ctx0048>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-03-004/itrp/0060	'We create a test dataset by randomly sampling 12k documents from the FACC1 corpus [65][[ refid=''br000325'' ]], a preprocessed version of the ClueWeb dataset where entity mentions have been linked to their corresponding Freebase identifiers.'				100_classified_usesDataFrom
uses_data_from	Applications and experiments	R. Parker, English Gigaword fifth edition, linguistic Data Consortium, Philadelphia, 2011.	http://dx.doi.org/10.1016/j.websem.2016.03.004	motivation	methods	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-03-004/br/br000310>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-03-004/sec/7>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-03-004/ctx/ctx0039>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-03-004/itrp/0087	'We used the Los Angeles Times/Washington Post (henceforth LTW) part of the English Gigaword v5 corpus [62][[ refid=''br000310'' ]].'				100_classified_usesDataFrom
cites_as_review	Setting the scope	P. Calado, M. Herschel, L. Leitão, An Overview of XML Duplicate Detection Algorithms, vol. 255, 2010, pp. 193–224.	http://dx.doi.org/10.1016/j.websem.2016.06.002			<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-06-002/br/br000070>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-06-002/sec/2>	<http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-06-002/ctx/ctx0005>				http://www.scar.disi.unibo.it/r/10-1016-j-websem-2016-06-002/itrp/0053	'The first approaches for instance matching for general Web of Data addressed the problem for XML data [14][[ refid=''br000070'' ]].'				100_classified_usesDataFrom
extends	Use case scenarios	A.-S. Dadzie, J. Domingue, Visual exploration of formal requirements for data science demand analysis, in: VOILA! 2015: Proc., International Workshop on Visualizations and User Interfaces for Ontologies and Linked Data, 2015, pp. 1–12.	http://dx.doi.org/10.1016/j.websem.2017.12.004	scenario		http://www.scar.disi.unibo.it/r/10-1016-j-websem-2017-12-004/br/b9	http://www.scar.disi.unibo.it/r/10-1016-j-websem-2017-12-004/sec/2	http://www.scar.disi.unibo.it/r/10-1016-j-websem-2017-12-004/ctx/ctx0005		69	10	http://www.scar.disi.unibo.it/r/10-1016-j-websem-2017-12-004/itrp/0054	'This paper extends the findings from this study [9[[ refid=''b9'' ]]] and reviews the initial requirements, to feed into the current exploratory and analytical stage.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""" id=""""p18"""">Our study methodology involves the exploration of skill demand and supply scenarios that consider the information-seeking and analysis requirements of the five target end user types identified in the early stages of the study [<ce:cross-ref refid=""""b9"""" id=""""d1e1576"""">9[[ refid=''''b9'''' ]]</ce:cross-ref>], the: <ce:list id=""""d1e1581""""><ce:list-item id=""""lst4""""><ce:label>(1)</ce:label><ce:para view=""""all"""" id=""""p19"""">policy- or decision-maker,</ce:para></ce:list-item><ce:list-item id=""""lst5""""><ce:label>(2)</ce:label><ce:para view=""""all"""" id=""""p20"""">educator or trainer,</ce:para></ce:list-item><ce:list-item id=""""lst6""""><ce:label>(3)</ce:label><ce:para view=""""all"""" id=""""p21"""">recruitment agent,</ce:para></ce:list-item><ce:list-item id=""""lst7""""><ce:label>(4)</ce:label><ce:para view=""""all"""" id=""""p22"""">practitioner and the trainee or (skilled) job seeker and</ce:para></ce:list-item><ce:list-item id=""""lst8""""><ce:label>(5)</ce:label><ce:para view=""""all"""" id=""""p23"""">the interested public.</ce:para></ce:list-item></ce:list>Based on the initial exploration of the requirements of our targets we created a task-based questionnaire that we use to guide our user-centred design (UCD) process, following an iterative cycle of design, development and evaluation. This paper extends the findings from this study [<ce:cross-ref refid=""""b9"""" id=""""d1e1608"""">9[[ refid=''''b9'''' ]]</ce:cross-ref>] and reviews the initial requirements, to feed into the current exploratory and analytical stage. We focus here on the <ce:italic>practitioner</ce:italic> and the <ce:italic>trainee/job seeker</ce:italic> aspiring to this role – technical end users with data science-oriented backgrounds, and also non-technical users with good knowledge of the requirements for working with big data. Where relevant and for completeness, we highlight where requirements and our findings overlap with those of the other user types, as we explore in depth the data, and in an iterative UCD cycle, design for user-focused exploration and analysis tasks in line with users’ interim and ultimate information seeking goals.</ce:para>""''"'	extends	ANG	
cites	The SME market failure argument and how public service providers address this issue	C. Sternitzke, A. Bartkowski, R. Schramm, Regional PATLIB centres as integrated one-stop service providers for intellectual property services , World Patent Information , vol. 29 (2007), pp.241-245	http://dx.doi.org/10.1016/j.wpi.2009.09.003			http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2009-09-003/br/bib11	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2009-09-003/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2009-09-003/ctx/ctx0010		29	6	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2009-09-003/itrp/0038	'Sternitzke [11][[ refid=''bib11'' ]] expands, among others, on the way the German PATON patent information centre, Ilmenau can handle IP support programmes (in that particular case, the German SIGNO programme which extends financial support to first-time SME patentees).'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" view=""""all"""">The ways publicly funded patent information services address SMEs with new offerings are manifold: Andrick <ce:cross-ref refid=""""bib10"""">[10][[ refid=''''bib10'''' ]]</ce:cross-ref> describes how the German patent information centre MIPO GmbH, Halle tries to help SMEs in using patent information databases and caters also for information requests that extend beyond the scope of patent information (e.g. questions about companies, literature and invitations to tender). Sternitzke <ce:cross-ref refid=""""bib11"""">[11][[ refid=''''bib11'''' ]]</ce:cross-ref> expands, among others, on the way the German PATON patent information centre, Ilmenau can handle IP support programmes (in that particular case, the German SIGNO programme which extends financial support to first-time SME patentees). From these sources, and also from the observations from the benchmarking study, it becomes clear that many public patent information service providers frequently try to enrich their portfolio of activities for SMEs through the provision of value-added search services, seminars and lecturing activities or by organising events with local patent attorneys (free initial consulting). </ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
extends	Acknowledgements	S. Vrochidis, Patent image retrieval based on concept extraction and classification , None, IRFS (2011)	http://dx.doi.org/10.1016/j.wpi.2012.07.002	acknowledgements		http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2012-07-002/br/bib33	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2012-07-002/sec/sec7	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2012-07-002/ctx/ctx0033		33	6	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2012-07-002/itrp/0027	'Parts of this work were presented in IRFS 2011 [33][[ refid=''bib33'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0340"""" view=""""all"""">This work was supported by the project PESCaDO (<ce:grant-number refid=""""gs1"""">FP7-248594</ce:grant-number>) funded by the <ce:grant-sponsor id=""""gs1"""" xlink:type=""""simple"""" xlink:role=""""http://www.elsevier.com/xml/linking-roles/grant-sponsor"""">European Commission</ce:grant-sponsor>. Parts of this work were presented in IRFS 2011 <ce:cross-ref refid=""""bib33"""">[33][[ refid=''''bib33'''' ]]</ce:cross-ref>. The authors would like to thank Dominic De Marco for his help defining the concepts for patent images and Panagiotis Sidiropoulos for providing the code for AHDH feature extraction.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_extends_semweb
uses_method_in	The building strategy and process of patent database	W. Yuanqi, F. Rongyang, Studies on algorithmic theories and result comparisons of cluster analysis , Journal of Zhanjiang Ocean University , vol. 22 (2002), pp.7	http://dx.doi.org/10.1016/j.wpi.2013.04.007	data		http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-04-007/br/bib17	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-04-007/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-04-007/ctx/ctx0017		17	3	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-04-007/itrp/0003	'In clustering analysis, we select the squared Euclidean distance [17][[ refid=''bib17'' ]] for measuring the distances of variables and between-groups linkage method for clustering groups.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0170"""" view=""""all"""">In clustering analysis, we select the squared Euclidean distance <ce:cross-ref refid=""""bib17"""" id=""""crosref0120"""">[17][[ refid=''''bib17'''' ]]</ce:cross-ref> for measuring the distances of variables and between-groups linkage method for clustering groups.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Horváth–Materne ranking, or pivot ranking	C. Denis, R. Menidjel, Patentability searching for biomaterial and related polymers , World Pat Inf , vol. 34 (01-12-2012), pp.284-291	http://dx.doi.org/10.1016/j.wpi.2013.09.003			http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-09-003/br/bib21	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-09-003/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-09-003/ctx/ctx0023		24	4	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-09-003/itrp/0002	'As an example, consider European publication EP1598090 described by C. Denis and R. Menidjel [21][[ refid=''bib21'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0695"""" view=""""all"""">As an example, consider European publication EP1598090 described by C. Denis and R. Menidjel <ce:cross-ref refid=""""bib21"""" id=""""crosref0235"""">[21][[ refid=''''bib21'''' ]]</ce:cross-ref>. Claim 1 of the application reads:</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Conclusions and future research directions	W.D. Yu, S.S. Lo, Patent analysis-based fuzzy inference system for technological strategy planning , Automat Constr , vol. 18 (2009), pp.770-776	http://dx.doi.org/10.1016/j.wpi.2013.12.006	conclusion		http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-12-006/br/bib25	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-12-006/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-12-006/ctx/ctx0078		78	4	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-12-006/itrp/0010	'It would be worthwhile for the managers if the approaches are made more efficient and flexible to offer multiple suggestions for devising strategies [25][[ refid=''bib25'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0255"""" view=""""all"""">Despite the fact that the techniques for patent analysis have become mature, there are areas that still need improvements. For instance, the tools using SAO based extraction techniques also extract certain irrelevant structures <ce:cross-ref refid=""""bib34"""" id=""""crosref0430"""">[34][[ refid=''''bib34'''' ]]</ce:cross-ref>. Therefore, the existing SAO based approaches need to be improved in a way that only the semantically relevant information is retrieved. Moreover, the hybrid approaches used for patent retrieval can also be utilized to search for the documents other than patents, such as journal articles <ce:cross-ref refid=""""bib3"""" id=""""crosref0435"""">[3][[ refid=''''bib3'''' ]]</ce:cross-ref>. Furthermore, the patent analysis approaches for strategic technology planning developed so far are capable of suggesting one strategy only. It would be worthwhile for the managers if the approaches are made more efficient and flexible to offer multiple suggestions for devising strategies <ce:cross-ref refid=""""bib25"""" id=""""crosref0440"""">[25][[ refid=''''bib25'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Conclusions and future research directions	C. Sungchul, H. Kim, J. Yoon, K. Kim, J.Y. Lee, An SAO-based text-mining approach for technology roadmapping using patent information , R&D Manag , vol. 43 (2013), pp.52-74	http://dx.doi.org/10.1016/j.wpi.2013.12.006	conclusion		http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-12-006/br/bib34	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-12-006/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-12-006/ctx/ctx0076		78	4	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-12-006/itrp/0033	'For instance, the tools using SAO based extraction techniques also extract certain irrelevant structures [34][[ refid=''bib34'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0255"""" view=""""all"""">Despite the fact that the techniques for patent analysis have become mature, there are areas that still need improvements. For instance, the tools using SAO based extraction techniques also extract certain irrelevant structures <ce:cross-ref refid=""""bib34"""" id=""""crosref0430"""">[34][[ refid=''''bib34'''' ]]</ce:cross-ref>. Therefore, the existing SAO based approaches need to be improved in a way that only the semantically relevant information is retrieved. Moreover, the hybrid approaches used for patent retrieval can also be utilized to search for the documents other than patents, such as journal articles <ce:cross-ref refid=""""bib3"""" id=""""crosref0435"""">[3][[ refid=''''bib3'''' ]]</ce:cross-ref>. Furthermore, the patent analysis approaches for strategic technology planning developed so far are capable of suggesting one strategy only. It would be worthwhile for the managers if the approaches are made more efficient and flexible to offer multiple suggestions for devising strategies <ce:cross-ref refid=""""bib25"""" id=""""crosref0440"""">[25][[ refid=''''bib25'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
uses_method_in	Patent analysis techniques	H. Park, J. Yoon, K. Kim, Identifying patent infringement using SAO based semantic technological similarities , Scientometrics , vol. 90 (2012), pp.515-529	http://dx.doi.org/10.1016/j.wpi.2013.12.006	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-12-006/br/bib33	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-12-006/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-12-006/ctx/ctx0039		78	4	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2013-12-006/itrp/0061	'The SAO structures are extracted directly from the patent documents [33][[ refid=''bib33'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0110"""" view=""""all"""">The NLP is a text mining approach that uses computational mechanisms to analyze and represent the textual information present in electronic documents. In patent analysis, the NLP has also been used for the transformation of the technological information into simple language structures by extracting the grammatical structures from the textual data and creating the structural relationships among the components <ce:cross-ref refid=""""bib52"""" id=""""crosref0215"""">[52][[ refid=''''bib52'''' ]]</ce:cross-ref>. The NLP based text mining approaches are broadly categorized into: (a) keyword based approaches and (b) Subject–Action–Object (SAO) based approaches <ce:cross-ref refid=""""bib22"""" id=""""crosref0220"""">[22][[ refid=''''bib22'''' ]]</ce:cross-ref>. Although keyword based text mining approaches are simple to implement, they lack in representation of important technological concepts and relationships. The keyword based approach involves predefining keywords and key phrases that require expert knowledge. On the other hand, the SAO based text mining techniques are capable of analyzing unstructured information by representing the relationships among key technological components <ce:cross-ref refid=""""bib43"""" id=""""crosref0225"""">[43][[ refid=''''bib43'''' ]]</ce:cross-ref>. The patent documents are transformed into SAO structures and each structure consists of a Subject (S), Action (A), and Object (O). Unlike keyword based approaches that rely on keyword vectors composed of frequency of occurrences <ce:cross-ref refid=""""bib22"""" id=""""crosref0230"""">[22][[ refid=''''bib22'''' ]]</ce:cross-ref>. The SAO structures are extracted directly from the patent documents <ce:cross-ref refid=""""bib33"""" id=""""crosref0235"""">[33][[ refid=''''bib33'''' ]]</ce:cross-ref>. The SAO structures allow the representation of the concepts in the format of problem-solution and are usually based on TRIZ <ce:cross-ref refid=""""bib34"""" id=""""crosref0240"""">[34][[ refid=''''bib34'''' ]]</ce:cross-ref>. However, the NLP based approaches suffer from the issues of lexical and grammatical ambiguities and also lack in representing the semantic relationships among the grammatical structures. Despite their limitations, the NLP based approaches have proved extremely effective in processing large documents containing huge volumes of textual data. The keyword based and the SAO based approaches are presented below.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites	Discussion	P. Vakkari, N. Hakala, Changes in relevance criteria and problem stages in task performance , J Doc , vol. 56 (2000), pp.540-562	http://dx.doi.org/10.1016/j.wpi.2014.08.001	discussion		http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2014-08-001/br/bib34	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2014-08-001/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2014-08-001/ctx/ctx0025		27	5	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2014-08-001/itrp/0012	'For example we know that users at the beginning of their tasks, are less likely to start their initial queries by introducing all the search terms [34][[ refid=''bib34'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0240"""" view=""""all"""">For example a search for prior art should retrieve the best available prior art documents and must be done efficiently. Another task is when confronting the claims of a patent. Criteria for selecting which patent resources to search and which technical tools to use must be established. But it is not only where and what to search. A strategy for carrying out the search has to be also established <ce:cross-ref refid=""""bib30"""" id=""""crosref0145"""">[30][[ refid=''''bib30'''' ]]</ce:cross-ref>. But not only that, we know from different studies of search models that the search strategy, the current state of searcher''''s knowledge, the process and the criteria should be continuously revised and updated <ce:cross-refs refid=""""bib31 bib32 bib33"""" id=""""crosrefs0050"""">[31–33][[ refid=''''bib31 bib32 bib33'''' ]]</ce:cross-refs>. For example we know that users at the beginning of their tasks, are less likely to start their initial queries by introducing all the search terms <ce:cross-ref refid=""""bib34"""" id=""""crosref0150"""">[34][[ refid=''''bib34'''' ]]</ce:cross-ref>.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
cites_as_review	Summary and future work	D. Bonino, A. Ciaramella, F. Corno, Review of the state of the art and forthcoming evolutions in intelligent patent informatics , World Patent Information , vol. 32 (2010), pp.30-38	http://dx.doi.org/10.1016/j.wpi.2014.10.003	conclusion		http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2014-10-003/br/bib3	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2014-10-003/sec/5	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2014-10-003/ctx/ctx0022		22	5	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2014-10-003/itrp/0001	'Their use increases the efficiency and accuracy of nearly all common applications in the patent domain [3][[ refid=''bib3'' ]], including analysis of a single patent or a set of patents, landscaping of a patent set, and patent search.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0480"""" view=""""all"""">In this article, we presented advanced techniques for patent analysis and summarization that form part of the TOPAS workbench. Each of these techniques addresses a need of IP professionals and constitutes a contribution to the state of the art in the field of patent document processing. Their use increases the efficiency and accuracy of nearly all common applications in the patent domain <ce:cross-ref refid=""""bib3"""" id=""""crosref0320"""">[3][[ refid=''''bib3'''' ]]</ce:cross-ref>, including analysis of a single patent or a set of patents, landscaping of a patent set, and patent search. In particular, single patent analysis benefits from TOPAS technologies – for instance, for more efficient navigation in a patent or for identification of specific entities (e.g., substances, processes, and measurements) and their distribution in the patent. <ce:cross-ref refid=""""fig3"""" id=""""crosref0325"""">Figure 3</ce:cross-ref><ce:float-anchor refid=""""fig3""""/> shows a pdf-interface that supports entity type-specific visualization in different sections of the document.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
uses_method_in	Patent summarization	H. Saggion, SUMMA: A robust and Adaptable summarization tool , Trait Autom Des Langues , vol. 49 (2008), pp.None	http://dx.doi.org/10.1016/j.wpi.2014.10.003			http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2014-10-003/br/bib25	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2014-10-003/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2014-10-003/ctx/ctx0018		22	5	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2014-10-003/itrp/0015	'To support feature computation and combination in GATE (see Section 2), we make use of the SUMMA summarization library [25][[ refid=''bib25'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0330"""" view=""""all"""">The summarization in TOPAS combines the two techniques known for summarization, extractive and abstractive summarization; see <ce:cross-ref refid=""""bib26"""" id=""""crosref0265"""">[26][[ refid=''''bib26'''' ]]</ce:cross-ref> for an overview. Extractive summarization is surface-oriented in that it applies relevance metrics usually based on distribution heuristics to select relevant linguistic constructions (as a rule, entire sentences) for inclusion into the summary. In contrast, abstractive summarization selects summary-relevant content elements and assembles them using linguistic aggregation or natural language text generation techniques into a coherent summary. Abstractive summarization thus requires a robust semantic analysis. Such an analysis is beyond the state of the art for generic discourse, let alone for patent material. On the other side, the selection of entire sentences from a patent (and, in particular, of claim sentences) is not appropriate either. Therefore, the TOPAS summarization first selects segments from a patent based on a patent-specific relevance metric and then aggregates the selected segments into one coherent and cohesive summary using deep linguistic techniques. The relevance metric incorporates a combination of a number of weighted segment features. To support feature computation and combination in GATE (see Section <ce:cross-ref refid=""""sec2"""" id=""""crosref0270"""">2</ce:cross-ref>), we make use of the SUMMA summarization library <ce:cross-ref refid=""""bib25"""" id=""""crosref0275"""">[25][[ refid=''''bib25'''' ]]</ce:cross-ref>. Given that the features are combined in a linear formula, we optimize the weights by training on human annotated data.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
uses_method_in	Extracting lexical databases	K. De Vorsey, C. Elson, N. Gregorev, J. Hansen, The Development of a local thesaurus to improve access to the anthropological collections of the American Museum of Natural History , D-Lib Magaz , vol. 12 (2006), pp.None	http://dx.doi.org/10.1016/j.wpi.2015.02.005	data		http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2015-02-005/br/bib29	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2015-02-005/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2015-02-005/ctx/ctx0020		24	4	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2015-02-005/itrp/0004	'To query the lexical databases we use the open source thesaurus management software TheW32 [29][[ refid=''bib29'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0105"""" view=""""all"""">The lexical databases provide English keyword phrases for each specific patent class. Terms which in combination constitute a keyword phrase are linked to each other. To query the lexical databases we use the open source thesaurus management software <ce:italic>TheW32</ce:italic> <ce:cross-ref refid=""""bib29"""" id=""""crosref0120"""">[29][[ refid=''''bib29'''' ]]</ce:cross-ref>. The resulting lexical resources can be used, particularly in each specific US patent class, for (semi-) automated query suggestion, particularly for query scope limitation. For example, the query term “control” can be expanded using the domain specific lexical databases to limit the query scope as shown in <ce:cross-refs refid=""""fig2 fig3"""" id=""""crosrefs0060"""">Figs. 2 and 3</ce:cross-refs><ce:float-anchor refid=""""fig2""""/><ce:float-anchor refid=""""fig3""""/>.</ce:para>""''"'	uses_data_from	AGA+ANG	tba_50_classified_usesMethodIn_semweb
uses_method_in	Data processing for visualization in PatStream	H. Saggion, SUMMA: a robust and adaptable summarization tool , Trait. Autom. Des. Langues , vol. 49 (2008), pp.103-125	http://dx.doi.org/10.1016/j.wpi.2017.04.003	data		http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2017-04-003/br/bib31	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2017-04-003/sec/3	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2017-04-003/ctx/ctx0020		27	4	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2017-04-003/itrp/0003	'To compute the score, we use a series of features, similar to those used in state-of-the-art extractive summarization (see, e.g. [31][[ refid=''bib31'' ]]), but adapted to patent material.'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0140"""" view=""""all"""">The similarity between pairs of patents is measured using the cosine metric. For this purpose, a patent is represented as a weighted multidimensional concept vector. Each concept, i.e., term of each concept, encountered in a given patent collection is assigned a dimension in the vector.<ce:cross-ref refid=""""fn2"""" id=""""crosref0185""""><ce:sup loc=""""post"""">2</ce:sup></ce:cross-ref> The score of a concept dimension in the vector of a patent reflects its relevance to this patent. To compute the score, we use a series of features, similar to those used in state-of-the-art extractive summarization (see, e.g. <ce:cross-ref refid=""""bib31"""" id=""""crosref0190"""">[31][[ refid=''''bib31'''' ]]</ce:cross-ref>), but adapted to patent material. In particular, we use: (1) term score <ce:italic>ts</ce:italic> (the ratio between the relative frequency of the term in the given patent collection and its relative frequency in a general discourse reference corpus); (2) frequency of the term in the patent <ce:italic>tf</ce:italic> (the number of mentions of this term in the patent), (3) title score <ce:italic>tls</ce:italic> (the presence of the term in the title), (4) abstract score <ce:italic>as</ce:italic> (normalized position of the term in the abstract), (5) claims score <ce:italic>cls</ce:italic> (the highest score of any mention of the term in the claims section, with the score calculated as the normalized product of the position of the mention in the claim in which it occurs and the depth of this claim in the claim dependency tree); and (6) description score <ce:italic>ds</ce:italic> (the highest score of any mention of the term in the description section, with the score calculated as the normalized product of the position of the mention in the sentence in which it occurs and the position of this sentence in the description).</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
uses_method_in	PatStream in a nutshell	F. Heimerl, S. Lohmann, S. Lange, T. Ertl, Word cloud explorer: text analytics based on word clouds , Proc. HICSS, IEEE CS (2014)	http://dx.doi.org/10.1016/j.wpi.2017.04.003			http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2017-04-003/br/bib33	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2017-04-003/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2017-04-003/ctx/ctx0024		27	4	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2017-04-003/itrp/0006	'Using the strategy described in Section 3.3, we extract the most important concepts for each time slice in the stream and display them as word clouds [33][[ refid=''bib33'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0180"""" view=""""all"""">For depicting the structure and evolution of topics in the patent collection, a streamgraph visualization is used. In streamgraphs, topics are represented as horizontal streams, which are placed one on top of the other. In PatStream, the streams are further broken down into vertical time slices, which we call <ce:italic>blocks</ce:italic> and which represent periods of years. Using the strategy described in Section <ce:cross-ref refid=""""sec3.3"""" id=""""crosref0255"""">3.3</ce:cross-ref>, we extract the most important concepts for each time slice in the stream and display them as word clouds <ce:cross-ref refid=""""bib33"""" id=""""crosref0260"""">[33][[ refid=''''bib33'''' ]]</ce:cross-ref>. In case a block is too small to contain enough concepts for its interpretation, users can mouse over it to activate a tool tip with a larger word cloud that contains additional concepts. Mousing over a stream will visually highlight it by fading all other streams, making it easy to follow a stream along the timeline. When a block is selected by a mouse click, it is extended to its right within the stream graph panel and attached to the IPC tree panel (<ce:cross-ref refid=""""fig1"""" id=""""crosref0265"""">Fig. 1</ce:cross-ref>f); see also Section <ce:cross-ref refid=""""sec4.2"""" id=""""crosref0270"""">4.2</ce:cross-ref> below. The selection of a block automatically updates the content of all other panels via brushing and linking to show additional important aspects of it.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
uses_method_in	PatStream in a nutshell	F. Heimerl, Q. Han, S. Koch, T. Ertl, CiteRivers: visual analytics of citation patterns , IEEE TVCG , vol. 22 (2016), pp.190-199	http://dx.doi.org/10.1016/j.wpi.2017.04.003			http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2017-04-003/br/bib5	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2017-04-003/sec/4	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2017-04-003/ctx/ctx0028		27	4	http://www.scar.disi.unibo.it/r/10-1016-j-wpi-2017-04-003/itrp/0008	'It is computed by comparing all patents in the past of a given patent to all follow up (“future”) patents [5][[ refid=''bib5'' ]].'	'"''""<ce:para xmlns:ce=""""http://www.elsevier.com/xml/common/schema"""" xmlns:doc=""""http://www.elsevier.com/xml/document/schema"""" xmlns:dp=""""http://www.elsevier.com/xml/common/doc-properties/schema"""" xmlns:cps=""""http://www.elsevier.com/xml/common/consyn-properties/schema"""" xmlns:rdf=""""http://www.w3.org/1999/02/22-rdf-syntax-ns#"""" xmlns:dct=""""http://purl.org/dc/terms/"""" xmlns:prism=""""http://prismstandard.org/namespaces/basic/2.0/"""" xmlns:oa=""""http://vtw.elsevier.com/data/ns/properties/OpenAccess-1/"""" xmlns:cp=""""http://vtw.elsevier.com/data/ns/properties/Copyright-1/"""" xmlns:cja=""""http://www.elsevier.com/xml/cja/schema"""" xmlns:ja=""""http://www.elsevier.com/xml/ja/schema"""" xmlns:bk=""""http://www.elsevier.com/xml/bk/schema"""" xmlns:mml=""""http://www.w3.org/1998/Math/MathML"""" xmlns:cals=""""http://www.elsevier.com/xml/common/cals/schema"""" xmlns:tb=""""http://www.elsevier.com/xml/common/table/schema"""" xmlns:sa=""""http://www.elsevier.com/xml/common/struct-aff/schema"""" xmlns:sb=""""http://www.elsevier.com/xml/common/struct-bib/schema"""" xmlns:xlink=""""http://www.w3.org/1999/xlink"""" id=""""p0245"""" view=""""all"""">The two dimensions in the scatter plot are the citation count and the innovation score. The citation count is the number of citations to a particular patent. The innovation score measures the innovation and impact of a patent based on its content. It is computed by comparing all patents in the past of a given patent to all follow up (“future”) patents <ce:cross-ref refid=""""bib5"""" id=""""crosref0370"""">[5][[ refid=''''bib5'''' ]]</ce:cross-ref>. The more similar a document is to its future and the less similar it is to its past, the higher its innovation score.<ce:cross-ref refid=""""fn3"""" id=""""crosref0375""""><ce:sup loc=""""post"""">3</ce:sup></ce:cross-ref> The innovation score thus increases the rating for patents that contain concepts also occurring in more recent patents. In combination with the citation count, it gives a more complete and accurate account of the acceptance of a patent than the citation count alone. Patents that appear in the lower left part of the scatter plot have rare forward citations and a low innovation score. In contrast, highly cited and innovative patents are positioned in the upper right part.</ce:para>""''"'	cites	AGA+ANG	tba_50_classified_usesMethodIn_semweb
